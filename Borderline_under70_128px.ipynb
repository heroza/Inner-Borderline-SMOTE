{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/heroza/Inner-Borderline-SMOTE/blob/main/Borderline_under70_128px.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Eus_4tUgfEk9",
        "outputId": "0afa2754-4e66-44bd-ff1b-7a62090f0d16"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E_x4c0_DTkaa"
      },
      "source": [
        "#Library, atribut, and function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "nR2MJBYq-oiB"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import os\n",
        "from collections import Counter\n",
        "from pathlib import Path\n",
        "from PIL import Image\n",
        "from sklearn import preprocessing\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "from sklearn.metrics import precision_recall_fscore_support, balanced_accuracy_score, confusion_matrix, accuracy_score\n",
        "from keras.callbacks import ReduceLROnPlateau, EarlyStopping, ModelCheckpoint\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D, UpSampling2D\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.optimizers import Adam, SGD\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input, decode_predictions\n",
        "from tensorflow.keras.applications.inception_v3 import InceptionV3, preprocess_input\n",
        "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Input, Dropout, Flatten\n",
        "from tensorflow.keras.models import Model, load_model\n",
        "from keras.utils.np_utils import to_categorical\n",
        "import imblearn\n",
        "from imblearn.over_sampling import SMOTE, BorderlineSMOTE, SVMSMOTE, ADASYN, KMeansSMOTE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "9-c7Xghg4SB4"
      },
      "outputs": [],
      "source": [
        "# input image size\n",
        "IMAGE_W = 128\n",
        "IMAGE_H = 128\n",
        "IMG_SIZE = (IMAGE_W,IMAGE_H)\n",
        "num_classes = 7\n",
        "EPOCHS = 50\n",
        "BATCH_SIZE = 64\n",
        "opt_adam = Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
        "opt_SGD = SGD(learning_rate=0.001)\n",
        "the_arch = 'resnet50'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "JffFid9sOXeo"
      },
      "outputs": [],
      "source": [
        "# load train and test dataset\n",
        "def preprocess_image_input(input_images, arch = the_arch):\n",
        "  input_images = input_images.astype('float32')\n",
        "  if arch == 'inception_v3':\n",
        "    output_ims = tf.keras.applications.inception_v3.preprocess_input(input_images)\n",
        "  else:\n",
        "    output_ims = tf.keras.applications.resnet50.preprocess_input(input_images)\n",
        "  return output_ims\n",
        "\n",
        "def load_cifar10_dataset():\n",
        "  from keras.datasets import cifar10\n",
        "    # load dataset\n",
        "  (X_train, y_train), (X_val, y_val) = cifar10.load_data()\n",
        "    # one hot encode target values\n",
        "  y_train = to_categorical(y_train)\n",
        "  y_val = to_categorical(y_val)\n",
        "\n",
        "  return X_train, y_train, X_val, y_val\n",
        "\n",
        "def true_positive(l1,l2):\n",
        "  tp = 0\n",
        "  for i in range(len(l1)):\n",
        "    tp = tf.cond(l1[i]==l2[i]==1, lambda: tp+1)\n",
        "  return tp\n",
        "\n",
        "def true_negative(l1,l2):\n",
        "  tn = 0\n",
        "  for i in range(len(l1)):\n",
        "    tn = tf.cond(l1[i]==l2[i]==0, lambda: tn+1)\n",
        "  return tn\n",
        "\n",
        "def false_positive(l1,l2):\n",
        "  fp = 0\n",
        "  for i in range(len(l1)):\n",
        "    fp = tf.cond(l1[i] != l2[i] and l2[i]==1, lambda: fp+1)\n",
        "  return fp\n",
        "\n",
        "def false_negative(l1,l2):\n",
        "  fn = 0\n",
        "  for i in range(len(l1)):\n",
        "    fn = tf.cond(l1[i] != l2[i] and l2[i] == 0, lambda: fn+1)\n",
        "  return fn\n",
        "\n",
        "def balanced_acc(y_true,y_pred):\n",
        "    from keras import backend as K\n",
        "    tensor1 = tf.math.argmax(y_true, axis=1)\n",
        "    tensor2 = tf.math.argmax(y_pred, axis=1)\n",
        "    cm = tf.math.confusion_matrix(tensor1, tensor2)\n",
        "    diag = tf.linalg.tensor_diag_part (cm)\n",
        "    tpfn = tf.cast(K.sum(cm, axis = 1), tf.float32) + K.epsilon()\n",
        "    recall = tf.divide(tf.cast(diag, tf.float32),tpfn)\n",
        "    balanced_acc = K.mean(recall)\n",
        "    balanced_acc = K.mean(balanced_acc)\n",
        "\n",
        "    return balanced_acc\n",
        "\n",
        "def define_base_model(arch = the_arch, start_trainable_layer = 9999, attention=False):\n",
        "  #x = data_augmentation(input_tensor)\n",
        "  #x = layers.Rescaling(1.0 / 255)(input_tensor)  # Rescale inputs\n",
        "  if arch != 'dense':\n",
        "    input_tensor = Input(shape=(IMAGE_H, IMAGE_W, 3))\n",
        "    #x = UpSampling2D(size=(7,7))(input_tensor)\n",
        "    if arch == 'resnet50':\n",
        "      base_model = ResNet50(input_tensor=input_tensor, weights='imagenet', include_top=False)\n",
        "    elif arch == 'inception_v3':\n",
        "      base_model = InceptionV3(input_tensor=input_tensor, weights='imagenet', include_top=False)\n",
        "    elif arch == 'ResNet':\n",
        "      base_model = ResNet(classes ,image_shape)(input_tensor)\n",
        "    \n",
        "    for layer in base_model.layers:\n",
        "      layer.trainable = False\n",
        "    if start_trainable_layer != 9999:\n",
        "      for layer in base_model.layers[start_trainable_layer:]:\n",
        "        layer.trainable = True\n",
        "    \n",
        "    x = base_model.output\n",
        "    if attention:\n",
        "      x = Attention(1024,1024,7,8)(x)\n",
        "    \n",
        "    x = GlobalAveragePooling2D()(x)\n",
        "    x = Flatten()(x)\n",
        "  else:\n",
        "    input_tensor = Input(shape=(2048))\n",
        "    x = input_tensor\n",
        "  #x = Flatten()(x)\n",
        "  x = Dense(1024, activation='relu')(x)\n",
        "  #x = Dropout(0.2)(x)\n",
        "  x = Dense(512, activation='relu')(x)\n",
        "  predictions = Dense(num_classes, activation='softmax')(x)\n",
        "  model = Model(inputs=input_tensor, outputs=predictions)\n",
        "  model.compile(optimizer = opt_SGD , loss = \"categorical_crossentropy\", metrics=['accuracy', balanced_acc])\n",
        "  return model\n",
        "\n",
        "def define_model_resnet():\n",
        "  input_shape = (IMAGE_H, IMAGE_W, 3)\n",
        "  input_tensor = Input(shape=input_shape)\n",
        "  x = ResNet50(input_shape=input_shape, weights='imagenet', include_top=False)(input_tensor, training=False)\n",
        "  x = GlobalAveragePooling2D()(x)\n",
        "  x = Flatten()(x)\n",
        "  x = Dense(1024, activation='relu')(x)\n",
        "  x = Dense(512, activation='relu')(x)\n",
        "  predictions = Dense(num_classes, activation='softmax')(x)\n",
        "  model = Model(inputs=input_tensor, outputs=predictions)\n",
        "  model.compile(optimizer = opt_SGD , loss = \"categorical_crossentropy\", metrics=['accuracy', balanced_acc])\n",
        "  return model\n",
        "\n",
        "# plot diagnostic learning curves\n",
        "def summarize_diagnostics(history):\n",
        "    # plot loss\n",
        "    plt.subplot(211)\n",
        "    plt.title('Cross Entropy Loss')\n",
        "    plt.plot(history.history['loss'], color='blue', label='train')\n",
        "    plt.plot(history.history['val_loss'], color='orange', label='test')\n",
        "    # plot accuracy\n",
        "    plt.subplot(212)\n",
        "    plt.title('Classification Accuracy')\n",
        "    plt.plot(history.history['accuracy'], color='blue', label='train')\n",
        "    plt.plot(history.history['val_accuracy'], color='orange', label='test')\n",
        " \n",
        "# scale pixels\n",
        "def norm_pixels(train, test):\n",
        "    # convert from integers to floats\n",
        "    train_norm = train.astype('float32')\n",
        "    test_norm = test.astype('float32')\n",
        "    # normalize to range 0-1\n",
        "    train_norm = train_norm / 255.0\n",
        "    test_norm = test_norm / 255.0\n",
        "    # return normalized images\n",
        "    return train_norm, test_norm\n",
        "\n",
        "def load_isic2018_dataset(train_under_frac = 0):\n",
        "  df_train = pd.read_csv('/content/drive/MyDrive/PHD/Datasets/isic2018/ISIC2018_Task3_Training_GroundTruth/ISIC2018_Task3_Training_GroundTruth.csv') \n",
        "  df_val = pd.read_csv('/content/drive/MyDrive/PHD/Datasets/isic2018/ISIC2018_Task3_Validation_GroundTruth/ISIC2018_Task3_Validation_GroundTruth.csv') \n",
        "\n",
        "  #decode one hot label\n",
        "  df_train[\"Labels\"] = (df_train.iloc[:, 1:]).idxmax(axis=1)\n",
        "  df_val[\"Labels\"] = (df_val.iloc[:, 1:]).idxmax(axis=1)\n",
        "\n",
        "  #random undersampling for training dataset\n",
        "  if train_under_frac !=0:\n",
        "    df_train = df_train.drop(df_train[df_train['Labels'] == 'NV'].sample(frac=train_under_frac).index)\n",
        "\n",
        "  #drop one-hot column\n",
        "  df_train = df_train.drop(columns=['MEL', 'NV', 'BCC', 'AKIEC', 'BKL', 'DF', 'VASC'])\n",
        "  df_val = df_val.drop(columns=['MEL', 'NV', 'BCC', 'AKIEC', 'BKL', 'DF', 'VASC'])\n",
        "\n",
        "  #make filepaths of the image\n",
        "  dir_train = '/content/drive/MyDrive/PHD/Datasets/isic2018/ISIC2018_Task3_Training_Input/'\n",
        "  dir_val = '/content/drive/MyDrive/PHD/Datasets/isic2018/ISIC2018_Task3_Validation_Input/'\n",
        "  df_train['FilePaths'] = dir_train + df_train['image'] + '.jpg'\n",
        "  df_val['FilePaths'] = dir_val + df_val['image'] + '.jpg'\n",
        "  \n",
        "  #load image pixels to dataframe\n",
        "  df_train['image_px'] = df_train['FilePaths'].map(lambda x: np.asarray(Image.open(x).resize(IMG_SIZE)))\n",
        "  df_val['image_px'] = df_val['FilePaths'].map(lambda x: np.asarray(Image.open(x).resize(IMG_SIZE)))\n",
        "\n",
        "  X_train = np.asarray(df_train['image_px'].tolist())\n",
        "  X_val = np.asarray(df_val['image_px'].tolist())\n",
        "  y_train = np.array(df_train['Labels'].values)\n",
        "  y_val = np.array(df_val['Labels'].values)\n",
        "\n",
        "  label_encoder = preprocessing.LabelEncoder()\n",
        "  y_train = label_encoder.fit_transform(y_train)\n",
        "  y_val = label_encoder.fit_transform(y_val)\n",
        "  \n",
        "  y_train = to_categorical(y_train, num_classes = num_classes)\n",
        "  y_val = to_categorical(y_val, num_classes = num_classes)\n",
        "\n",
        "  return X_train, y_train, X_val, y_val\n",
        "\n",
        "def reset_dataset(df_train, df_val):\n",
        "  X_train = np.asarray(df_train['image_px'].tolist())\n",
        "  X_val = np.asarray(df_val['image_px'].tolist())\n",
        "  y_train = np.array(df_train['Labels'].values)\n",
        "  y_val = np.array(df_val['Labels'].values)\n",
        "\n",
        "  X_train = preprocess_image_input(X_train, the_arch)\n",
        "  X_val = preprocess_image_input(X_val, the_arch)\n",
        "\n",
        "  label_encoder = preprocessing.LabelEncoder()\n",
        "  y_train = label_encoder.fit_transform(y_train)\n",
        "  y_val = label_encoder.fit_transform(y_val)\n",
        "  \n",
        "  y_train = to_categorical(y_train, num_classes = num_classes)\n",
        "  y_val = to_categorical(y_val, num_classes = num_classes)\n",
        "  return X_train, y_train, X_val, y_val\n",
        "\n",
        "def SMOTE_Data(X, y, one_hot = False, k = 5, width = IMAGE_W, height = IMAGE_H, c = 3, type = 'smote'):\n",
        "  if one_hot:\n",
        "    y = np.argmax(y, axis=1)\n",
        "  if type == 'borderline':\n",
        "    sm = BorderlineSMOTE(random_state=42, k_neighbors=k)\n",
        "  elif type == 'svm':\n",
        "    sm = SVMSMOTE()\n",
        "  elif type == 'adasyn':\n",
        "    sm = ADASYN(random_state=42, n_neighbors=k)\n",
        "  elif type == 'kmeans':\n",
        "    sm = KMeansSMOTE(k_neighbors=k, kmeans_estimator=10)\n",
        "  else:\n",
        "    sm = SMOTE(random_state=42, k_neighbors=k)\n",
        "  X_resampled, y_resampled = sm.fit_resample(X.reshape((-1, width * height * c)), y)\n",
        "  X_resampled = X_resampled.reshape(-1, width, height, c)\n",
        "  if one_hot:\n",
        "    y_resampled = to_categorical(y_resampled, num_classes = num_classes)\n",
        "  else:\n",
        "    y_resampled = y_resampled.reshape(-1,1)\n",
        "  return X_resampled, y_resampled\n",
        "\n",
        "def SMOTE_Data2(X, y, one_hot = False, k = 5, type = 'smote'):\n",
        "  if one_hot:\n",
        "    y = np.argmax(y, axis=1)\n",
        "  if type == 'borderline':\n",
        "    sm = BorderlineSMOTE(random_state=42, k_neighbors=k)\n",
        "  elif type == 'svm':\n",
        "    sm = SVMSMOTE()\n",
        "  elif type == 'adasyn':\n",
        "    sm = ADASYN(random_state=42, n_neighbors=k)\n",
        "  elif type == 'kmeans':\n",
        "    sm = KMeansSMOTE(k_neighbors=k, kmeans_estimator=10)\n",
        "  else:\n",
        "    sm = SMOTE(random_state=42, k_neighbors=k)\n",
        "  X_resampled, y_resampled = sm.fit_resample(X, y)\n",
        "  if one_hot:\n",
        "    y_resampled = to_categorical(y_resampled, num_classes = num_classes)\n",
        "  else:\n",
        "    y_resampled = y_resampled.reshape(-1,1)\n",
        "  return X_resampled, y_resampled"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BE9FCWBe8deT"
      },
      "source": [
        "#Inner-Borderline SMOTE"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8jXtnjDwkSrP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s3UnuaKz8kzJ"
      },
      "outputs": [],
      "source": [
        "def get_class(X, y, c):\n",
        "    xbeg = X[y == c]\n",
        "    ybeg = y[y == c]\n",
        "    \n",
        "    return xbeg, ybeg\n",
        "def find_border(xclass, yclass, X, y, cli, n_neigh=5):\n",
        "    nn = NearestNeighbors(n_neighbors=n_neigh, n_jobs=1)\n",
        "    nn.fit(X)\n",
        "    dist, ind = nn.kneighbors(xclass)\n",
        "    ret = []\n",
        "    for i in range(len(ind)):\n",
        "      ret.append(sum(y[ind[i,j]] != cli for j in range(1,len(ind[i]))))\n",
        "    ret = np.array(ret)\n",
        "    xclass = xclass[np.logical_and(ret < (n_neigh-1),ret > ((n_neigh-1)/2))]\n",
        "    yclass = yclass[np.logical_and(ret < (n_neigh-1),ret > ((n_neigh-1)/2))]\n",
        "\n",
        "    return xclass, yclass\n",
        "def find_inner_border(xclass, yclass, X, y, cli, n_neigh=5):\n",
        "    nn = NearestNeighbors(n_neighbors=n_neigh, n_jobs=1)\n",
        "    nn.fit(X)\n",
        "    dist, ind = nn.kneighbors(X)\n",
        "    ret = []\n",
        "    for i in range(len(ind)):\n",
        "      if y[i] != cli:\n",
        "        ret.append(n_neigh)  \n",
        "      else:\n",
        "        ret.append(sum(y[ind[i,j]] != cli for j in range(1,len(ind[i]))))\n",
        "    ret = np.array(ret)\n",
        "    is_border = np.logical_and(ret < (n_neigh-1),ret > ((n_neigh-1)/2))\n",
        "    \n",
        "    ret = []\n",
        "    for i in range(len(ind)):\n",
        "      ret.append(sum(is_border[ind[i,j]] for j in range(1,len(ind[i]))))\n",
        "    ret = np.array(ret)\n",
        "    xclass = X[np.logical_and(np.logical_not(is_border),ret > 0)]\n",
        "    yclass = y[np.logical_and(np.logical_not(is_border),ret > 0)]\n",
        "    return xclass, yclass\n",
        "\n",
        "def G_SM(xclass,n_to_sample,cl, n_neigh = 6):\n",
        "    \n",
        "    nn = NearestNeighbors(n_neighbors=n_neigh, n_jobs=1)\n",
        "    nn.fit(xclass)\n",
        "    dist, ind = nn.kneighbors(xclass)\n",
        "\n",
        "    # generating samples\n",
        "    base_indices = np.random.choice(list(range(len(xclass))),n_to_sample)\n",
        "    neighbor_indices = np.random.choice(list(range(1, n_neigh)),n_to_sample)\n",
        "\n",
        "    X_base = xclass[base_indices]\n",
        "    X_neighbor = xclass[ind[base_indices, neighbor_indices]]\n",
        "\n",
        "    samples = X_base + np.multiply(np.random.rand(n_to_sample,1),\n",
        "            X_neighbor - X_base)\n",
        "\n",
        "    #use 10 as label because 0 to 9 real classes and 1 fake/smoted = 10\n",
        "    return samples, [cl]*n_to_sample\n",
        "\n",
        "def Borderline_SMOTE(X_train, y_train, random_state=42, k_neighbors=5, start=0, n=7):\n",
        "  #reshape X_train\n",
        "  X_train = X_train.reshape(-1, IMAGE_W * IMAGE_H * 3)\n",
        "  #decode y_train from one-hot encoding\n",
        "  y_train = np.argmax(y_train, axis=1) \n",
        "\n",
        "  counter = Counter(y_train)\n",
        "  key_max = max(counter, key=counter.get)\n",
        "  class_max = counter[key_max]\n",
        "  resx=[]\n",
        "  resy=[]\n",
        "\n",
        "  for i in range(start,n):\n",
        "      xclass, yclass = get_class(X_train, y_train, i)\n",
        "      if xclass.shape[0] == class_max:\n",
        "        continue\n",
        "      xclass_bdr, yclass_bdr = find_inner_border(xclass, yclass, X_train, y_train, i, n_neigh=k_neighbors)\n",
        "      n = class_max - xclass.shape[0]\n",
        "      xsamp, ysamp = G_SM(xclass_bdr,n,i, n_neigh=k_neighbors)\n",
        "      ysamp = np.array(ysamp)\n",
        "      resx.append(xsamp)\n",
        "      resy.append(ysamp)\n",
        "  \n",
        "  resx = np.vstack(resx)\n",
        "  resy = np.hstack(resy)\n",
        "  X_train = np.vstack((resx,X_train))\n",
        "  y_train = np.hstack((resy,y_train))\n",
        "  y_train = to_categorical(y_train)\n",
        "  X_train = X_train.reshape(-1, IMAGE_W, IMAGE_H, 3)\n",
        "  return X_train, y_train"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5v7sLC2svMuJ"
      },
      "source": [
        "# Main"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "exp_name=\"borderline\"\n",
        "dataset_name=\"under70_128px\"\n",
        "train_under_frac = 0.8"
      ],
      "metadata": {
        "id": "udkMXcZHXglm"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qge6cnxQPnH6",
        "outputId": "0d3c969b-64ab-4e34-e48c-db32e455c8d4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(5321, 128, 128, 3)\n",
            "(5321, 7)\n",
            "(193, 128, 128, 3)\n",
            "(193, 7)\n",
            "Counter train data:  Counter({5: 2011, 4: 1113, 2: 1099, 1: 514, 0: 327, 6: 142, 3: 115})\n",
            "Counter val data:  Counter({5: 123, 2: 22, 4: 21, 1: 15, 0: 8, 6: 3, 3: 1})\n"
          ]
        }
      ],
      "source": [
        "path = '/content/drive/MyDrive/PHD/Datasets/isic2018/'\n",
        "df1 = pd.read_pickle(path+\"isic2018_train_\"+dataset_name+\".pkl\")\n",
        "X_train = df1.loc[:, df1.columns != 'y_train'].to_numpy()\n",
        "X_train = X_train.reshape(-1,IMAGE_W,IMAGE_H,3)\n",
        "y_train = df1.loc[:, df1.columns == 'y_train'].to_numpy()\n",
        "y_train = to_categorical(y_train)\n",
        "\n",
        "#df1 = pd.read_pickle(path+\"isic2018_val_\"+dataset_name+\".pkl\")\n",
        "df1 = pd.read_pickle(path+\"isic2018_val.pkl\")\n",
        "X_val = df1.loc[:, df1.columns != 'y_val'].to_numpy()\n",
        "X_val = X_val.reshape(-1,IMAGE_W,IMAGE_H,3)\n",
        "y_val = df1.loc[:, df1.columns == 'y_val'].to_numpy()\n",
        "y_val = to_categorical(y_val)\n",
        "\n",
        "print(X_train.shape)\n",
        "print(y_train.shape)\n",
        "print(X_val.shape)\n",
        "print(y_val.shape)\n",
        "print('Counter train data: ', Counter(np.argmax(y_train, axis=1)))\n",
        "print('Counter val data: ', Counter(np.argmax(y_val, axis=1)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xArGWuciBt_-",
        "outputId": "bde3fb63-2405-4ec2-a592-2c3f4f0bb88f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(14077, 128, 128, 3)\n",
            "(14077, 7)\n",
            "(193, 128, 128, 3)\n",
            "(193, 7)\n",
            "Counter train data:  Counter({5: 2011, 4: 2011, 2: 2011, 3: 2011, 0: 2011, 1: 2011, 6: 2011})\n",
            "Counter val data:  Counter({5: 123, 2: 22, 4: 21, 1: 15, 0: 8, 6: 3, 3: 1})\n"
          ]
        }
      ],
      "source": [
        "X_train, y_train = SMOTE_Data(X_train, y_train, True, type = 'borderline')\n",
        "#X_train, y_train = Borderline_SMOTE(X_train, y_train)\n",
        "print(X_train.shape)\n",
        "print(y_train.shape)\n",
        "print(X_val.shape)\n",
        "print(y_val.shape)\n",
        "print('Counter train data: ', Counter(np.argmax(y_train, axis=1)))\n",
        "print('Counter val data: ', Counter(np.argmax(y_val, axis=1)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "0V5PjA7jFhVU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "38b5f38e-272e-483a-fa48-6186f4b7efcd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(9487, 2048)\n",
            "(9487, 7)\n",
            "Counter train data:  Counter({0: 1441, 5: 1341, 4: 1341, 2: 1341, 3: 1341, 1: 1341, 6: 1341})\n"
          ]
        }
      ],
      "source": [
        "n_new_samples = 100\n",
        "X_train = np.append(X_train_fm_ov, np.zeros(shape=(n_new_samples, 2048), dtype='object'), axis=0)\n",
        "y_train = np.argmax(y_train_ov, axis=1) \n",
        "y_train = y_train.reshape(-1,1)\n",
        "y_train = np.append(y_train, np.zeros(shape=(n_new_samples, 1), dtype='object'))\n",
        "y_train = to_categorical(y_train)\n",
        "print(X_train.shape)\n",
        "print(y_train.shape)\n",
        "print('Counter train data: ', Counter(np.argmax(y_train, axis=1)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0lFpLlexMUaM",
        "outputId": "137599b4-6ee6-49de-8cd9-13e82b8c2c89"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(9887, 2048)\n",
            "(9887, 7)\n",
            "Counter train data:  Counter({5: 1441, 4: 1441, 2: 1441, 1: 1441, 6: 1441, 3: 1341, 0: 1341})\n"
          ]
        }
      ],
      "source": [
        "# remove rows having all zeroes\n",
        "index = range(9387,9487)\n",
        "y_train = np.delete(y_train_ov, index, axis = 0)\n",
        "X_train = np.delete(X_train_fm_ov, index, axis = 0)\n",
        "print(X_train.shape)\n",
        "print(y_train.shape)\n",
        "print('Counter train data: ', Counter(np.argmax(y_train, axis=1)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V7Z_nccu6QjB"
      },
      "outputs": [],
      "source": [
        "#path = '/content/drive/MyDrive/PHD/Datasets/isic2018/'\n",
        "#df1 = pd.DataFrame(X_train.reshape(X_train.shape[0],-1))\n",
        "#df1['y_train'] = np.argmax(y_train, axis=1).tolist()\n",
        "#df2 = pd.DataFrame(X_val.reshape(X_val.shape[0],-1))\n",
        "#df2['y_val'] = np.argmax(y_val, axis=1).tolist()\n",
        "#df1.to_pickle(path+\"isic2018_train_under83.pkl\")\n",
        "#df2.to_pickle(path+\"isic2018_val.pkl\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "vIygrW81Ln4z",
        "outputId": "e5818c99-e34b-42fb-dbfc-fa30f1cee8df"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "best_model_fpath:/content/drive/MyDrive/PHD/Model/best_model_borderline_under70_128px.h5\n",
            "Epoch 1/50\n",
            "219/219 [==============================] - ETA: 0s - loss: 1.0054 - accuracy: 0.6193 - balanced_acc: 0.6209\n",
            "Epoch 1: val_balanced_acc improved from -inf to 0.54523, saving model to /content/drive/MyDrive/PHD/Model/best_model_borderline_under70_128px.h5\n",
            "219/219 [==============================] - 60s 232ms/step - loss: 1.0054 - accuracy: 0.6193 - balanced_acc: 0.6209 - val_loss: 0.7717 - val_accuracy: 0.7047 - val_balanced_acc: 0.5452 - lr: 0.0010\n",
            "Epoch 2/50\n",
            "219/219 [==============================] - ETA: 0s - loss: 0.5716 - accuracy: 0.7848 - balanced_acc: 0.7849\n",
            "Epoch 2: val_balanced_acc did not improve from 0.54523\n",
            "219/219 [==============================] - 52s 229ms/step - loss: 0.5716 - accuracy: 0.7848 - balanced_acc: 0.7849 - val_loss: 0.8464 - val_accuracy: 0.6684 - val_balanced_acc: 0.4925 - lr: 0.0010\n",
            "Epoch 3/50\n",
            "219/219 [==============================] - ETA: 0s - loss: 0.4294 - accuracy: 0.8414 - balanced_acc: 0.8402\n",
            "Epoch 3: val_balanced_acc improved from 0.54523 to 0.58239, saving model to /content/drive/MyDrive/PHD/Model/best_model_borderline_under70_128px.h5\n",
            "219/219 [==============================] - 51s 234ms/step - loss: 0.4294 - accuracy: 0.8414 - balanced_acc: 0.8402 - val_loss: 0.6036 - val_accuracy: 0.7927 - val_balanced_acc: 0.5824 - lr: 0.0010\n",
            "Epoch 4/50\n",
            "219/219 [==============================] - ETA: 0s - loss: 0.3401 - accuracy: 0.8793 - balanced_acc: 0.8789\n",
            "Epoch 4: val_balanced_acc did not improve from 0.58239\n",
            "219/219 [==============================] - 50s 228ms/step - loss: 0.3401 - accuracy: 0.8793 - balanced_acc: 0.8789 - val_loss: 0.7817 - val_accuracy: 0.6943 - val_balanced_acc: 0.5548 - lr: 0.0010\n",
            "Epoch 5/50\n",
            "219/219 [==============================] - ETA: 0s - loss: 0.2834 - accuracy: 0.8966 - balanced_acc: 0.8961\n",
            "Epoch 5: val_balanced_acc did not improve from 0.58239\n",
            "219/219 [==============================] - 50s 228ms/step - loss: 0.2834 - accuracy: 0.8966 - balanced_acc: 0.8961 - val_loss: 0.6332 - val_accuracy: 0.7513 - val_balanced_acc: 0.4185 - lr: 0.0010\n",
            "Epoch 6/50\n",
            "219/219 [==============================] - ETA: 0s - loss: 0.2239 - accuracy: 0.9219 - balanced_acc: 0.9226\n",
            "Epoch 6: val_balanced_acc did not improve from 0.58239\n",
            "219/219 [==============================] - 50s 228ms/step - loss: 0.2239 - accuracy: 0.9219 - balanced_acc: 0.9226 - val_loss: 0.7440 - val_accuracy: 0.7254 - val_balanced_acc: 0.5757 - lr: 0.0010\n",
            "Epoch 7/50\n",
            "219/219 [==============================] - ETA: 0s - loss: 0.1860 - accuracy: 0.9384 - balanced_acc: 0.9382\n",
            "Epoch 7: val_balanced_acc improved from 0.58239 to 0.60393, saving model to /content/drive/MyDrive/PHD/Model/best_model_borderline_under70_128px.h5\n",
            "219/219 [==============================] - 51s 235ms/step - loss: 0.1860 - accuracy: 0.9384 - balanced_acc: 0.9382 - val_loss: 0.6378 - val_accuracy: 0.7565 - val_balanced_acc: 0.6039 - lr: 0.0010\n",
            "Epoch 8/50\n",
            "219/219 [==============================] - ETA: 0s - loss: 0.1492 - accuracy: 0.9511 - balanced_acc: 0.9512\n",
            "Epoch 8: val_balanced_acc did not improve from 0.60393\n",
            "219/219 [==============================] - 50s 229ms/step - loss: 0.1492 - accuracy: 0.9511 - balanced_acc: 0.9512 - val_loss: 0.7485 - val_accuracy: 0.7565 - val_balanced_acc: 0.5001 - lr: 0.0010\n",
            "Epoch 9/50\n",
            "219/219 [==============================] - ETA: 0s - loss: 0.1165 - accuracy: 0.9635 - balanced_acc: 0.9645\n",
            "Epoch 9: val_balanced_acc did not improve from 0.60393\n",
            "219/219 [==============================] - 50s 228ms/step - loss: 0.1165 - accuracy: 0.9635 - balanced_acc: 0.9645 - val_loss: 0.6710 - val_accuracy: 0.7876 - val_balanced_acc: 0.4660 - lr: 0.0010\n",
            "Epoch 10/50\n",
            "219/219 [==============================] - ETA: 0s - loss: 0.0839 - accuracy: 0.9745 - balanced_acc: 0.9747\n",
            "Epoch 10: val_balanced_acc improved from 0.60393 to 0.62312, saving model to /content/drive/MyDrive/PHD/Model/best_model_borderline_under70_128px.h5\n",
            "219/219 [==============================] - 52s 235ms/step - loss: 0.0839 - accuracy: 0.9745 - balanced_acc: 0.9747 - val_loss: 0.9444 - val_accuracy: 0.7254 - val_balanced_acc: 0.6231 - lr: 0.0010\n",
            "Epoch 11/50\n",
            "219/219 [==============================] - ETA: 0s - loss: 0.1038 - accuracy: 0.9714 - balanced_acc: 0.9712\n",
            "Epoch 11: val_balanced_acc did not improve from 0.62312\n",
            "219/219 [==============================] - 50s 229ms/step - loss: 0.1038 - accuracy: 0.9714 - balanced_acc: 0.9712 - val_loss: 0.8877 - val_accuracy: 0.7306 - val_balanced_acc: 0.6117 - lr: 0.0010\n",
            "Epoch 12/50\n",
            "219/219 [==============================] - ETA: 0s - loss: 0.0465 - accuracy: 0.9887 - balanced_acc: 0.9880\n",
            "Epoch 12: val_balanced_acc did not improve from 0.62312\n",
            "219/219 [==============================] - 50s 229ms/step - loss: 0.0465 - accuracy: 0.9887 - balanced_acc: 0.9880 - val_loss: 0.9321 - val_accuracy: 0.7150 - val_balanced_acc: 0.5505 - lr: 0.0010\n",
            "Epoch 13/50\n",
            "219/219 [==============================] - ETA: 0s - loss: 0.0925 - accuracy: 0.9772 - balanced_acc: 0.9772\n",
            "Epoch 13: val_balanced_acc did not improve from 0.62312\n",
            "219/219 [==============================] - 50s 228ms/step - loss: 0.0925 - accuracy: 0.9772 - balanced_acc: 0.9772 - val_loss: 0.7864 - val_accuracy: 0.7565 - val_balanced_acc: 0.5894 - lr: 0.0010\n",
            "Epoch 14/50\n",
            "219/219 [==============================] - ETA: 0s - loss: 0.0260 - accuracy: 0.9955 - balanced_acc: 0.9952\n",
            "Epoch 14: val_balanced_acc did not improve from 0.62312\n",
            "219/219 [==============================] - 50s 229ms/step - loss: 0.0260 - accuracy: 0.9955 - balanced_acc: 0.9952 - val_loss: 0.7982 - val_accuracy: 0.7824 - val_balanced_acc: 0.6005 - lr: 0.0010\n",
            "Epoch 15/50\n",
            "219/219 [==============================] - ETA: 0s - loss: 0.0144 - accuracy: 0.9982 - balanced_acc: 0.9984\n",
            "Epoch 15: val_balanced_acc improved from 0.62312 to 0.63008, saving model to /content/drive/MyDrive/PHD/Model/best_model_borderline_under70_128px.h5\n",
            "219/219 [==============================] - 52s 235ms/step - loss: 0.0144 - accuracy: 0.9982 - balanced_acc: 0.9984 - val_loss: 0.8432 - val_accuracy: 0.7927 - val_balanced_acc: 0.6301 - lr: 0.0010\n",
            "Epoch 16/50\n",
            "219/219 [==============================] - ETA: 0s - loss: 0.0076 - accuracy: 0.9996 - balanced_acc: 0.9996\n",
            "Epoch 16: val_balanced_acc did not improve from 0.63008\n",
            "219/219 [==============================] - 50s 229ms/step - loss: 0.0076 - accuracy: 0.9996 - balanced_acc: 0.9996 - val_loss: 0.9156 - val_accuracy: 0.7824 - val_balanced_acc: 0.4715 - lr: 0.0010\n",
            "Epoch 17/50\n",
            "219/219 [==============================] - ETA: 0s - loss: 0.0056 - accuracy: 0.9996 - balanced_acc: 0.9996\n",
            "Epoch 17: val_balanced_acc did not improve from 0.63008\n",
            "219/219 [==============================] - 50s 229ms/step - loss: 0.0056 - accuracy: 0.9996 - balanced_acc: 0.9996 - val_loss: 0.9915 - val_accuracy: 0.7927 - val_balanced_acc: 0.6279 - lr: 0.0010\n",
            "Epoch 18/50\n",
            "219/219 [==============================] - ETA: 0s - loss: 0.0036 - accuracy: 0.9999 - balanced_acc: 0.9999\n",
            "Epoch 18: val_balanced_acc did not improve from 0.63008\n",
            "219/219 [==============================] - 50s 229ms/step - loss: 0.0036 - accuracy: 0.9999 - balanced_acc: 0.9999 - val_loss: 1.0225 - val_accuracy: 0.7772 - val_balanced_acc: 0.4758 - lr: 0.0010\n",
            "Epoch 19/50\n",
            "219/219 [==============================] - ETA: 0s - loss: 0.0029 - accuracy: 1.0000 - balanced_acc: 1.0000\n",
            "Epoch 19: val_balanced_acc did not improve from 0.63008\n",
            "219/219 [==============================] - 50s 229ms/step - loss: 0.0029 - accuracy: 1.0000 - balanced_acc: 1.0000 - val_loss: 1.0026 - val_accuracy: 0.7876 - val_balanced_acc: 0.6101 - lr: 0.0010\n",
            "Epoch 20/50\n",
            "219/219 [==============================] - ETA: 0s - loss: 0.0023 - accuracy: 1.0000 - balanced_acc: 1.0000\n",
            "Epoch 20: val_balanced_acc did not improve from 0.63008\n",
            "219/219 [==============================] - 50s 229ms/step - loss: 0.0023 - accuracy: 1.0000 - balanced_acc: 1.0000 - val_loss: 1.0465 - val_accuracy: 0.7927 - val_balanced_acc: 0.6109 - lr: 0.0010\n",
            "Epoch 21/50\n",
            "219/219 [==============================] - ETA: 0s - loss: 0.0019 - accuracy: 1.0000 - balanced_acc: 1.0000\n",
            "Epoch 21: val_balanced_acc did not improve from 0.63008\n",
            "219/219 [==============================] - 50s 229ms/step - loss: 0.0019 - accuracy: 1.0000 - balanced_acc: 1.0000 - val_loss: 1.1037 - val_accuracy: 0.7668 - val_balanced_acc: 0.4774 - lr: 0.0010\n",
            "Epoch 22/50\n",
            "219/219 [==============================] - ETA: 0s - loss: 0.0017 - accuracy: 1.0000 - balanced_acc: 1.0000\n",
            "Epoch 22: val_balanced_acc did not improve from 0.63008\n",
            "219/219 [==============================] - 50s 229ms/step - loss: 0.0017 - accuracy: 1.0000 - balanced_acc: 1.0000 - val_loss: 1.1339 - val_accuracy: 0.7720 - val_balanced_acc: 0.6073 - lr: 0.0010\n",
            "Epoch 23/50\n",
            "219/219 [==============================] - ETA: 0s - loss: 0.0014 - accuracy: 1.0000 - balanced_acc: 1.0000\n",
            "Epoch 23: val_balanced_acc did not improve from 0.63008\n",
            "219/219 [==============================] - 50s 229ms/step - loss: 0.0014 - accuracy: 1.0000 - balanced_acc: 1.0000 - val_loss: 1.1047 - val_accuracy: 0.7772 - val_balanced_acc: 0.4740 - lr: 0.0010\n",
            "Epoch 24/50\n",
            "219/219 [==============================] - ETA: 0s - loss: 0.0013 - accuracy: 1.0000 - balanced_acc: 1.0000\n",
            "Epoch 24: val_balanced_acc did not improve from 0.63008\n",
            "219/219 [==============================] - 50s 229ms/step - loss: 0.0013 - accuracy: 1.0000 - balanced_acc: 1.0000 - val_loss: 1.1556 - val_accuracy: 0.7876 - val_balanced_acc: 0.6101 - lr: 0.0010\n",
            "Epoch 25/50\n",
            "219/219 [==============================] - ETA: 0s - loss: 0.0012 - accuracy: 1.0000 - balanced_acc: 1.0000\n",
            "Epoch 25: val_balanced_acc did not improve from 0.63008\n",
            "219/219 [==============================] - 50s 229ms/step - loss: 0.0012 - accuracy: 1.0000 - balanced_acc: 1.0000 - val_loss: 1.1795 - val_accuracy: 0.7617 - val_balanced_acc: 0.4712 - lr: 0.0010\n",
            "Epoch 26/50\n",
            "219/219 [==============================] - ETA: 0s - loss: 0.0011 - accuracy: 1.0000 - balanced_acc: 1.0000\n",
            "Epoch 26: val_balanced_acc did not improve from 0.63008\n",
            "219/219 [==============================] - 50s 229ms/step - loss: 0.0011 - accuracy: 1.0000 - balanced_acc: 1.0000 - val_loss: 1.1717 - val_accuracy: 0.7772 - val_balanced_acc: 0.4740 - lr: 0.0010\n",
            "Epoch 27/50\n",
            "219/219 [==============================] - ETA: 0s - loss: 9.2883e-04 - accuracy: 1.0000 - balanced_acc: 1.0000\n",
            "Epoch 27: val_balanced_acc did not improve from 0.63008\n",
            "219/219 [==============================] - 50s 229ms/step - loss: 9.2883e-04 - accuracy: 1.0000 - balanced_acc: 1.0000 - val_loss: 1.1568 - val_accuracy: 0.7772 - val_balanced_acc: 0.4740 - lr: 0.0010\n",
            "Epoch 28/50\n",
            "219/219 [==============================] - ETA: 0s - loss: 8.7956e-04 - accuracy: 1.0000 - balanced_acc: 1.0000\n",
            "Epoch 28: val_balanced_acc did not improve from 0.63008\n",
            "219/219 [==============================] - 50s 229ms/step - loss: 8.7956e-04 - accuracy: 1.0000 - balanced_acc: 1.0000 - val_loss: 1.2021 - val_accuracy: 0.7720 - val_balanced_acc: 0.4732 - lr: 0.0010\n",
            "Epoch 29/50\n",
            "219/219 [==============================] - ETA: 0s - loss: 7.9790e-04 - accuracy: 1.0000 - balanced_acc: 1.0000\n",
            "Epoch 29: val_balanced_acc did not improve from 0.63008\n",
            "219/219 [==============================] - 50s 229ms/step - loss: 7.9790e-04 - accuracy: 1.0000 - balanced_acc: 1.0000 - val_loss: 1.2137 - val_accuracy: 0.7824 - val_balanced_acc: 0.6041 - lr: 0.0010\n",
            "Epoch 30/50\n",
            "219/219 [==============================] - ETA: 0s - loss: 7.3551e-04 - accuracy: 1.0000 - balanced_acc: 1.0000\n",
            "Epoch 30: val_balanced_acc did not improve from 0.63008\n",
            "219/219 [==============================] - 50s 229ms/step - loss: 7.3551e-04 - accuracy: 1.0000 - balanced_acc: 1.0000 - val_loss: 1.2173 - val_accuracy: 0.7876 - val_balanced_acc: 0.6101 - lr: 0.0010\n",
            "Epoch 31/50\n",
            "219/219 [==============================] - ETA: 0s - loss: 6.9524e-04 - accuracy: 1.0000 - balanced_acc: 1.0000\n",
            "Epoch 31: val_balanced_acc did not improve from 0.63008\n",
            "219/219 [==============================] - 50s 229ms/step - loss: 6.9524e-04 - accuracy: 1.0000 - balanced_acc: 1.0000 - val_loss: 1.2252 - val_accuracy: 0.7876 - val_balanced_acc: 0.6101 - lr: 0.0010\n",
            "Epoch 32/50\n",
            "219/219 [==============================] - ETA: 0s - loss: 6.5238e-04 - accuracy: 1.0000 - balanced_acc: 1.0000\n",
            "Epoch 32: val_balanced_acc did not improve from 0.63008\n",
            "219/219 [==============================] - 50s 229ms/step - loss: 6.5238e-04 - accuracy: 1.0000 - balanced_acc: 1.0000 - val_loss: 1.2276 - val_accuracy: 0.7876 - val_balanced_acc: 0.6050 - lr: 0.0010\n",
            "Epoch 33/50\n",
            "219/219 [==============================] - ETA: 0s - loss: 6.0942e-04 - accuracy: 1.0000 - balanced_acc: 1.0000\n",
            "Epoch 33: val_balanced_acc did not improve from 0.63008\n",
            "219/219 [==============================] - 50s 228ms/step - loss: 6.0942e-04 - accuracy: 1.0000 - balanced_acc: 1.0000 - val_loss: 1.2281 - val_accuracy: 0.7824 - val_balanced_acc: 0.4800 - lr: 0.0010\n",
            "Epoch 34/50\n",
            "219/219 [==============================] - ETA: 0s - loss: 5.7794e-04 - accuracy: 1.0000 - balanced_acc: 1.0000\n",
            "Epoch 34: val_balanced_acc did not improve from 0.63008\n",
            "219/219 [==============================] - 50s 229ms/step - loss: 5.7794e-04 - accuracy: 1.0000 - balanced_acc: 1.0000 - val_loss: 1.2673 - val_accuracy: 0.7772 - val_balanced_acc: 0.4740 - lr: 0.0010\n",
            "Epoch 35/50\n",
            "219/219 [==============================] - ETA: 0s - loss: 5.4018e-04 - accuracy: 1.0000 - balanced_acc: 1.0000\n",
            "Epoch 35: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "\n",
            "Epoch 35: val_balanced_acc did not improve from 0.63008\n",
            "219/219 [==============================] - 50s 229ms/step - loss: 5.4018e-04 - accuracy: 1.0000 - balanced_acc: 1.0000 - val_loss: 1.2663 - val_accuracy: 0.7824 - val_balanced_acc: 0.6005 - lr: 0.0010\n",
            "Epoch 36/50\n",
            "219/219 [==============================] - ETA: 0s - loss: 5.1598e-04 - accuracy: 1.0000 - balanced_acc: 1.0000\n",
            "Epoch 36: val_balanced_acc did not improve from 0.63008\n",
            "219/219 [==============================] - 50s 229ms/step - loss: 5.1598e-04 - accuracy: 1.0000 - balanced_acc: 1.0000 - val_loss: 1.2648 - val_accuracy: 0.7876 - val_balanced_acc: 0.6050 - lr: 5.0000e-04\n",
            "Epoch 37/50\n",
            "219/219 [==============================] - ETA: 0s - loss: 4.9755e-04 - accuracy: 1.0000 - balanced_acc: 1.0000\n",
            "Epoch 37: val_balanced_acc did not improve from 0.63008\n",
            "219/219 [==============================] - 50s 229ms/step - loss: 4.9755e-04 - accuracy: 1.0000 - balanced_acc: 1.0000 - val_loss: 1.2818 - val_accuracy: 0.7824 - val_balanced_acc: 0.6041 - lr: 5.0000e-04\n",
            "Epoch 38/50\n",
            "219/219 [==============================] - ETA: 0s - loss: 4.8243e-04 - accuracy: 1.0000 - balanced_acc: 1.0000\n",
            "Epoch 38: val_balanced_acc did not improve from 0.63008\n",
            "219/219 [==============================] - 50s 229ms/step - loss: 4.8243e-04 - accuracy: 1.0000 - balanced_acc: 1.0000 - val_loss: 1.2785 - val_accuracy: 0.7876 - val_balanced_acc: 0.6050 - lr: 5.0000e-04\n",
            "Epoch 39/50\n",
            "219/219 [==============================] - ETA: 0s - loss: 4.6838e-04 - accuracy: 1.0000 - balanced_acc: 1.0000\n",
            "Epoch 39: val_balanced_acc did not improve from 0.63008\n",
            "219/219 [==============================] - 50s 229ms/step - loss: 4.6838e-04 - accuracy: 1.0000 - balanced_acc: 1.0000 - val_loss: 1.2865 - val_accuracy: 0.7824 - val_balanced_acc: 0.6041 - lr: 5.0000e-04\n",
            "Epoch 40/50\n",
            "219/219 [==============================] - ETA: 0s - loss: 4.6236e-04 - accuracy: 1.0000 - balanced_acc: 1.0000\n",
            "Epoch 40: val_balanced_acc did not improve from 0.63008\n",
            "219/219 [==============================] - 50s 229ms/step - loss: 4.6236e-04 - accuracy: 1.0000 - balanced_acc: 1.0000 - val_loss: 1.2922 - val_accuracy: 0.7824 - val_balanced_acc: 0.6041 - lr: 5.0000e-04\n",
            "Epoch 41/50\n",
            "219/219 [==============================] - ETA: 0s - loss: 4.5585e-04 - accuracy: 1.0000 - balanced_acc: 0.9993\n",
            "Epoch 41: val_balanced_acc did not improve from 0.63008\n",
            "219/219 [==============================] - 50s 229ms/step - loss: 4.5585e-04 - accuracy: 1.0000 - balanced_acc: 0.9993 - val_loss: 1.2977 - val_accuracy: 0.7876 - val_balanced_acc: 0.6050 - lr: 5.0000e-04\n",
            "Epoch 42/50\n",
            "219/219 [==============================] - ETA: 0s - loss: 4.3856e-04 - accuracy: 1.0000 - balanced_acc: 1.0000\n",
            "Epoch 42: val_balanced_acc did not improve from 0.63008\n",
            "219/219 [==============================] - 50s 229ms/step - loss: 4.3856e-04 - accuracy: 1.0000 - balanced_acc: 1.0000 - val_loss: 1.2948 - val_accuracy: 0.7772 - val_balanced_acc: 0.4791 - lr: 5.0000e-04\n",
            "Epoch 43/50\n",
            "219/219 [==============================] - ETA: 0s - loss: 4.3493e-04 - accuracy: 1.0000 - balanced_acc: 1.0000\n",
            "Epoch 43: val_balanced_acc did not improve from 0.63008\n",
            "219/219 [==============================] - 50s 229ms/step - loss: 4.3493e-04 - accuracy: 1.0000 - balanced_acc: 1.0000 - val_loss: 1.3054 - val_accuracy: 0.7876 - val_balanced_acc: 0.6050 - lr: 5.0000e-04\n",
            "Epoch 44/50\n",
            "219/219 [==============================] - ETA: 0s - loss: 4.1211e-04 - accuracy: 1.0000 - balanced_acc: 1.0000\n",
            "Epoch 44: val_balanced_acc did not improve from 0.63008\n",
            "219/219 [==============================] - 50s 229ms/step - loss: 4.1211e-04 - accuracy: 1.0000 - balanced_acc: 1.0000 - val_loss: 1.3013 - val_accuracy: 0.7824 - val_balanced_acc: 0.6041 - lr: 5.0000e-04\n",
            "Epoch 45/50\n",
            "219/219 [==============================] - ETA: 0s - loss: 4.1604e-04 - accuracy: 1.0000 - balanced_acc: 1.0000\n",
            "Epoch 45: val_balanced_acc did not improve from 0.63008\n",
            "219/219 [==============================] - 50s 229ms/step - loss: 4.1604e-04 - accuracy: 1.0000 - balanced_acc: 1.0000 - val_loss: 1.2984 - val_accuracy: 0.7824 - val_balanced_acc: 0.6041 - lr: 5.0000e-04\n",
            "Epoch 46/50\n",
            "219/219 [==============================] - ETA: 0s - loss: 4.0106e-04 - accuracy: 1.0000 - balanced_acc: 1.0000\n",
            "Epoch 46: val_balanced_acc did not improve from 0.63008\n",
            "219/219 [==============================] - 50s 229ms/step - loss: 4.0106e-04 - accuracy: 1.0000 - balanced_acc: 1.0000 - val_loss: 1.3063 - val_accuracy: 0.7824 - val_balanced_acc: 0.6041 - lr: 5.0000e-04\n",
            "Epoch 47/50\n",
            "219/219 [==============================] - ETA: 0s - loss: 3.9079e-04 - accuracy: 1.0000 - balanced_acc: 1.0000\n",
            "Epoch 47: val_balanced_acc did not improve from 0.63008\n",
            "219/219 [==============================] - 50s 229ms/step - loss: 3.9079e-04 - accuracy: 1.0000 - balanced_acc: 1.0000 - val_loss: 1.2934 - val_accuracy: 0.7824 - val_balanced_acc: 0.6005 - lr: 5.0000e-04\n",
            "Epoch 48/50\n",
            "219/219 [==============================] - ETA: 0s - loss: 3.8415e-04 - accuracy: 1.0000 - balanced_acc: 1.0000\n",
            "Epoch 48: val_balanced_acc did not improve from 0.63008\n",
            "219/219 [==============================] - 50s 229ms/step - loss: 3.8415e-04 - accuracy: 1.0000 - balanced_acc: 1.0000 - val_loss: 1.3108 - val_accuracy: 0.7824 - val_balanced_acc: 0.6005 - lr: 5.0000e-04\n",
            "Epoch 49/50\n",
            "219/219 [==============================] - ETA: 0s - loss: 3.7746e-04 - accuracy: 1.0000 - balanced_acc: 1.0000\n",
            "Epoch 49: val_balanced_acc did not improve from 0.63008\n",
            "219/219 [==============================] - 50s 229ms/step - loss: 3.7746e-04 - accuracy: 1.0000 - balanced_acc: 1.0000 - val_loss: 1.3355 - val_accuracy: 0.7772 - val_balanced_acc: 0.5996 - lr: 5.0000e-04\n",
            "Epoch 50/50\n",
            "219/219 [==============================] - ETA: 0s - loss: 3.7616e-04 - accuracy: 1.0000 - balanced_acc: 1.0000\n",
            "Epoch 50: val_balanced_acc did not improve from 0.63008\n",
            "219/219 [==============================] - 50s 229ms/step - loss: 3.7616e-04 - accuracy: 1.0000 - balanced_acc: 1.0000 - val_loss: 1.3148 - val_accuracy: 0.7876 - val_balanced_acc: 0.6050 - lr: 5.0000e-04\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "# define model\n",
        "model = define_model_resnet()\n",
        "#Callbacks\n",
        "best_model_fpath = '/content/drive/MyDrive/PHD/Model/best_model_'+exp_name+'_'+dataset_name+'.h5'\n",
        "print(\"best_model_fpath:\"+best_model_fpath)\n",
        "mc = ModelCheckpoint(best_model_fpath, monitor='val_balanced_acc', mode='max', verbose=1, save_best_only=True)\n",
        "learning_rate_reduction = ReduceLROnPlateau(monitor='val_balanced_acc', patience=20, verbose=1, factor=0.5, min_lr=0.00001)\n",
        "early_stopping_monitor = EarlyStopping(patience=40,monitor='val_balanced_acc')\n",
        "#model.summary()\n",
        "hst = model.fit(X_train, y_train, epochs=EPOCHS, batch_size=BATCH_SIZE, validation_data=(X_val, y_val), verbose=1,\n",
        "                    steps_per_epoch=X_train.shape[0] // BATCH_SIZE, \n",
        "                    #callbacks=[learning_rate_reduction,early_stopping_monitor, mc])\n",
        "                    callbacks=[learning_rate_reduction,mc])\n",
        "# learning curves\n",
        "summarize_diagnostics(hst)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "SPz8NH1Oylv9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "43cebb76-fc8b-4a69-8551-39ac5b9156f5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "model saved\n"
          ]
        }
      ],
      "source": [
        "#save last model\n",
        "last_model_fpath = '/content/drive/MyDrive/PHD/Model/last_model_'+exp_name+'_'+dataset_name+'.h5'\n",
        "model.save(last_model_fpath)\n",
        "print(\"model saved\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "vXnW3lmCgln3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "e64dad91-4639-4086-a686-b59240a3f8ed"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "# summarize history for accuracy\n",
        "plt.plot(hst.history['accuracy'])\n",
        "plt.plot(hst.history['balanced_acc'])\n",
        "plt.plot(hst.history['val_accuracy'])\n",
        "plt.plot(hst.history['val_balanced_acc'])\n",
        "plt.title('Model accuracy')\n",
        "plt.ylabel('Performance')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train accuracy', 'train balanced acc.', 'val. accuracy', 'val. balanced acc.'], loc='lower right')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "icgjmi-4UIT-"
      },
      "source": [
        "#Evaluate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "lS3ewyxO_anU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "70286e63-d676-40d6-d8c5-06638793c38c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "440/440 [==============================] - 18s 37ms/step\n",
            "7/7 [==============================] - 0s 36ms/step\n",
            "accuracy on training 1.0\n",
            "balanced accuracy on training 1.0\n",
            "accuracy on validation 0.7875647668393783\n",
            "balanced accuracy on validation 0.7896190627026863\n",
            "Score on val data:  (0.6511733235318141, 0.7896190627026863, 0.7004823975281627, None)\n"
          ]
        }
      ],
      "source": [
        "#last_model_fpath = '/content/drive/MyDrive/PHD/Model/last_model_'+'no_smote'+'_'+dataset_name+'.h5'\n",
        "last_model = load_model(last_model_fpath, custom_objects={'balanced_acc' : balanced_acc})\n",
        "y_train_pred = last_model.predict(X_train)\n",
        "y_val_pred = last_model.predict(X_val)\n",
        "\n",
        "#print('accuracy on training',accuracy_score(np.argmax(y_train, axis=1), np.argmax(y_train_pred, axis=1)))\n",
        "print('accuracy on training',accuracy_score(np.argmax(y_train, axis=1), np.argmax(y_train_pred, axis=1)))\n",
        "print('balanced accuracy on training',balanced_accuracy_score(np.argmax(y_train, axis=1), np.argmax(y_train_pred, axis=1)))\n",
        "print('accuracy on validation',accuracy_score(np.argmax(y_val, axis=1), np.argmax(y_val_pred, axis=1)))\n",
        "print('balanced accuracy on validation',balanced_accuracy_score(np.argmax(y_val, axis=1), np.argmax(y_val_pred, axis=1)))\n",
        "print('Score on val data: ',precision_recall_fscore_support(np.argmax(y_val, axis=1), np.argmax(y_val_pred, axis=1), average='macro'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "W3IyWjdGG4Xq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c403a7ac-29fe-4382-a02f-c9b8ffe4e98d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "440/440 [==============================] - 17s 37ms/step\n",
            "7/7 [==============================] - 0s 36ms/step\n",
            "accuracy on training 0.9992896213681892\n",
            "balanced accuracy on training 0.9992896213681892\n",
            "accuracy on validation 0.7927461139896373\n",
            "balanced accuracy on validation 0.8105355445947781\n",
            "Score on val data:  (0.7324120741413974, 0.8105355445947781, 0.7620921143787911, None)\n"
          ]
        }
      ],
      "source": [
        "best_model = load_model(best_model_fpath, custom_objects={'balanced_acc' : balanced_acc})\n",
        "y_train_pred = best_model.predict(X_train)\n",
        "y_val_pred = best_model.predict(X_val)\n",
        "\n",
        "print('accuracy on training',accuracy_score(np.argmax(y_train, axis=1), np.argmax(y_train_pred, axis=1)))\n",
        "print('balanced accuracy on training',balanced_accuracy_score(np.argmax(y_train, axis=1), np.argmax(y_train_pred, axis=1)))\n",
        "print('accuracy on validation',accuracy_score(np.argmax(y_val, axis=1), np.argmax(y_val_pred, axis=1)))\n",
        "print('balanced accuracy on validation',balanced_accuracy_score(np.argmax(y_val, axis=1), np.argmax(y_val_pred, axis=1)))\n",
        "print('Score on val data: ',precision_recall_fscore_support(np.argmax(y_val, axis=1), np.argmax(y_val_pred, axis=1), average='macro'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iDRWiTnO0MGh"
      },
      "source": [
        "#Cut-off"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tGnCoIdLyDHS"
      },
      "outputs": [],
      "source": [
        "df_val_pred = pd.DataFrame(y_val_pred, columns = ['AKIEC', 'BCC', 'BKL', 'DF', 'MEL', 'NV', 'VASC'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QdyCbloQyWTC"
      },
      "outputs": [],
      "source": [
        "numbers = [float(x)/40 for x in range(11)]\n",
        "for i in numbers:\n",
        "    df_val_pred[i]= df_val_pred.MEL.map(lambda x: 1 if x > i else 0)\n",
        "df_val_pred.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G4SQsRx73kgk"
      },
      "outputs": [],
      "source": [
        "y_val_true= [1 if x == 4 else 0 for x in np.argmax(y_val, axis=1)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QcUISWFi0J05"
      },
      "outputs": [],
      "source": [
        "#num = [0.0,0.05,0.1,0.15,0.2,0.25,0.3,0.35,0.4,0.45,0.5]\n",
        "cutoff_df = pd.DataFrame( columns = ['Probability','Accuracy','Sensitivity','Specificity'])\n",
        "for i in numbers:\n",
        "    cm1 = confusion_matrix(y_val_true, df_val_pred[i])\n",
        "    total1=sum(sum(cm1))\n",
        "    Accuracy = (cm1[0,0]+cm1[1,1])/total1\n",
        "    Specificity = cm1[0,0]/(cm1[0,0]+cm1[0,1])\n",
        "    Sensitivity = cm1[1,1]/(cm1[1,0]+cm1[1,1])\n",
        "    cutoff_df.loc[i] =[ i ,Accuracy,Sensitivity,Specificity]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W31LSzov1tCt"
      },
      "outputs": [],
      "source": [
        "cutoff_df[['Accuracy','Sensitivity','Specificity']].plot()\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P6CIKT94Jqye"
      },
      "outputs": [],
      "source": [
        "i = 0.025\n",
        "cm1 = confusion_matrix(y_val_true, df_val_pred[i])\n",
        "total1=sum(sum(cm1))\n",
        "Accuracy = (cm1[0,0]+cm1[1,1])/total1\n",
        "Specificity = cm1[0,0]/(cm1[0,0]+cm1[0,1])\n",
        "Sensitivity = cm1[1,1]/(cm1[1,0]+cm1[1,1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3U2tkFebL_VC"
      },
      "outputs": [],
      "source": [
        "print('Accuracy: ', Accuracy)\n",
        "print('Sensitivity: ', Sensitivity)\n",
        "print('Specificity: ', Specificity)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eaK4zbtoaAaC"
      },
      "source": [
        "#Confusion Metric on Validation Set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YkPOFLehOmFg"
      },
      "outputs": [],
      "source": [
        "#change melanoma flag back to 4\n",
        "df_val_pred[df_val_pred[i] == 1] = 4\n",
        "#decode one-hot y_val_pred while use cut-off melanoma data\n",
        "condition = df_val_pred[i] == 4\n",
        "y_val_pred2 = np.where(condition, df_val_pred[i], np.argmax(y_val_pred, axis=1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LOVl6dWlTDLo"
      },
      "outputs": [],
      "source": [
        "print('Accuracy: ',accuracy_score(np.argmax(y_val, axis=1), y_val_pred2))\n",
        "print('Balanced accuracy: ',balanced_accuracy_score(np.argmax(y_val, axis=1), y_val_pred2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mqvYutTKRhR_"
      },
      "outputs": [],
      "source": [
        "#Get the confusion matrix\n",
        "cf_matrix = confusion_matrix(np.argmax(y_val, axis=1), y_val_pred2)\n",
        "print(cf_matrix)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gVtvW3YeaLlC"
      },
      "outputs": [],
      "source": [
        "ax = sns.heatmap(cf_matrix / cf_matrix.sum(axis=1, keepdims=True), annot=True, \n",
        "            cmap='Blues')\n",
        "\n",
        "ax.set_title('Confusion Matrix \\n');\n",
        "ax.set_xlabel('\\nPredicted')\n",
        "ax.set_ylabel('Actual ');\n",
        "\n",
        "## Ticket labels - List must be in alphabetical order\n",
        "ax.xaxis.set_ticklabels(['AKIEC', 'BCC', 'BKL', 'DF', 'MEL', 'NV', 'VASC'])\n",
        "ax.yaxis.set_ticklabels(['AKIEC', 'BCC', 'BKL', 'DF', 'MEL', 'NV', 'VASC'])\n",
        "\n",
        "plt.rcParams[\"figure.figsize\"] = (15,3)\n",
        "\n",
        "## Display the visualization of the Confusion Matrix.\n",
        "plt.xticks(rotation=45, ha='right')\n",
        "plt.yticks(rotation=0, ha='right')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ey-1yjWGeKs7"
      },
      "outputs": [],
      "source": [
        "# ordered count of rows per unique label\n",
        "#labels_count = df_val['Labels'].value_counts().sort_index()\n",
        "\n",
        "#f = plt.figure(figsize=(15, 6))\n",
        "#s = sns.barplot(x=labels_count.index,y=labels_count.values)\n",
        "#s.set_xticklabels(s.get_xticklabels(), rotation = 30)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3K908bbiYwbS"
      },
      "source": [
        "#Testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cN98sOWPyT3P",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2316c488-05c7-4494-8159-333a4ec5c717"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1512, 224, 224, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "df_test = pd.read_pickle(path+\"isic2018_test.pkl\")\n",
        "X_test = df_test.loc[:, df_test.columns != 'y_train'].to_numpy()\n",
        "X_test = X_test.reshape(-1,224,224,3)\n",
        "X_test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NeMY2yvMYxsC"
      },
      "outputs": [],
      "source": [
        "dir_test = '/content/drive/MyDrive/PHD/Datasets/isic2018/ISIC2018_Task3_Test_Input/'\n",
        "filepaths = sorted( filter( lambda x: (os.path.isfile(os.path.join(dir_test, x))) and (x.endswith('.jpg')),\n",
        "                        os.listdir(dir_test) ) )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6ic95mefkpG3"
      },
      "outputs": [],
      "source": [
        "df_test = pd.DataFrame(filepaths, columns =['image'])\n",
        "df_test['FilePaths'] = dir_test + df_test['image']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NBa1TxPuY8ni"
      },
      "outputs": [],
      "source": [
        "df_test['image_px'] = df_test['FilePaths'].map(lambda x: np.asarray(Image.open(x).resize(IMG_SIZE)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "60LYAT7VsNOZ",
        "outputId": "e2210f76-2e3a-4add-995e-79582acdab74"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1512, 128, 128, 3)\n"
          ]
        }
      ],
      "source": [
        "X_test = np.asarray(df_test['image_px'].tolist())\n",
        "print(np.array(X_test).shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cXnnIIwC4cHE"
      },
      "outputs": [],
      "source": [
        "#preprocess\n",
        "X_test = preprocess_image_input(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JC17MArBxhSW"
      },
      "outputs": [],
      "source": [
        "df3 = pd.DataFrame(X_test.reshape(X_test.shape[0],-1))\n",
        "df3.to_pickle(path+\"isic2018_test_128px.pkl\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FF7ml90JZ8FK"
      },
      "source": [
        "Calculate y_pred from training and testing for analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KeDTXdaMLmyU",
        "outputId": "a6ea64da-79f0-424f-f913-5b0bd6c66170"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(1512, 2048)"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#FOR MAKING FEATURE SPACE DATA\n",
        "X_test = model1.predict(X_test)\n",
        "X_test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dIX0AmEFNv3Y",
        "outputId": "0ed9a370-faec-457b-8d99-7c7de11457df"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "48/48 [==============================] - 2s 46ms/step\n",
            "Y_pred2 (1512, 7)\n"
          ]
        }
      ],
      "source": [
        "# predicting\n",
        "#CHANGE THE MODEL IF NECESSARY\n",
        "Y_pred2 = best_model.predict(X_test)\n",
        "#Y_pred2 = model2.predict(X_test)\n",
        "print(\"Y_pred2\", Y_pred2.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7oeArO5CtxGb"
      },
      "outputs": [],
      "source": [
        "df_pred = pd.DataFrame(Y_pred2, columns = ['AKIEC', 'BCC', 'BKL', 'DF', 'MEL', 'NV', 'VASC'])\n",
        "df_pred['image'] = df_test['FilePaths'].map(lambda x: x.replace(dir_test, '').replace('.jpg', ''))\n",
        "df_pred = df_pred[['image', 'MEL', 'NV', 'BCC', 'AKIEC', 'BKL', 'DF', 'VASC']]\n",
        "df_pred.set_index(\"image\", inplace = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9ynyd8PjT589"
      },
      "outputs": [],
      "source": [
        "#update MEL data using cut-off value\n",
        "df_pred.MEL[df_pred.MEL > i] = 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fjRdONoQVMq0"
      },
      "outputs": [],
      "source": [
        "df_pred.loc[df_pred.MEL > i, ['NV', 'BCC', 'AKIEC', 'BKL', 'DF', 'VASC']] = 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K4Iv_3s4z0R9"
      },
      "outputs": [],
      "source": [
        "df_pred.head(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sOnjc3RJ0e4T"
      },
      "outputs": [],
      "source": [
        "df_pred.to_csv('/content/drive/MyDrive/PHD/Datasets/isic2018/response_50epochs-128px-SMOTE.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P0MghVs0tsGw"
      },
      "source": [
        "result: 0.601"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UswA0co2y1wl"
      },
      "source": [
        "#Exp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dnqJYIONy34l"
      },
      "outputs": [],
      "source": [
        "input_tensor = Input(shape=(IMAGE_H, IMAGE_W, 3))\n",
        "base_model = ResNet50(input_shape=(224,224,3), weights='imagenet', include_top=False)\n",
        "x = base_model(input_tensor, training=False)\n",
        "x = Attention(2048,2048,7,8)(x)\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "res50 = Model(inputs=input_tensor, outputs=x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kcn8hQg3J8yP"
      },
      "outputs": [],
      "source": [
        "#Train i-last layer\n",
        "# summarize feature map shapes\n",
        "for i in range(len(model.layers)):\n",
        "    layer = model.layers[i]\n",
        "    # summarize output shape\n",
        "    print(i, layer.name, layer.output.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UA7Af2Y73FUv"
      },
      "outputs": [],
      "source": [
        "X_train = res50.predict(X_train)\n",
        "X_val = res50.predict(X_val)\n",
        "print(X_train.shape)\n",
        "print(y_train.shape)\n",
        "print(X_val.shape)\n",
        "print(y_val.shape)\n",
        "print('Counter train data: ', Counter(np.argmax(y_train, axis=1)))\n",
        "print('Counter val data: ', Counter(np.argmax(y_val, axis=1)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "krJiAb1m3QNf"
      },
      "outputs": [],
      "source": [
        "X_train, y_train = SMOTE_Data2(X_train, y_train, True)\n",
        "print(X_train.shape)\n",
        "print(y_train.shape)\n",
        "print(X_val.shape)\n",
        "print(y_val.shape)\n",
        "print('Counter train data: ', Counter(np.argmax(y_train, axis=1)))\n",
        "print('Counter val data: ', Counter(np.argmax(y_val, axis=1)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LfcFpsBwM0d4"
      },
      "source": [
        "#Attention"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 398
        },
        "id": "C_s6OIGKM26a",
        "outputId": "371bd24a-4bf9-491a-e0ec-78b7eb06e6d9"
      },
      "outputs": [
        {
          "ename": "AttributeError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-ff488085aaa5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mConv2D\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mMaxPooling2D\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mAveragePooling2D\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mBatchNormalization\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mAdd\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mZeroPadding2D\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mFlatten\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mInput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mLeakyReLU\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mSoftmax\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mReLU\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAdam\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    471\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_current_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"keras\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    472\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 473\u001b[0;31m     \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    474\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    475\u001b[0m     \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/lazy_loader.py\u001b[0m in \u001b[0;36m_load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;34m\"\"\"Load the module and insert it into the parent's globals.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0;31m# Import the target module and insert it into the parent's namespace\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m     \u001b[0mmodule\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimportlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimport_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_module_globals\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_local_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/importlib/__init__.py\u001b[0m in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m    125\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m             \u001b[0mlevel\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_bootstrap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gcd_import\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpackage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;31m# See b/110718070#comment18 for more details about this import.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_layer\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mInput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/models.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv2\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmetrics\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmetrics_module\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0moptimizer_v1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfunctional\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/metrics.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mwarnings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mactivations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbase_layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/activations.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0madvanced_activations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgeneric_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdeserialize_keras_object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgeneric_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mserialize_keras_object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/layers/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_spec\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mInputSpec\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_layer\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLayer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_preprocessing_layer\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPreprocessingLayer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;31m# Image preprocessing layers.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/base_preprocessing_layer.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mabc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdata_adapter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_layer\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLayer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mversion_utils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m   \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m  \u001b[0;31m# pylint: disable=g-import-not-at-top\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m   \u001b[0mpd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tester\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 179\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtesting\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    180\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/testing.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m from pandas._testing import (\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0massert_extension_array_equal\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0massert_frame_equal\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/_testing/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    946\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    947\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 948\u001b[0;31m \u001b[0mcython_table\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommon\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cython_table\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    949\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    950\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: module 'pandas' has no attribute 'core'"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow.keras as tk\n",
        "from tensorflow.keras.layers import Conv2D,MaxPooling2D,AveragePooling2D,BatchNormalization,Add,ZeroPadding2D,Flatten,Dense,Input,LeakyReLU,Softmax,ReLU\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.models import Model\n",
        "import numpy as np\n",
        "import pickle\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "\n",
        "class Attention(tk.layers.Layer):\n",
        "    \n",
        "    def __init__(self,input_channels,output_channel,kernel_size,groups):\n",
        "        super().__init__()\n",
        "        self.input_channels = input_channels\n",
        "        self.output_channel = output_channel    \n",
        "        self.kernel_size = kernel_size\n",
        "        self.stride = 1\n",
        "        self.groups = groups\n",
        "\n",
        "        assert output_channel % groups == 0\n",
        "        \n",
        "        self.rel_h = tk.backend.variable(lambda : tk.backend.truncated_normal((1,1,kernel_size,1,output_channel//2),stddev = 0.1)) \n",
        "        #output_channels//2 is the number of channels on which the relative position will be considered,1 denotes the number of those filters and the one after that too and (kernel_size,1) denotes the size of that filter\n",
        "        self.rel_w = tk.backend.variable(lambda : tk.backend.truncated_normal((1,1,1,kernel_size,output_channel//2),stddev = 0.1)) \n",
        "\n",
        "        self.key_weights = Conv2D(self.output_channel,kernel_size = 1,strides = self.stride)\n",
        "        self.query_weights = Conv2D(self.output_channel,kernel_size = 1,strides = self.stride)\n",
        "        self.value_weights = Conv2D(self.output_channel,kernel_size = 1,strides = self.stride)\n",
        "\n",
        "    def call(self,x):\n",
        "        \n",
        "        batch,height,width,channels = x.shape\n",
        "        x_padded = ZeroPadding2D(padding=(self.kernel_size//2,self.kernel_size//2))(x)\n",
        "        query = self.query_weights(x)\n",
        "        value = self.value_weights(x_padded)\n",
        "        key = self.key_weights(x_padded)\n",
        "        #key,query and value will have the shape of (batch,height,width,depth)\n",
        "        keys = tf.image.extract_patches(images = key,sizes = [1,self.kernel_size,self.kernel_size,1],strides = [1,self.stride,self.stride,1],rates = [1,1,1,1], padding = \"VALID\")\n",
        "        value = tf.image.extract_patches(images = value,sizes = [1,self.kernel_size,self.kernel_size,1],strides = [1,self.stride,self.stride,1],rates = [1,1,1,1], padding = \"VALID\")\n",
        "        no_of_kernels = key.shape[-2] - self.kernel_size + 1\n",
        "        keys = tf.reshape(keys,shape = (-1,no_of_kernels, no_of_kernels,self.kernel_size,self.kernel_size,self.output_channel))\n",
        "        key_split_h,key_split_w = tf.split(keys,num_or_size_splits = 2,axis = -1)\n",
        "        key_with_rel = tk.layers.concatenate([key_split_h + self.rel_h,key_split_w + self.rel_w],axis = -1) \n",
        "        \n",
        "        #reshaping the query and key\n",
        "        key_with_rel = tf.reshape(key_with_rel,(-1,self.groups,no_of_kernels,no_of_kernels,self.kernel_size*self.kernel_size,self.output_channel//self.groups))\n",
        "        query  = tf.reshape(query,(-1,self.groups,no_of_kernels,no_of_kernels,1,self.output_channel//self.groups))        \n",
        "        value = tf.reshape(value,(-1,self.groups,no_of_kernels,no_of_kernels,self.kernel_size*self.kernel_size,self.output_channel//self.groups))\n",
        "        \n",
        "        #multiplication  of key and query\n",
        "        #assert key_with_rel.shape == query.shape        \n",
        "        key_prod_query = query*key_with_rel\n",
        "        \n",
        "        # Now the function is passed through the softmax and is multiplied with the values\n",
        "        s = Softmax(axis = -2)(key_prod_query)\n",
        "        y = tf.einsum('bnchwk,bnchwk->bnchk',s,value)\n",
        "        y = tf.reshape(y,(-1,height,width,self.output_channel))\n",
        "        return y\n",
        "\n",
        "    def get_config(self):\n",
        "        config = super().get_config().copy()\n",
        "        config.update({\n",
        "            \"input_channels\": self.input_channels, \n",
        "            \"output_channel\": self.output_channel, \n",
        "            \"kernel_size\": self.kernel_size, \n",
        "            \"stride\": self.stride, \n",
        "            \"groups\": self.groups, \n",
        "            \"rel_h\": self.rel_h, \n",
        "            \"rel_w\": self.rel_w, \n",
        "            \"key_weights\": self.key_weights, \n",
        "            \"query_weights\": self.query_weights, \n",
        "            \"value_weights\": self.value_weights\n",
        "        })\n",
        "        return config\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kE8Ziq-BlEP4"
      },
      "source": [
        "#Oversampling on feature map level"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = best_model"
      ],
      "metadata": {
        "id": "wqfEP5L9BgcF"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lm05Zet_B5am",
        "outputId": "fbfdf6eb-85ab-47da-dd67-9144153e76fe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 input_1 [(None, 128, 128, 3)] True\n",
            "1 resnet50 (None, 4, 4, 2048) True\n",
            "2 global_average_pooling2d (None, 2048) True\n",
            "3 flatten (None, 2048) True\n",
            "4 dense (None, 1024) True\n",
            "5 dense_1 (None, 512) True\n",
            "6 dense_2 (None, 7) True\n"
          ]
        }
      ],
      "source": [
        "for i in range(len(model.layers)):\n",
        "  layer = model.layers[i]\n",
        "  print(i, layer.name, layer.output_shape, layer.trainable)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "KqeSic6NmLsR"
      },
      "outputs": [],
      "source": [
        "# redefine model to output right after the first hidden layer\n",
        "end = 2\n",
        "model1 = Model(inputs=model.inputs, outputs=model.layers[end].output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "ZVHYG9Rwm28i",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "458bfcaa-caad-4ada-9451-8f940b72defa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "146/146 [==============================] - 6s 33ms/step\n",
            "7/7 [==============================] - 0s 31ms/step\n"
          ]
        }
      ],
      "source": [
        "# get feature map for first hidden layer\n",
        "X_train_fm = model1.predict(X_train)\n",
        "X_val_fm = model1.predict(X_val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "Xx0OnnZPl7_t",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dfdab64b-92ae-4ca5-b79f-80072a38ff32"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(4651, 2048)\n",
            "(4651, 7)\n",
            "(193, 2048)\n",
            "(193, 7)\n",
            "Counter train data:  Counter({5: 1341, 4: 1113, 2: 1099, 1: 514, 0: 327, 6: 142, 3: 115})\n",
            "Counter val data:  Counter({5: 123, 2: 22, 4: 21, 1: 15, 0: 8, 6: 3, 3: 1})\n"
          ]
        }
      ],
      "source": [
        "print(X_train_fm.shape)\n",
        "print(y_train.shape)\n",
        "print(X_val_fm.shape)\n",
        "print(y_val.shape)\n",
        "print('Counter train data: ', Counter(np.argmax(y_train, axis=1)))\n",
        "print('Counter val data: ', Counter(np.argmax(y_val, axis=1)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "19hK7aQNeAQo",
        "outputId": "692063d8-a6c6-4ed3-d48b-ad35990afbaf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(9987, 2048)\n",
            "(9987, 7)\n",
            "(193, 2048)\n",
            "(193, 7)\n",
            "Counter train data:  Counter({5: 1441, 4: 1441, 2: 1441, 0: 1441, 1: 1441, 6: 1441, 3: 1341})\n",
            "Counter val data:  Counter({5: 123, 2: 22, 4: 21, 1: 15, 0: 8, 6: 3, 3: 1})\n"
          ]
        }
      ],
      "source": [
        "X_train_fm_ov, y_train_ov = SMOTE_Data2(X_train, y_train, True, 5, type=\"borderline\")\n",
        "print(X_train_fm_ov.shape)\n",
        "print(y_train_ov.shape)\n",
        "print(X_val_fm.shape)\n",
        "print(y_val.shape)\n",
        "print('Counter train data: ', Counter(np.argmax(y_train_ov, axis=1)))\n",
        "print('Counter val data: ', Counter(np.argmax(y_val, axis=1)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "5qP4iyYcnAYa"
      },
      "outputs": [],
      "source": [
        "model2 = Model(inputs=model.layers[end+1].input, outputs=model.layers[len(model.layers)-1].output)\n",
        "#model2 = define_base_model(arch = 'dense')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pzdjs0WbvDB0",
        "outputId": "2f3c4624-af07-4c16-cfe6-295695195aff"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "best_model_fpath:/content/drive/MyDrive/PHD/Model/best_model_borderline_after_smote_on_featurespace_under80_128px.h5\n",
            "last_model_fpath:/content/drive/MyDrive/PHD/Model/last_model_borderline_after_smote_on_featurespace_under80_128px.h5\n",
            "Epoch 1/50\n",
            "153/156 [============================>.] - ETA: 0s - loss: 0.4016 - accuracy: 0.8682 - balanced_acc: 0.8692\n",
            "Epoch 1: val_balanced_acc improved from -inf to 0.42675, saving model to /content/drive/MyDrive/PHD/Model/best_model_borderline_after_smote_on_featurespace_under80_128px.h5\n",
            "156/156 [==============================] - 2s 6ms/step - loss: 0.4016 - accuracy: 0.8682 - balanced_acc: 0.8693 - val_loss: 0.6877 - val_accuracy: 0.7202 - val_balanced_acc: 0.4267 - lr: 0.0010\n",
            "Epoch 2/50\n",
            "149/156 [===========================>..] - ETA: 0s - loss: 0.3630 - accuracy: 0.8827 - balanced_acc: 0.8791\n",
            "Epoch 2: val_balanced_acc did not improve from 0.42675\n",
            "156/156 [==============================] - 1s 4ms/step - loss: 0.3636 - accuracy: 0.8818 - balanced_acc: 0.8785 - val_loss: 0.6546 - val_accuracy: 0.7617 - val_balanced_acc: 0.4160 - lr: 0.0010\n",
            "Epoch 3/50\n",
            "144/156 [==========================>...] - ETA: 0s - loss: 0.3374 - accuracy: 0.8924 - balanced_acc: 0.8888\n",
            "Epoch 3: val_balanced_acc did not improve from 0.42675\n",
            "156/156 [==============================] - 1s 4ms/step - loss: 0.3386 - accuracy: 0.8919 - balanced_acc: 0.8887 - val_loss: 0.6659 - val_accuracy: 0.7461 - val_balanced_acc: 0.4081 - lr: 0.0010\n",
            "Epoch 4/50\n",
            "153/156 [============================>.] - ETA: 0s - loss: 0.3193 - accuracy: 0.9011 - balanced_acc: 0.8976\n",
            "Epoch 4: val_balanced_acc improved from 0.42675 to 0.43782, saving model to /content/drive/MyDrive/PHD/Model/best_model_borderline_after_smote_on_featurespace_under80_128px.h5\n",
            "156/156 [==============================] - 1s 4ms/step - loss: 0.3201 - accuracy: 0.9005 - balanced_acc: 0.8972 - val_loss: 0.6597 - val_accuracy: 0.7513 - val_balanced_acc: 0.4378 - lr: 0.0010\n",
            "Epoch 5/50\n",
            "145/156 [==========================>...] - ETA: 0s - loss: 0.3072 - accuracy: 0.9042 - balanced_acc: 0.9002\n",
            "Epoch 5: val_balanced_acc did not improve from 0.43782\n",
            "156/156 [==============================] - 1s 4ms/step - loss: 0.3089 - accuracy: 0.9024 - balanced_acc: 0.8986 - val_loss: 0.6315 - val_accuracy: 0.7617 - val_balanced_acc: 0.4189 - lr: 0.0010\n",
            "Epoch 6/50\n",
            "155/156 [============================>.] - ETA: 0s - loss: 0.2947 - accuracy: 0.9071 - balanced_acc: 0.9065\n",
            "Epoch 6: val_balanced_acc did not improve from 0.43782\n",
            "156/156 [==============================] - 1s 4ms/step - loss: 0.2948 - accuracy: 0.9072 - balanced_acc: 0.9066 - val_loss: 0.6740 - val_accuracy: 0.7306 - val_balanced_acc: 0.4000 - lr: 0.0010\n",
            "Epoch 7/50\n",
            "143/156 [==========================>...] - ETA: 0s - loss: 0.2854 - accuracy: 0.9118 - balanced_acc: 0.9148\n",
            "Epoch 7: val_balanced_acc improved from 0.43782 to 0.45081, saving model to /content/drive/MyDrive/PHD/Model/best_model_borderline_after_smote_on_featurespace_under80_128px.h5\n",
            "156/156 [==============================] - 1s 4ms/step - loss: 0.2854 - accuracy: 0.9117 - balanced_acc: 0.9148 - val_loss: 0.6830 - val_accuracy: 0.7358 - val_balanced_acc: 0.4508 - lr: 0.0010\n",
            "Epoch 8/50\n",
            "155/156 [============================>.] - ETA: 0s - loss: 0.2753 - accuracy: 0.9149 - balanced_acc: 0.9115\n",
            "Epoch 8: val_balanced_acc improved from 0.45081 to 0.45762, saving model to /content/drive/MyDrive/PHD/Model/best_model_borderline_after_smote_on_featurespace_under80_128px.h5\n",
            "156/156 [==============================] - 1s 4ms/step - loss: 0.2757 - accuracy: 0.9147 - balanced_acc: 0.9113 - val_loss: 0.6377 - val_accuracy: 0.7617 - val_balanced_acc: 0.4576 - lr: 0.0010\n",
            "Epoch 9/50\n",
            "142/156 [==========================>...] - ETA: 0s - loss: 0.2705 - accuracy: 0.9157 - balanced_acc: 0.9120\n",
            "Epoch 9: val_balanced_acc improved from 0.45762 to 0.45975, saving model to /content/drive/MyDrive/PHD/Model/best_model_borderline_after_smote_on_featurespace_under80_128px.h5\n",
            "156/156 [==============================] - 1s 4ms/step - loss: 0.2666 - accuracy: 0.9174 - balanced_acc: 0.9136 - val_loss: 0.6718 - val_accuracy: 0.7617 - val_balanced_acc: 0.4597 - lr: 0.0010\n",
            "Epoch 10/50\n",
            "141/156 [==========================>...] - ETA: 0s - loss: 0.2623 - accuracy: 0.9206 - balanced_acc: 0.9167\n",
            "Epoch 10: val_balanced_acc did not improve from 0.45975\n",
            "156/156 [==============================] - 1s 3ms/step - loss: 0.2622 - accuracy: 0.9203 - balanced_acc: 0.9169 - val_loss: 0.6259 - val_accuracy: 0.7720 - val_balanced_acc: 0.4230 - lr: 0.0010\n",
            "Epoch 11/50\n",
            "143/156 [==========================>...] - ETA: 0s - loss: 0.2528 - accuracy: 0.9249 - balanced_acc: 0.9216\n",
            "Epoch 11: val_balanced_acc did not improve from 0.45975\n",
            "156/156 [==============================] - 1s 3ms/step - loss: 0.2522 - accuracy: 0.9248 - balanced_acc: 0.9220 - val_loss: 0.6355 - val_accuracy: 0.7617 - val_balanced_acc: 0.4208 - lr: 0.0010\n",
            "Epoch 12/50\n",
            "144/156 [==========================>...] - ETA: 0s - loss: 0.2451 - accuracy: 0.9258 - balanced_acc: 0.9233\n",
            "Epoch 12: val_balanced_acc did not improve from 0.45975\n",
            "156/156 [==============================] - 1s 3ms/step - loss: 0.2454 - accuracy: 0.9260 - balanced_acc: 0.9240 - val_loss: 0.6528 - val_accuracy: 0.7513 - val_balanced_acc: 0.4140 - lr: 0.0010\n",
            "Epoch 13/50\n",
            "144/156 [==========================>...] - ETA: 0s - loss: 0.2395 - accuracy: 0.9292 - balanced_acc: 0.9299\n",
            "Epoch 13: val_balanced_acc did not improve from 0.45975\n",
            "156/156 [==============================] - 1s 3ms/step - loss: 0.2394 - accuracy: 0.9296 - balanced_acc: 0.9300 - val_loss: 0.7099 - val_accuracy: 0.7409 - val_balanced_acc: 0.4123 - lr: 0.0010\n",
            "Epoch 14/50\n",
            "142/156 [==========================>...] - ETA: 0s - loss: 0.2288 - accuracy: 0.9325 - balanced_acc: 0.9293\n",
            "Epoch 14: val_balanced_acc did not improve from 0.45975\n",
            "156/156 [==============================] - 1s 3ms/step - loss: 0.2293 - accuracy: 0.9317 - balanced_acc: 0.9288 - val_loss: 0.7138 - val_accuracy: 0.7358 - val_balanced_acc: 0.4166 - lr: 0.0010\n",
            "Epoch 15/50\n",
            "145/156 [==========================>...] - ETA: 0s - loss: 0.2276 - accuracy: 0.9322 - balanced_acc: 0.9265\n",
            "Epoch 15: val_balanced_acc did not improve from 0.45975\n",
            "156/156 [==============================] - 1s 3ms/step - loss: 0.2278 - accuracy: 0.9316 - balanced_acc: 0.9264 - val_loss: 0.6547 - val_accuracy: 0.7565 - val_balanced_acc: 0.4214 - lr: 0.0010\n",
            "Epoch 16/50\n",
            "144/156 [==========================>...] - ETA: 0s - loss: 0.2190 - accuracy: 0.9349 - balanced_acc: 0.9314\n",
            "Epoch 16: val_balanced_acc did not improve from 0.45975\n",
            "156/156 [==============================] - 1s 3ms/step - loss: 0.2203 - accuracy: 0.9348 - balanced_acc: 0.9317 - val_loss: 0.6975 - val_accuracy: 0.7409 - val_balanced_acc: 0.4270 - lr: 0.0010\n",
            "Epoch 17/50\n",
            "142/156 [==========================>...] - ETA: 0s - loss: 0.2144 - accuracy: 0.9381 - balanced_acc: 0.9353\n",
            "Epoch 17: val_balanced_acc did not improve from 0.45975\n",
            "156/156 [==============================] - 1s 3ms/step - loss: 0.2142 - accuracy: 0.9375 - balanced_acc: 0.9354 - val_loss: 0.6577 - val_accuracy: 0.7617 - val_balanced_acc: 0.4202 - lr: 0.0010\n",
            "Epoch 18/50\n",
            "143/156 [==========================>...] - ETA: 0s - loss: 0.2134 - accuracy: 0.9384 - balanced_acc: 0.9353\n",
            "Epoch 18: val_balanced_acc improved from 0.45975 to 0.46312, saving model to /content/drive/MyDrive/PHD/Model/best_model_borderline_after_smote_on_featurespace_under80_128px.h5\n",
            "156/156 [==============================] - 1s 4ms/step - loss: 0.2152 - accuracy: 0.9370 - balanced_acc: 0.9347 - val_loss: 0.6686 - val_accuracy: 0.7617 - val_balanced_acc: 0.4631 - lr: 0.0010\n",
            "Epoch 19/50\n",
            "141/156 [==========================>...] - ETA: 0s - loss: 0.2042 - accuracy: 0.9408 - balanced_acc: 0.9396\n",
            "Epoch 19: val_balanced_acc did not improve from 0.46312\n",
            "156/156 [==============================] - 1s 3ms/step - loss: 0.2060 - accuracy: 0.9400 - balanced_acc: 0.9392 - val_loss: 0.6387 - val_accuracy: 0.7668 - val_balanced_acc: 0.4234 - lr: 0.0010\n",
            "Epoch 20/50\n",
            "143/156 [==========================>...] - ETA: 0s - loss: 0.2034 - accuracy: 0.9412 - balanced_acc: 0.9396\n",
            "Epoch 20: val_balanced_acc did not improve from 0.46312\n",
            "156/156 [==============================] - 1s 3ms/step - loss: 0.2032 - accuracy: 0.9409 - balanced_acc: 0.9390 - val_loss: 0.6606 - val_accuracy: 0.7565 - val_balanced_acc: 0.4151 - lr: 0.0010\n",
            "Epoch 21/50\n",
            "144/156 [==========================>...] - ETA: 0s - loss: 0.1987 - accuracy: 0.9410 - balanced_acc: 0.9373\n",
            "Epoch 21: val_balanced_acc did not improve from 0.46312\n",
            "156/156 [==============================] - 1s 3ms/step - loss: 0.1991 - accuracy: 0.9415 - balanced_acc: 0.9379 - val_loss: 0.7158 - val_accuracy: 0.7513 - val_balanced_acc: 0.4173 - lr: 0.0010\n",
            "Epoch 22/50\n",
            "146/156 [===========================>..] - ETA: 0s - loss: 0.1941 - accuracy: 0.9443 - balanced_acc: 0.9418\n",
            "Epoch 22: val_balanced_acc did not improve from 0.46312\n",
            "156/156 [==============================] - 1s 3ms/step - loss: 0.1933 - accuracy: 0.9444 - balanced_acc: 0.9421 - val_loss: 0.7183 - val_accuracy: 0.7409 - val_balanced_acc: 0.4561 - lr: 0.0010\n",
            "Epoch 23/50\n",
            "142/156 [==========================>...] - ETA: 0s - loss: 0.1896 - accuracy: 0.9484 - balanced_acc: 0.9475\n",
            "Epoch 23: val_balanced_acc did not improve from 0.46312\n",
            "156/156 [==============================] - 1s 3ms/step - loss: 0.1873 - accuracy: 0.9498 - balanced_acc: 0.9489 - val_loss: 0.6852 - val_accuracy: 0.7513 - val_balanced_acc: 0.4239 - lr: 0.0010\n",
            "Epoch 24/50\n",
            "143/156 [==========================>...] - ETA: 0s - loss: 0.1883 - accuracy: 0.9474 - balanced_acc: 0.9451\n",
            "Epoch 24: val_balanced_acc did not improve from 0.46312\n",
            "156/156 [==============================] - 1s 3ms/step - loss: 0.1875 - accuracy: 0.9482 - balanced_acc: 0.9459 - val_loss: 0.6669 - val_accuracy: 0.7617 - val_balanced_acc: 0.4225 - lr: 0.0010\n",
            "Epoch 25/50\n",
            "145/156 [==========================>...] - ETA: 0s - loss: 0.1822 - accuracy: 0.9491 - balanced_acc: 0.9462\n",
            "Epoch 25: val_balanced_acc did not improve from 0.46312\n",
            "156/156 [==============================] - 1s 3ms/step - loss: 0.1808 - accuracy: 0.9495 - balanced_acc: 0.9464 - val_loss: 0.6831 - val_accuracy: 0.7565 - val_balanced_acc: 0.4214 - lr: 0.0010\n",
            "Epoch 26/50\n",
            "141/156 [==========================>...] - ETA: 0s - loss: 0.1805 - accuracy: 0.9500 - balanced_acc: 0.9476\n",
            "Epoch 26: val_balanced_acc did not improve from 0.46312\n",
            "156/156 [==============================] - 1s 3ms/step - loss: 0.1815 - accuracy: 0.9497 - balanced_acc: 0.9475 - val_loss: 0.6915 - val_accuracy: 0.7461 - val_balanced_acc: 0.3955 - lr: 0.0010\n",
            "Epoch 27/50\n",
            "145/156 [==========================>...] - ETA: 0s - loss: 0.1762 - accuracy: 0.9516 - balanced_acc: 0.9482\n",
            "Epoch 27: val_balanced_acc did not improve from 0.46312\n",
            "156/156 [==============================] - 1s 3ms/step - loss: 0.1756 - accuracy: 0.9519 - balanced_acc: 0.9491 - val_loss: 0.6899 - val_accuracy: 0.7565 - val_balanced_acc: 0.4205 - lr: 0.0010\n",
            "Epoch 28/50\n",
            "144/156 [==========================>...] - ETA: 0s - loss: 0.1723 - accuracy: 0.9520 - balanced_acc: 0.9467\n",
            "Epoch 28: val_balanced_acc did not improve from 0.46312\n",
            "156/156 [==============================] - 1s 3ms/step - loss: 0.1720 - accuracy: 0.9524 - balanced_acc: 0.9477 - val_loss: 0.6772 - val_accuracy: 0.7668 - val_balanced_acc: 0.4315 - lr: 0.0010\n",
            "Epoch 29/50\n",
            "154/156 [============================>.] - ETA: 0s - loss: 0.1681 - accuracy: 0.9533 - balanced_acc: 0.9501\n",
            "Epoch 29: val_balanced_acc did not improve from 0.46312\n",
            "156/156 [==============================] - 1s 4ms/step - loss: 0.1691 - accuracy: 0.9530 - balanced_acc: 0.9498 - val_loss: 0.6537 - val_accuracy: 0.7565 - val_balanced_acc: 0.4154 - lr: 0.0010\n",
            "Epoch 30/50\n",
            "144/156 [==========================>...] - ETA: 0s - loss: 0.1652 - accuracy: 0.9552 - balanced_acc: 0.9526\n",
            "Epoch 30: val_balanced_acc did not improve from 0.46312\n",
            "156/156 [==============================] - 1s 3ms/step - loss: 0.1673 - accuracy: 0.9541 - balanced_acc: 0.9520 - val_loss: 0.6963 - val_accuracy: 0.7617 - val_balanced_acc: 0.4271 - lr: 0.0010\n",
            "Epoch 31/50\n",
            "145/156 [==========================>...] - ETA: 0s - loss: 0.1615 - accuracy: 0.9567 - balanced_acc: 0.9526\n",
            "Epoch 31: val_balanced_acc did not improve from 0.46312\n",
            "156/156 [==============================] - 1s 3ms/step - loss: 0.1616 - accuracy: 0.9566 - balanced_acc: 0.9528 - val_loss: 0.6431 - val_accuracy: 0.7668 - val_balanced_acc: 0.4197 - lr: 0.0010\n",
            "Epoch 32/50\n",
            "142/156 [==========================>...] - ETA: 0s - loss: 0.1595 - accuracy: 0.9564 - balanced_acc: 0.9530\n",
            "Epoch 32: val_balanced_acc did not improve from 0.46312\n",
            "156/156 [==============================] - 1s 3ms/step - loss: 0.1601 - accuracy: 0.9563 - balanced_acc: 0.9531 - val_loss: 0.6407 - val_accuracy: 0.7565 - val_balanced_acc: 0.4211 - lr: 0.0010\n",
            "Epoch 33/50\n",
            "143/156 [==========================>...] - ETA: 0s - loss: 0.1588 - accuracy: 0.9580 - balanced_acc: 0.9543\n",
            "Epoch 33: val_balanced_acc did not improve from 0.46312\n",
            "156/156 [==============================] - 1s 3ms/step - loss: 0.1600 - accuracy: 0.9578 - balanced_acc: 0.9544 - val_loss: 0.6802 - val_accuracy: 0.7565 - val_balanced_acc: 0.4199 - lr: 0.0010\n",
            "Epoch 34/50\n",
            "143/156 [==========================>...] - ETA: 0s - loss: 0.1540 - accuracy: 0.9602 - balanced_acc: 0.9573\n",
            "Epoch 34: val_balanced_acc did not improve from 0.46312\n",
            "156/156 [==============================] - 1s 3ms/step - loss: 0.1527 - accuracy: 0.9606 - balanced_acc: 0.9577 - val_loss: 0.7330 - val_accuracy: 0.7461 - val_balanced_acc: 0.4260 - lr: 0.0010\n",
            "Epoch 35/50\n",
            "142/156 [==========================>...] - ETA: 0s - loss: 0.1524 - accuracy: 0.9599 - balanced_acc: 0.9568\n",
            "Epoch 35: val_balanced_acc did not improve from 0.46312\n",
            "156/156 [==============================] - 1s 3ms/step - loss: 0.1535 - accuracy: 0.9593 - balanced_acc: 0.9565 - val_loss: 0.6659 - val_accuracy: 0.7617 - val_balanced_acc: 0.4193 - lr: 0.0010\n",
            "Epoch 36/50\n",
            "141/156 [==========================>...] - ETA: 0s - loss: 0.1563 - accuracy: 0.9592 - balanced_acc: 0.9549\n",
            "Epoch 36: val_balanced_acc did not improve from 0.46312\n",
            "156/156 [==============================] - 1s 3ms/step - loss: 0.1552 - accuracy: 0.9599 - balanced_acc: 0.9559 - val_loss: 0.6999 - val_accuracy: 0.7513 - val_balanced_acc: 0.4184 - lr: 0.0010\n",
            "Epoch 37/50\n",
            "144/156 [==========================>...] - ETA: 0s - loss: 0.1438 - accuracy: 0.9634 - balanced_acc: 0.9574\n",
            "Epoch 37: val_balanced_acc did not improve from 0.46312\n",
            "156/156 [==============================] - 1s 3ms/step - loss: 0.1435 - accuracy: 0.9633 - balanced_acc: 0.9578 - val_loss: 0.6781 - val_accuracy: 0.7617 - val_balanced_acc: 0.4318 - lr: 0.0010\n",
            "Epoch 38/50\n",
            "144/156 [==========================>...] - ETA: 0s - loss: 0.1485 - accuracy: 0.9625 - balanced_acc: 0.9597\n",
            "Epoch 38: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "\n",
            "Epoch 38: val_balanced_acc did not improve from 0.46312\n",
            "156/156 [==============================] - 1s 3ms/step - loss: 0.1475 - accuracy: 0.9626 - balanced_acc: 0.9601 - val_loss: 0.6438 - val_accuracy: 0.7668 - val_balanced_acc: 0.4279 - lr: 0.0010\n",
            "Epoch 39/50\n",
            "142/156 [==========================>...] - ETA: 0s - loss: 0.1377 - accuracy: 0.9659 - balanced_acc: 0.9649\n",
            "Epoch 39: val_balanced_acc did not improve from 0.46312\n",
            "156/156 [==============================] - 1s 3ms/step - loss: 0.1372 - accuracy: 0.9660 - balanced_acc: 0.9652 - val_loss: 0.6817 - val_accuracy: 0.7617 - val_balanced_acc: 0.4318 - lr: 5.0000e-04\n",
            "Epoch 40/50\n",
            "143/156 [==========================>...] - ETA: 0s - loss: 0.1378 - accuracy: 0.9672 - balanced_acc: 0.9644\n",
            "Epoch 40: val_balanced_acc did not improve from 0.46312\n",
            "156/156 [==============================] - 1s 3ms/step - loss: 0.1380 - accuracy: 0.9665 - balanced_acc: 0.9640 - val_loss: 0.7267 - val_accuracy: 0.7513 - val_balanced_acc: 0.4269 - lr: 5.0000e-04\n",
            "Epoch 41/50\n",
            "141/156 [==========================>...] - ETA: 0s - loss: 0.1341 - accuracy: 0.9698 - balanced_acc: 0.9659\n",
            "Epoch 41: val_balanced_acc did not improve from 0.46312\n",
            "156/156 [==============================] - 1s 4ms/step - loss: 0.1364 - accuracy: 0.9685 - balanced_acc: 0.9651 - val_loss: 0.7219 - val_accuracy: 0.7565 - val_balanced_acc: 0.4340 - lr: 5.0000e-04\n",
            "Epoch 42/50\n",
            "151/156 [============================>.] - ETA: 0s - loss: 0.1360 - accuracy: 0.9672 - balanced_acc: 0.9633\n",
            "Epoch 42: val_balanced_acc did not improve from 0.46312\n",
            "156/156 [==============================] - 1s 4ms/step - loss: 0.1355 - accuracy: 0.9676 - balanced_acc: 0.9637 - val_loss: 0.7055 - val_accuracy: 0.7565 - val_balanced_acc: 0.4307 - lr: 5.0000e-04\n",
            "Epoch 43/50\n",
            "142/156 [==========================>...] - ETA: 0s - loss: 0.1388 - accuracy: 0.9671 - balanced_acc: 0.9639\n",
            "Epoch 43: val_balanced_acc did not improve from 0.46312\n",
            "156/156 [==============================] - 1s 3ms/step - loss: 0.1370 - accuracy: 0.9679 - balanced_acc: 0.9651 - val_loss: 0.6786 - val_accuracy: 0.7668 - val_balanced_acc: 0.4279 - lr: 5.0000e-04\n",
            "Epoch 44/50\n",
            "143/156 [==========================>...] - ETA: 0s - loss: 0.1312 - accuracy: 0.9698 - balanced_acc: 0.9651\n",
            "Epoch 44: val_balanced_acc did not improve from 0.46312\n",
            "156/156 [==============================] - 1s 3ms/step - loss: 0.1307 - accuracy: 0.9699 - balanced_acc: 0.9659 - val_loss: 0.6860 - val_accuracy: 0.7668 - val_balanced_acc: 0.4360 - lr: 5.0000e-04\n",
            "Epoch 45/50\n",
            "154/156 [============================>.] - ETA: 0s - loss: 0.1339 - accuracy: 0.9676 - balanced_acc: 0.9647\n",
            "Epoch 45: val_balanced_acc did not improve from 0.46312\n",
            "156/156 [==============================] - 1s 4ms/step - loss: 0.1346 - accuracy: 0.9677 - balanced_acc: 0.9648 - val_loss: 0.6957 - val_accuracy: 0.7565 - val_balanced_acc: 0.4277 - lr: 5.0000e-04\n",
            "Epoch 46/50\n",
            "143/156 [==========================>...] - ETA: 0s - loss: 0.1300 - accuracy: 0.9692 - balanced_acc: 0.9671\n",
            "Epoch 46: val_balanced_acc did not improve from 0.46312\n",
            "156/156 [==============================] - 1s 3ms/step - loss: 0.1316 - accuracy: 0.9689 - balanced_acc: 0.9666 - val_loss: 0.6940 - val_accuracy: 0.7668 - val_balanced_acc: 0.4360 - lr: 5.0000e-04\n",
            "Epoch 47/50\n",
            "145/156 [==========================>...] - ETA: 0s - loss: 0.1289 - accuracy: 0.9720 - balanced_acc: 0.9673\n",
            "Epoch 47: val_balanced_acc did not improve from 0.46312\n",
            "156/156 [==============================] - 1s 3ms/step - loss: 0.1296 - accuracy: 0.9713 - balanced_acc: 0.9663 - val_loss: 0.6926 - val_accuracy: 0.7617 - val_balanced_acc: 0.4271 - lr: 5.0000e-04\n",
            "Epoch 48/50\n",
            "144/156 [==========================>...] - ETA: 0s - loss: 0.1280 - accuracy: 0.9719 - balanced_acc: 0.9697\n",
            "Epoch 48: val_balanced_acc did not improve from 0.46312\n",
            "156/156 [==============================] - 1s 3ms/step - loss: 0.1306 - accuracy: 0.9709 - balanced_acc: 0.9693 - val_loss: 0.7107 - val_accuracy: 0.7513 - val_balanced_acc: 0.4251 - lr: 5.0000e-04\n",
            "Epoch 49/50\n",
            "143/156 [==========================>...] - ETA: 0s - loss: 0.1296 - accuracy: 0.9705 - balanced_acc: 0.9673\n",
            "Epoch 49: val_balanced_acc did not improve from 0.46312\n",
            "156/156 [==============================] - 1s 3ms/step - loss: 0.1295 - accuracy: 0.9707 - balanced_acc: 0.9677 - val_loss: 0.7301 - val_accuracy: 0.7409 - val_balanced_acc: 0.4171 - lr: 5.0000e-04\n",
            "Epoch 50/50\n",
            "142/156 [==========================>...] - ETA: 0s - loss: 0.1249 - accuracy: 0.9724 - balanced_acc: 0.9694\n",
            "Epoch 50: val_balanced_acc did not improve from 0.46312\n",
            "156/156 [==============================] - 1s 3ms/step - loss: 0.1254 - accuracy: 0.9724 - balanced_acc: 0.9696 - val_loss: 0.6951 - val_accuracy: 0.7668 - val_balanced_acc: 0.4360 - lr: 5.0000e-04\n"
          ]
        }
      ],
      "source": [
        "best_model_fpath = '/content/drive/MyDrive/PHD/Model/best_model_'+exp_name+'_'+dataset_name+'.h5'\n",
        "print(\"best_model_fpath:\"+best_model_fpath)\n",
        "last_model_fpath = '/content/drive/MyDrive/PHD/Model/last_model_'+exp_name+'_'+dataset_name+'.h5'\n",
        "print(\"last_model_fpath:\"+last_model_fpath)\n",
        "mc1 = ModelCheckpoint(best_model_fpath, monitor='val_balanced_acc', mode='max', verbose=1, save_best_only=True)\n",
        "learning_rate_reduction = ReduceLROnPlateau(monitor='val_balanced_acc', patience=20, verbose=1, factor=0.5, min_lr=0.00001)\n",
        "early_stopping_monitor = EarlyStopping(patience=40,monitor='val_balanced_acc')\n",
        "model2.compile(optimizer = opt_SGD , loss = \"categorical_crossentropy\", metrics=['accuracy', balanced_acc])\n",
        "hst = model2.fit(X_train_fm_ov, y_train_ov, epochs=EPOCHS, batch_size=BATCH_SIZE, validation_data=(X_val_fm, y_val), verbose=1,\n",
        "                    steps_per_epoch=X_train_fm_ov.shape[0] // BATCH_SIZE, \n",
        "                    #callbacks=[learning_rate_reduction,early_stopping_monitor, mc1])\n",
        "                    callbacks=[learning_rate_reduction,mc1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "8XhlbWn--8Or",
        "outputId": "69127b4a-c638-4449-a068-fd80494a4008"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "# summarize history for accuracy\n",
        "plt.plot(hst.history['accuracy'])\n",
        "plt.plot(hst.history['balanced_acc'])\n",
        "plt.plot(hst.history['val_accuracy'])\n",
        "plt.plot(hst.history['val_balanced_acc'])\n",
        "plt.title('Model accuracy')\n",
        "plt.ylabel('Performance')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train accuracy', 'train balanced acc.', 'val. accuracy', 'val. balanced acc.'], loc='lower right')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "u-x0SENPGmm9"
      },
      "outputs": [],
      "source": [
        "#save last model\n",
        "model2.save(last_model_fpath)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U-e3ZaeeG1Bf",
        "outputId": "43185207-f891-4f63-85ec-9a590e61815f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 0s 1ms/step\n",
            "7/7 [==============================] - 0s 2ms/step\n",
            "accuracy on training 0.9733653749874838\n",
            "balanced accuracy on training 0.9736294240111035\n",
            "accuracy on validation 0.7668393782383419\n",
            "balanced accuracy on validation 0.5717909558501892\n",
            "Score on val data:  (0.5185897435897436, 0.5717909558501892, 0.5377159543062507, None)\n"
          ]
        }
      ],
      "source": [
        "last_model = load_model(last_model_fpath, custom_objects={'balanced_acc' : balanced_acc})\n",
        "y_train_pred = last_model.predict(X_train_fm_ov)\n",
        "y_val_pred = last_model.predict(X_val_fm)\n",
        "\n",
        "#print('accuracy on training',accuracy_score(np.argmax(y_train, axis=1), np.argmax(y_train_pred, axis=1)))\n",
        "print('accuracy on training',accuracy_score(np.argmax(y_train_ov, axis=1), np.argmax(y_train_pred, axis=1)))\n",
        "print('balanced accuracy on training',balanced_accuracy_score(np.argmax(y_train_ov, axis=1), np.argmax(y_train_pred, axis=1)))\n",
        "print('accuracy on validation',accuracy_score(np.argmax(y_val, axis=1), np.argmax(y_val_pred, axis=1)))\n",
        "print('balanced accuracy on validation',balanced_accuracy_score(np.argmax(y_val, axis=1), np.argmax(y_val_pred, axis=1)))\n",
        "print('Score on val data: ',precision_recall_fscore_support(np.argmax(y_val, axis=1), np.argmax(y_val_pred, axis=1), average='macro'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EQ3baQLsHLat",
        "outputId": "71206047-eb2f-4c68-fc42-a6301a8a48c7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 0s 1ms/step\n",
            "7/7 [==============================] - 0s 2ms/step\n",
            "accuracy on training 0.9419245018524082\n",
            "balanced accuracy on training 0.9424854622354494\n",
            "accuracy on validation 0.7616580310880829\n",
            "balanced accuracy on validation 0.6986307826900162\n",
            "Score on val data:  (0.5416475972540045, 0.6986307826900162, 0.5756277857054772, None)\n"
          ]
        }
      ],
      "source": [
        "best_model = load_model(best_model_fpath, custom_objects={'balanced_acc' : balanced_acc})\n",
        "y_train_pred = best_model.predict(X_train_fm_ov)\n",
        "y_val_pred = best_model.predict(X_val_fm)\n",
        "\n",
        "print('accuracy on training',accuracy_score(np.argmax(y_train_ov, axis=1), np.argmax(y_train_pred, axis=1)))\n",
        "print('balanced accuracy on training',balanced_accuracy_score(np.argmax(y_train_ov, axis=1), np.argmax(y_train_pred, axis=1)))\n",
        "print('accuracy on validation',accuracy_score(np.argmax(y_val, axis=1), np.argmax(y_val_pred, axis=1)))\n",
        "print('balanced accuracy on validation',balanced_accuracy_score(np.argmax(y_val, axis=1), np.argmax(y_val_pred, axis=1)))\n",
        "print('Score on val data: ',precision_recall_fscore_support(np.argmax(y_val, axis=1), np.argmax(y_val_pred, axis=1), average='macro'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RcRGeofw-8tK"
      },
      "source": [
        "#Load ISIC 2018 Challange Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "l3P7IjyLuZGY"
      },
      "outputs": [],
      "source": [
        "X_train, y_train, X_val, y_val = load_isic2018_dataset(train_under_frac = train_under_frac)\n",
        "print(X_train.shape)\n",
        "print(y_train.shape)\n",
        "print(X_val.shape)\n",
        "print(y_val.shape)\n",
        "print('Counter train data: ', Counter(np.argmax(y_train, axis=1)))\n",
        "print('Counter val data: ', Counter(np.argmax(y_val, axis=1)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "XT95XFaHQD6d"
      },
      "outputs": [],
      "source": [
        "X_train = preprocess_image_input(X_train, the_arch)\n",
        "X_val = preprocess_image_input(X_val, the_arch)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path = '/content/drive/MyDrive/PHD/Datasets/isic2018/'\n",
        "df1 = pd.DataFrame(X_train.reshape(X_train.shape[0],-1))\n",
        "df1['y_train'] = np.argmax(y_train, axis=1).tolist()\n",
        "df2 = pd.DataFrame(X_val.reshape(X_val.shape[0],-1))\n",
        "df2['y_val'] = np.argmax(y_val, axis=1).tolist()\n",
        "df1.to_pickle(path+\"isic2018_train_\"+dataset_name+\".pkl\")\n",
        "df2.to_pickle(path+\"isic2018_val_\"+dataset_name+\".pkl\")"
      ],
      "metadata": {
        "id": "APHFdj25vatJ"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"dataset saved:\", dataset_name)"
      ],
      "metadata": {
        "id": "NMEfVJy052YF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c9642a12-986c-40c8-cd08-7a3d23ae1736"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dataset saved: under80_128px\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2IncA-_o_n5w"
      },
      "outputs": [],
      "source": [
        "# ordered count of rows per unique label\n",
        "labels_count = y_train.value_counts(ascending=True)\n",
        "\n",
        "f = plt.figure(figsize=(15, 6))\n",
        "s = sns.barplot(x=labels_count.index,y=labels_count.values)\n",
        "s.set_xticklabels(s.get_xticklabels(), rotation = 30)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AnKMKSb4Bkym"
      },
      "source": [
        "Plot 3 images per label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jdnVuqbFBW3K"
      },
      "outputs": [],
      "source": [
        "def plot_images_per_label(df, label, cols: int, size: tuple):\n",
        "    fig, axs = plt.subplots(nrows=1, ncols=cols, figsize=size)\n",
        "\n",
        "    cntMax = cols\n",
        "    cntCur = 0\n",
        "    for index, row in df.iterrows():\n",
        "        if(y_train == label and cntCur < cntMax):\n",
        "            axs[cntCur].imshow(plt.imread(df.FilePaths[index]))\n",
        "            axs[cntCur].set_title(df.Labels[index])\n",
        "\n",
        "            cntCur += 1\n",
        "        else:\n",
        "            if(cntCur >= cntMax):\n",
        "                break\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "# unique labels\n",
        "labels = sorted(df1['y_train'].unique())\n",
        "for label in range(7):\n",
        "    plot_images_per_label(df1, label, 3, (12,9))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "asV1O58Lrq-R"
      },
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "img = Image.fromarray(X_train[0], 'RGB')\n",
        "display(img)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qRKKrNacAZtl"
      },
      "source": [
        "Drop duplicate images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ERwfyPDHP-zC"
      },
      "outputs": [],
      "source": [
        "#df_group = pd.read_csv('/content/drive/MyDrive/PHD/Datasets/isic2018/ISIC2018_Task3_Training_LesionGroupings.csv') \n",
        "#df_train = df_train.set_index('image').join(df_group.set_index('image'))\n",
        "#df_train = df_train.drop_duplicates(subset=['lesion_id'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cNBXx28B9yGu"
      },
      "source": [
        "#DeepSMOTE Oversampling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YmX_Uqbmj-tN"
      },
      "outputs": [],
      "source": [
        "from numpy import moveaxis\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "max_el = np.inf\n",
        "\n",
        "args = {}\n",
        "args['dim_h'] = 64         # factor controlling size of hidden layers\n",
        "args['n_channel'] = 3#1    # number of channels in the input data \n",
        "args['n_z'] = 600 #300     # number of dimensions in latent space. \n",
        "args['sigma'] = 1.0        # variance in n_z\n",
        "args['lambda'] = 0.01      # hyper param for weight of discriminator loss\n",
        "args['lr'] = 0.0002        # learning rate for Adam optimizer .000\n",
        "args['epochs'] = 300       # how many epochs to run for\n",
        "args['batch_size'] = 100   # batch size for SGD\n",
        "args['save'] = True        # save weights at each epoch of training if True\n",
        "args['train'] = True       # train networks if True, else load networks from\n",
        "args['patience'] = 20"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NydOdPMajEfT"
      },
      "outputs": [],
      "source": [
        "class Encoder(nn.Module):\n",
        "    def __init__(self, args):\n",
        "        super(Encoder, self).__init__()\n",
        "\n",
        "        self.n_channel = args['n_channel']\n",
        "        self.dim_h = args['dim_h']\n",
        "        self.n_z = args['n_z']\n",
        "        \n",
        "        # convolutional filters, work excellent with image data\n",
        "        # [(WK+2P)/S]+1\n",
        "        self.conv = nn.Sequential(\n",
        "            nn.AvgPool2d(7, stride=7),\n",
        "            nn.Conv2d(self.n_channel, self.dim_h, 4, 2, 1, bias=False),# 16\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Conv2d(self.dim_h, self.dim_h * 2, 4, 2, 1, bias=False), # 8\n",
        "            nn.BatchNorm2d(self.dim_h * 2),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Conv2d(self.dim_h * 2, self.dim_h * 4, 4, 2, 1, bias=False),# 4\n",
        "            nn.BatchNorm2d(self.dim_h * 4),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Conv2d(self.dim_h * 4, self.dim_h * 8, 4, 2, 0, bias=False),#14\n",
        "            nn.BatchNorm2d(self.dim_h * 8),\n",
        "            nn.LeakyReLU(0.2, inplace=True))\n",
        "        self.fc = nn.Linear(self.dim_h * (2 ** 3), self.n_z)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv(x)\n",
        "        \n",
        "        x = x.squeeze()\n",
        "        x = self.fc(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self, args):\n",
        "        super(Decoder, self).__init__()\n",
        "\n",
        "        self.n_channel = args['n_channel']\n",
        "        self.dim_h = args['dim_h']\n",
        "        self.n_z = args['n_z']\n",
        "\n",
        "        # first layer is fully connected\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(self.n_z, self.dim_h * 2**3 * 7 * 7),\n",
        "            nn.ReLU())\n",
        "\n",
        "        # deconvolutional filters, essentially inverse of convolutional filters\n",
        "        # H_out = (H_in1)*stride[0]  2padding[0] + dilation[0](kernel_size[0]1) + output_padding[0] + 1\n",
        "        self.deconv = nn.Sequential(\n",
        "            nn.ConvTranspose2d(self.dim_h * 8, self.dim_h * 4, 4), #10\n",
        "            nn.BatchNorm2d(self.dim_h * 4),\n",
        "            nn.ReLU(True),\n",
        "            nn.ConvTranspose2d(self.dim_h * 4, self.dim_h * 2, 4), #13\n",
        "            nn.BatchNorm2d(self.dim_h * 2),\n",
        "            nn.ReLU(True),\n",
        "            nn.ConvTranspose2d(self.dim_h * 2, self.dim_h, 4),# 16\n",
        "            nn.BatchNorm2d(self.dim_h),\n",
        "            nn.ReLU(True),\n",
        "            nn.ConvTranspose2d(self.dim_h, 3, 4, 2, 1),# 32\n",
        "            nn.UpsamplingBilinear2d(scale_factor=7),\n",
        "            nn.Tanh())\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.fc(x)\n",
        "        x = x.view(-1, self.dim_h * 2**3, 7, 7)\n",
        "        x = self.deconv(x)\n",
        "        return x\n",
        "\n",
        "##############################################################################\n",
        "\"\"\"set models, loss functions\"\"\"\n",
        "# control which parameters are frozen / free for optimization\n",
        "def free_params(module: nn.Module):\n",
        "    for p in module.parameters():\n",
        "        p.requires_grad = True\n",
        "\n",
        "def frozen_params(module: nn.Module):\n",
        "    for p in module.parameters():\n",
        "        p.requires_grad = False\n",
        "\n",
        "def biased_get_class(X, y, c):\n",
        "    \n",
        "    xbeg = X[y == c]\n",
        "    ybeg = y[y == c]\n",
        "    \n",
        "    return xbeg, ybeg\n",
        "    #return xclass, yclass\n",
        "\n",
        "def G_SM(X, y,n_to_sample,cl):\n",
        "    n_neigh = 5\n",
        "    nn = NearestNeighbors(n_neighbors=n_neigh, n_jobs=1)\n",
        "    nn.fit(X)\n",
        "    dist, ind = nn.kneighbors(X)\n",
        "\n",
        "    # generating samples\n",
        "    base_indices = np.random.choice(list(range(len(X))),n_to_sample)\n",
        "    neighbor_indices = np.random.choice(list(range(1, n_neigh)),n_to_sample)\n",
        "\n",
        "    X_base = X[base_indices]\n",
        "    X_neighbor = X[ind[base_indices, neighbor_indices]]\n",
        "\n",
        "    samples = X_base + np.multiply(np.random.rand(n_to_sample,1),\n",
        "            X_neighbor - X_base)\n",
        "\n",
        "    #use 10 as label because 0 to 9 real classes and 1 fake/smoted = 10\n",
        "    return samples, [cl]*n_to_sample\n",
        "\n",
        "def DeepSMOTE_train(X_train, y_train, one_hot = False):\n",
        "  from torch.utils.data import TensorDataset\n",
        "  import os\n",
        "\n",
        "  max_el = np.max(X_train)\n",
        "  X_train = X_train / max_el\n",
        "  X_train = moveaxis(X_train, 3, 1)\n",
        "  if one_hot:\n",
        "    y_train = np.argmax(y_train, axis=1)\n",
        "  #X_train = X_train.astype('float32') / 255.\n",
        "  \n",
        "  batch_size = args['batch_size']\n",
        "  patience = args['patience']\n",
        "  encoder = Encoder(args)\n",
        "  decoder = Decoder(args)\n",
        "\n",
        "  device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "  print(device)\n",
        "  decoder = decoder.to(device)\n",
        "  encoder = encoder.to(device)\n",
        "\n",
        "  train_on_gpu = torch.cuda.is_available()\n",
        "\n",
        "  #decoder loss function\n",
        "  criterion = nn.MSELoss()\n",
        "  criterion = criterion.to(device)\n",
        "\n",
        "  num_workers = 0\n",
        "\n",
        "  #torch.Tensor returns float so if want long then use torch.tensor\n",
        "  tensor_x = torch.from_numpy(X_train.copy())#torch.Tensor(X_train)\n",
        "  tensor_y = torch.tensor(y_train,dtype=torch.long)\n",
        "  mnist_bal = TensorDataset(tensor_x,tensor_y) \n",
        "  train_loader = torch.utils.data.DataLoader(mnist_bal, \n",
        "      batch_size=batch_size,shuffle=True,num_workers=num_workers)\n",
        "\n",
        "  best_loss = np.inf\n",
        "\n",
        "  enc_optim = torch.optim.Adam(encoder.parameters(), lr = args['lr'])\n",
        "  dec_optim = torch.optim.Adam(decoder.parameters(), lr = args['lr'])\n",
        "\n",
        "  for epoch in range(args['epochs']):\n",
        "      train_loss = 0.0\n",
        "      tmse_loss = 0.0\n",
        "      tdiscr_loss = 0.0\n",
        "      # train for one epoch -- set nets to train mode\n",
        "      encoder.train()\n",
        "      decoder.train()\n",
        "  \n",
        "      for images,labs in train_loader:\n",
        "      \n",
        "          # zero gradients for each batch\n",
        "          encoder.zero_grad()\n",
        "          decoder.zero_grad()\n",
        "          images, labs = images.to(device), labs.to(device)\n",
        "          labsn = labs.detach().cpu().numpy()\n",
        "#            print('images shape', images.shape)\n",
        "          # run images\n",
        "          z_hat = encoder(images)\n",
        "#            print('images shape after encoding', z_hat.shape)\n",
        "      \n",
        "          x_hat = decoder(z_hat) #decoder outputs tanh\n",
        "#            print('images shape after decoding', x_hat.shape)\n",
        "          mse = criterion(x_hat,images)\n",
        "                  \n",
        "          resx = []\n",
        "          resy = []\n",
        "      \n",
        "          tc = np.random.choice(num_classes,1)\n",
        "          #tc = 9\n",
        "          xbeg = X_train[y_train == tc]\n",
        "          ybeg = y_train[y_train == tc] \n",
        "          xlen = len(xbeg)\n",
        "          nsamp = min(xlen, 100)\n",
        "          ind = np.random.choice(list(range(len(xbeg))),nsamp,replace=False)\n",
        "          xclass = xbeg[ind]\n",
        "          yclass = ybeg[ind]\n",
        "      \n",
        "          xclen = len(xclass)\n",
        "          xcminus = np.arange(1,xclen)\n",
        "          \n",
        "          xcplus = np.append(xcminus,0)\n",
        "          xcnew = (xclass[[xcplus],:])\n",
        "          xcnew = xcnew.reshape(xcnew.shape[1],xcnew.shape[2],xcnew.shape[3],xcnew.shape[4])\n",
        "      \n",
        "          xcnew = torch.Tensor(xcnew)\n",
        "          xcnew = xcnew.to(device)\n",
        "      \n",
        "          #encode xclass to feature space\n",
        "          xclass = torch.Tensor(xclass)\n",
        "          xclass = xclass.to(device)\n",
        "          xclass = encoder(xclass)\n",
        "      \n",
        "          xclass = xclass.detach().cpu().numpy()\n",
        "      \n",
        "          xc_enc = (xclass[[xcplus],:])\n",
        "          xc_enc = np.squeeze(xc_enc)\n",
        "      \n",
        "          xc_enc = torch.Tensor(xc_enc)\n",
        "          xc_enc = xc_enc.to(device)\n",
        "          \n",
        "          ximg = decoder(xc_enc)\n",
        "          \n",
        "          mse2 = criterion(ximg,xcnew)\n",
        "      \n",
        "          comb_loss = mse2 + mse\n",
        "          comb_loss.backward()\n",
        "      \n",
        "          enc_optim.step()\n",
        "          dec_optim.step()\n",
        "      \n",
        "          train_loss += comb_loss.item()*images.size(0)\n",
        "          tmse_loss += mse.item()*images.size(0)\n",
        "          tdiscr_loss += mse2.item()*images.size(0)\n",
        "\n",
        "      train_loss = train_loss/len(train_loader)\n",
        "      tmse_loss = tmse_loss/len(train_loader)\n",
        "      tdiscr_loss = tdiscr_loss/len(train_loader)\n",
        "      print('Epoch: {} \\tTrain Loss: {:.6f} \\tmse loss: {:.6f} \\tmse2 loss: {:.6f}'.format(epoch,\n",
        "              train_loss,tmse_loss,tdiscr_loss))\n",
        "      \n",
        "  \n",
        "  \n",
        "      #store the best encoder and decoder models\n",
        "      #here, /crs5 is a reference to 5 way cross validation, but is not\n",
        "      #necessary for illustration purposes\n",
        "      if train_loss < best_loss:\n",
        "          print('Saving..')\n",
        "          patience = args['patience']\n",
        "          path_enc = '/content/drive/MyDrive/PHD/Model/DeepSMOTE/32/bst_enc.pth'\n",
        "          path_dec = '/content/drive/MyDrive/PHD/Model/DeepSMOTE/32/bst_dec.pth'\n",
        "        \n",
        "          torch.save(encoder.state_dict(), path_enc)\n",
        "          torch.save(decoder.state_dict(), path_dec)\n",
        "  \n",
        "          best_loss = train_loss\n",
        "      else:\n",
        "          patience = patience - 1\n",
        "\n",
        "      if patience == 0:\n",
        "          print('Out of patience. \\n')\n",
        "          break\n",
        "\n",
        "def DeepSMOTE_Data(X_train, y_train, one_hot = False):\n",
        "  batch_size = args['batch_size']\n",
        "  max_el = np.max(X_train)\n",
        "  X_train = X_train / max_el\n",
        "  X_train = moveaxis(X_train, 3, 1)\n",
        "  if one_hot:\n",
        "    y_train = np.argmax(y_train, axis=1)\n",
        "  #Generate artificial images\n",
        "  import torch\n",
        "  np.printoptions(precision=5,suppress=True)\n",
        "\n",
        "  #path on the computer where the models are stored\n",
        "  modpth = '/content/drive/MyDrive/PHD/Model/DeepSMOTE/32/'\n",
        "\n",
        "  path_enc = modpth + '/bst_enc.pth'\n",
        "  path_dec = modpth + '/bst_dec.pth'\n",
        "  \n",
        "  train_on_gpu = torch.cuda.is_available()\n",
        "  device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "  encoder = Encoder(args)\n",
        "  encoder.load_state_dict(torch.load(path_enc), strict=False)\n",
        "  encoder = encoder.to(device)\n",
        "\n",
        "  decoder = Decoder(args)\n",
        "  decoder.load_state_dict(torch.load(path_dec), strict=False)\n",
        "  decoder = decoder.to(device)\n",
        "\n",
        "  encoder.eval()\n",
        "  decoder.eval()\n",
        "\n",
        "  resx = []\n",
        "  resy = []\n",
        "  \n",
        "  counter = Counter(y_train)\n",
        "  counter = sorted(counter.items())\n",
        "  counter = [value for _, value in counter]\n",
        "\n",
        "  for i in range(num_classes):\n",
        "      torch.cuda.empty_cache()\n",
        "\n",
        "      xclass, yclass = biased_get_class(X_train, y_train, i)\n",
        "      #encode xclass to feature space\n",
        "      xclass = torch.Tensor(xclass)\n",
        "      xclass = xclass.to(device)\n",
        "      xclass = encoder(xclass)\n",
        "          \n",
        "      xclass = xclass.detach().cpu().numpy()\n",
        "      n = np.max(counter) - counter[i]\n",
        "      if n == 0:\n",
        "        continue\n",
        "#        resx2 = []\n",
        "#        resy2 = []\n",
        "#        for j in range(batch_size, n+batch_size+1, batch_size):\n",
        "#          if j <= n:\n",
        "#            batch_size_max = batch_size\n",
        "#          elif n % batch_size != 0:\n",
        "#            batch_size_max = n%batch_size\n",
        "#          else:\n",
        "#            break\n",
        "#          xsamp, ysamp = G_SM(xclass,yclass,batch_size_max,i)\n",
        "      xsamp, ysamp = G_SM(xclass,yclass,n,i)\n",
        "      ysamp = np.array(ysamp)\n",
        "  \n",
        "      \"\"\"to generate samples for resnet\"\"\"   \n",
        "      xsamp = torch.Tensor(xsamp)\n",
        "      xsamp = xsamp.to(device)\n",
        "      ximg = decoder(xsamp)\n",
        "\n",
        "      ximn = ximg.detach().cpu().numpy()\n",
        "#        resx2.append(ximn)\n",
        "#        resy2.append(ysamp)\n",
        "#        \n",
        "#        resx2 = np.vstack(resx2)\n",
        "#        resy2 = np.hstack(resy2)\n",
        "      resx.append(ximn)\n",
        "      resy.append(ysamp)\n",
        "  \n",
        "  resx1 = np.vstack(resx)\n",
        "  resy1 = np.hstack(resy)\n",
        "  resx1 = resx1.reshape(resx1.shape[0],-1)\n",
        "  X_train = X_train.reshape(X_train.shape[0],-1)\n",
        "  X_train = np.vstack((resx1,X_train))\n",
        "  y_train = np.hstack((resy1,y_train))\n",
        "  y_train = to_categorical(y_train)\n",
        "  X_train = X_train.reshape(-1, 3, IMAGE_W, IMAGE_H)\n",
        "  X_train = moveaxis(X_train, 1, 3)\n",
        "  X_train = X_train * max_el\n",
        "  return X_train, y_train"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0jrJ33lUDkCM"
      },
      "source": [
        "#Split dataset to train and val"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e6qneWL_Bs2U"
      },
      "outputs": [],
      "source": [
        "# stratified train and rem (20%) datasets\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, stratify=y_train, random_state=1)\n",
        "\n",
        "print('Train Data: ', X_train.shape)\n",
        "print('Remaining Data: ', X_val.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8Kef4r_zxjgk"
      },
      "outputs": [],
      "source": [
        "#Data Augmentation\n",
        "dataaugment = ImageDataGenerator(\n",
        "        rotation_range=90,  # randomly rotate images in the range (degrees, 0 to 180)\n",
        "        zoom_range = 0.1, # Randomly zoom image \n",
        "        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
        "        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
        "        horizontal_flip=True,  # randomly flip images\n",
        "        vertical_flip=True,  # randomly flip images\n",
        "        shear_range = 10) \n",
        "\n",
        "dataaugment.fit(X_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B2PgksTFkOAq"
      },
      "source": [
        "#Fine Tune"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nr1jnSM7yzJc"
      },
      "outputs": [],
      "source": [
        "limit = 171\n",
        "for layer in model.layers[:limit]:\n",
        "   layer.trainable = False\n",
        "for layer in model.layers[limit:]:\n",
        "   layer.trainable = True\n",
        "\n",
        "optimizer_SGD = SGD(learning_rate=0.0001, momentum=0.9)\n",
        "model.compile(optimizer = optimizer_SGD , loss = \"categorical_crossentropy\", metrics=['accuracy', balanced_acc])\n",
        "hst2 = model.fit(train_data_batches,\n",
        "                    epochs = EPOCHS, validation_data = valid_data_batches,\n",
        "                    callbacks=[learning_rate_reduction,early_stopping_monitor, mc])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vO1aAQBmiy0K"
      },
      "outputs": [],
      "source": [
        "# summarize history for accuracy\n",
        "plt.plot(hst2.history['balanced_acc'])\n",
        "plt.plot(hst2.history['val_balanced_acc'])\n",
        "plt.title('model balance_acc after tunning')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'val'], loc='upper left')\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "E_x4c0_DTkaa",
        "BE9FCWBe8deT",
        "iDRWiTnO0MGh",
        "eaK4zbtoaAaC",
        "3K908bbiYwbS",
        "UswA0co2y1wl",
        "LfcFpsBwM0d4",
        "cNBXx28B9yGu",
        "0jrJ33lUDkCM",
        "B2PgksTFkOAq"
      ],
      "machine_shape": "hm",
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}