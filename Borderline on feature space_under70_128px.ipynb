{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/heroza/Inner-Borderline-SMOTE/blob/main/Borderline%20on%20feature%20space_under70_128px.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Eus_4tUgfEk9",
        "outputId": "c608ddc9-4438-4b63-b5c4-9d204d569c05"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E_x4c0_DTkaa"
      },
      "source": [
        "#Library, atribut, and function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "nR2MJBYq-oiB"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import os\n",
        "from collections import Counter\n",
        "from pathlib import Path\n",
        "from PIL import Image\n",
        "from sklearn import preprocessing\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "from sklearn.metrics import precision_recall_fscore_support, balanced_accuracy_score, confusion_matrix, accuracy_score\n",
        "from keras.callbacks import ReduceLROnPlateau, EarlyStopping, ModelCheckpoint\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D, UpSampling2D\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.optimizers import Adam, SGD\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input, decode_predictions\n",
        "from tensorflow.keras.applications.inception_v3 import InceptionV3, preprocess_input\n",
        "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Input, Dropout, Flatten\n",
        "from tensorflow.keras.models import Model, load_model\n",
        "from keras.utils.np_utils import to_categorical\n",
        "import imblearn\n",
        "from imblearn.over_sampling import SMOTE, BorderlineSMOTE, SVMSMOTE, ADASYN, KMeansSMOTE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "9-c7Xghg4SB4"
      },
      "outputs": [],
      "source": [
        "# input image size\n",
        "IMAGE_W = 128\n",
        "IMAGE_H = 128\n",
        "IMG_SIZE = (IMAGE_W,IMAGE_H)\n",
        "num_classes = 7\n",
        "EPOCHS = 50\n",
        "BATCH_SIZE = 64\n",
        "opt_adam = Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
        "opt_SGD = SGD(learning_rate=0.001)\n",
        "the_arch = 'resnet50'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "JffFid9sOXeo"
      },
      "outputs": [],
      "source": [
        "# load train and test dataset\n",
        "def preprocess_image_input(input_images, arch = the_arch):\n",
        "  input_images = input_images.astype('float32')\n",
        "  if arch == 'inception_v3':\n",
        "    output_ims = tf.keras.applications.inception_v3.preprocess_input(input_images)\n",
        "  else:\n",
        "    output_ims = tf.keras.applications.resnet50.preprocess_input(input_images)\n",
        "  return output_ims\n",
        "\n",
        "def load_cifar10_dataset():\n",
        "  from keras.datasets import cifar10\n",
        "    # load dataset\n",
        "  (X_train, y_train), (X_val, y_val) = cifar10.load_data()\n",
        "    # one hot encode target values\n",
        "  y_train = to_categorical(y_train)\n",
        "  y_val = to_categorical(y_val)\n",
        "\n",
        "  return X_train, y_train, X_val, y_val\n",
        "\n",
        "def true_positive(l1,l2):\n",
        "  tp = 0\n",
        "  for i in range(len(l1)):\n",
        "    tp = tf.cond(l1[i]==l2[i]==1, lambda: tp+1)\n",
        "  return tp\n",
        "\n",
        "def true_negative(l1,l2):\n",
        "  tn = 0\n",
        "  for i in range(len(l1)):\n",
        "    tn = tf.cond(l1[i]==l2[i]==0, lambda: tn+1)\n",
        "  return tn\n",
        "\n",
        "def false_positive(l1,l2):\n",
        "  fp = 0\n",
        "  for i in range(len(l1)):\n",
        "    fp = tf.cond(l1[i] != l2[i] and l2[i]==1, lambda: fp+1)\n",
        "  return fp\n",
        "\n",
        "def false_negative(l1,l2):\n",
        "  fn = 0\n",
        "  for i in range(len(l1)):\n",
        "    fn = tf.cond(l1[i] != l2[i] and l2[i] == 0, lambda: fn+1)\n",
        "  return fn\n",
        "\n",
        "def balanced_acc(y_true,y_pred):\n",
        "    from keras import backend as K\n",
        "    tensor1 = tf.math.argmax(y_true, axis=1)\n",
        "    tensor2 = tf.math.argmax(y_pred, axis=1)\n",
        "    cm = tf.math.confusion_matrix(tensor1, tensor2)\n",
        "    diag = tf.linalg.tensor_diag_part (cm)\n",
        "    tpfn = tf.cast(K.sum(cm, axis = 1), tf.float32) + K.epsilon()\n",
        "    recall = tf.divide(tf.cast(diag, tf.float32),tpfn)\n",
        "    balanced_acc = K.mean(recall)\n",
        "    balanced_acc = K.mean(balanced_acc)\n",
        "\n",
        "    return balanced_acc\n",
        "\n",
        "def define_base_model(arch = the_arch, start_trainable_layer = 9999, attention=False):\n",
        "  #x = data_augmentation(input_tensor)\n",
        "  #x = layers.Rescaling(1.0 / 255)(input_tensor)  # Rescale inputs\n",
        "  if arch != 'dense':\n",
        "    input_tensor = Input(shape=(IMAGE_H, IMAGE_W, 3))\n",
        "    #x = UpSampling2D(size=(7,7))(input_tensor)\n",
        "    if arch == 'resnet50':\n",
        "      base_model = ResNet50(input_tensor=input_tensor, weights='imagenet', include_top=False)\n",
        "    elif arch == 'inception_v3':\n",
        "      base_model = InceptionV3(input_tensor=input_tensor, weights='imagenet', include_top=False)\n",
        "    elif arch == 'ResNet':\n",
        "      base_model = ResNet(classes ,image_shape)(input_tensor)\n",
        "    \n",
        "    for layer in base_model.layers:\n",
        "      layer.trainable = False\n",
        "    if start_trainable_layer != 9999:\n",
        "      for layer in base_model.layers[start_trainable_layer:]:\n",
        "        layer.trainable = True\n",
        "    \n",
        "    x = base_model.output\n",
        "    if attention:\n",
        "      x = Attention(1024,1024,7,8)(x)\n",
        "    \n",
        "    x = GlobalAveragePooling2D()(x)\n",
        "    x = Flatten()(x)\n",
        "  else:\n",
        "    input_tensor = Input(shape=(2048))\n",
        "    x = input_tensor\n",
        "  #x = Flatten()(x)\n",
        "  x = Dense(1024, activation='relu')(x)\n",
        "  #x = Dropout(0.2)(x)\n",
        "  x = Dense(512, activation='relu')(x)\n",
        "  predictions = Dense(num_classes, activation='softmax')(x)\n",
        "  model = Model(inputs=input_tensor, outputs=predictions)\n",
        "  model.compile(optimizer = opt_SGD , loss = \"categorical_crossentropy\", metrics=['accuracy', balanced_acc])\n",
        "  return model\n",
        "\n",
        "def define_model_resnet():\n",
        "  input_shape = (IMAGE_H, IMAGE_W, 3)\n",
        "  input_tensor = Input(shape=input_shape)\n",
        "  x = ResNet50(input_shape=input_shape, weights='imagenet', include_top=False)(input_tensor, training=False)\n",
        "  x = GlobalAveragePooling2D()(x)\n",
        "  x = Flatten()(x)\n",
        "  x = Dense(1024, activation='relu')(x)\n",
        "  x = Dense(512, activation='relu')(x)\n",
        "  predictions = Dense(num_classes, activation='softmax')(x)\n",
        "  model = Model(inputs=input_tensor, outputs=predictions)\n",
        "  model.compile(optimizer = opt_SGD , loss = \"categorical_crossentropy\", metrics=['accuracy', balanced_acc])\n",
        "  return model\n",
        "\n",
        "# plot diagnostic learning curves\n",
        "def summarize_diagnostics(history):\n",
        "    # plot loss\n",
        "    plt.subplot(211)\n",
        "    plt.title('Cross Entropy Loss')\n",
        "    plt.plot(history.history['loss'], color='blue', label='train')\n",
        "    plt.plot(history.history['val_loss'], color='orange', label='test')\n",
        "    # plot accuracy\n",
        "    plt.subplot(212)\n",
        "    plt.title('Classification Accuracy')\n",
        "    plt.plot(history.history['accuracy'], color='blue', label='train')\n",
        "    plt.plot(history.history['val_accuracy'], color='orange', label='test')\n",
        " \n",
        "# scale pixels\n",
        "def norm_pixels(train, test):\n",
        "    # convert from integers to floats\n",
        "    train_norm = train.astype('float32')\n",
        "    test_norm = test.astype('float32')\n",
        "    # normalize to range 0-1\n",
        "    train_norm = train_norm / 255.0\n",
        "    test_norm = test_norm / 255.0\n",
        "    # return normalized images\n",
        "    return train_norm, test_norm\n",
        "\n",
        "def load_isic2018_dataset(train_under_frac = 0):\n",
        "  df_train = pd.read_csv('/content/drive/MyDrive/PHD/Datasets/isic2018/ISIC2018_Task3_Training_GroundTruth/ISIC2018_Task3_Training_GroundTruth.csv') \n",
        "  df_val = pd.read_csv('/content/drive/MyDrive/PHD/Datasets/isic2018/ISIC2018_Task3_Validation_GroundTruth/ISIC2018_Task3_Validation_GroundTruth.csv') \n",
        "\n",
        "  #decode one hot label\n",
        "  df_train[\"Labels\"] = (df_train.iloc[:, 1:]).idxmax(axis=1)\n",
        "  df_val[\"Labels\"] = (df_val.iloc[:, 1:]).idxmax(axis=1)\n",
        "\n",
        "  #random undersampling for training dataset\n",
        "  if train_under_frac !=0:\n",
        "    df_train = df_train.drop(df_train[df_train['Labels'] == 'NV'].sample(frac=train_under_frac).index)\n",
        "\n",
        "  #drop one-hot column\n",
        "  df_train = df_train.drop(columns=['MEL', 'NV', 'BCC', 'AKIEC', 'BKL', 'DF', 'VASC'])\n",
        "  df_val = df_val.drop(columns=['MEL', 'NV', 'BCC', 'AKIEC', 'BKL', 'DF', 'VASC'])\n",
        "\n",
        "  #make filepaths of the image\n",
        "  dir_train = '/content/drive/MyDrive/PHD/Datasets/isic2018/ISIC2018_Task3_Training_Input/'\n",
        "  dir_val = '/content/drive/MyDrive/PHD/Datasets/isic2018/ISIC2018_Task3_Validation_Input/'\n",
        "  df_train['FilePaths'] = dir_train + df_train['image'] + '.jpg'\n",
        "  df_val['FilePaths'] = dir_val + df_val['image'] + '.jpg'\n",
        "  \n",
        "  #load image pixels to dataframe\n",
        "  df_train['image_px'] = df_train['FilePaths'].map(lambda x: np.asarray(Image.open(x).resize(IMG_SIZE)))\n",
        "  df_val['image_px'] = df_val['FilePaths'].map(lambda x: np.asarray(Image.open(x).resize(IMG_SIZE)))\n",
        "\n",
        "  X_train = np.asarray(df_train['image_px'].tolist())\n",
        "  X_val = np.asarray(df_val['image_px'].tolist())\n",
        "  y_train = np.array(df_train['Labels'].values)\n",
        "  y_val = np.array(df_val['Labels'].values)\n",
        "\n",
        "  label_encoder = preprocessing.LabelEncoder()\n",
        "  y_train = label_encoder.fit_transform(y_train)\n",
        "  y_val = label_encoder.fit_transform(y_val)\n",
        "  \n",
        "  y_train = to_categorical(y_train, num_classes = num_classes)\n",
        "  y_val = to_categorical(y_val, num_classes = num_classes)\n",
        "\n",
        "  return X_train, y_train, X_val, y_val\n",
        "\n",
        "def reset_dataset(df_train, df_val):\n",
        "  X_train = np.asarray(df_train['image_px'].tolist())\n",
        "  X_val = np.asarray(df_val['image_px'].tolist())\n",
        "  y_train = np.array(df_train['Labels'].values)\n",
        "  y_val = np.array(df_val['Labels'].values)\n",
        "\n",
        "  X_train = preprocess_image_input(X_train, the_arch)\n",
        "  X_val = preprocess_image_input(X_val, the_arch)\n",
        "\n",
        "  label_encoder = preprocessing.LabelEncoder()\n",
        "  y_train = label_encoder.fit_transform(y_train)\n",
        "  y_val = label_encoder.fit_transform(y_val)\n",
        "  \n",
        "  y_train = to_categorical(y_train, num_classes = num_classes)\n",
        "  y_val = to_categorical(y_val, num_classes = num_classes)\n",
        "  return X_train, y_train, X_val, y_val\n",
        "\n",
        "def SMOTE_Data(X, y, one_hot = False, k = 5, width = IMAGE_W, height = IMAGE_H, c = 3, type = 'smote'):\n",
        "  if one_hot:\n",
        "    y = np.argmax(y, axis=1)\n",
        "  if type == 'borderline':\n",
        "    sm = BorderlineSMOTE(random_state=42, k_neighbors=k)\n",
        "  elif type == 'svm':\n",
        "    sm = SVMSMOTE()\n",
        "  elif type == 'adasyn':\n",
        "    sm = ADASYN(random_state=42, n_neighbors=k)\n",
        "  elif type == 'kmeans':\n",
        "    sm = KMeansSMOTE(k_neighbors=k, kmeans_estimator=10)\n",
        "  else:\n",
        "    sm = SMOTE(random_state=42, k_neighbors=k)\n",
        "  X_resampled, y_resampled = sm.fit_resample(X.reshape((-1, width * height * c)), y)\n",
        "  X_resampled = X_resampled.reshape(-1, width, height, c)\n",
        "  if one_hot:\n",
        "    y_resampled = to_categorical(y_resampled, num_classes = num_classes)\n",
        "  else:\n",
        "    y_resampled = y_resampled.reshape(-1,1)\n",
        "  return X_resampled, y_resampled\n",
        "\n",
        "def SMOTE_Data2(X, y, one_hot = False, k = 5, type = 'smote'):\n",
        "  if one_hot:\n",
        "    y = np.argmax(y, axis=1)\n",
        "  if type == 'borderline':\n",
        "    sm = BorderlineSMOTE(random_state=42, k_neighbors=k)\n",
        "  elif type == 'svm':\n",
        "    sm = SVMSMOTE()\n",
        "  elif type == 'adasyn':\n",
        "    sm = ADASYN(random_state=42, n_neighbors=k)\n",
        "  elif type == 'kmeans':\n",
        "    sm = KMeansSMOTE(k_neighbors=k, kmeans_estimator=10)\n",
        "  else:\n",
        "    sm = SMOTE(random_state=42, k_neighbors=k)\n",
        "  X_resampled, y_resampled = sm.fit_resample(X, y)\n",
        "  if one_hot:\n",
        "    y_resampled = to_categorical(y_resampled, num_classes = num_classes)\n",
        "  else:\n",
        "    y_resampled = y_resampled.reshape(-1,1)\n",
        "  return X_resampled, y_resampled"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BE9FCWBe8deT"
      },
      "source": [
        "#Inner-Borderline SMOTE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s3UnuaKz8kzJ"
      },
      "outputs": [],
      "source": [
        "def get_class(X, y, c):\n",
        "    xbeg = X[y == c]\n",
        "    ybeg = y[y == c]\n",
        "    \n",
        "    return xbeg, ybeg\n",
        "def find_border(xclass, yclass, X, y, cli, n_neigh=5):\n",
        "    nn = NearestNeighbors(n_neighbors=n_neigh, n_jobs=1)\n",
        "    nn.fit(X)\n",
        "    dist, ind = nn.kneighbors(xclass)\n",
        "    ret = []\n",
        "    for i in range(len(ind)):\n",
        "      ret.append(sum(y[ind[i,j]] != cli for j in range(1,len(ind[i]))))\n",
        "    ret = np.array(ret)\n",
        "    xclass = xclass[np.logical_and(ret < (n_neigh-1),ret > ((n_neigh-1)/2))]\n",
        "    yclass = yclass[np.logical_and(ret < (n_neigh-1),ret > ((n_neigh-1)/2))]\n",
        "\n",
        "    return xclass, yclass\n",
        "def find_inner_border(xclass, yclass, X, y, cli, n_neigh=5):\n",
        "    nn = NearestNeighbors(n_neighbors=n_neigh, n_jobs=1)\n",
        "    nn.fit(X)\n",
        "    dist, ind = nn.kneighbors(X)\n",
        "    ret = []\n",
        "    for i in range(len(ind)):\n",
        "      if y[i] != cli:\n",
        "        ret.append(n_neigh)  \n",
        "      else:\n",
        "        ret.append(sum(y[ind[i,j]] != cli for j in range(1,len(ind[i]))))\n",
        "    ret = np.array(ret)\n",
        "    is_border = np.logical_and(ret < (n_neigh-1),ret > ((n_neigh-1)/2))\n",
        "    \n",
        "    ret = []\n",
        "    for i in range(len(ind)):\n",
        "      ret.append(sum(is_border[ind[i,j]] for j in range(1,len(ind[i]))))\n",
        "    ret = np.array(ret)\n",
        "    xclass = X[np.logical_and(np.logical_not(is_border),ret > 0)]\n",
        "    yclass = y[np.logical_and(np.logical_not(is_border),ret > 0)]\n",
        "    return xclass, yclass\n",
        "\n",
        "def G_SM(xclass,n_to_sample,cl, n_neigh = 6):\n",
        "    \n",
        "    nn = NearestNeighbors(n_neighbors=n_neigh, n_jobs=1)\n",
        "    nn.fit(xclass)\n",
        "    dist, ind = nn.kneighbors(xclass)\n",
        "\n",
        "    # generating samples\n",
        "    base_indices = np.random.choice(list(range(len(xclass))),n_to_sample)\n",
        "    neighbor_indices = np.random.choice(list(range(1, n_neigh)),n_to_sample)\n",
        "\n",
        "    X_base = xclass[base_indices]\n",
        "    X_neighbor = xclass[ind[base_indices, neighbor_indices]]\n",
        "\n",
        "    samples = X_base + np.multiply(np.random.rand(n_to_sample,1),\n",
        "            X_neighbor - X_base)\n",
        "\n",
        "    #use 10 as label because 0 to 9 real classes and 1 fake/smoted = 10\n",
        "    return samples, [cl]*n_to_sample\n",
        "\n",
        "def Borderline_SMOTE(X_train, y_train, random_state=42, k_neighbors=5, start=0, n=7):\n",
        "  #reshape X_train\n",
        "  X_train = X_train.reshape(-1, IMAGE_W * IMAGE_H * 3)\n",
        "  #decode y_train from one-hot encoding\n",
        "  y_train = np.argmax(y_train, axis=1) \n",
        "\n",
        "  counter = Counter(y_train)\n",
        "  key_max = max(counter, key=counter.get)\n",
        "  class_max = counter[key_max]\n",
        "  resx=[]\n",
        "  resy=[]\n",
        "\n",
        "  for i in range(start,n):\n",
        "      xclass, yclass = get_class(X_train, y_train, i)\n",
        "      if xclass.shape[0] == class_max:\n",
        "        continue\n",
        "      xclass_bdr, yclass_bdr = find_inner_border(xclass, yclass, X_train, y_train, i, n_neigh=k_neighbors)\n",
        "      n = class_max - xclass.shape[0]\n",
        "      xsamp, ysamp = G_SM(xclass_bdr,n,i, n_neigh=k_neighbors)\n",
        "      ysamp = np.array(ysamp)\n",
        "      resx.append(xsamp)\n",
        "      resy.append(ysamp)\n",
        "  \n",
        "  resx = np.vstack(resx)\n",
        "  resy = np.hstack(resy)\n",
        "  X_train = np.vstack((resx,X_train))\n",
        "  y_train = np.hstack((resy,y_train))\n",
        "  y_train = to_categorical(y_train)\n",
        "  X_train = X_train.reshape(-1, IMAGE_W, IMAGE_H, 3)\n",
        "  return X_train, y_train"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5v7sLC2svMuJ"
      },
      "source": [
        "# Main"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "exp_name=\"borderline_on_featurespace\"\n",
        "dataset_name=\"under70_128px\""
      ],
      "metadata": {
        "id": "udkMXcZHXglm"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qge6cnxQPnH6",
        "outputId": "cbaeab7b-e53c-41f5-acd0-512f7062524c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(5321, 128, 128, 3)\n",
            "(5321, 7)\n",
            "(193, 128, 128, 3)\n",
            "(193, 7)\n",
            "Counter train data:  Counter({5: 2011, 4: 1113, 2: 1099, 1: 514, 0: 327, 6: 142, 3: 115})\n",
            "Counter val data:  Counter({5: 123, 2: 22, 4: 21, 1: 15, 0: 8, 6: 3, 3: 1})\n"
          ]
        }
      ],
      "source": [
        "path = '/content/drive/MyDrive/PHD/Datasets/isic2018/'\n",
        "df1 = pd.read_pickle(path+\"isic2018_train_\"+dataset_name+\".pkl\")\n",
        "X_train = df1.loc[:, df1.columns != 'y_train'].to_numpy()\n",
        "X_train = X_train.reshape(-1,IMAGE_W,IMAGE_H,3)\n",
        "y_train = df1.loc[:, df1.columns == 'y_train'].to_numpy()\n",
        "y_train = to_categorical(y_train)\n",
        "\n",
        "df1 = pd.read_pickle(path+\"isic2018_val.pkl\")\n",
        "X_val = df1.loc[:, df1.columns != 'y_val'].to_numpy()\n",
        "X_val = X_val.reshape(-1,IMAGE_W,IMAGE_H,3)\n",
        "y_val = df1.loc[:, df1.columns == 'y_val'].to_numpy()\n",
        "y_val = to_categorical(y_val)\n",
        "\n",
        "print(X_train.shape)\n",
        "print(y_train.shape)\n",
        "print(X_val.shape)\n",
        "print(y_val.shape)\n",
        "print('Counter train data: ', Counter(np.argmax(y_train, axis=1)))\n",
        "print('Counter val data: ', Counter(np.argmax(y_val, axis=1)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xArGWuciBt_-"
      },
      "outputs": [],
      "source": [
        "X_train, y_train = SMOTE_Data(X_train, y_train, True, type = 'smote')\n",
        "#X_train, y_train = Borderline_SMOTE(X_train, y_train)\n",
        "print(X_train.shape)\n",
        "print(y_train.shape)\n",
        "print(X_val.shape)\n",
        "print(y_val.shape)\n",
        "print('Counter train data: ', Counter(np.argmax(y_train, axis=1)))\n",
        "print('Counter val data: ', Counter(np.argmax(y_val, axis=1)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0V5PjA7jFhVU",
        "outputId": "80afb394-3ef2-41ad-f477-4e0203e9535f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(14277, 2048)\n",
            "(14277, 7)\n",
            "Counter train data:  Counter({0: 2211, 5: 2011, 4: 2011, 2: 2011, 3: 2011, 1: 2011, 6: 2011})\n"
          ]
        }
      ],
      "source": [
        "X_train_fm_ov = np.append(X_train_fm_ov, np.zeros(shape=(200, 2048), dtype='object'), axis=0)\n",
        "y_train_ov = np.argmax(y_train_ov, axis=1) \n",
        "y_train_ov = y_train_ov.reshape(-1,1)\n",
        "y_train_ov = np.append(y_train_ov, np.zeros(shape=(200, 1), dtype='object'))\n",
        "y_train = to_categorical(y_train_ov)\n",
        "print(X_train_fm_ov.shape)\n",
        "print(y_train.shape)\n",
        "print('Counter train data: ', Counter(np.argmax(y_train, axis=1)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0lFpLlexMUaM",
        "outputId": "59dfc36a-e35a-4599-9c65-45a281c87241"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(15277, 32, 32, 3)\n",
            "(15277, 7)\n",
            "Counter train data:  Counter({5: 2211, 4: 2211, 2: 2211, 3: 2211, 1: 2211, 6: 2211, 0: 2011})\n"
          ]
        }
      ],
      "source": [
        "# remove rows having all zeroes\n",
        "index = range(14077,14277)\n",
        "y_train = np.delete(y_train, index, axis = 0)\n",
        "X_train = np.delete(X_train, index, axis = 0)\n",
        "print(X_train.shape)\n",
        "print(y_train.shape)\n",
        "print('Counter train data: ', Counter(np.argmax(y_train, axis=1)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V7Z_nccu6QjB"
      },
      "outputs": [],
      "source": [
        "#path = '/content/drive/MyDrive/PHD/Datasets/isic2018/'\n",
        "#df1 = pd.DataFrame(X_train.reshape(X_train.shape[0],-1))\n",
        "#df1['y_train'] = np.argmax(y_train, axis=1).tolist()\n",
        "#df2 = pd.DataFrame(X_val.reshape(X_val.shape[0],-1))\n",
        "#df2['y_val'] = np.argmax(y_val, axis=1).tolist()\n",
        "#df1.to_pickle(path+\"isic2018_train_under83.pkl\")\n",
        "#df2.to_pickle(path+\"isic2018_val.pkl\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "vIygrW81Ln4z",
        "outputId": "74f0359a-abda-4cc4-8028-cfb87e4cbef2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "94765736/94765736 [==============================] - 0s 0us/step\n",
            "best_model_fpath:/content/drive/MyDrive/PHD/Model/best_model_no_smote_under70_128px.h5\n",
            "Epoch 1/50\n",
            "83/83 [==============================] - ETA: 0s - loss: 1.2717 - accuracy: 0.5149 - balanced_acc: 0.3129\n",
            "Epoch 1: val_balanced_acc improved from -inf to 0.37356, saving model to /content/drive/MyDrive/PHD/Model/best_model_no_smote_under70_128px.h5\n",
            "83/83 [==============================] - 37s 261ms/step - loss: 1.2717 - accuracy: 0.5149 - balanced_acc: 0.3129 - val_loss: 1.0859 - val_accuracy: 0.6114 - val_balanced_acc: 0.3736 - lr: 0.0010\n",
            "Epoch 2/50\n",
            "83/83 [==============================] - ETA: 0s - loss: 0.9843 - accuracy: 0.6283 - balanced_acc: 0.4660\n",
            "Epoch 2: val_balanced_acc improved from 0.37356 to 0.44390, saving model to /content/drive/MyDrive/PHD/Model/best_model_no_smote_under70_128px.h5\n",
            "83/83 [==============================] - 21s 238ms/step - loss: 0.9843 - accuracy: 0.6283 - balanced_acc: 0.4660 - val_loss: 0.6365 - val_accuracy: 0.7824 - val_balanced_acc: 0.4439 - lr: 0.0010\n",
            "Epoch 3/50\n",
            "83/83 [==============================] - ETA: 0s - loss: 0.8530 - accuracy: 0.6709 - balanced_acc: 0.5315\n",
            "Epoch 3: val_balanced_acc improved from 0.44390 to 0.49670, saving model to /content/drive/MyDrive/PHD/Model/best_model_no_smote_under70_128px.h5\n",
            "83/83 [==============================] - 20s 240ms/step - loss: 0.8530 - accuracy: 0.6709 - balanced_acc: 0.5315 - val_loss: 0.5699 - val_accuracy: 0.8135 - val_balanced_acc: 0.4967 - lr: 0.0010\n",
            "Epoch 4/50\n",
            "83/83 [==============================] - ETA: 0s - loss: 0.7683 - accuracy: 0.7052 - balanced_acc: 0.5844\n",
            "Epoch 4: val_balanced_acc improved from 0.49670 to 0.55016, saving model to /content/drive/MyDrive/PHD/Model/best_model_no_smote_under70_128px.h5\n",
            "83/83 [==============================] - 20s 243ms/step - loss: 0.7683 - accuracy: 0.7052 - balanced_acc: 0.5844 - val_loss: 0.6800 - val_accuracy: 0.7358 - val_balanced_acc: 0.5502 - lr: 0.0010\n",
            "Epoch 5/50\n",
            "83/83 [==============================] - ETA: 0s - loss: 0.7072 - accuracy: 0.7242 - balanced_acc: 0.6223\n",
            "Epoch 5: val_balanced_acc did not improve from 0.55016\n",
            "83/83 [==============================] - 19s 224ms/step - loss: 0.7072 - accuracy: 0.7242 - balanced_acc: 0.6223 - val_loss: 0.5822 - val_accuracy: 0.7927 - val_balanced_acc: 0.5248 - lr: 0.0010\n",
            "Epoch 6/50\n",
            "83/83 [==============================] - ETA: 0s - loss: 0.6377 - accuracy: 0.7552 - balanced_acc: 0.6750\n",
            "Epoch 6: val_balanced_acc improved from 0.55016 to 0.60059, saving model to /content/drive/MyDrive/PHD/Model/best_model_no_smote_under70_128px.h5\n",
            "83/83 [==============================] - 20s 246ms/step - loss: 0.6377 - accuracy: 0.7552 - balanced_acc: 0.6750 - val_loss: 0.4882 - val_accuracy: 0.8187 - val_balanced_acc: 0.6006 - lr: 0.0010\n",
            "Epoch 7/50\n",
            "83/83 [==============================] - ETA: 0s - loss: 0.5931 - accuracy: 0.7788 - balanced_acc: 0.6778\n",
            "Epoch 7: val_balanced_acc did not improve from 0.60059\n",
            "83/83 [==============================] - 19s 232ms/step - loss: 0.5931 - accuracy: 0.7788 - balanced_acc: 0.6778 - val_loss: 0.5441 - val_accuracy: 0.8135 - val_balanced_acc: 0.5924 - lr: 0.0010\n",
            "Epoch 8/50\n",
            "83/83 [==============================] - ETA: 0s - loss: 0.5691 - accuracy: 0.7877 - balanced_acc: 0.7094\n",
            "Epoch 8: val_balanced_acc improved from 0.60059 to 0.60822, saving model to /content/drive/MyDrive/PHD/Model/best_model_no_smote_under70_128px.h5\n",
            "83/83 [==============================] - 21s 253ms/step - loss: 0.5691 - accuracy: 0.7877 - balanced_acc: 0.7094 - val_loss: 0.5205 - val_accuracy: 0.8394 - val_balanced_acc: 0.6082 - lr: 0.0010\n",
            "Epoch 9/50\n",
            "83/83 [==============================] - ETA: 0s - loss: 0.5208 - accuracy: 0.8084 - balanced_acc: 0.7521\n",
            "Epoch 9: val_balanced_acc did not improve from 0.60822\n",
            "83/83 [==============================] - 19s 234ms/step - loss: 0.5208 - accuracy: 0.8084 - balanced_acc: 0.7521 - val_loss: 0.7585 - val_accuracy: 0.7306 - val_balanced_acc: 0.4654 - lr: 0.0010\n",
            "Epoch 10/50\n",
            "83/83 [==============================] - ETA: 0s - loss: 0.4592 - accuracy: 0.8400 - balanced_acc: 0.7777\n",
            "Epoch 10: val_balanced_acc did not improve from 0.60822\n",
            "83/83 [==============================] - 19s 233ms/step - loss: 0.4592 - accuracy: 0.8400 - balanced_acc: 0.7777 - val_loss: 0.4993 - val_accuracy: 0.8083 - val_balanced_acc: 0.5772 - lr: 0.0010\n",
            "Epoch 11/50\n",
            "83/83 [==============================] - ETA: 0s - loss: 0.4350 - accuracy: 0.8452 - balanced_acc: 0.7772\n",
            "Epoch 11: val_balanced_acc did not improve from 0.60822\n",
            "83/83 [==============================] - 19s 233ms/step - loss: 0.4350 - accuracy: 0.8452 - balanced_acc: 0.7772 - val_loss: 0.6895 - val_accuracy: 0.7824 - val_balanced_acc: 0.5466 - lr: 0.0010\n",
            "Epoch 12/50\n",
            "83/83 [==============================] - ETA: 0s - loss: 0.3882 - accuracy: 0.8570 - balanced_acc: 0.8029\n",
            "Epoch 12: val_balanced_acc did not improve from 0.60822\n",
            "83/83 [==============================] - 19s 234ms/step - loss: 0.3882 - accuracy: 0.8570 - balanced_acc: 0.8029 - val_loss: 0.5949 - val_accuracy: 0.7979 - val_balanced_acc: 0.4691 - lr: 0.0010\n",
            "Epoch 13/50\n",
            "83/83 [==============================] - ETA: 0s - loss: 0.3602 - accuracy: 0.8691 - balanced_acc: 0.8081\n",
            "Epoch 13: val_balanced_acc did not improve from 0.60822\n",
            "83/83 [==============================] - 19s 234ms/step - loss: 0.3602 - accuracy: 0.8691 - balanced_acc: 0.8081 - val_loss: 0.5271 - val_accuracy: 0.8394 - val_balanced_acc: 0.4844 - lr: 0.0010\n",
            "Epoch 14/50\n",
            "83/83 [==============================] - ETA: 0s - loss: 0.3140 - accuracy: 0.8952 - balanced_acc: 0.8417\n",
            "Epoch 14: val_balanced_acc improved from 0.60822 to 0.61341, saving model to /content/drive/MyDrive/PHD/Model/best_model_no_smote_under70_128px.h5\n",
            "83/83 [==============================] - 21s 253ms/step - loss: 0.3140 - accuracy: 0.8952 - balanced_acc: 0.8417 - val_loss: 0.5362 - val_accuracy: 0.8549 - val_balanced_acc: 0.6134 - lr: 0.0010\n",
            "Epoch 15/50\n",
            "83/83 [==============================] - ETA: 0s - loss: 0.2953 - accuracy: 0.8940 - balanced_acc: 0.8441\n",
            "Epoch 15: val_balanced_acc did not improve from 0.61341\n",
            "83/83 [==============================] - 19s 234ms/step - loss: 0.2953 - accuracy: 0.8940 - balanced_acc: 0.8441 - val_loss: 0.6821 - val_accuracy: 0.7668 - val_balanced_acc: 0.4717 - lr: 0.0010\n",
            "Epoch 16/50\n",
            "83/83 [==============================] - ETA: 0s - loss: 0.2794 - accuracy: 0.9119 - balanced_acc: 0.8550\n",
            "Epoch 16: val_balanced_acc did not improve from 0.61341\n",
            "83/83 [==============================] - 19s 234ms/step - loss: 0.2794 - accuracy: 0.9119 - balanced_acc: 0.8550 - val_loss: 0.6102 - val_accuracy: 0.8083 - val_balanced_acc: 0.5996 - lr: 0.0010\n",
            "Epoch 17/50\n",
            "83/83 [==============================] - ETA: 0s - loss: 0.2066 - accuracy: 0.9325 - balanced_acc: 0.8795\n",
            "Epoch 17: val_balanced_acc did not improve from 0.61341\n",
            "83/83 [==============================] - 19s 234ms/step - loss: 0.2066 - accuracy: 0.9325 - balanced_acc: 0.8795 - val_loss: 0.5341 - val_accuracy: 0.8394 - val_balanced_acc: 0.6065 - lr: 0.0010\n",
            "Epoch 18/50\n",
            "83/83 [==============================] - ETA: 0s - loss: 0.1883 - accuracy: 0.9424 - balanced_acc: 0.8870\n",
            "Epoch 18: val_balanced_acc did not improve from 0.61341\n",
            "83/83 [==============================] - 19s 235ms/step - loss: 0.1883 - accuracy: 0.9424 - balanced_acc: 0.8870 - val_loss: 0.6750 - val_accuracy: 0.7513 - val_balanced_acc: 0.4354 - lr: 0.0010\n",
            "Epoch 19/50\n",
            "83/83 [==============================] - ETA: 0s - loss: 0.2427 - accuracy: 0.9309 - balanced_acc: 0.8935\n",
            "Epoch 19: val_balanced_acc did not improve from 0.61341\n",
            "83/83 [==============================] - 20s 236ms/step - loss: 0.2427 - accuracy: 0.9309 - balanced_acc: 0.8935 - val_loss: 0.5366 - val_accuracy: 0.8187 - val_balanced_acc: 0.4780 - lr: 0.0010\n",
            "Epoch 20/50\n",
            "83/83 [==============================] - ETA: 0s - loss: 0.1045 - accuracy: 0.9760 - balanced_acc: 0.9347\n",
            "Epoch 20: val_balanced_acc did not improve from 0.61341\n",
            "83/83 [==============================] - 19s 234ms/step - loss: 0.1045 - accuracy: 0.9760 - balanced_acc: 0.9347 - val_loss: 0.5967 - val_accuracy: 0.8135 - val_balanced_acc: 0.4769 - lr: 0.0010\n",
            "Epoch 21/50\n",
            "83/83 [==============================] - ETA: 0s - loss: 0.2010 - accuracy: 0.9481 - balanced_acc: 0.9120\n",
            "Epoch 21: val_balanced_acc improved from 0.61341 to 0.64772, saving model to /content/drive/MyDrive/PHD/Model/best_model_no_smote_under70_128px.h5\n",
            "83/83 [==============================] - 21s 255ms/step - loss: 0.2010 - accuracy: 0.9481 - balanced_acc: 0.9120 - val_loss: 0.6083 - val_accuracy: 0.8653 - val_balanced_acc: 0.6477 - lr: 0.0010\n",
            "Epoch 22/50\n",
            "83/83 [==============================] - ETA: 0s - loss: 0.0565 - accuracy: 0.9907 - balanced_acc: 0.9536\n",
            "Epoch 22: val_balanced_acc did not improve from 0.64772\n",
            "83/83 [==============================] - 20s 236ms/step - loss: 0.0565 - accuracy: 0.9907 - balanced_acc: 0.9536 - val_loss: 0.6459 - val_accuracy: 0.8187 - val_balanced_acc: 0.5948 - lr: 0.0010\n",
            "Epoch 23/50\n",
            "83/83 [==============================] - ETA: 0s - loss: 0.0452 - accuracy: 0.9926 - balanced_acc: 0.9489\n",
            "Epoch 23: val_balanced_acc did not improve from 0.64772\n",
            "83/83 [==============================] - 19s 234ms/step - loss: 0.0452 - accuracy: 0.9926 - balanced_acc: 0.9489 - val_loss: 0.7389 - val_accuracy: 0.8031 - val_balanced_acc: 0.4867 - lr: 0.0010\n",
            "Epoch 24/50\n",
            "83/83 [==============================] - ETA: 0s - loss: 0.3307 - accuracy: 0.8920 - balanced_acc: 0.8315\n",
            "Epoch 24: val_balanced_acc did not improve from 0.64772\n",
            "83/83 [==============================] - 19s 234ms/step - loss: 0.3307 - accuracy: 0.8920 - balanced_acc: 0.8315 - val_loss: 0.5788 - val_accuracy: 0.8394 - val_balanced_acc: 0.4832 - lr: 0.0010\n",
            "Epoch 25/50\n",
            "83/83 [==============================] - ETA: 0s - loss: 0.0522 - accuracy: 0.9924 - balanced_acc: 0.9498\n",
            "Epoch 25: val_balanced_acc did not improve from 0.64772\n",
            "83/83 [==============================] - 19s 234ms/step - loss: 0.0522 - accuracy: 0.9924 - balanced_acc: 0.9498 - val_loss: 0.6792 - val_accuracy: 0.8187 - val_balanced_acc: 0.4829 - lr: 0.0010\n",
            "Epoch 26/50\n",
            "83/83 [==============================] - ETA: 0s - loss: 0.1387 - accuracy: 0.9635 - balanced_acc: 0.9197\n",
            "Epoch 26: val_balanced_acc did not improve from 0.64772\n",
            "83/83 [==============================] - 19s 234ms/step - loss: 0.1387 - accuracy: 0.9635 - balanced_acc: 0.9197 - val_loss: 0.5854 - val_accuracy: 0.8342 - val_balanced_acc: 0.4890 - lr: 0.0010\n",
            "Epoch 27/50\n",
            "83/83 [==============================] - ETA: 0s - loss: 0.0751 - accuracy: 0.9817 - balanced_acc: 0.9407\n",
            "Epoch 27: val_balanced_acc did not improve from 0.64772\n",
            "83/83 [==============================] - 19s 234ms/step - loss: 0.0751 - accuracy: 0.9817 - balanced_acc: 0.9407 - val_loss: 0.6520 - val_accuracy: 0.8290 - val_balanced_acc: 0.6039 - lr: 0.0010\n",
            "Epoch 28/50\n",
            "83/83 [==============================] - ETA: 0s - loss: 0.0149 - accuracy: 1.0000 - balanced_acc: 0.9627\n",
            "Epoch 28: val_balanced_acc did not improve from 0.64772\n",
            "83/83 [==============================] - 19s 234ms/step - loss: 0.0149 - accuracy: 1.0000 - balanced_acc: 0.9627 - val_loss: 0.7107 - val_accuracy: 0.8238 - val_balanced_acc: 0.6030 - lr: 0.0010\n",
            "Epoch 29/50\n",
            "83/83 [==============================] - ETA: 0s - loss: 0.0092 - accuracy: 1.0000 - balanced_acc: 0.9464\n",
            "Epoch 29: val_balanced_acc did not improve from 0.64772\n",
            "83/83 [==============================] - 19s 234ms/step - loss: 0.0092 - accuracy: 1.0000 - balanced_acc: 0.9464 - val_loss: 0.7499 - val_accuracy: 0.8083 - val_balanced_acc: 0.6003 - lr: 0.0010\n",
            "Epoch 30/50\n",
            "83/83 [==============================] - ETA: 0s - loss: 0.0074 - accuracy: 1.0000 - balanced_acc: 0.9515\n",
            "Epoch 30: val_balanced_acc did not improve from 0.64772\n",
            "83/83 [==============================] - 19s 234ms/step - loss: 0.0074 - accuracy: 1.0000 - balanced_acc: 0.9515 - val_loss: 0.7642 - val_accuracy: 0.8238 - val_balanced_acc: 0.6079 - lr: 0.0010\n",
            "Epoch 31/50\n",
            "83/83 [==============================] - ETA: 0s - loss: 0.0058 - accuracy: 1.0000 - balanced_acc: 0.9547\n",
            "Epoch 31: val_balanced_acc did not improve from 0.64772\n",
            "83/83 [==============================] - 19s 234ms/step - loss: 0.0058 - accuracy: 1.0000 - balanced_acc: 0.9547 - val_loss: 0.7955 - val_accuracy: 0.8187 - val_balanced_acc: 0.6071 - lr: 0.0010\n",
            "Epoch 32/50\n",
            "83/83 [==============================] - ETA: 0s - loss: 0.0051 - accuracy: 1.0000 - balanced_acc: 0.9598\n",
            "Epoch 32: val_balanced_acc did not improve from 0.64772\n",
            "83/83 [==============================] - 19s 235ms/step - loss: 0.0051 - accuracy: 1.0000 - balanced_acc: 0.9598 - val_loss: 0.7987 - val_accuracy: 0.8187 - val_balanced_acc: 0.6022 - lr: 0.0010\n",
            "Epoch 33/50\n",
            "83/83 [==============================] - ETA: 0s - loss: 0.0044 - accuracy: 1.0000 - balanced_acc: 0.9552\n",
            "Epoch 33: val_balanced_acc did not improve from 0.64772\n",
            "83/83 [==============================] - 19s 234ms/step - loss: 0.0044 - accuracy: 1.0000 - balanced_acc: 0.9552 - val_loss: 0.8183 - val_accuracy: 0.8187 - val_balanced_acc: 0.6071 - lr: 0.0010\n",
            "Epoch 34/50\n",
            "83/83 [==============================] - ETA: 0s - loss: 0.0037 - accuracy: 1.0000 - balanced_acc: 0.9570\n",
            "Epoch 34: val_balanced_acc did not improve from 0.64772\n",
            "83/83 [==============================] - 19s 234ms/step - loss: 0.0037 - accuracy: 1.0000 - balanced_acc: 0.9570 - val_loss: 0.8232 - val_accuracy: 0.8187 - val_balanced_acc: 0.6071 - lr: 0.0010\n",
            "Epoch 35/50\n",
            "83/83 [==============================] - ETA: 0s - loss: 0.0034 - accuracy: 1.0000 - balanced_acc: 0.9593\n",
            "Epoch 35: val_balanced_acc did not improve from 0.64772\n",
            "83/83 [==============================] - 19s 233ms/step - loss: 0.0034 - accuracy: 1.0000 - balanced_acc: 0.9593 - val_loss: 0.8401 - val_accuracy: 0.8238 - val_balanced_acc: 0.6082 - lr: 0.0010\n",
            "Epoch 36/50\n",
            "83/83 [==============================] - ETA: 0s - loss: 0.0032 - accuracy: 1.0000 - balanced_acc: 0.9641\n",
            "Epoch 36: val_balanced_acc did not improve from 0.64772\n",
            "83/83 [==============================] - 19s 234ms/step - loss: 0.0032 - accuracy: 1.0000 - balanced_acc: 0.9641 - val_loss: 0.8578 - val_accuracy: 0.8238 - val_balanced_acc: 0.6112 - lr: 0.0010\n",
            "Epoch 37/50\n",
            "83/83 [==============================] - ETA: 0s - loss: 0.0027 - accuracy: 1.0000 - balanced_acc: 0.9552\n",
            "Epoch 37: val_balanced_acc did not improve from 0.64772\n",
            "83/83 [==============================] - 19s 234ms/step - loss: 0.0027 - accuracy: 1.0000 - balanced_acc: 0.9552 - val_loss: 0.8592 - val_accuracy: 0.8187 - val_balanced_acc: 0.6071 - lr: 0.0010\n",
            "Epoch 38/50\n",
            "83/83 [==============================] - ETA: 0s - loss: 0.0026 - accuracy: 1.0000 - balanced_acc: 0.9550\n",
            "Epoch 38: val_balanced_acc did not improve from 0.64772\n",
            "83/83 [==============================] - 19s 234ms/step - loss: 0.0026 - accuracy: 1.0000 - balanced_acc: 0.9550 - val_loss: 0.8552 - val_accuracy: 0.8238 - val_balanced_acc: 0.6082 - lr: 0.0010\n",
            "Epoch 39/50\n",
            "83/83 [==============================] - ETA: 0s - loss: 0.0023 - accuracy: 1.0000 - balanced_acc: 0.9687\n",
            "Epoch 39: val_balanced_acc did not improve from 0.64772\n",
            "83/83 [==============================] - 19s 234ms/step - loss: 0.0023 - accuracy: 1.0000 - balanced_acc: 0.9687 - val_loss: 0.8869 - val_accuracy: 0.8083 - val_balanced_acc: 0.6054 - lr: 0.0010\n",
            "Epoch 40/50\n",
            "83/83 [==============================] - ETA: 0s - loss: 0.0022 - accuracy: 1.0000 - balanced_acc: 0.9489\n",
            "Epoch 40: val_balanced_acc did not improve from 0.64772\n",
            "83/83 [==============================] - 19s 234ms/step - loss: 0.0022 - accuracy: 1.0000 - balanced_acc: 0.9489 - val_loss: 0.8809 - val_accuracy: 0.8238 - val_balanced_acc: 0.6082 - lr: 0.0010\n",
            "Epoch 41/50\n",
            "83/83 [==============================] - ETA: 0s - loss: 0.0021 - accuracy: 1.0000 - balanced_acc: 0.9667\n",
            "Epoch 41: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "\n",
            "Epoch 41: val_balanced_acc did not improve from 0.64772\n",
            "83/83 [==============================] - 19s 234ms/step - loss: 0.0021 - accuracy: 1.0000 - balanced_acc: 0.9667 - val_loss: 0.8870 - val_accuracy: 0.8290 - val_balanced_acc: 0.6123 - lr: 0.0010\n",
            "Epoch 42/50\n",
            "83/83 [==============================] - ETA: 0s - loss: 0.0019 - accuracy: 1.0000 - balanced_acc: 0.9395\n",
            "Epoch 42: val_balanced_acc did not improve from 0.64772\n",
            "83/83 [==============================] - 19s 235ms/step - loss: 0.0019 - accuracy: 1.0000 - balanced_acc: 0.9395 - val_loss: 0.8863 - val_accuracy: 0.8290 - val_balanced_acc: 0.6123 - lr: 5.0000e-04\n",
            "Epoch 43/50\n",
            "83/83 [==============================] - ETA: 0s - loss: 0.0018 - accuracy: 1.0000 - balanced_acc: 0.9613\n",
            "Epoch 43: val_balanced_acc did not improve from 0.64772\n",
            "83/83 [==============================] - 19s 234ms/step - loss: 0.0018 - accuracy: 1.0000 - balanced_acc: 0.9613 - val_loss: 0.8914 - val_accuracy: 0.8238 - val_balanced_acc: 0.6082 - lr: 5.0000e-04\n",
            "Epoch 44/50\n",
            "83/83 [==============================] - ETA: 0s - loss: 0.0018 - accuracy: 1.0000 - balanced_acc: 0.9593\n",
            "Epoch 44: val_balanced_acc did not improve from 0.64772\n",
            "83/83 [==============================] - 19s 234ms/step - loss: 0.0018 - accuracy: 1.0000 - balanced_acc: 0.9593 - val_loss: 0.9075 - val_accuracy: 0.8135 - val_balanced_acc: 0.6062 - lr: 5.0000e-04\n",
            "Epoch 45/50\n",
            "83/83 [==============================] - ETA: 0s - loss: 0.0017 - accuracy: 1.0000 - balanced_acc: 0.9601\n",
            "Epoch 45: val_balanced_acc did not improve from 0.64772\n",
            "83/83 [==============================] - 19s 234ms/step - loss: 0.0017 - accuracy: 1.0000 - balanced_acc: 0.9601 - val_loss: 0.9016 - val_accuracy: 0.8290 - val_balanced_acc: 0.6123 - lr: 5.0000e-04\n",
            "Epoch 46/50\n",
            "83/83 [==============================] - ETA: 0s - loss: 0.0016 - accuracy: 1.0000 - balanced_acc: 0.9664\n",
            "Epoch 46: val_balanced_acc did not improve from 0.64772\n",
            "83/83 [==============================] - 19s 234ms/step - loss: 0.0016 - accuracy: 1.0000 - balanced_acc: 0.9664 - val_loss: 0.9148 - val_accuracy: 0.8135 - val_balanced_acc: 0.6062 - lr: 5.0000e-04\n",
            "Epoch 47/50\n",
            "83/83 [==============================] - ETA: 0s - loss: 0.0016 - accuracy: 1.0000 - balanced_acc: 0.9590\n",
            "Epoch 47: val_balanced_acc did not improve from 0.64772\n",
            "83/83 [==============================] - 19s 234ms/step - loss: 0.0016 - accuracy: 1.0000 - balanced_acc: 0.9590 - val_loss: 0.9096 - val_accuracy: 0.8238 - val_balanced_acc: 0.6082 - lr: 5.0000e-04\n",
            "Epoch 48/50\n",
            "83/83 [==============================] - ETA: 0s - loss: 0.0016 - accuracy: 1.0000 - balanced_acc: 0.9487\n",
            "Epoch 48: val_balanced_acc did not improve from 0.64772\n",
            "83/83 [==============================] - 19s 234ms/step - loss: 0.0016 - accuracy: 1.0000 - balanced_acc: 0.9487 - val_loss: 0.9156 - val_accuracy: 0.8238 - val_balanced_acc: 0.6115 - lr: 5.0000e-04\n",
            "Epoch 49/50\n",
            "83/83 [==============================] - ETA: 0s - loss: 0.0015 - accuracy: 1.0000 - balanced_acc: 0.9641\n",
            "Epoch 49: val_balanced_acc did not improve from 0.64772\n",
            "83/83 [==============================] - 19s 234ms/step - loss: 0.0015 - accuracy: 1.0000 - balanced_acc: 0.9641 - val_loss: 0.9251 - val_accuracy: 0.8187 - val_balanced_acc: 0.6073 - lr: 5.0000e-04\n",
            "Epoch 50/50\n",
            "83/83 [==============================] - ETA: 0s - loss: 0.0015 - accuracy: 1.0000 - balanced_acc: 0.9561\n",
            "Epoch 50: val_balanced_acc did not improve from 0.64772\n",
            "83/83 [==============================] - 19s 234ms/step - loss: 0.0015 - accuracy: 1.0000 - balanced_acc: 0.9561 - val_loss: 0.9266 - val_accuracy: 0.8135 - val_balanced_acc: 0.6062 - lr: 5.0000e-04\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "# define model\n",
        "model = define_model_resnet()\n",
        "#Callbacks\n",
        "best_model_fpath = '/content/drive/MyDrive/PHD/Model/best_model_'+'no_smote'+'_'+dataset_name+'.h5'\n",
        "print(\"best_model_fpath:\"+best_model_fpath)\n",
        "mc = ModelCheckpoint(best_model_fpath, monitor='val_balanced_acc', mode='max', verbose=1, save_best_only=True)\n",
        "learning_rate_reduction = ReduceLROnPlateau(monitor='val_balanced_acc', patience=20, verbose=1, factor=0.5, min_lr=0.00001)\n",
        "early_stopping_monitor = EarlyStopping(patience=40,monitor='val_balanced_acc')\n",
        "#model.summary()\n",
        "hst = model.fit(X_train, y_train, epochs=EPOCHS, batch_size=BATCH_SIZE, validation_data=(X_val, y_val), verbose=1,\n",
        "                    steps_per_epoch=X_train.shape[0] // BATCH_SIZE, \n",
        "                    #callbacks=[learning_rate_reduction,early_stopping_monitor, mc])\n",
        "                    callbacks=[learning_rate_reduction,mc])\n",
        "# learning curves\n",
        "summarize_diagnostics(hst)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "SPz8NH1Oylv9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8ef4fbc6-59af-403d-d951-3fd14e45d395"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "model saved\n"
          ]
        }
      ],
      "source": [
        "#save last model\n",
        "last_model_fpath = '/content/drive/MyDrive/PHD/Model/last_model_'+'no_smote'+'_'+dataset_name+'.h5'\n",
        "model.save(last_model_fpath)\n",
        "print(\"model saved\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "vXnW3lmCgln3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "8dd7706b-ff2b-4c38-8a71-81e857a6fc0b"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "# summarize history for accuracy\n",
        "plt.plot(hst.history['accuracy'])\n",
        "plt.plot(hst.history['balanced_acc'])\n",
        "plt.plot(hst.history['val_accuracy'])\n",
        "plt.plot(hst.history['val_balanced_acc'])\n",
        "plt.title('Model accuracy')\n",
        "plt.ylabel('Performance')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train accuracy', 'train balanced acc.', 'val. accuracy', 'val. balanced acc.'], loc='lower right')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "icgjmi-4UIT-"
      },
      "source": [
        "#Evaluate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "lS3ewyxO_anU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "57eb5a28-1d96-4d70-8479-41030187e842"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "167/167 [==============================] - 8s 37ms/step\n",
            "7/7 [==============================] - 0s 36ms/step\n",
            "accuracy on training 1.0\n",
            "balanced accuracy on training 1.0\n",
            "accuracy on validation 0.8134715025906736\n",
            "balanced accuracy on validation 0.7570508469463173\n",
            "Score on val data:  (0.7747822450214207, 0.7570508469463173, 0.7498695315313916, None)\n"
          ]
        }
      ],
      "source": [
        "last_model_fpath = '/content/drive/MyDrive/PHD/Model/last_model_'+'no_smote'+'_'+dataset_name+'.h5'\n",
        "last_model = load_model(last_model_fpath, custom_objects={'balanced_acc' : balanced_acc})\n",
        "y_train_pred = last_model.predict(X_train)\n",
        "y_val_pred = last_model.predict(X_val)\n",
        "\n",
        "#print('accuracy on training',accuracy_score(np.argmax(y_train, axis=1), np.argmax(y_train_pred, axis=1)))\n",
        "print('accuracy on training',accuracy_score(np.argmax(y_train, axis=1), np.argmax(y_train_pred, axis=1)))\n",
        "print('balanced accuracy on training',balanced_accuracy_score(np.argmax(y_train, axis=1), np.argmax(y_train_pred, axis=1)))\n",
        "print('accuracy on validation',accuracy_score(np.argmax(y_val, axis=1), np.argmax(y_val_pred, axis=1)))\n",
        "print('balanced accuracy on validation',balanced_accuracy_score(np.argmax(y_val, axis=1), np.argmax(y_val_pred, axis=1)))\n",
        "print('Score on val data: ',precision_recall_fscore_support(np.argmax(y_val, axis=1), np.argmax(y_val_pred, axis=1), average='macro'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "W3IyWjdGG4Xq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0e801c05-575f-40aa-f9bf-1dffdc24e63b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "167/167 [==============================] - 7s 38ms/step\n",
            "7/7 [==============================] - 0s 37ms/step\n",
            "accuracy on training 0.992858485247134\n",
            "balanced accuracy on training 0.99055145365288\n",
            "accuracy on validation 0.8652849740932642\n",
            "balanced accuracy on validation 0.80326862452298\n",
            "Score on val data:  (0.8062119584675976, 0.80326862452298, 0.7697449361934251, None)\n"
          ]
        }
      ],
      "source": [
        "best_model = load_model(best_model_fpath, custom_objects={'balanced_acc' : balanced_acc})\n",
        "y_train_pred = best_model.predict(X_train)\n",
        "y_val_pred = best_model.predict(X_val)\n",
        "\n",
        "print('accuracy on training',accuracy_score(np.argmax(y_train, axis=1), np.argmax(y_train_pred, axis=1)))\n",
        "print('balanced accuracy on training',balanced_accuracy_score(np.argmax(y_train, axis=1), np.argmax(y_train_pred, axis=1)))\n",
        "print('accuracy on validation',accuracy_score(np.argmax(y_val, axis=1), np.argmax(y_val_pred, axis=1)))\n",
        "print('balanced accuracy on validation',balanced_accuracy_score(np.argmax(y_val, axis=1), np.argmax(y_val_pred, axis=1)))\n",
        "print('Score on val data: ',precision_recall_fscore_support(np.argmax(y_val, axis=1), np.argmax(y_val_pred, axis=1), average='macro'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iDRWiTnO0MGh"
      },
      "source": [
        "#Cut-off"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tGnCoIdLyDHS"
      },
      "outputs": [],
      "source": [
        "df_val_pred = pd.DataFrame(y_val_pred, columns = ['AKIEC', 'BCC', 'BKL', 'DF', 'MEL', 'NV', 'VASC'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QdyCbloQyWTC"
      },
      "outputs": [],
      "source": [
        "numbers = [float(x)/40 for x in range(11)]\n",
        "for i in numbers:\n",
        "    df_val_pred[i]= df_val_pred.MEL.map(lambda x: 1 if x > i else 0)\n",
        "df_val_pred.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G4SQsRx73kgk"
      },
      "outputs": [],
      "source": [
        "y_val_true= [1 if x == 4 else 0 for x in np.argmax(y_val, axis=1)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QcUISWFi0J05"
      },
      "outputs": [],
      "source": [
        "#num = [0.0,0.05,0.1,0.15,0.2,0.25,0.3,0.35,0.4,0.45,0.5]\n",
        "cutoff_df = pd.DataFrame( columns = ['Probability','Accuracy','Sensitivity','Specificity'])\n",
        "for i in numbers:\n",
        "    cm1 = confusion_matrix(y_val_true, df_val_pred[i])\n",
        "    total1=sum(sum(cm1))\n",
        "    Accuracy = (cm1[0,0]+cm1[1,1])/total1\n",
        "    Specificity = cm1[0,0]/(cm1[0,0]+cm1[0,1])\n",
        "    Sensitivity = cm1[1,1]/(cm1[1,0]+cm1[1,1])\n",
        "    cutoff_df.loc[i] =[ i ,Accuracy,Sensitivity,Specificity]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W31LSzov1tCt"
      },
      "outputs": [],
      "source": [
        "cutoff_df[['Accuracy','Sensitivity','Specificity']].plot()\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P6CIKT94Jqye"
      },
      "outputs": [],
      "source": [
        "i = 0.025\n",
        "cm1 = confusion_matrix(y_val_true, df_val_pred[i])\n",
        "total1=sum(sum(cm1))\n",
        "Accuracy = (cm1[0,0]+cm1[1,1])/total1\n",
        "Specificity = cm1[0,0]/(cm1[0,0]+cm1[0,1])\n",
        "Sensitivity = cm1[1,1]/(cm1[1,0]+cm1[1,1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3U2tkFebL_VC"
      },
      "outputs": [],
      "source": [
        "print('Accuracy: ', Accuracy)\n",
        "print('Sensitivity: ', Sensitivity)\n",
        "print('Specificity: ', Specificity)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eaK4zbtoaAaC"
      },
      "source": [
        "#Confusion Metric on Validation Set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YkPOFLehOmFg"
      },
      "outputs": [],
      "source": [
        "#change melanoma flag back to 4\n",
        "df_val_pred[df_val_pred[i] == 1] = 4\n",
        "#decode one-hot y_val_pred while use cut-off melanoma data\n",
        "condition = df_val_pred[i] == 4\n",
        "y_val_pred2 = np.where(condition, df_val_pred[i], np.argmax(y_val_pred, axis=1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LOVl6dWlTDLo"
      },
      "outputs": [],
      "source": [
        "print('Accuracy: ',accuracy_score(np.argmax(y_val, axis=1), y_val_pred2))\n",
        "print('Balanced accuracy: ',balanced_accuracy_score(np.argmax(y_val, axis=1), y_val_pred2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mqvYutTKRhR_"
      },
      "outputs": [],
      "source": [
        "#Get the confusion matrix\n",
        "cf_matrix = confusion_matrix(np.argmax(y_val, axis=1), y_val_pred2)\n",
        "print(cf_matrix)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gVtvW3YeaLlC"
      },
      "outputs": [],
      "source": [
        "ax = sns.heatmap(cf_matrix / cf_matrix.sum(axis=1, keepdims=True), annot=True, \n",
        "            cmap='Blues')\n",
        "\n",
        "ax.set_title('Confusion Matrix \\n');\n",
        "ax.set_xlabel('\\nPredicted')\n",
        "ax.set_ylabel('Actual ');\n",
        "\n",
        "## Ticket labels - List must be in alphabetical order\n",
        "ax.xaxis.set_ticklabels(['AKIEC', 'BCC', 'BKL', 'DF', 'MEL', 'NV', 'VASC'])\n",
        "ax.yaxis.set_ticklabels(['AKIEC', 'BCC', 'BKL', 'DF', 'MEL', 'NV', 'VASC'])\n",
        "\n",
        "plt.rcParams[\"figure.figsize\"] = (15,3)\n",
        "\n",
        "## Display the visualization of the Confusion Matrix.\n",
        "plt.xticks(rotation=45, ha='right')\n",
        "plt.yticks(rotation=0, ha='right')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ey-1yjWGeKs7"
      },
      "outputs": [],
      "source": [
        "# ordered count of rows per unique label\n",
        "#labels_count = df_val['Labels'].value_counts().sort_index()\n",
        "\n",
        "#f = plt.figure(figsize=(15, 6))\n",
        "#s = sns.barplot(x=labels_count.index,y=labels_count.values)\n",
        "#s.set_xticklabels(s.get_xticklabels(), rotation = 30)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3K908bbiYwbS"
      },
      "source": [
        "#Testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "cN98sOWPyT3P",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2316c488-05c7-4494-8159-333a4ec5c717"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1512, 224, 224, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "df_test = pd.read_pickle(path+\"isic2018_test.pkl\")\n",
        "X_test = df_test.loc[:, df_test.columns != 'y_train'].to_numpy()\n",
        "X_test = X_test.reshape(-1,224,224,3)\n",
        "X_test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "NeMY2yvMYxsC"
      },
      "outputs": [],
      "source": [
        "dir_test = '/content/drive/MyDrive/PHD/Datasets/isic2018/ISIC2018_Task3_Test_Input/'\n",
        "filepaths = sorted( filter( lambda x: (os.path.isfile(os.path.join(dir_test, x))) and (x.endswith('.jpg')),\n",
        "                        os.listdir(dir_test) ) )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "6ic95mefkpG3"
      },
      "outputs": [],
      "source": [
        "df_test = pd.DataFrame(filepaths, columns =['image'])\n",
        "df_test['FilePaths'] = dir_test + df_test['image']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "NBa1TxPuY8ni"
      },
      "outputs": [],
      "source": [
        "df_test['image_px'] = df_test['FilePaths'].map(lambda x: np.asarray(Image.open(x).resize(IMG_SIZE)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "60LYAT7VsNOZ",
        "outputId": "e2210f76-2e3a-4add-995e-79582acdab74"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1512, 128, 128, 3)\n"
          ]
        }
      ],
      "source": [
        "X_test = np.asarray(df_test['image_px'].tolist())\n",
        "print(np.array(X_test).shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "cXnnIIwC4cHE"
      },
      "outputs": [],
      "source": [
        "#preprocess\n",
        "X_test = preprocess_image_input(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "JC17MArBxhSW"
      },
      "outputs": [],
      "source": [
        "df3 = pd.DataFrame(X_test.reshape(X_test.shape[0],-1))\n",
        "df3.to_pickle(path+\"isic2018_test_128px.pkl\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FF7ml90JZ8FK"
      },
      "source": [
        "Calculate y_pred from training and testing for analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KeDTXdaMLmyU",
        "outputId": "a6ea64da-79f0-424f-f913-5b0bd6c66170"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(1512, 2048)"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#FOR MAKING FEATURE SPACE DATA\n",
        "X_test = model1.predict(X_test)\n",
        "X_test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dIX0AmEFNv3Y",
        "outputId": "0ed9a370-faec-457b-8d99-7c7de11457df"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "48/48 [==============================] - 2s 46ms/step\n",
            "Y_pred2 (1512, 7)\n"
          ]
        }
      ],
      "source": [
        "# predicting\n",
        "#CHANGE THE MODEL IF NECESSARY\n",
        "Y_pred2 = best_model.predict(X_test)\n",
        "#Y_pred2 = model2.predict(X_test)\n",
        "print(\"Y_pred2\", Y_pred2.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "7oeArO5CtxGb"
      },
      "outputs": [],
      "source": [
        "df_pred = pd.DataFrame(Y_pred2, columns = ['AKIEC', 'BCC', 'BKL', 'DF', 'MEL', 'NV', 'VASC'])\n",
        "df_pred['image'] = df_test['FilePaths'].map(lambda x: x.replace(dir_test, '').replace('.jpg', ''))\n",
        "df_pred = df_pred[['image', 'MEL', 'NV', 'BCC', 'AKIEC', 'BKL', 'DF', 'VASC']]\n",
        "df_pred.set_index(\"image\", inplace = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9ynyd8PjT589"
      },
      "outputs": [],
      "source": [
        "#update MEL data using cut-off value\n",
        "df_pred.MEL[df_pred.MEL > i] = 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fjRdONoQVMq0"
      },
      "outputs": [],
      "source": [
        "df_pred.loc[df_pred.MEL > i, ['NV', 'BCC', 'AKIEC', 'BKL', 'DF', 'VASC']] = 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K4Iv_3s4z0R9"
      },
      "outputs": [],
      "source": [
        "df_pred.head(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "sOnjc3RJ0e4T"
      },
      "outputs": [],
      "source": [
        "df_pred.to_csv('/content/drive/MyDrive/PHD/Datasets/isic2018/response_50epochs-128px-SMOTE.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P0MghVs0tsGw"
      },
      "source": [
        "result: 0.601"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UswA0co2y1wl"
      },
      "source": [
        "#Exp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dnqJYIONy34l"
      },
      "outputs": [],
      "source": [
        "input_tensor = Input(shape=(IMAGE_H, IMAGE_W, 3))\n",
        "base_model = ResNet50(input_shape=(224,224,3), weights='imagenet', include_top=False)\n",
        "x = base_model(input_tensor, training=False)\n",
        "x = Attention(2048,2048,7,8)(x)\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "res50 = Model(inputs=input_tensor, outputs=x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kcn8hQg3J8yP"
      },
      "outputs": [],
      "source": [
        "#Train i-last layer\n",
        "# summarize feature map shapes\n",
        "for i in range(len(model.layers)):\n",
        "    layer = model.layers[i]\n",
        "    # summarize output shape\n",
        "    print(i, layer.name, layer.output.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UA7Af2Y73FUv"
      },
      "outputs": [],
      "source": [
        "X_train = res50.predict(X_train)\n",
        "X_val = res50.predict(X_val)\n",
        "print(X_train.shape)\n",
        "print(y_train.shape)\n",
        "print(X_val.shape)\n",
        "print(y_val.shape)\n",
        "print('Counter train data: ', Counter(np.argmax(y_train, axis=1)))\n",
        "print('Counter val data: ', Counter(np.argmax(y_val, axis=1)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "krJiAb1m3QNf"
      },
      "outputs": [],
      "source": [
        "X_train, y_train = SMOTE_Data2(X_train, y_train, True)\n",
        "print(X_train.shape)\n",
        "print(y_train.shape)\n",
        "print(X_val.shape)\n",
        "print(y_val.shape)\n",
        "print('Counter train data: ', Counter(np.argmax(y_train, axis=1)))\n",
        "print('Counter val data: ', Counter(np.argmax(y_val, axis=1)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LfcFpsBwM0d4"
      },
      "source": [
        "#Attention"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 398
        },
        "id": "C_s6OIGKM26a",
        "outputId": "371bd24a-4bf9-491a-e0ec-78b7eb06e6d9"
      },
      "outputs": [
        {
          "ename": "AttributeError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-ff488085aaa5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mConv2D\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mMaxPooling2D\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mAveragePooling2D\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mBatchNormalization\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mAdd\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mZeroPadding2D\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mFlatten\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mInput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mLeakyReLU\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mSoftmax\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mReLU\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAdam\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    471\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_current_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"keras\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    472\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 473\u001b[0;31m     \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    474\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    475\u001b[0m     \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/lazy_loader.py\u001b[0m in \u001b[0;36m_load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;34m\"\"\"Load the module and insert it into the parent's globals.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0;31m# Import the target module and insert it into the parent's namespace\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m     \u001b[0mmodule\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimportlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimport_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_module_globals\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_local_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/importlib/__init__.py\u001b[0m in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m    125\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m             \u001b[0mlevel\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_bootstrap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gcd_import\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpackage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;31m# See b/110718070#comment18 for more details about this import.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_layer\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mInput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/models.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv2\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmetrics\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmetrics_module\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0moptimizer_v1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfunctional\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/metrics.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mwarnings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mactivations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbase_layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/activations.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0madvanced_activations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgeneric_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdeserialize_keras_object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgeneric_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mserialize_keras_object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/layers/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_spec\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mInputSpec\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_layer\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLayer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_preprocessing_layer\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPreprocessingLayer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;31m# Image preprocessing layers.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/base_preprocessing_layer.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mabc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdata_adapter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_layer\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLayer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mversion_utils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m   \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m  \u001b[0;31m# pylint: disable=g-import-not-at-top\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m   \u001b[0mpd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tester\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 179\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtesting\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    180\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/testing.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m from pandas._testing import (\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0massert_extension_array_equal\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0massert_frame_equal\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/_testing/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    946\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    947\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 948\u001b[0;31m \u001b[0mcython_table\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommon\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cython_table\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    949\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    950\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: module 'pandas' has no attribute 'core'"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow.keras as tk\n",
        "from tensorflow.keras.layers import Conv2D,MaxPooling2D,AveragePooling2D,BatchNormalization,Add,ZeroPadding2D,Flatten,Dense,Input,LeakyReLU,Softmax,ReLU\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.models import Model\n",
        "import numpy as np\n",
        "import pickle\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "\n",
        "class Attention(tk.layers.Layer):\n",
        "    \n",
        "    def __init__(self,input_channels,output_channel,kernel_size,groups):\n",
        "        super().__init__()\n",
        "        self.input_channels = input_channels\n",
        "        self.output_channel = output_channel    \n",
        "        self.kernel_size = kernel_size\n",
        "        self.stride = 1\n",
        "        self.groups = groups\n",
        "\n",
        "        assert output_channel % groups == 0\n",
        "        \n",
        "        self.rel_h = tk.backend.variable(lambda : tk.backend.truncated_normal((1,1,kernel_size,1,output_channel//2),stddev = 0.1)) \n",
        "        #output_channels//2 is the number of channels on which the relative position will be considered,1 denotes the number of those filters and the one after that too and (kernel_size,1) denotes the size of that filter\n",
        "        self.rel_w = tk.backend.variable(lambda : tk.backend.truncated_normal((1,1,1,kernel_size,output_channel//2),stddev = 0.1)) \n",
        "\n",
        "        self.key_weights = Conv2D(self.output_channel,kernel_size = 1,strides = self.stride)\n",
        "        self.query_weights = Conv2D(self.output_channel,kernel_size = 1,strides = self.stride)\n",
        "        self.value_weights = Conv2D(self.output_channel,kernel_size = 1,strides = self.stride)\n",
        "\n",
        "    def call(self,x):\n",
        "        \n",
        "        batch,height,width,channels = x.shape\n",
        "        x_padded = ZeroPadding2D(padding=(self.kernel_size//2,self.kernel_size//2))(x)\n",
        "        query = self.query_weights(x)\n",
        "        value = self.value_weights(x_padded)\n",
        "        key = self.key_weights(x_padded)\n",
        "        #key,query and value will have the shape of (batch,height,width,depth)\n",
        "        keys = tf.image.extract_patches(images = key,sizes = [1,self.kernel_size,self.kernel_size,1],strides = [1,self.stride,self.stride,1],rates = [1,1,1,1], padding = \"VALID\")\n",
        "        value = tf.image.extract_patches(images = value,sizes = [1,self.kernel_size,self.kernel_size,1],strides = [1,self.stride,self.stride,1],rates = [1,1,1,1], padding = \"VALID\")\n",
        "        no_of_kernels = key.shape[-2] - self.kernel_size + 1\n",
        "        keys = tf.reshape(keys,shape = (-1,no_of_kernels, no_of_kernels,self.kernel_size,self.kernel_size,self.output_channel))\n",
        "        key_split_h,key_split_w = tf.split(keys,num_or_size_splits = 2,axis = -1)\n",
        "        key_with_rel = tk.layers.concatenate([key_split_h + self.rel_h,key_split_w + self.rel_w],axis = -1) \n",
        "        \n",
        "        #reshaping the query and key\n",
        "        key_with_rel = tf.reshape(key_with_rel,(-1,self.groups,no_of_kernels,no_of_kernels,self.kernel_size*self.kernel_size,self.output_channel//self.groups))\n",
        "        query  = tf.reshape(query,(-1,self.groups,no_of_kernels,no_of_kernels,1,self.output_channel//self.groups))        \n",
        "        value = tf.reshape(value,(-1,self.groups,no_of_kernels,no_of_kernels,self.kernel_size*self.kernel_size,self.output_channel//self.groups))\n",
        "        \n",
        "        #multiplication  of key and query\n",
        "        #assert key_with_rel.shape == query.shape        \n",
        "        key_prod_query = query*key_with_rel\n",
        "        \n",
        "        # Now the function is passed through the softmax and is multiplied with the values\n",
        "        s = Softmax(axis = -2)(key_prod_query)\n",
        "        y = tf.einsum('bnchwk,bnchwk->bnchk',s,value)\n",
        "        y = tf.reshape(y,(-1,height,width,self.output_channel))\n",
        "        return y\n",
        "\n",
        "    def get_config(self):\n",
        "        config = super().get_config().copy()\n",
        "        config.update({\n",
        "            \"input_channels\": self.input_channels, \n",
        "            \"output_channel\": self.output_channel, \n",
        "            \"kernel_size\": self.kernel_size, \n",
        "            \"stride\": self.stride, \n",
        "            \"groups\": self.groups, \n",
        "            \"rel_h\": self.rel_h, \n",
        "            \"rel_w\": self.rel_w, \n",
        "            \"key_weights\": self.key_weights, \n",
        "            \"query_weights\": self.query_weights, \n",
        "            \"value_weights\": self.value_weights\n",
        "        })\n",
        "        return config\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kE8Ziq-BlEP4"
      },
      "source": [
        "#Oversampling on feature map level"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = best_model"
      ],
      "metadata": {
        "id": "wqfEP5L9BgcF"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lm05Zet_B5am",
        "outputId": "668a8d9c-c574-4e23-be1d-18deba3c44c9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 input_1 [(None, 128, 128, 3)] True\n",
            "1 resnet50 (None, 4, 4, 2048) True\n",
            "2 global_average_pooling2d (None, 2048) True\n",
            "3 flatten (None, 2048) True\n",
            "4 dense (None, 1024) True\n",
            "5 dense_1 (None, 512) True\n",
            "6 dense_2 (None, 7) True\n"
          ]
        }
      ],
      "source": [
        "for i in range(len(model.layers)):\n",
        "  layer = model.layers[i]\n",
        "  print(i, layer.name, layer.output_shape, layer.trainable)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "KqeSic6NmLsR"
      },
      "outputs": [],
      "source": [
        "# redefine model to output right after the first hidden layer\n",
        "end = 3\n",
        "model1 = Model(inputs=model.inputs, outputs=model.layers[end].output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "ZVHYG9Rwm28i",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "54b27cc7-9d21-47e7-a89a-61f60350b54e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "167/167 [==============================] - 6s 35ms/step\n",
            "7/7 [==============================] - 0s 33ms/step\n"
          ]
        }
      ],
      "source": [
        "# get feature map for first hidden layer\n",
        "X_train_fm = model1.predict(X_train)\n",
        "X_val_fm = model1.predict(X_val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "Xx0OnnZPl7_t",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f2380739-a093-4f40-8834-f86ed1c26c6f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(5321, 2048)\n",
            "(5321, 7)\n",
            "(193, 2048)\n",
            "(193, 7)\n",
            "Counter train data:  Counter({5: 2011, 4: 1113, 2: 1099, 1: 514, 0: 327, 6: 142, 3: 115})\n",
            "Counter val data:  Counter({5: 123, 2: 22, 4: 21, 1: 15, 0: 8, 6: 3, 3: 1})\n"
          ]
        }
      ],
      "source": [
        "print(X_train_fm.shape)\n",
        "print(y_train.shape)\n",
        "print(X_val_fm.shape)\n",
        "print(y_val.shape)\n",
        "print('Counter train data: ', Counter(np.argmax(y_train, axis=1)))\n",
        "print('Counter val data: ', Counter(np.argmax(y_val, axis=1)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "19hK7aQNeAQo",
        "outputId": "b5e70a67-ad64-41b2-fc36-6b5d51a14510"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(14077, 2048)\n",
            "(14077, 7)\n",
            "(193, 2048)\n",
            "(193, 7)\n",
            "Counter train data:  Counter({5: 2011, 4: 2011, 2: 2011, 3: 2011, 0: 2011, 1: 2011, 6: 2011})\n",
            "Counter val data:  Counter({5: 123, 2: 22, 4: 21, 1: 15, 0: 8, 6: 3, 3: 1})\n"
          ]
        }
      ],
      "source": [
        "X_train_fm_ov, y_train_ov = SMOTE_Data2(X_train_fm, y_train, True, 5, type=\"borderline\")\n",
        "print(X_train_fm_ov.shape)\n",
        "print(y_train_ov.shape)\n",
        "print(X_val_fm.shape)\n",
        "print(y_val.shape)\n",
        "print('Counter train data: ', Counter(np.argmax(y_train_ov, axis=1)))\n",
        "print('Counter val data: ', Counter(np.argmax(y_val, axis=1)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "5qP4iyYcnAYa"
      },
      "outputs": [],
      "source": [
        "model2 = Model(inputs=model.layers[end+1].input, outputs=model.layers[len(model.layers)-1].output)\n",
        "#model2 = define_base_model(arch = 'dense')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pzdjs0WbvDB0",
        "outputId": "6dfab766-6293-4c31-a5fd-5dd34394597c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "best_model_fpath:/content/drive/MyDrive/PHD/Model/best_model_borderline_on_featurespace_under70_128px.h5\n",
            "last_model_fpath:/content/drive/MyDrive/PHD/Model/last_model_borderline_on_featurespace_under70_128px.h5\n",
            "Epoch 1/50\n",
            "217/219 [============================>.] - ETA: 0s - loss: 0.0646 - accuracy: 0.9970 - balanced_acc: 0.9971\n",
            "Epoch 1: val_balanced_acc improved from -inf to 0.48927, saving model to /content/drive/MyDrive/PHD/Model/best_model_borderline_on_featurespace_under70_128px.h5\n",
            "219/219 [==============================] - 2s 5ms/step - loss: 0.0647 - accuracy: 0.9970 - balanced_acc: 0.9971 - val_loss: 0.5779 - val_accuracy: 0.8187 - val_balanced_acc: 0.4893 - lr: 3.1250e-05\n",
            "Epoch 2/50\n",
            "205/219 [===========================>..] - ETA: 0s - loss: 0.0564 - accuracy: 0.9976 - balanced_acc: 0.9977\n",
            "Epoch 2: val_balanced_acc did not improve from 0.48927\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.0562 - accuracy: 0.9976 - balanced_acc: 0.9977 - val_loss: 0.5785 - val_accuracy: 0.8187 - val_balanced_acc: 0.4893 - lr: 3.1250e-05\n",
            "Epoch 3/50\n",
            "209/219 [===========================>..] - ETA: 0s - loss: 0.0540 - accuracy: 0.9975 - balanced_acc: 0.9976\n",
            "Epoch 3: val_balanced_acc did not improve from 0.48927\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.0539 - accuracy: 0.9974 - balanced_acc: 0.9975 - val_loss: 0.5817 - val_accuracy: 0.8187 - val_balanced_acc: 0.4893 - lr: 3.1250e-05\n",
            "Epoch 4/50\n",
            "209/219 [===========================>..] - ETA: 0s - loss: 0.0537 - accuracy: 0.9971 - balanced_acc: 0.9972\n",
            "Epoch 4: val_balanced_acc did not improve from 0.48927\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.0534 - accuracy: 0.9971 - balanced_acc: 0.9973 - val_loss: 0.5836 - val_accuracy: 0.8135 - val_balanced_acc: 0.4884 - lr: 3.1250e-05\n",
            "Epoch 5/50\n",
            "209/219 [===========================>..] - ETA: 0s - loss: 0.0522 - accuracy: 0.9974 - balanced_acc: 0.9973\n",
            "Epoch 5: val_balanced_acc did not improve from 0.48927\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.0522 - accuracy: 0.9974 - balanced_acc: 0.9974 - val_loss: 0.5856 - val_accuracy: 0.8135 - val_balanced_acc: 0.4884 - lr: 3.1250e-05\n",
            "Epoch 6/50\n",
            "209/219 [===========================>..] - ETA: 0s - loss: 0.0516 - accuracy: 0.9972 - balanced_acc: 0.9971\n",
            "Epoch 6: val_balanced_acc did not improve from 0.48927\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.0518 - accuracy: 0.9971 - balanced_acc: 0.9970 - val_loss: 0.5855 - val_accuracy: 0.8083 - val_balanced_acc: 0.4825 - lr: 3.1250e-05\n",
            "Epoch 7/50\n",
            "208/219 [===========================>..] - ETA: 0s - loss: 0.0512 - accuracy: 0.9974 - balanced_acc: 0.9975\n",
            "Epoch 7: val_balanced_acc did not improve from 0.48927\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.0511 - accuracy: 0.9975 - balanced_acc: 0.9976 - val_loss: 0.5861 - val_accuracy: 0.8135 - val_balanced_acc: 0.4884 - lr: 3.1250e-05\n",
            "Epoch 8/50\n",
            "218/219 [============================>.] - ETA: 0s - loss: 0.0502 - accuracy: 0.9975 - balanced_acc: 0.9973\n",
            "Epoch 8: val_balanced_acc did not improve from 0.48927\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.0502 - accuracy: 0.9975 - balanced_acc: 0.9973 - val_loss: 0.5877 - val_accuracy: 0.8135 - val_balanced_acc: 0.4884 - lr: 3.1250e-05\n",
            "Epoch 9/50\n",
            "208/219 [===========================>..] - ETA: 0s - loss: 0.0500 - accuracy: 0.9977 - balanced_acc: 0.9974\n",
            "Epoch 9: val_balanced_acc did not improve from 0.48927\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.0499 - accuracy: 0.9976 - balanced_acc: 0.9974 - val_loss: 0.5905 - val_accuracy: 0.8135 - val_balanced_acc: 0.4884 - lr: 3.1250e-05\n",
            "Epoch 10/50\n",
            "219/219 [==============================] - ETA: 0s - loss: 0.0495 - accuracy: 0.9975 - balanced_acc: 0.9976\n",
            "Epoch 10: val_balanced_acc did not improve from 0.48927\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 0.0495 - accuracy: 0.9975 - balanced_acc: 0.9976 - val_loss: 0.5888 - val_accuracy: 0.8135 - val_balanced_acc: 0.4884 - lr: 3.1250e-05\n",
            "Epoch 11/50\n",
            "211/219 [===========================>..] - ETA: 0s - loss: 0.0487 - accuracy: 0.9976 - balanced_acc: 0.9977\n",
            "Epoch 11: val_balanced_acc did not improve from 0.48927\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.0485 - accuracy: 0.9976 - balanced_acc: 0.9978 - val_loss: 0.5885 - val_accuracy: 0.8135 - val_balanced_acc: 0.4884 - lr: 3.1250e-05\n",
            "Epoch 12/50\n",
            "208/219 [===========================>..] - ETA: 0s - loss: 0.0483 - accuracy: 0.9976 - balanced_acc: 0.9977\n",
            "Epoch 12: val_balanced_acc did not improve from 0.48927\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.0486 - accuracy: 0.9975 - balanced_acc: 0.9976 - val_loss: 0.5886 - val_accuracy: 0.8135 - val_balanced_acc: 0.4884 - lr: 3.1250e-05\n",
            "Epoch 13/50\n",
            "210/219 [===========================>..] - ETA: 0s - loss: 0.0484 - accuracy: 0.9977 - balanced_acc: 0.9979\n",
            "Epoch 13: val_balanced_acc did not improve from 0.48927\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.0483 - accuracy: 0.9976 - balanced_acc: 0.9978 - val_loss: 0.5891 - val_accuracy: 0.8135 - val_balanced_acc: 0.4884 - lr: 3.1250e-05\n",
            "Epoch 14/50\n",
            "208/219 [===========================>..] - ETA: 0s - loss: 0.0470 - accuracy: 0.9979 - balanced_acc: 0.9976\n",
            "Epoch 14: val_balanced_acc did not improve from 0.48927\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.0471 - accuracy: 0.9977 - balanced_acc: 0.9975 - val_loss: 0.5905 - val_accuracy: 0.8135 - val_balanced_acc: 0.4884 - lr: 3.1250e-05\n",
            "Epoch 15/50\n",
            "212/219 [============================>.] - ETA: 0s - loss: 0.0476 - accuracy: 0.9975 - balanced_acc: 0.9975\n",
            "Epoch 15: val_balanced_acc did not improve from 0.48927\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.0475 - accuracy: 0.9975 - balanced_acc: 0.9975 - val_loss: 0.5893 - val_accuracy: 0.8135 - val_balanced_acc: 0.4884 - lr: 3.1250e-05\n",
            "Epoch 16/50\n",
            "210/219 [===========================>..] - ETA: 0s - loss: 0.0467 - accuracy: 0.9979 - balanced_acc: 0.9979\n",
            "Epoch 16: val_balanced_acc did not improve from 0.48927\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.0471 - accuracy: 0.9977 - balanced_acc: 0.9977 - val_loss: 0.5884 - val_accuracy: 0.8135 - val_balanced_acc: 0.4884 - lr: 3.1250e-05\n",
            "Epoch 17/50\n",
            "211/219 [===========================>..] - ETA: 0s - loss: 0.0462 - accuracy: 0.9979 - balanced_acc: 0.9977\n",
            "Epoch 17: val_balanced_acc did not improve from 0.48927\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.0464 - accuracy: 0.9976 - balanced_acc: 0.9976 - val_loss: 0.5899 - val_accuracy: 0.8135 - val_balanced_acc: 0.4884 - lr: 3.1250e-05\n",
            "Epoch 18/50\n",
            "205/219 [===========================>..] - ETA: 0s - loss: 0.0455 - accuracy: 0.9980 - balanced_acc: 0.9982\n",
            "Epoch 18: val_balanced_acc did not improve from 0.48927\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.0458 - accuracy: 0.9978 - balanced_acc: 0.9980 - val_loss: 0.5897 - val_accuracy: 0.8135 - val_balanced_acc: 0.4884 - lr: 3.1250e-05\n",
            "Epoch 19/50\n",
            "217/219 [============================>.] - ETA: 0s - loss: 0.0457 - accuracy: 0.9978 - balanced_acc: 0.9978\n",
            "Epoch 19: val_balanced_acc did not improve from 0.48927\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.0457 - accuracy: 0.9979 - balanced_acc: 0.9979 - val_loss: 0.5888 - val_accuracy: 0.8135 - val_balanced_acc: 0.4884 - lr: 3.1250e-05\n",
            "Epoch 20/50\n",
            "208/219 [===========================>..] - ETA: 0s - loss: 0.0461 - accuracy: 0.9976 - balanced_acc: 0.9977\n",
            "Epoch 20: val_balanced_acc did not improve from 0.48927\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.0460 - accuracy: 0.9976 - balanced_acc: 0.9977 - val_loss: 0.5904 - val_accuracy: 0.8083 - val_balanced_acc: 0.4843 - lr: 3.1250e-05\n",
            "Epoch 21/50\n",
            "208/219 [===========================>..] - ETA: 0s - loss: 0.0447 - accuracy: 0.9980 - balanced_acc: 0.9973\n",
            "Epoch 21: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
            "\n",
            "Epoch 21: val_balanced_acc did not improve from 0.48927\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.0450 - accuracy: 0.9979 - balanced_acc: 0.9972 - val_loss: 0.5897 - val_accuracy: 0.8083 - val_balanced_acc: 0.4843 - lr: 3.1250e-05\n",
            "Epoch 22/50\n",
            "206/219 [===========================>..] - ETA: 0s - loss: 0.0447 - accuracy: 0.9979 - balanced_acc: 0.9977\n",
            "Epoch 22: val_balanced_acc did not improve from 0.48927\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.0447 - accuracy: 0.9980 - balanced_acc: 0.9979 - val_loss: 0.5904 - val_accuracy: 0.8083 - val_balanced_acc: 0.4843 - lr: 1.5625e-05\n",
            "Epoch 23/50\n",
            "208/219 [===========================>..] - ETA: 0s - loss: 0.0450 - accuracy: 0.9976 - balanced_acc: 0.9975\n",
            "Epoch 23: val_balanced_acc did not improve from 0.48927\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.0450 - accuracy: 0.9976 - balanced_acc: 0.9976 - val_loss: 0.5905 - val_accuracy: 0.8083 - val_balanced_acc: 0.4843 - lr: 1.5625e-05\n",
            "Epoch 24/50\n",
            "207/219 [===========================>..] - ETA: 0s - loss: 0.0446 - accuracy: 0.9981 - balanced_acc: 0.9983\n",
            "Epoch 24: val_balanced_acc did not improve from 0.48927\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.0445 - accuracy: 0.9981 - balanced_acc: 0.9983 - val_loss: 0.5912 - val_accuracy: 0.8083 - val_balanced_acc: 0.4843 - lr: 1.5625e-05\n",
            "Epoch 25/50\n",
            "209/219 [===========================>..] - ETA: 0s - loss: 0.0439 - accuracy: 0.9982 - balanced_acc: 0.9981\n",
            "Epoch 25: val_balanced_acc did not improve from 0.48927\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.0438 - accuracy: 0.9982 - balanced_acc: 0.9981 - val_loss: 0.5914 - val_accuracy: 0.8083 - val_balanced_acc: 0.4843 - lr: 1.5625e-05\n",
            "Epoch 26/50\n",
            "207/219 [===========================>..] - ETA: 0s - loss: 0.0451 - accuracy: 0.9975 - balanced_acc: 0.9972\n",
            "Epoch 26: val_balanced_acc did not improve from 0.48927\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.0450 - accuracy: 0.9976 - balanced_acc: 0.9974 - val_loss: 0.5913 - val_accuracy: 0.8083 - val_balanced_acc: 0.4843 - lr: 1.5625e-05\n",
            "Epoch 27/50\n",
            "209/219 [===========================>..] - ETA: 0s - loss: 0.0448 - accuracy: 0.9976 - balanced_acc: 0.9976\n",
            "Epoch 27: val_balanced_acc did not improve from 0.48927\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.0445 - accuracy: 0.9977 - balanced_acc: 0.9977 - val_loss: 0.5915 - val_accuracy: 0.8083 - val_balanced_acc: 0.4843 - lr: 1.5625e-05\n",
            "Epoch 28/50\n",
            "208/219 [===========================>..] - ETA: 0s - loss: 0.0440 - accuracy: 0.9981 - balanced_acc: 0.9980\n",
            "Epoch 28: val_balanced_acc did not improve from 0.48927\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.0439 - accuracy: 0.9981 - balanced_acc: 0.9979 - val_loss: 0.5915 - val_accuracy: 0.8083 - val_balanced_acc: 0.4843 - lr: 1.5625e-05\n",
            "Epoch 29/50\n",
            "205/219 [===========================>..] - ETA: 0s - loss: 0.0441 - accuracy: 0.9982 - balanced_acc: 0.9984\n",
            "Epoch 29: val_balanced_acc did not improve from 0.48927\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.0439 - accuracy: 0.9982 - balanced_acc: 0.9984 - val_loss: 0.5923 - val_accuracy: 0.8083 - val_balanced_acc: 0.4843 - lr: 1.5625e-05\n",
            "Epoch 30/50\n",
            "208/219 [===========================>..] - ETA: 0s - loss: 0.0440 - accuracy: 0.9977 - balanced_acc: 0.9976\n",
            "Epoch 30: val_balanced_acc did not improve from 0.48927\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.0439 - accuracy: 0.9979 - balanced_acc: 0.9977 - val_loss: 0.5912 - val_accuracy: 0.8083 - val_balanced_acc: 0.4843 - lr: 1.5625e-05\n",
            "Epoch 31/50\n",
            "205/219 [===========================>..] - ETA: 0s - loss: 0.0438 - accuracy: 0.9982 - balanced_acc: 0.9983\n",
            "Epoch 31: val_balanced_acc did not improve from 0.48927\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.0437 - accuracy: 0.9982 - balanced_acc: 0.9984 - val_loss: 0.5921 - val_accuracy: 0.8083 - val_balanced_acc: 0.4843 - lr: 1.5625e-05\n",
            "Epoch 32/50\n",
            "209/219 [===========================>..] - ETA: 0s - loss: 0.0431 - accuracy: 0.9981 - balanced_acc: 0.9980\n",
            "Epoch 32: val_balanced_acc did not improve from 0.48927\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.0433 - accuracy: 0.9981 - balanced_acc: 0.9979 - val_loss: 0.5920 - val_accuracy: 0.8083 - val_balanced_acc: 0.4843 - lr: 1.5625e-05\n",
            "Epoch 33/50\n",
            "206/219 [===========================>..] - ETA: 0s - loss: 0.0434 - accuracy: 0.9983 - balanced_acc: 0.9985\n",
            "Epoch 33: val_balanced_acc did not improve from 0.48927\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.0433 - accuracy: 0.9982 - balanced_acc: 0.9984 - val_loss: 0.5923 - val_accuracy: 0.8083 - val_balanced_acc: 0.4843 - lr: 1.5625e-05\n",
            "Epoch 34/50\n",
            "207/219 [===========================>..] - ETA: 0s - loss: 0.0436 - accuracy: 0.9985 - balanced_acc: 0.9975\n",
            "Epoch 34: val_balanced_acc did not improve from 0.48927\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.0434 - accuracy: 0.9986 - balanced_acc: 0.9976 - val_loss: 0.5928 - val_accuracy: 0.8083 - val_balanced_acc: 0.4843 - lr: 1.5625e-05\n",
            "Epoch 35/50\n",
            "206/219 [===========================>..] - ETA: 0s - loss: 0.0430 - accuracy: 0.9978 - balanced_acc: 0.9978\n",
            "Epoch 35: val_balanced_acc did not improve from 0.48927\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.0430 - accuracy: 0.9978 - balanced_acc: 0.9978 - val_loss: 0.5922 - val_accuracy: 0.8083 - val_balanced_acc: 0.4843 - lr: 1.5625e-05\n",
            "Epoch 36/50\n",
            "211/219 [===========================>..] - ETA: 0s - loss: 0.0436 - accuracy: 0.9981 - balanced_acc: 0.9980\n",
            "Epoch 36: val_balanced_acc did not improve from 0.48927\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.0434 - accuracy: 0.9981 - balanced_acc: 0.9981 - val_loss: 0.5914 - val_accuracy: 0.8083 - val_balanced_acc: 0.4843 - lr: 1.5625e-05\n",
            "Epoch 37/50\n",
            "208/219 [===========================>..] - ETA: 0s - loss: 0.0433 - accuracy: 0.9983 - balanced_acc: 0.9982\n",
            "Epoch 37: val_balanced_acc did not improve from 0.48927\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.0430 - accuracy: 0.9983 - balanced_acc: 0.9982 - val_loss: 0.5910 - val_accuracy: 0.8083 - val_balanced_acc: 0.4843 - lr: 1.5625e-05\n",
            "Epoch 38/50\n",
            "207/219 [===========================>..] - ETA: 0s - loss: 0.0433 - accuracy: 0.9981 - balanced_acc: 0.9981\n",
            "Epoch 38: val_balanced_acc did not improve from 0.48927\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.0431 - accuracy: 0.9982 - balanced_acc: 0.9982 - val_loss: 0.5922 - val_accuracy: 0.8083 - val_balanced_acc: 0.4843 - lr: 1.5625e-05\n",
            "Epoch 39/50\n",
            "210/219 [===========================>..] - ETA: 0s - loss: 0.0426 - accuracy: 0.9982 - balanced_acc: 0.9982\n",
            "Epoch 39: val_balanced_acc did not improve from 0.48927\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.0426 - accuracy: 0.9982 - balanced_acc: 0.9982 - val_loss: 0.5925 - val_accuracy: 0.8083 - val_balanced_acc: 0.4843 - lr: 1.5625e-05\n",
            "Epoch 40/50\n",
            "208/219 [===========================>..] - ETA: 0s - loss: 0.0427 - accuracy: 0.9980 - balanced_acc: 0.9976\n",
            "Epoch 40: val_balanced_acc did not improve from 0.48927\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.0429 - accuracy: 0.9980 - balanced_acc: 0.9976 - val_loss: 0.5927 - val_accuracy: 0.8083 - val_balanced_acc: 0.4843 - lr: 1.5625e-05\n",
            "Epoch 41/50\n",
            "205/219 [===========================>..] - ETA: 0s - loss: 0.0421 - accuracy: 0.9981 - balanced_acc: 0.9981\n",
            "Epoch 41: ReduceLROnPlateau reducing learning rate to 1e-05.\n",
            "\n",
            "Epoch 41: val_balanced_acc did not improve from 0.48927\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.0419 - accuracy: 0.9981 - balanced_acc: 0.9982 - val_loss: 0.5926 - val_accuracy: 0.8083 - val_balanced_acc: 0.4843 - lr: 1.5625e-05\n",
            "Epoch 42/50\n",
            "208/219 [===========================>..] - ETA: 0s - loss: 0.0419 - accuracy: 0.9987 - balanced_acc: 0.9988\n",
            "Epoch 42: val_balanced_acc did not improve from 0.48927\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.0423 - accuracy: 0.9986 - balanced_acc: 0.9987 - val_loss: 0.5932 - val_accuracy: 0.8083 - val_balanced_acc: 0.4843 - lr: 1.0000e-05\n",
            "Epoch 43/50\n",
            "208/219 [===========================>..] - ETA: 0s - loss: 0.0417 - accuracy: 0.9984 - balanced_acc: 0.9983\n",
            "Epoch 43: val_balanced_acc did not improve from 0.48927\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.0418 - accuracy: 0.9984 - balanced_acc: 0.9983 - val_loss: 0.5934 - val_accuracy: 0.8083 - val_balanced_acc: 0.4843 - lr: 1.0000e-05\n",
            "Epoch 44/50\n",
            "207/219 [===========================>..] - ETA: 0s - loss: 0.0427 - accuracy: 0.9983 - balanced_acc: 0.9975\n",
            "Epoch 44: val_balanced_acc did not improve from 0.48927\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.0428 - accuracy: 0.9984 - balanced_acc: 0.9977 - val_loss: 0.5931 - val_accuracy: 0.8083 - val_balanced_acc: 0.4843 - lr: 1.0000e-05\n",
            "Epoch 45/50\n",
            "208/219 [===========================>..] - ETA: 0s - loss: 0.0418 - accuracy: 0.9981 - balanced_acc: 0.9982\n",
            "Epoch 45: val_balanced_acc did not improve from 0.48927\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.0419 - accuracy: 0.9982 - balanced_acc: 0.9982 - val_loss: 0.5925 - val_accuracy: 0.8083 - val_balanced_acc: 0.4843 - lr: 1.0000e-05\n",
            "Epoch 46/50\n",
            "207/219 [===========================>..] - ETA: 0s - loss: 0.0422 - accuracy: 0.9984 - balanced_acc: 0.9985\n",
            "Epoch 46: val_balanced_acc did not improve from 0.48927\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.0421 - accuracy: 0.9984 - balanced_acc: 0.9978 - val_loss: 0.5929 - val_accuracy: 0.8083 - val_balanced_acc: 0.4843 - lr: 1.0000e-05\n",
            "Epoch 47/50\n",
            "209/219 [===========================>..] - ETA: 0s - loss: 0.0423 - accuracy: 0.9981 - balanced_acc: 0.9982\n",
            "Epoch 47: val_balanced_acc did not improve from 0.48927\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.0420 - accuracy: 0.9981 - balanced_acc: 0.9983 - val_loss: 0.5933 - val_accuracy: 0.8083 - val_balanced_acc: 0.4843 - lr: 1.0000e-05\n",
            "Epoch 48/50\n",
            "206/219 [===========================>..] - ETA: 0s - loss: 0.0423 - accuracy: 0.9983 - balanced_acc: 0.9982\n",
            "Epoch 48: val_balanced_acc did not improve from 0.48927\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.0426 - accuracy: 0.9982 - balanced_acc: 0.9982 - val_loss: 0.5926 - val_accuracy: 0.8083 - val_balanced_acc: 0.4843 - lr: 1.0000e-05\n",
            "Epoch 49/50\n",
            "210/219 [===========================>..] - ETA: 0s - loss: 0.0409 - accuracy: 0.9985 - balanced_acc: 0.9986\n",
            "Epoch 49: val_balanced_acc did not improve from 0.48927\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.0412 - accuracy: 0.9985 - balanced_acc: 0.9986 - val_loss: 0.5939 - val_accuracy: 0.8083 - val_balanced_acc: 0.4843 - lr: 1.0000e-05\n",
            "Epoch 50/50\n",
            "205/219 [===========================>..] - ETA: 0s - loss: 0.0419 - accuracy: 0.9979 - balanced_acc: 0.9980\n",
            "Epoch 50: val_balanced_acc did not improve from 0.48927\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.0419 - accuracy: 0.9979 - balanced_acc: 0.9980 - val_loss: 0.5942 - val_accuracy: 0.8083 - val_balanced_acc: 0.4843 - lr: 1.0000e-05\n"
          ]
        }
      ],
      "source": [
        "best_model_fpath = '/content/drive/MyDrive/PHD/Model/best_model_'+exp_name+'_'+dataset_name+'.h5'\n",
        "print(\"best_model_fpath:\"+best_model_fpath)\n",
        "last_model_fpath = '/content/drive/MyDrive/PHD/Model/last_model_'+exp_name+'_'+dataset_name+'.h5'\n",
        "print(\"last_model_fpath:\"+last_model_fpath)\n",
        "mc1 = ModelCheckpoint(best_model_fpath, monitor='val_balanced_acc', mode='max', verbose=1, save_best_only=True)\n",
        "learning_rate_reduction = ReduceLROnPlateau(monitor='val_balanced_acc', patience=20, verbose=1, factor=0.5, min_lr=0.00001)\n",
        "early_stopping_monitor = EarlyStopping(patience=40,monitor='val_balanced_acc')\n",
        "model2.compile(optimizer = opt_SGD , loss = \"categorical_crossentropy\", metrics=['accuracy', balanced_acc])\n",
        "hst = model2.fit(X_train_fm_ov, y_train_ov, epochs=EPOCHS, batch_size=BATCH_SIZE, validation_data=(X_val_fm, y_val), verbose=1,\n",
        "                    steps_per_epoch=X_train_fm_ov.shape[0] // BATCH_SIZE, \n",
        "                    #callbacks=[learning_rate_reduction,early_stopping_monitor, mc1])\n",
        "                    callbacks=[learning_rate_reduction,mc1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "8XhlbWn--8Or",
        "outputId": "4ff62e20-8f19-4817-893d-4726c601f630"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "# summarize history for accuracy\n",
        "plt.plot(hst.history['accuracy'])\n",
        "plt.plot(hst.history['balanced_acc'])\n",
        "plt.plot(hst.history['val_accuracy'])\n",
        "plt.plot(hst.history['val_balanced_acc'])\n",
        "plt.title('Model accuracy')\n",
        "plt.ylabel('Performance')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train accuracy', 'train balanced acc.', 'val. accuracy', 'val. balanced acc.'], loc='lower right')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "u-x0SENPGmm9"
      },
      "outputs": [],
      "source": [
        "#save last model\n",
        "model2.save(last_model_fpath)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U-e3ZaeeG1Bf",
        "outputId": "bfe8b847-756b-4811-95ce-7d5e45f66b85"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "440/440 [==============================] - 1s 1ms/step\n",
            "7/7 [==============================] - 0s 2ms/step\n",
            "accuracy on training 0.9982950912836542\n",
            "balanced accuracy on training 0.9982950912836542\n",
            "accuracy on validation 0.8082901554404145\n",
            "balanced accuracy on validation 0.7501380152948098\n",
            "Score on val data:  (0.656493299165713, 0.7501380152948098, 0.6708167990143054, None)\n"
          ]
        }
      ],
      "source": [
        "last_model = load_model(last_model_fpath, custom_objects={'balanced_acc' : balanced_acc})\n",
        "y_train_pred = last_model.predict(X_train_fm_ov)\n",
        "y_val_pred = last_model.predict(X_val_fm)\n",
        "\n",
        "#print('accuracy on training',accuracy_score(np.argmax(y_train, axis=1), np.argmax(y_train_pred, axis=1)))\n",
        "print('accuracy on training',accuracy_score(np.argmax(y_train_ov, axis=1), np.argmax(y_train_pred, axis=1)))\n",
        "print('balanced accuracy on training',balanced_accuracy_score(np.argmax(y_train_ov, axis=1), np.argmax(y_train_pred, axis=1)))\n",
        "print('accuracy on validation',accuracy_score(np.argmax(y_val, axis=1), np.argmax(y_val_pred, axis=1)))\n",
        "print('balanced accuracy on validation',balanced_accuracy_score(np.argmax(y_val, axis=1), np.argmax(y_val_pred, axis=1)))\n",
        "print('Score on val data: ',precision_recall_fscore_support(np.argmax(y_val, axis=1), np.argmax(y_val_pred, axis=1), average='macro'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EQ3baQLsHLat",
        "outputId": "957b5387-442c-4611-a7a5-8a4e2fea772b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "440/440 [==============================] - 1s 1ms/step\n",
            "7/7 [==============================] - 0s 2ms/step\n",
            "accuracy on training 0.9975847126518435\n",
            "balanced accuracy on training 0.9975847126518433\n",
            "accuracy on validation 0.8186528497409327\n",
            "balanced accuracy on validation 0.7577929619741467\n",
            "Score on val data:  (0.7128414128414128, 0.7577929619741467, 0.6976800976800976, None)\n"
          ]
        }
      ],
      "source": [
        "best_model = load_model(best_model_fpath, custom_objects={'balanced_acc' : balanced_acc})\n",
        "y_train_pred = best_model.predict(X_train_fm_ov)\n",
        "y_val_pred = best_model.predict(X_val_fm)\n",
        "\n",
        "print('accuracy on training',accuracy_score(np.argmax(y_train_ov, axis=1), np.argmax(y_train_pred, axis=1)))\n",
        "print('balanced accuracy on training',balanced_accuracy_score(np.argmax(y_train_ov, axis=1), np.argmax(y_train_pred, axis=1)))\n",
        "print('accuracy on validation',accuracy_score(np.argmax(y_val, axis=1), np.argmax(y_val_pred, axis=1)))\n",
        "print('balanced accuracy on validation',balanced_accuracy_score(np.argmax(y_val, axis=1), np.argmax(y_val_pred, axis=1)))\n",
        "print('Score on val data: ',precision_recall_fscore_support(np.argmax(y_val, axis=1), np.argmax(y_val_pred, axis=1), average='macro'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RcRGeofw-8tK"
      },
      "source": [
        "#Load ISIC 2018 Challange Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "l3P7IjyLuZGY"
      },
      "outputs": [],
      "source": [
        "X_train, y_train, X_val, y_val = load_isic2018_dataset(train_under_frac = 0.7)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "XT95XFaHQD6d"
      },
      "outputs": [],
      "source": [
        "X_train = preprocess_image_input(X_train, the_arch)\n",
        "X_val = preprocess_image_input(X_val, the_arch)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path = '/content/drive/MyDrive/PHD/Datasets/isic2018/'\n",
        "df1 = pd.DataFrame(X_train.reshape(X_train.shape[0],-1))\n",
        "df1['y_train'] = np.argmax(y_train, axis=1).tolist()\n",
        "df2 = pd.DataFrame(X_val.reshape(X_val.shape[0],-1))\n",
        "df2['y_val'] = np.argmax(y_val, axis=1).tolist()\n",
        "df1.to_pickle(path+\"isic2018_train_under70_128px.pkl\")\n",
        "df2.to_pickle(path+\"isic2018_val.pkl\")"
      ],
      "metadata": {
        "id": "APHFdj25vatJ"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2IncA-_o_n5w"
      },
      "outputs": [],
      "source": [
        "# ordered count of rows per unique label\n",
        "labels_count = y_train.value_counts(ascending=True)\n",
        "\n",
        "f = plt.figure(figsize=(15, 6))\n",
        "s = sns.barplot(x=labels_count.index,y=labels_count.values)\n",
        "s.set_xticklabels(s.get_xticklabels(), rotation = 30)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AnKMKSb4Bkym"
      },
      "source": [
        "Plot 3 images per label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jdnVuqbFBW3K"
      },
      "outputs": [],
      "source": [
        "def plot_images_per_label(df, label, cols: int, size: tuple):\n",
        "    fig, axs = plt.subplots(nrows=1, ncols=cols, figsize=size)\n",
        "\n",
        "    cntMax = cols\n",
        "    cntCur = 0\n",
        "    for index, row in df.iterrows():\n",
        "        if(y_train == label and cntCur < cntMax):\n",
        "            axs[cntCur].imshow(plt.imread(df.FilePaths[index]))\n",
        "            axs[cntCur].set_title(df.Labels[index])\n",
        "\n",
        "            cntCur += 1\n",
        "        else:\n",
        "            if(cntCur >= cntMax):\n",
        "                break\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "# unique labels\n",
        "labels = sorted(df1['y_train'].unique())\n",
        "for label in range(7):\n",
        "    plot_images_per_label(df1, label, 3, (12,9))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "asV1O58Lrq-R"
      },
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "img = Image.fromarray(X_train[0], 'RGB')\n",
        "display(img)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qRKKrNacAZtl"
      },
      "source": [
        "Drop duplicate images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ERwfyPDHP-zC"
      },
      "outputs": [],
      "source": [
        "#df_group = pd.read_csv('/content/drive/MyDrive/PHD/Datasets/isic2018/ISIC2018_Task3_Training_LesionGroupings.csv') \n",
        "#df_train = df_train.set_index('image').join(df_group.set_index('image'))\n",
        "#df_train = df_train.drop_duplicates(subset=['lesion_id'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cNBXx28B9yGu"
      },
      "source": [
        "#DeepSMOTE Oversampling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YmX_Uqbmj-tN"
      },
      "outputs": [],
      "source": [
        "from numpy import moveaxis\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "max_el = np.inf\n",
        "\n",
        "args = {}\n",
        "args['dim_h'] = 64         # factor controlling size of hidden layers\n",
        "args['n_channel'] = 3#1    # number of channels in the input data \n",
        "args['n_z'] = 600 #300     # number of dimensions in latent space. \n",
        "args['sigma'] = 1.0        # variance in n_z\n",
        "args['lambda'] = 0.01      # hyper param for weight of discriminator loss\n",
        "args['lr'] = 0.0002        # learning rate for Adam optimizer .000\n",
        "args['epochs'] = 300       # how many epochs to run for\n",
        "args['batch_size'] = 100   # batch size for SGD\n",
        "args['save'] = True        # save weights at each epoch of training if True\n",
        "args['train'] = True       # train networks if True, else load networks from\n",
        "args['patience'] = 20"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NydOdPMajEfT"
      },
      "outputs": [],
      "source": [
        "class Encoder(nn.Module):\n",
        "    def __init__(self, args):\n",
        "        super(Encoder, self).__init__()\n",
        "\n",
        "        self.n_channel = args['n_channel']\n",
        "        self.dim_h = args['dim_h']\n",
        "        self.n_z = args['n_z']\n",
        "        \n",
        "        # convolutional filters, work excellent with image data\n",
        "        # [(W−K+2P)/S]+1\n",
        "        self.conv = nn.Sequential(\n",
        "            nn.AvgPool2d(7, stride=7),\n",
        "            nn.Conv2d(self.n_channel, self.dim_h, 4, 2, 1, bias=False),# 16\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Conv2d(self.dim_h, self.dim_h * 2, 4, 2, 1, bias=False), # 8\n",
        "            nn.BatchNorm2d(self.dim_h * 2),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Conv2d(self.dim_h * 2, self.dim_h * 4, 4, 2, 1, bias=False),# 4\n",
        "            nn.BatchNorm2d(self.dim_h * 4),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Conv2d(self.dim_h * 4, self.dim_h * 8, 4, 2, 0, bias=False),#14\n",
        "            nn.BatchNorm2d(self.dim_h * 8),\n",
        "            nn.LeakyReLU(0.2, inplace=True))\n",
        "        self.fc = nn.Linear(self.dim_h * (2 ** 3), self.n_z)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv(x)\n",
        "        \n",
        "        x = x.squeeze()\n",
        "        x = self.fc(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self, args):\n",
        "        super(Decoder, self).__init__()\n",
        "\n",
        "        self.n_channel = args['n_channel']\n",
        "        self.dim_h = args['dim_h']\n",
        "        self.n_z = args['n_z']\n",
        "\n",
        "        # first layer is fully connected\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(self.n_z, self.dim_h * 2**3 * 7 * 7),\n",
        "            nn.ReLU())\n",
        "\n",
        "        # deconvolutional filters, essentially inverse of convolutional filters\n",
        "        # H_out ​= (H_in​−1)*stride[0] − 2×padding[0] + dilation[0]×(kernel_size[0]−1) + output_padding[0] + 1\n",
        "        self.deconv = nn.Sequential(\n",
        "            nn.ConvTranspose2d(self.dim_h * 8, self.dim_h * 4, 4), #10\n",
        "            nn.BatchNorm2d(self.dim_h * 4),\n",
        "            nn.ReLU(True),\n",
        "            nn.ConvTranspose2d(self.dim_h * 4, self.dim_h * 2, 4), #13\n",
        "            nn.BatchNorm2d(self.dim_h * 2),\n",
        "            nn.ReLU(True),\n",
        "            nn.ConvTranspose2d(self.dim_h * 2, self.dim_h, 4),# 16\n",
        "            nn.BatchNorm2d(self.dim_h),\n",
        "            nn.ReLU(True),\n",
        "            nn.ConvTranspose2d(self.dim_h, 3, 4, 2, 1),# 32\n",
        "            nn.UpsamplingBilinear2d(scale_factor=7),\n",
        "            nn.Tanh())\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.fc(x)\n",
        "        x = x.view(-1, self.dim_h * 2**3, 7, 7)\n",
        "        x = self.deconv(x)\n",
        "        return x\n",
        "\n",
        "##############################################################################\n",
        "\"\"\"set models, loss functions\"\"\"\n",
        "# control which parameters are frozen / free for optimization\n",
        "def free_params(module: nn.Module):\n",
        "    for p in module.parameters():\n",
        "        p.requires_grad = True\n",
        "\n",
        "def frozen_params(module: nn.Module):\n",
        "    for p in module.parameters():\n",
        "        p.requires_grad = False\n",
        "\n",
        "def biased_get_class(X, y, c):\n",
        "    \n",
        "    xbeg = X[y == c]\n",
        "    ybeg = y[y == c]\n",
        "    \n",
        "    return xbeg, ybeg\n",
        "    #return xclass, yclass\n",
        "\n",
        "def G_SM(X, y,n_to_sample,cl):\n",
        "    n_neigh = 5\n",
        "    nn = NearestNeighbors(n_neighbors=n_neigh, n_jobs=1)\n",
        "    nn.fit(X)\n",
        "    dist, ind = nn.kneighbors(X)\n",
        "\n",
        "    # generating samples\n",
        "    base_indices = np.random.choice(list(range(len(X))),n_to_sample)\n",
        "    neighbor_indices = np.random.choice(list(range(1, n_neigh)),n_to_sample)\n",
        "\n",
        "    X_base = X[base_indices]\n",
        "    X_neighbor = X[ind[base_indices, neighbor_indices]]\n",
        "\n",
        "    samples = X_base + np.multiply(np.random.rand(n_to_sample,1),\n",
        "            X_neighbor - X_base)\n",
        "\n",
        "    #use 10 as label because 0 to 9 real classes and 1 fake/smoted = 10\n",
        "    return samples, [cl]*n_to_sample\n",
        "\n",
        "def DeepSMOTE_train(X_train, y_train, one_hot = False):\n",
        "  from torch.utils.data import TensorDataset\n",
        "  import os\n",
        "\n",
        "  max_el = np.max(X_train)\n",
        "  X_train = X_train / max_el\n",
        "  X_train = moveaxis(X_train, 3, 1)\n",
        "  if one_hot:\n",
        "    y_train = np.argmax(y_train, axis=1)\n",
        "  #X_train = X_train.astype('float32') / 255.\n",
        "  \n",
        "  batch_size = args['batch_size']\n",
        "  patience = args['patience']\n",
        "  encoder = Encoder(args)\n",
        "  decoder = Decoder(args)\n",
        "\n",
        "  device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "  print(device)\n",
        "  decoder = decoder.to(device)\n",
        "  encoder = encoder.to(device)\n",
        "\n",
        "  train_on_gpu = torch.cuda.is_available()\n",
        "\n",
        "  #decoder loss function\n",
        "  criterion = nn.MSELoss()\n",
        "  criterion = criterion.to(device)\n",
        "\n",
        "  num_workers = 0\n",
        "\n",
        "  #torch.Tensor returns float so if want long then use torch.tensor\n",
        "  tensor_x = torch.from_numpy(X_train.copy())#torch.Tensor(X_train)\n",
        "  tensor_y = torch.tensor(y_train,dtype=torch.long)\n",
        "  mnist_bal = TensorDataset(tensor_x,tensor_y) \n",
        "  train_loader = torch.utils.data.DataLoader(mnist_bal, \n",
        "      batch_size=batch_size,shuffle=True,num_workers=num_workers)\n",
        "\n",
        "  best_loss = np.inf\n",
        "\n",
        "  enc_optim = torch.optim.Adam(encoder.parameters(), lr = args['lr'])\n",
        "  dec_optim = torch.optim.Adam(decoder.parameters(), lr = args['lr'])\n",
        "\n",
        "  for epoch in range(args['epochs']):\n",
        "      train_loss = 0.0\n",
        "      tmse_loss = 0.0\n",
        "      tdiscr_loss = 0.0\n",
        "      # train for one epoch -- set nets to train mode\n",
        "      encoder.train()\n",
        "      decoder.train()\n",
        "  \n",
        "      for images,labs in train_loader:\n",
        "      \n",
        "          # zero gradients for each batch\n",
        "          encoder.zero_grad()\n",
        "          decoder.zero_grad()\n",
        "          images, labs = images.to(device), labs.to(device)\n",
        "          labsn = labs.detach().cpu().numpy()\n",
        "#            print('images shape', images.shape)\n",
        "          # run images\n",
        "          z_hat = encoder(images)\n",
        "#            print('images shape after encoding', z_hat.shape)\n",
        "      \n",
        "          x_hat = decoder(z_hat) #decoder outputs tanh\n",
        "#            print('images shape after decoding', x_hat.shape)\n",
        "          mse = criterion(x_hat,images)\n",
        "                  \n",
        "          resx = []\n",
        "          resy = []\n",
        "      \n",
        "          tc = np.random.choice(num_classes,1)\n",
        "          #tc = 9\n",
        "          xbeg = X_train[y_train == tc]\n",
        "          ybeg = y_train[y_train == tc] \n",
        "          xlen = len(xbeg)\n",
        "          nsamp = min(xlen, 100)\n",
        "          ind = np.random.choice(list(range(len(xbeg))),nsamp,replace=False)\n",
        "          xclass = xbeg[ind]\n",
        "          yclass = ybeg[ind]\n",
        "      \n",
        "          xclen = len(xclass)\n",
        "          xcminus = np.arange(1,xclen)\n",
        "          \n",
        "          xcplus = np.append(xcminus,0)\n",
        "          xcnew = (xclass[[xcplus],:])\n",
        "          xcnew = xcnew.reshape(xcnew.shape[1],xcnew.shape[2],xcnew.shape[3],xcnew.shape[4])\n",
        "      \n",
        "          xcnew = torch.Tensor(xcnew)\n",
        "          xcnew = xcnew.to(device)\n",
        "      \n",
        "          #encode xclass to feature space\n",
        "          xclass = torch.Tensor(xclass)\n",
        "          xclass = xclass.to(device)\n",
        "          xclass = encoder(xclass)\n",
        "      \n",
        "          xclass = xclass.detach().cpu().numpy()\n",
        "      \n",
        "          xc_enc = (xclass[[xcplus],:])\n",
        "          xc_enc = np.squeeze(xc_enc)\n",
        "      \n",
        "          xc_enc = torch.Tensor(xc_enc)\n",
        "          xc_enc = xc_enc.to(device)\n",
        "          \n",
        "          ximg = decoder(xc_enc)\n",
        "          \n",
        "          mse2 = criterion(ximg,xcnew)\n",
        "      \n",
        "          comb_loss = mse2 + mse\n",
        "          comb_loss.backward()\n",
        "      \n",
        "          enc_optim.step()\n",
        "          dec_optim.step()\n",
        "      \n",
        "          train_loss += comb_loss.item()*images.size(0)\n",
        "          tmse_loss += mse.item()*images.size(0)\n",
        "          tdiscr_loss += mse2.item()*images.size(0)\n",
        "\n",
        "      train_loss = train_loss/len(train_loader)\n",
        "      tmse_loss = tmse_loss/len(train_loader)\n",
        "      tdiscr_loss = tdiscr_loss/len(train_loader)\n",
        "      print('Epoch: {} \\tTrain Loss: {:.6f} \\tmse loss: {:.6f} \\tmse2 loss: {:.6f}'.format(epoch,\n",
        "              train_loss,tmse_loss,tdiscr_loss))\n",
        "      \n",
        "  \n",
        "  \n",
        "      #store the best encoder and decoder models\n",
        "      #here, /crs5 is a reference to 5 way cross validation, but is not\n",
        "      #necessary for illustration purposes\n",
        "      if train_loss < best_loss:\n",
        "          print('Saving..')\n",
        "          patience = args['patience']\n",
        "          path_enc = '/content/drive/MyDrive/PHD/Model/DeepSMOTE/32/bst_enc.pth'\n",
        "          path_dec = '/content/drive/MyDrive/PHD/Model/DeepSMOTE/32/bst_dec.pth'\n",
        "        \n",
        "          torch.save(encoder.state_dict(), path_enc)\n",
        "          torch.save(decoder.state_dict(), path_dec)\n",
        "  \n",
        "          best_loss = train_loss\n",
        "      else:\n",
        "          patience = patience - 1\n",
        "\n",
        "      if patience == 0:\n",
        "          print('Out of patience. \\n')\n",
        "          break\n",
        "\n",
        "def DeepSMOTE_Data(X_train, y_train, one_hot = False):\n",
        "  batch_size = args['batch_size']\n",
        "  max_el = np.max(X_train)\n",
        "  X_train = X_train / max_el\n",
        "  X_train = moveaxis(X_train, 3, 1)\n",
        "  if one_hot:\n",
        "    y_train = np.argmax(y_train, axis=1)\n",
        "  #Generate artificial images\n",
        "  import torch\n",
        "  np.printoptions(precision=5,suppress=True)\n",
        "\n",
        "  #path on the computer where the models are stored\n",
        "  modpth = '/content/drive/MyDrive/PHD/Model/DeepSMOTE/32/'\n",
        "\n",
        "  path_enc = modpth + '/bst_enc.pth'\n",
        "  path_dec = modpth + '/bst_dec.pth'\n",
        "  \n",
        "  train_on_gpu = torch.cuda.is_available()\n",
        "  device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "  encoder = Encoder(args)\n",
        "  encoder.load_state_dict(torch.load(path_enc), strict=False)\n",
        "  encoder = encoder.to(device)\n",
        "\n",
        "  decoder = Decoder(args)\n",
        "  decoder.load_state_dict(torch.load(path_dec), strict=False)\n",
        "  decoder = decoder.to(device)\n",
        "\n",
        "  encoder.eval()\n",
        "  decoder.eval()\n",
        "\n",
        "  resx = []\n",
        "  resy = []\n",
        "  \n",
        "  counter = Counter(y_train)\n",
        "  counter = sorted(counter.items())\n",
        "  counter = [value for _, value in counter]\n",
        "\n",
        "  for i in range(num_classes):\n",
        "      torch.cuda.empty_cache()\n",
        "\n",
        "      xclass, yclass = biased_get_class(X_train, y_train, i)\n",
        "      #encode xclass to feature space\n",
        "      xclass = torch.Tensor(xclass)\n",
        "      xclass = xclass.to(device)\n",
        "      xclass = encoder(xclass)\n",
        "          \n",
        "      xclass = xclass.detach().cpu().numpy()\n",
        "      n = np.max(counter) - counter[i]\n",
        "      if n == 0:\n",
        "        continue\n",
        "#        resx2 = []\n",
        "#        resy2 = []\n",
        "#        for j in range(batch_size, n+batch_size+1, batch_size):\n",
        "#          if j <= n:\n",
        "#            batch_size_max = batch_size\n",
        "#          elif n % batch_size != 0:\n",
        "#            batch_size_max = n%batch_size\n",
        "#          else:\n",
        "#            break\n",
        "#          xsamp, ysamp = G_SM(xclass,yclass,batch_size_max,i)\n",
        "      xsamp, ysamp = G_SM(xclass,yclass,n,i)\n",
        "      ysamp = np.array(ysamp)\n",
        "  \n",
        "      \"\"\"to generate samples for resnet\"\"\"   \n",
        "      xsamp = torch.Tensor(xsamp)\n",
        "      xsamp = xsamp.to(device)\n",
        "      ximg = decoder(xsamp)\n",
        "\n",
        "      ximn = ximg.detach().cpu().numpy()\n",
        "#        resx2.append(ximn)\n",
        "#        resy2.append(ysamp)\n",
        "#        \n",
        "#        resx2 = np.vstack(resx2)\n",
        "#        resy2 = np.hstack(resy2)\n",
        "      resx.append(ximn)\n",
        "      resy.append(ysamp)\n",
        "  \n",
        "  resx1 = np.vstack(resx)\n",
        "  resy1 = np.hstack(resy)\n",
        "  resx1 = resx1.reshape(resx1.shape[0],-1)\n",
        "  X_train = X_train.reshape(X_train.shape[0],-1)\n",
        "  X_train = np.vstack((resx1,X_train))\n",
        "  y_train = np.hstack((resy1,y_train))\n",
        "  y_train = to_categorical(y_train)\n",
        "  X_train = X_train.reshape(-1, 3, IMAGE_W, IMAGE_H)\n",
        "  X_train = moveaxis(X_train, 1, 3)\n",
        "  X_train = X_train * max_el\n",
        "  return X_train, y_train"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0jrJ33lUDkCM"
      },
      "source": [
        "#Split dataset to train and val"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e6qneWL_Bs2U"
      },
      "outputs": [],
      "source": [
        "# stratified train and rem (20%) datasets\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, stratify=y_train, random_state=1)\n",
        "\n",
        "print('Train Data: ', X_train.shape)\n",
        "print('Remaining Data: ', X_val.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8Kef4r_zxjgk"
      },
      "outputs": [],
      "source": [
        "#Data Augmentation\n",
        "dataaugment = ImageDataGenerator(\n",
        "        rotation_range=90,  # randomly rotate images in the range (degrees, 0 to 180)\n",
        "        zoom_range = 0.1, # Randomly zoom image \n",
        "        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
        "        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
        "        horizontal_flip=True,  # randomly flip images\n",
        "        vertical_flip=True,  # randomly flip images\n",
        "        shear_range = 10) \n",
        "\n",
        "dataaugment.fit(X_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B2PgksTFkOAq"
      },
      "source": [
        "#Fine Tune"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nr1jnSM7yzJc"
      },
      "outputs": [],
      "source": [
        "limit = 171\n",
        "for layer in model.layers[:limit]:\n",
        "   layer.trainable = False\n",
        "for layer in model.layers[limit:]:\n",
        "   layer.trainable = True\n",
        "\n",
        "optimizer_SGD = SGD(learning_rate=0.0001, momentum=0.9)\n",
        "model.compile(optimizer = optimizer_SGD , loss = \"categorical_crossentropy\", metrics=['accuracy', balanced_acc])\n",
        "hst2 = model.fit(train_data_batches,\n",
        "                    epochs = EPOCHS, validation_data = valid_data_batches,\n",
        "                    callbacks=[learning_rate_reduction,early_stopping_monitor, mc])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vO1aAQBmiy0K"
      },
      "outputs": [],
      "source": [
        "# summarize history for accuracy\n",
        "plt.plot(hst2.history['balanced_acc'])\n",
        "plt.plot(hst2.history['val_balanced_acc'])\n",
        "plt.title('model balance_acc after tunning')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'val'], loc='upper left')\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "E_x4c0_DTkaa",
        "BE9FCWBe8deT",
        "iDRWiTnO0MGh",
        "eaK4zbtoaAaC",
        "3K908bbiYwbS",
        "UswA0co2y1wl",
        "LfcFpsBwM0d4",
        "cNBXx28B9yGu",
        "0jrJ33lUDkCM",
        "B2PgksTFkOAq"
      ],
      "machine_shape": "hm",
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}