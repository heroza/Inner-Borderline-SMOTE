{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/heroza/Inner-Borderline-SMOTE/blob/main/Borderline%20Local%20under70%20128px.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Eus_4tUgfEk9",
        "outputId": "55870f94-f722-475e-f6d5-6e66201256f4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E_x4c0_DTkaa"
      },
      "source": [
        "#Library, atribut, and function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "nR2MJBYq-oiB"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import os\n",
        "from collections import Counter\n",
        "from pathlib import Path\n",
        "from PIL import Image\n",
        "from sklearn import preprocessing\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "from sklearn.metrics import precision_recall_fscore_support, balanced_accuracy_score, confusion_matrix, accuracy_score\n",
        "from keras.callbacks import ReduceLROnPlateau, EarlyStopping, ModelCheckpoint\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D, UpSampling2D\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.optimizers import Adam, SGD\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input, decode_predictions\n",
        "from tensorflow.keras.applications.inception_v3 import InceptionV3, preprocess_input\n",
        "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Input, Dropout, Flatten\n",
        "from tensorflow.keras.models import Model, load_model\n",
        "from keras.utils.np_utils import to_categorical\n",
        "import imblearn\n",
        "from imblearn.over_sampling import SMOTE, SVMSMOTE, ADASYN, KMeansSMOTE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "9-c7Xghg4SB4"
      },
      "outputs": [],
      "source": [
        "# input image size\n",
        "IMAGE_W = 128\n",
        "IMAGE_H = 128\n",
        "IMG_SIZE = (IMAGE_W,IMAGE_H)\n",
        "num_classes = 7\n",
        "EPOCHS = 50\n",
        "BATCH_SIZE = 64\n",
        "opt_adam = Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
        "opt_SGD = SGD(learning_rate=0.001)\n",
        "the_arch = 'resnet50'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "JffFid9sOXeo"
      },
      "outputs": [],
      "source": [
        "# load train and test dataset\n",
        "def preprocess_image_input(input_images, arch = the_arch):\n",
        "  input_images = input_images.astype('float32')\n",
        "  if arch == 'inception_v3':\n",
        "    output_ims = tf.keras.applications.inception_v3.preprocess_input(input_images)\n",
        "  else:\n",
        "    output_ims = tf.keras.applications.resnet50.preprocess_input(input_images)\n",
        "  return output_ims\n",
        "\n",
        "def load_cifar10_dataset():\n",
        "  from keras.datasets import cifar10\n",
        "    # load dataset\n",
        "  (X_train, y_train), (X_val, y_val) = cifar10.load_data()\n",
        "    # one hot encode target values\n",
        "  y_train = to_categorical(y_train)\n",
        "  y_val = to_categorical(y_val)\n",
        "\n",
        "  return X_train, y_train, X_val, y_val\n",
        "\n",
        "def true_positive(l1,l2):\n",
        "  tp = 0\n",
        "  for i in range(len(l1)):\n",
        "    tp = tf.cond(l1[i]==l2[i]==1, lambda: tp+1)\n",
        "  return tp\n",
        "\n",
        "def true_negative(l1,l2):\n",
        "  tn = 0\n",
        "  for i in range(len(l1)):\n",
        "    tn = tf.cond(l1[i]==l2[i]==0, lambda: tn+1)\n",
        "  return tn\n",
        "\n",
        "def false_positive(l1,l2):\n",
        "  fp = 0\n",
        "  for i in range(len(l1)):\n",
        "    fp = tf.cond(l1[i] != l2[i] and l2[i]==1, lambda: fp+1)\n",
        "  return fp\n",
        "\n",
        "def false_negative(l1,l2):\n",
        "  fn = 0\n",
        "  for i in range(len(l1)):\n",
        "    fn = tf.cond(l1[i] != l2[i] and l2[i] == 0, lambda: fn+1)\n",
        "  return fn\n",
        "\n",
        "def balanced_acc(y_true,y_pred):\n",
        "    from keras import backend as K\n",
        "    tensor1 = tf.math.argmax(y_true, axis=1)\n",
        "    tensor2 = tf.math.argmax(y_pred, axis=1)\n",
        "    cm = tf.math.confusion_matrix(tensor1, tensor2)\n",
        "    diag = tf.linalg.tensor_diag_part (cm)\n",
        "    tpfn = tf.cast(K.sum(cm, axis = 1), tf.float32) + K.epsilon()\n",
        "    recall = tf.divide(tf.cast(diag, tf.float32),tpfn)\n",
        "    balanced_acc = K.mean(recall)\n",
        "    balanced_acc = K.mean(balanced_acc)\n",
        "\n",
        "    return balanced_acc\n",
        "\n",
        "def define_base_model(arch = the_arch, start_trainable_layer = 9999, attention=False):\n",
        "  #x = data_augmentation(input_tensor)\n",
        "  #x = layers.Rescaling(1.0 / 255)(input_tensor)  # Rescale inputs\n",
        "  if arch != 'dense':\n",
        "    input_tensor = Input(shape=(IMAGE_H, IMAGE_W, 3))\n",
        "    #x = UpSampling2D(size=(7,7))(input_tensor)\n",
        "    if arch == 'resnet50':\n",
        "      base_model = ResNet50(input_tensor=input_tensor, weights='imagenet', include_top=False)\n",
        "    elif arch == 'inception_v3':\n",
        "      base_model = InceptionV3(input_tensor=input_tensor, weights='imagenet', include_top=False)\n",
        "    elif arch == 'ResNet':\n",
        "      base_model = ResNet(classes ,image_shape)(input_tensor)\n",
        "    \n",
        "    for layer in base_model.layers:\n",
        "      layer.trainable = False\n",
        "    if start_trainable_layer != 9999:\n",
        "      for layer in base_model.layers[start_trainable_layer:]:\n",
        "        layer.trainable = True\n",
        "    \n",
        "    x = base_model.output\n",
        "    if attention:\n",
        "      x = Attention(1024,1024,7,8)(x)\n",
        "    \n",
        "    x = GlobalAveragePooling2D()(x)\n",
        "    x = Flatten()(x)\n",
        "  else:\n",
        "    input_tensor = Input(shape=(2048))\n",
        "    x = input_tensor\n",
        "  #x = Flatten()(x)\n",
        "  x = Dense(1024, activation='relu')(x)\n",
        "  #x = Dropout(0.2)(x)\n",
        "  x = Dense(512, activation='relu')(x)\n",
        "  predictions = Dense(num_classes, activation='softmax')(x)\n",
        "  model = Model(inputs=input_tensor, outputs=predictions)\n",
        "  model.compile(optimizer = opt_SGD , loss = \"categorical_crossentropy\", metrics=['accuracy', balanced_acc])\n",
        "  return model\n",
        "\n",
        "def define_model_resnet():\n",
        "  input_shape = (IMAGE_H, IMAGE_W, 3)\n",
        "  input_tensor = Input(shape=input_shape)\n",
        "  x = ResNet50(input_shape=input_shape, weights='imagenet', include_top=False)(input_tensor, training=False)\n",
        "  x = GlobalAveragePooling2D()(x)\n",
        "  x = Flatten()(x)\n",
        "  x = Dense(1024, activation='relu')(x)\n",
        "  x = Dense(512, activation='relu')(x)\n",
        "  predictions = Dense(num_classes, activation='softmax')(x)\n",
        "  model = Model(inputs=input_tensor, outputs=predictions)\n",
        "  model.compile(optimizer = opt_SGD , loss = \"categorical_crossentropy\", metrics=['accuracy', balanced_acc])\n",
        "  return model\n",
        "\n",
        "# plot diagnostic learning curves\n",
        "def summarize_diagnostics(history):\n",
        "    # plot loss\n",
        "    plt.subplot(211)\n",
        "    plt.title('Cross Entropy Loss')\n",
        "    plt.plot(history.history['loss'], color='blue', label='train')\n",
        "    plt.plot(history.history['val_loss'], color='orange', label='test')\n",
        "    # plot accuracy\n",
        "    plt.subplot(212)\n",
        "    plt.title('Classification Accuracy')\n",
        "    plt.plot(history.history['accuracy'], color='blue', label='train')\n",
        "    plt.plot(history.history['val_accuracy'], color='orange', label='test')\n",
        " \n",
        "# scale pixels\n",
        "def norm_pixels(train, test):\n",
        "    # convert from integers to floats\n",
        "    train_norm = train.astype('float32')\n",
        "    test_norm = test.astype('float32')\n",
        "    # normalize to range 0-1\n",
        "    train_norm = train_norm / 255.0\n",
        "    test_norm = test_norm / 255.0\n",
        "    # return normalized images\n",
        "    return train_norm, test_norm\n",
        "\n",
        "def load_isic2018_dataset(train_under_frac = 0):\n",
        "  df_train = pd.read_csv('/content/drive/MyDrive/PHD/Datasets/isic2018/ISIC2018_Task3_Training_GroundTruth/ISIC2018_Task3_Training_GroundTruth.csv') \n",
        "  df_val = pd.read_csv('/content/drive/MyDrive/PHD/Datasets/isic2018/ISIC2018_Task3_Validation_GroundTruth/ISIC2018_Task3_Validation_GroundTruth.csv') \n",
        "\n",
        "  #decode one hot label\n",
        "  df_train[\"Labels\"] = (df_train.iloc[:, 1:]).idxmax(axis=1)\n",
        "  df_val[\"Labels\"] = (df_val.iloc[:, 1:]).idxmax(axis=1)\n",
        "\n",
        "  #random undersampling for training dataset\n",
        "  if train_under_frac !=0:\n",
        "    df_train = df_train.drop(df_train[df_train['Labels'] == 'NV'].sample(frac=train_under_frac).index)\n",
        "\n",
        "  #drop one-hot column\n",
        "  df_train = df_train.drop(columns=['MEL', 'NV', 'BCC', 'AKIEC', 'BKL', 'DF', 'VASC'])\n",
        "  df_val = df_val.drop(columns=['MEL', 'NV', 'BCC', 'AKIEC', 'BKL', 'DF', 'VASC'])\n",
        "\n",
        "  #make filepaths of the image\n",
        "  dir_train = '/content/drive/MyDrive/PHD/Datasets/isic2018/ISIC2018_Task3_Training_Input/'\n",
        "  dir_val = '/content/drive/MyDrive/PHD/Datasets/isic2018/ISIC2018_Task3_Validation_Input/'\n",
        "  df_train['FilePaths'] = dir_train + df_train['image'] + '.jpg'\n",
        "  df_val['FilePaths'] = dir_val + df_val['image'] + '.jpg'\n",
        "  \n",
        "  #load image pixels to dataframe\n",
        "  df_train['image_px'] = df_train['FilePaths'].map(lambda x: np.asarray(Image.open(x).resize(IMG_SIZE)))\n",
        "  df_val['image_px'] = df_val['FilePaths'].map(lambda x: np.asarray(Image.open(x).resize(IMG_SIZE)))\n",
        "\n",
        "  X_train = np.asarray(df_train['image_px'].tolist())\n",
        "  X_val = np.asarray(df_val['image_px'].tolist())\n",
        "  y_train = np.array(df_train['Labels'].values)\n",
        "  y_val = np.array(df_val['Labels'].values)\n",
        "\n",
        "  label_encoder = preprocessing.LabelEncoder()\n",
        "  y_train = label_encoder.fit_transform(y_train)\n",
        "  y_val = label_encoder.fit_transform(y_val)\n",
        "  \n",
        "  y_train = to_categorical(y_train, num_classes = num_classes)\n",
        "  y_val = to_categorical(y_val, num_classes = num_classes)\n",
        "\n",
        "  return X_train, y_train, X_val, y_val\n",
        "\n",
        "def reset_dataset(df_train, df_val):\n",
        "  X_train = np.asarray(df_train['image_px'].tolist())\n",
        "  X_val = np.asarray(df_val['image_px'].tolist())\n",
        "  y_train = np.array(df_train['Labels'].values)\n",
        "  y_val = np.array(df_val['Labels'].values)\n",
        "\n",
        "  X_train = preprocess_image_input(X_train, the_arch)\n",
        "  X_val = preprocess_image_input(X_val, the_arch)\n",
        "\n",
        "  label_encoder = preprocessing.LabelEncoder()\n",
        "  y_train = label_encoder.fit_transform(y_train)\n",
        "  y_val = label_encoder.fit_transform(y_val)\n",
        "  \n",
        "  y_train = to_categorical(y_train, num_classes = num_classes)\n",
        "  y_val = to_categorical(y_val, num_classes = num_classes)\n",
        "  return X_train, y_train, X_val, y_val\n",
        "\n",
        "def SMOTE_Data(X, y, one_hot = False, k = 5, width = IMAGE_W, height = IMAGE_H, c = 3, type = 'smote'):\n",
        "  if one_hot:\n",
        "    y = np.argmax(y, axis=1)\n",
        "  if type == 'borderline':\n",
        "    sm = BorderlineSMOTE(random_state=42, k_neighbors=k)\n",
        "  elif type == 'svm':\n",
        "    sm = SVMSMOTE()\n",
        "  elif type == 'adasyn':\n",
        "    sm = ADASYN(random_state=42, n_neighbors=k)\n",
        "  elif type == 'kmeans':\n",
        "    sm = KMeansSMOTE(k_neighbors=k, kmeans_estimator=10)\n",
        "  else:\n",
        "    sm = SMOTE(random_state=42, k_neighbors=k)\n",
        "  X_resampled, y_resampled = sm.fit_resample(X.reshape((-1, width * height * c)), y)\n",
        "  X_resampled = X_resampled.reshape(-1, width, height, c)\n",
        "  if one_hot:\n",
        "    y_resampled = to_categorical(y_resampled, num_classes = num_classes)\n",
        "  else:\n",
        "    y_resampled = y_resampled.reshape(-1,1)\n",
        "  return X_resampled, y_resampled\n",
        "\n",
        "def SMOTE_Data2(X, y, one_hot = False, k = 5, type = 'smote'):\n",
        "  if one_hot:\n",
        "    y = np.argmax(y, axis=1)\n",
        "  if type == 'borderline':\n",
        "    sm = BorderlineSMOTE(random_state=42, k_neighbors=k)\n",
        "  elif type == 'svm':\n",
        "    sm = SVMSMOTE()\n",
        "  elif type == 'adasyn':\n",
        "    sm = ADASYN(random_state=42, n_neighbors=k)\n",
        "  elif type == 'kmeans':\n",
        "    sm = KMeansSMOTE(k_neighbors=k, kmeans_estimator=10)\n",
        "  else:\n",
        "    sm = SMOTE(random_state=42, k_neighbors=k)\n",
        "  X_resampled, y_resampled = sm.fit_resample(X, y)\n",
        "  if one_hot:\n",
        "    y_resampled = to_categorical(y_resampled, num_classes = num_classes)\n",
        "  else:\n",
        "    y_resampled = y_resampled.reshape(-1,1)\n",
        "  return X_resampled, y_resampled"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BE9FCWBe8deT"
      },
      "source": [
        "#Inner-Borderline SMOTE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s3UnuaKz8kzJ"
      },
      "outputs": [],
      "source": [
        "def get_class(X, y, c):\n",
        "    xbeg = X[y == c]\n",
        "    ybeg = y[y == c]\n",
        "    \n",
        "    return xbeg, ybeg\n",
        "def find_border(xclass, yclass, X, y, cli, n_neigh=5):\n",
        "    nn = NearestNeighbors(n_neighbors=n_neigh, n_jobs=1)\n",
        "    nn.fit(X)\n",
        "    dist, ind = nn.kneighbors(xclass)\n",
        "    ret = []\n",
        "    for i in range(len(ind)):\n",
        "      ret.append(sum(y[ind[i,j]] != cli for j in range(1,len(ind[i]))))\n",
        "    ret = np.array(ret)\n",
        "    xclass = xclass[np.logical_and(ret < (n_neigh-1),ret > ((n_neigh-1)/2))]\n",
        "    yclass = yclass[np.logical_and(ret < (n_neigh-1),ret > ((n_neigh-1)/2))]\n",
        "\n",
        "    return xclass, yclass\n",
        "def find_inner_border(xclass, yclass, X, y, cli, n_neigh=5):\n",
        "    nn = NearestNeighbors(n_neighbors=n_neigh, n_jobs=1)\n",
        "    nn.fit(X)\n",
        "    dist, ind = nn.kneighbors(X)\n",
        "    ret = []\n",
        "    for i in range(len(ind)):\n",
        "      if y[i] != cli:\n",
        "        ret.append(n_neigh)  \n",
        "      else:\n",
        "        ret.append(sum(y[ind[i,j]] != cli for j in range(1,len(ind[i]))))\n",
        "    ret = np.array(ret)\n",
        "    is_border = np.logical_and(ret < (n_neigh-1),ret > ((n_neigh-1)/2))\n",
        "    \n",
        "    ret = []\n",
        "    for i in range(len(ind)):\n",
        "      ret.append(sum(is_border[ind[i,j]] for j in range(1,len(ind[i]))))\n",
        "    ret = np.array(ret)\n",
        "    xclass = X[np.logical_and(np.logical_not(is_border),ret > 0)]\n",
        "    yclass = y[np.logical_and(np.logical_not(is_border),ret > 0)]\n",
        "    return xclass, yclass\n",
        "\n",
        "def G_SM(xclass,n_to_sample,cl, n_neigh = 6):\n",
        "    \n",
        "    nn = NearestNeighbors(n_neighbors=n_neigh, n_jobs=1)\n",
        "    nn.fit(xclass)\n",
        "    dist, ind = nn.kneighbors(xclass)\n",
        "\n",
        "    # generating samples\n",
        "    base_indices = np.random.choice(list(range(len(xclass))),n_to_sample)\n",
        "    neighbor_indices = np.random.choice(list(range(1, n_neigh)),n_to_sample)\n",
        "\n",
        "    X_base = xclass[base_indices]\n",
        "    X_neighbor = xclass[ind[base_indices, neighbor_indices]]\n",
        "\n",
        "    samples = X_base + np.multiply(np.random.rand(n_to_sample,1),\n",
        "            X_neighbor - X_base)\n",
        "\n",
        "    #use 10 as label because 0 to 9 real classes and 1 fake/smoted = 10\n",
        "    return samples, [cl]*n_to_sample\n",
        "\n",
        "def Borderline_SMOTE(X_train, y_train, random_state=42, k_neighbors=5, start=0, n=7):\n",
        "  #reshape X_train\n",
        "  X_train = X_train.reshape(-1, IMAGE_W * IMAGE_H * 3)\n",
        "  #decode y_train from one-hot encoding\n",
        "  y_train = np.argmax(y_train, axis=1) \n",
        "\n",
        "  counter = Counter(y_train)\n",
        "  key_max = max(counter, key=counter.get)\n",
        "  class_max = counter[key_max]\n",
        "  resx=[]\n",
        "  resy=[]\n",
        "\n",
        "  for i in range(start,n):\n",
        "      xclass, yclass = get_class(X_train, y_train, i)\n",
        "      if xclass.shape[0] == class_max:\n",
        "        continue\n",
        "      xclass_bdr, yclass_bdr = find_inner_border(xclass, yclass, X_train, y_train, i, n_neigh=k_neighbors)\n",
        "      n = class_max - xclass.shape[0]\n",
        "      xsamp, ysamp = G_SM(xclass_bdr,n,i, n_neigh=k_neighbors)\n",
        "      ysamp = np.array(ysamp)\n",
        "      resx.append(xsamp)\n",
        "      resy.append(ysamp)\n",
        "  \n",
        "  resx = np.vstack(resx)\n",
        "  resy = np.hstack(resy)\n",
        "  X_train = np.vstack((resx,X_train))\n",
        "  y_train = np.hstack((resy,y_train))\n",
        "  y_train = to_categorical(y_train)\n",
        "  X_train = X_train.reshape(-1, IMAGE_W, IMAGE_H, 3)\n",
        "  return X_train, y_train"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5v7sLC2svMuJ"
      },
      "source": [
        "# Main"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "HIW7uLrYvZDv"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "sys.path.append('/content/drive/MyDrive/PHD/Src/imbalanced-learn/imblearn/')\n",
        "sys.path.append('/content/drive/MyDrive/PHD/Src/imbalanced-learn/imblearn/over_sampling/')\n",
        "sys.path.append('/content/drive/MyDrive/PHD/Src/imbalanced-learn/imblearn/over_sampling/_smote/')\n",
        "from filter import BorderlineSMOTE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "udkMXcZHXglm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "34d3b405-12fb-45c5-a7bb-96ca19aa3794"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "best_model_fpath:/content/drive/MyDrive/PHD/Model/best_model_borderline_self_under70_128px.h5\n"
          ]
        }
      ],
      "source": [
        "exp_name=\"borderline_self\"\n",
        "dataset_name=\"under70_128px\"\n",
        "train_under_frac = 0.8\n",
        "\n",
        "best_model_fpath = '/content/drive/MyDrive/PHD/Model/best_model_'+exp_name+'_'+dataset_name+'.h5'\n",
        "print(\"best_model_fpath:\"+best_model_fpath)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qge6cnxQPnH6",
        "outputId": "90ab1822-5c86-4a34-a1a4-d3f316c12c0a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(5321, 128, 128, 3)\n",
            "(5321, 7)\n",
            "(193, 128, 128, 3)\n",
            "(193, 7)\n",
            "Counter train data:  Counter({5: 2011, 4: 1113, 2: 1099, 1: 514, 0: 327, 6: 142, 3: 115})\n",
            "Counter val data:  Counter({5: 123, 2: 22, 4: 21, 1: 15, 0: 8, 6: 3, 3: 1})\n"
          ]
        }
      ],
      "source": [
        "path = '/content/drive/MyDrive/PHD/Datasets/isic2018/'\n",
        "df1 = pd.read_pickle(path+\"isic2018_train_\"+dataset_name+\".pkl\")\n",
        "X_train = df1.loc[:, df1.columns != 'y_train'].to_numpy()\n",
        "X_train = X_train.reshape(-1,IMAGE_W,IMAGE_H,3)\n",
        "y_train = df1.loc[:, df1.columns == 'y_train'].to_numpy()\n",
        "y_train = to_categorical(y_train)\n",
        "\n",
        "#df1 = pd.read_pickle(path+\"isic2018_val_\"+dataset_name+\".pkl\")\n",
        "df1 = pd.read_pickle(path+\"isic2018_val.pkl\")\n",
        "X_val = df1.loc[:, df1.columns != 'y_val'].to_numpy()\n",
        "X_val = X_val.reshape(-1,IMAGE_W,IMAGE_H,3)\n",
        "y_val = df1.loc[:, df1.columns == 'y_val'].to_numpy()\n",
        "y_val = to_categorical(y_val)\n",
        "\n",
        "print(X_train.shape)\n",
        "print(y_train.shape)\n",
        "print(X_val.shape)\n",
        "print(y_val.shape)\n",
        "print('Counter train data: ', Counter(np.argmax(y_train, axis=1)))\n",
        "print('Counter val data: ', Counter(np.argmax(y_val, axis=1)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xArGWuciBt_-",
        "outputId": "b52ee898-2d1c-4c95-eb95-1c1746e12b8a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(14077, 128, 128, 3)\n",
            "(14077, 7)\n",
            "(193, 128, 128, 3)\n",
            "(193, 7)\n",
            "Counter train data:  Counter({5: 2011, 4: 2011, 2: 2011, 3: 2011, 0: 2011, 1: 2011, 6: 2011})\n",
            "Counter val data:  Counter({5: 123, 2: 22, 4: 21, 1: 15, 0: 8, 6: 3, 3: 1})\n"
          ]
        }
      ],
      "source": [
        "X_train, y_train = SMOTE_Data(X_train, y_train, True, type = 'borderline')\n",
        "#X_train, y_train = Borderline_SMOTE(X_train, y_train)\n",
        "print(X_train.shape)\n",
        "print(y_train.shape)\n",
        "print(X_val.shape)\n",
        "print(y_val.shape)\n",
        "print('Counter train data: ', Counter(np.argmax(y_train, axis=1)))\n",
        "print('Counter val data: ', Counter(np.argmax(y_val, axis=1)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0V5PjA7jFhVU",
        "outputId": "38b5f38e-272e-483a-fa48-6186f4b7efcd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(9487, 2048)\n",
            "(9487, 7)\n",
            "Counter train data:  Counter({0: 1441, 5: 1341, 4: 1341, 2: 1341, 3: 1341, 1: 1341, 6: 1341})\n"
          ]
        }
      ],
      "source": [
        "n_new_samples = 100\n",
        "X_train = np.append(X_train_fm_ov, np.zeros(shape=(n_new_samples, 2048), dtype='object'), axis=0)\n",
        "y_train = np.argmax(y_train_ov, axis=1) \n",
        "y_train = y_train.reshape(-1,1)\n",
        "y_train = np.append(y_train, np.zeros(shape=(n_new_samples, 1), dtype='object'))\n",
        "y_train = to_categorical(y_train)\n",
        "print(X_train.shape)\n",
        "print(y_train.shape)\n",
        "print('Counter train data: ', Counter(np.argmax(y_train, axis=1)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0lFpLlexMUaM",
        "outputId": "137599b4-6ee6-49de-8cd9-13e82b8c2c89"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(9887, 2048)\n",
            "(9887, 7)\n",
            "Counter train data:  Counter({5: 1441, 4: 1441, 2: 1441, 1: 1441, 6: 1441, 3: 1341, 0: 1341})\n"
          ]
        }
      ],
      "source": [
        "# remove rows having all zeroes\n",
        "index = range(9387,9487)\n",
        "y_train = np.delete(y_train_ov, index, axis = 0)\n",
        "X_train = np.delete(X_train_fm_ov, index, axis = 0)\n",
        "print(X_train.shape)\n",
        "print(y_train.shape)\n",
        "print('Counter train data: ', Counter(np.argmax(y_train, axis=1)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V7Z_nccu6QjB"
      },
      "outputs": [],
      "source": [
        "#path = '/content/drive/MyDrive/PHD/Datasets/isic2018/'\n",
        "#df1 = pd.DataFrame(X_train.reshape(X_train.shape[0],-1))\n",
        "#df1['y_train'] = np.argmax(y_train, axis=1).tolist()\n",
        "#df2 = pd.DataFrame(X_val.reshape(X_val.shape[0],-1))\n",
        "#df2['y_val'] = np.argmax(y_val, axis=1).tolist()\n",
        "#df1.to_pickle(path+\"isic2018_train_under83.pkl\")\n",
        "#df2.to_pickle(path+\"isic2018_val.pkl\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "vIygrW81Ln4z",
        "outputId": "99e6981d-5bdb-40ee-d980-87777f79a1e4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "best_model_fpath:/content/drive/MyDrive/PHD/Model/best_model_borderline_self_under70_128px.h5\n",
            "Epoch 1/50\n",
            "219/219 [==============================] - ETA: 0s - loss: 0.9781 - accuracy: 0.6302 - balanced_acc: 0.6286\n",
            "Epoch 1: val_balanced_acc improved from -inf to 0.53841, saving model to /content/drive/MyDrive/PHD/Model/best_model_borderline_self_under70_128px.h5\n",
            "219/219 [==============================] - 58s 226ms/step - loss: 0.9781 - accuracy: 0.6302 - balanced_acc: 0.6286 - val_loss: 0.8579 - val_accuracy: 0.6736 - val_balanced_acc: 0.5384 - lr: 0.0010\n",
            "Epoch 2/50\n",
            "219/219 [==============================] - ETA: 0s - loss: 0.5673 - accuracy: 0.7896 - balanced_acc: 0.7870\n",
            "Epoch 2: val_balanced_acc did not improve from 0.53841\n",
            "219/219 [==============================] - 50s 222ms/step - loss: 0.5673 - accuracy: 0.7896 - balanced_acc: 0.7870 - val_loss: 0.6705 - val_accuracy: 0.6995 - val_balanced_acc: 0.4383 - lr: 0.0010\n",
            "Epoch 3/50\n",
            "219/219 [==============================] - ETA: 0s - loss: 0.4487 - accuracy: 0.8371 - balanced_acc: 0.8396\n",
            "Epoch 3: val_balanced_acc did not improve from 0.53841\n",
            "219/219 [==============================] - 50s 229ms/step - loss: 0.4487 - accuracy: 0.8371 - balanced_acc: 0.8396 - val_loss: 0.6347 - val_accuracy: 0.7772 - val_balanced_acc: 0.4722 - lr: 0.0010\n",
            "Epoch 4/50\n",
            "219/219 [==============================] - ETA: 0s - loss: 0.3639 - accuracy: 0.8665 - balanced_acc: 0.8671\n",
            "Epoch 4: val_balanced_acc improved from 0.53841 to 0.63538, saving model to /content/drive/MyDrive/PHD/Model/best_model_borderline_self_under70_128px.h5\n",
            "219/219 [==============================] - 51s 234ms/step - loss: 0.3639 - accuracy: 0.8665 - balanced_acc: 0.8671 - val_loss: 0.6478 - val_accuracy: 0.7927 - val_balanced_acc: 0.6354 - lr: 0.0010\n",
            "Epoch 5/50\n",
            "219/219 [==============================] - ETA: 0s - loss: 0.2955 - accuracy: 0.8942 - balanced_acc: 0.8942\n",
            "Epoch 5: val_balanced_acc did not improve from 0.63538\n",
            "219/219 [==============================] - 50s 229ms/step - loss: 0.2955 - accuracy: 0.8942 - balanced_acc: 0.8942 - val_loss: 0.7827 - val_accuracy: 0.7098 - val_balanced_acc: 0.6107 - lr: 0.0010\n",
            "Epoch 6/50\n",
            "219/219 [==============================] - ETA: 0s - loss: 0.2359 - accuracy: 0.9167 - balanced_acc: 0.9163\n",
            "Epoch 6: val_balanced_acc did not improve from 0.63538\n",
            "219/219 [==============================] - 50s 228ms/step - loss: 0.2359 - accuracy: 0.9167 - balanced_acc: 0.9163 - val_loss: 0.7388 - val_accuracy: 0.6995 - val_balanced_acc: 0.4280 - lr: 0.0010\n",
            "Epoch 7/50\n",
            "219/219 [==============================] - ETA: 0s - loss: 0.2145 - accuracy: 0.9266 - balanced_acc: 0.9261\n",
            "Epoch 7: val_balanced_acc did not improve from 0.63538\n",
            "219/219 [==============================] - 50s 228ms/step - loss: 0.2145 - accuracy: 0.9266 - balanced_acc: 0.9261 - val_loss: 0.7008 - val_accuracy: 0.7306 - val_balanced_acc: 0.4857 - lr: 0.0010\n",
            "Epoch 8/50\n",
            "219/219 [==============================] - ETA: 0s - loss: 0.1776 - accuracy: 0.9420 - balanced_acc: 0.9423\n",
            "Epoch 8: val_balanced_acc did not improve from 0.63538\n",
            "219/219 [==============================] - 50s 229ms/step - loss: 0.1776 - accuracy: 0.9420 - balanced_acc: 0.9423 - val_loss: 0.7416 - val_accuracy: 0.7098 - val_balanced_acc: 0.4466 - lr: 0.0010\n",
            "Epoch 9/50\n",
            "219/219 [==============================] - ETA: 0s - loss: 0.1379 - accuracy: 0.9558 - balanced_acc: 0.9558\n",
            "Epoch 9: val_balanced_acc did not improve from 0.63538\n",
            "219/219 [==============================] - 50s 228ms/step - loss: 0.1379 - accuracy: 0.9558 - balanced_acc: 0.9558 - val_loss: 0.6215 - val_accuracy: 0.8290 - val_balanced_acc: 0.6283 - lr: 0.0010\n",
            "Epoch 10/50\n",
            "219/219 [==============================] - ETA: 0s - loss: 0.1140 - accuracy: 0.9632 - balanced_acc: 0.9618\n",
            "Epoch 10: val_balanced_acc did not improve from 0.63538\n",
            "219/219 [==============================] - 50s 229ms/step - loss: 0.1140 - accuracy: 0.9632 - balanced_acc: 0.9618 - val_loss: 0.7378 - val_accuracy: 0.7461 - val_balanced_acc: 0.4865 - lr: 0.0010\n",
            "Epoch 11/50\n",
            "219/219 [==============================] - ETA: 0s - loss: 0.0900 - accuracy: 0.9735 - balanced_acc: 0.9732\n",
            "Epoch 11: val_balanced_acc did not improve from 0.63538\n",
            "219/219 [==============================] - 50s 229ms/step - loss: 0.0900 - accuracy: 0.9735 - balanced_acc: 0.9732 - val_loss: 0.8094 - val_accuracy: 0.7513 - val_balanced_acc: 0.4860 - lr: 0.0010\n",
            "Epoch 12/50\n",
            "219/219 [==============================] - ETA: 0s - loss: 0.1410 - accuracy: 0.9585 - balanced_acc: 0.9599\n",
            "Epoch 12: val_balanced_acc did not improve from 0.63538\n",
            "219/219 [==============================] - 50s 229ms/step - loss: 0.1410 - accuracy: 0.9585 - balanced_acc: 0.9599 - val_loss: 0.8323 - val_accuracy: 0.7409 - val_balanced_acc: 0.4912 - lr: 0.0010\n",
            "Epoch 13/50\n",
            "219/219 [==============================] - ETA: 0s - loss: 0.0482 - accuracy: 0.9880 - balanced_acc: 0.9865\n",
            "Epoch 13: val_balanced_acc did not improve from 0.63538\n",
            "219/219 [==============================] - 50s 229ms/step - loss: 0.0482 - accuracy: 0.9880 - balanced_acc: 0.9865 - val_loss: 0.7791 - val_accuracy: 0.7461 - val_balanced_acc: 0.4661 - lr: 0.0010\n",
            "Epoch 14/50\n",
            "219/219 [==============================] - ETA: 0s - loss: 0.0790 - accuracy: 0.9804 - balanced_acc: 0.9809\n",
            "Epoch 14: val_balanced_acc did not improve from 0.63538\n",
            "219/219 [==============================] - 50s 229ms/step - loss: 0.0790 - accuracy: 0.9804 - balanced_acc: 0.9809 - val_loss: 0.7994 - val_accuracy: 0.7513 - val_balanced_acc: 0.4709 - lr: 0.0010\n",
            "Epoch 15/50\n",
            "219/219 [==============================] - ETA: 0s - loss: 0.0301 - accuracy: 0.9929 - balanced_acc: 0.9927\n",
            "Epoch 15: val_balanced_acc did not improve from 0.63538\n",
            "219/219 [==============================] - 50s 229ms/step - loss: 0.0301 - accuracy: 0.9929 - balanced_acc: 0.9927 - val_loss: 0.7895 - val_accuracy: 0.7979 - val_balanced_acc: 0.4781 - lr: 0.0010\n",
            "Epoch 16/50\n",
            "219/219 [==============================] - ETA: 0s - loss: 0.0173 - accuracy: 0.9971 - balanced_acc: 0.9968\n",
            "Epoch 16: val_balanced_acc did not improve from 0.63538\n",
            "219/219 [==============================] - 50s 229ms/step - loss: 0.0173 - accuracy: 0.9971 - balanced_acc: 0.9968 - val_loss: 0.9149 - val_accuracy: 0.7513 - val_balanced_acc: 0.4714 - lr: 0.0010\n",
            "Epoch 17/50\n",
            "219/219 [==============================] - ETA: 0s - loss: 0.0331 - accuracy: 0.9934 - balanced_acc: 0.9931\n",
            "Epoch 17: val_balanced_acc did not improve from 0.63538\n",
            "219/219 [==============================] - 50s 229ms/step - loss: 0.0331 - accuracy: 0.9934 - balanced_acc: 0.9931 - val_loss: 1.0389 - val_accuracy: 0.7098 - val_balanced_acc: 0.4495 - lr: 0.0010\n",
            "Epoch 18/50\n",
            "219/219 [==============================] - ETA: 0s - loss: 0.0100 - accuracy: 0.9990 - balanced_acc: 0.9990\n",
            "Epoch 18: val_balanced_acc did not improve from 0.63538\n",
            "219/219 [==============================] - 50s 229ms/step - loss: 0.0100 - accuracy: 0.9990 - balanced_acc: 0.9990 - val_loss: 0.9130 - val_accuracy: 0.7617 - val_balanced_acc: 0.4770 - lr: 0.0010\n",
            "Epoch 19/50\n",
            "219/219 [==============================] - ETA: 0s - loss: 0.0055 - accuracy: 0.9999 - balanced_acc: 0.9992\n",
            "Epoch 19: val_balanced_acc did not improve from 0.63538\n",
            "219/219 [==============================] - 50s 229ms/step - loss: 0.0055 - accuracy: 0.9999 - balanced_acc: 0.9992 - val_loss: 0.9358 - val_accuracy: 0.7513 - val_balanced_acc: 0.4688 - lr: 0.0010\n",
            "Epoch 20/50\n",
            "219/219 [==============================] - ETA: 0s - loss: 0.0040 - accuracy: 1.0000 - balanced_acc: 1.0000\n",
            "Epoch 20: val_balanced_acc did not improve from 0.63538\n",
            "219/219 [==============================] - 50s 229ms/step - loss: 0.0040 - accuracy: 1.0000 - balanced_acc: 1.0000 - val_loss: 1.0909 - val_accuracy: 0.7306 - val_balanced_acc: 0.4704 - lr: 0.0010\n",
            "Epoch 21/50\n",
            "219/219 [==============================] - ETA: 0s - loss: 0.0028 - accuracy: 1.0000 - balanced_acc: 1.0000\n",
            "Epoch 21: val_balanced_acc did not improve from 0.63538\n",
            "219/219 [==============================] - 50s 229ms/step - loss: 0.0028 - accuracy: 1.0000 - balanced_acc: 1.0000 - val_loss: 1.0680 - val_accuracy: 0.7461 - val_balanced_acc: 0.4734 - lr: 0.0010\n",
            "Epoch 22/50\n",
            "219/219 [==============================] - ETA: 0s - loss: 0.0022 - accuracy: 1.0000 - balanced_acc: 1.0000\n",
            "Epoch 22: val_balanced_acc did not improve from 0.63538\n",
            "219/219 [==============================] - 50s 229ms/step - loss: 0.0022 - accuracy: 1.0000 - balanced_acc: 1.0000 - val_loss: 1.0733 - val_accuracy: 0.7513 - val_balanced_acc: 0.4715 - lr: 0.0010\n",
            "Epoch 23/50\n",
            "219/219 [==============================] - ETA: 0s - loss: 0.0020 - accuracy: 1.0000 - balanced_acc: 1.0000\n",
            "Epoch 23: val_balanced_acc did not improve from 0.63538\n",
            "219/219 [==============================] - 50s 229ms/step - loss: 0.0020 - accuracy: 1.0000 - balanced_acc: 1.0000 - val_loss: 1.1318 - val_accuracy: 0.7461 - val_balanced_acc: 0.4698 - lr: 0.0010\n",
            "Epoch 24/50\n",
            "219/219 [==============================] - ETA: 0s - loss: 0.0017 - accuracy: 1.0000 - balanced_acc: 1.0000\n",
            "Epoch 24: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "\n",
            "Epoch 24: val_balanced_acc did not improve from 0.63538\n",
            "219/219 [==============================] - 50s 229ms/step - loss: 0.0017 - accuracy: 1.0000 - balanced_acc: 1.0000 - val_loss: 1.1615 - val_accuracy: 0.7306 - val_balanced_acc: 0.4682 - lr: 0.0010\n",
            "Epoch 25/50\n",
            "219/219 [==============================] - ETA: 0s - loss: 0.0014 - accuracy: 1.0000 - balanced_acc: 1.0000\n",
            "Epoch 25: val_balanced_acc did not improve from 0.63538\n",
            "219/219 [==============================] - 50s 229ms/step - loss: 0.0014 - accuracy: 1.0000 - balanced_acc: 1.0000 - val_loss: 1.1376 - val_accuracy: 0.7513 - val_balanced_acc: 0.4715 - lr: 5.0000e-04\n",
            "Epoch 26/50\n",
            "219/219 [==============================] - ETA: 0s - loss: 0.0013 - accuracy: 1.0000 - balanced_acc: 1.0000\n",
            "Epoch 26: val_balanced_acc did not improve from 0.63538\n",
            "219/219 [==============================] - 50s 229ms/step - loss: 0.0013 - accuracy: 1.0000 - balanced_acc: 1.0000 - val_loss: 1.1725 - val_accuracy: 0.7461 - val_balanced_acc: 0.4707 - lr: 5.0000e-04\n",
            "Epoch 27/50\n",
            "219/219 [==============================] - ETA: 0s - loss: 0.0013 - accuracy: 1.0000 - balanced_acc: 0.9993\n",
            "Epoch 27: val_balanced_acc did not improve from 0.63538\n",
            "219/219 [==============================] - 50s 229ms/step - loss: 0.0013 - accuracy: 1.0000 - balanced_acc: 0.9993 - val_loss: 1.1800 - val_accuracy: 0.7409 - val_balanced_acc: 0.4698 - lr: 5.0000e-04\n",
            "Epoch 28/50\n",
            "219/219 [==============================] - ETA: 0s - loss: 0.0012 - accuracy: 1.0000 - balanced_acc: 1.0000\n",
            "Epoch 28: val_balanced_acc did not improve from 0.63538\n",
            "219/219 [==============================] - 50s 229ms/step - loss: 0.0012 - accuracy: 1.0000 - balanced_acc: 1.0000 - val_loss: 1.1668 - val_accuracy: 0.7513 - val_balanced_acc: 0.4715 - lr: 5.0000e-04\n",
            "Epoch 29/50\n",
            "219/219 [==============================] - ETA: 0s - loss: 0.0011 - accuracy: 1.0000 - balanced_acc: 1.0000\n",
            "Epoch 29: val_balanced_acc did not improve from 0.63538\n",
            "219/219 [==============================] - 50s 229ms/step - loss: 0.0011 - accuracy: 1.0000 - balanced_acc: 1.0000 - val_loss: 1.1734 - val_accuracy: 0.7461 - val_balanced_acc: 0.4671 - lr: 5.0000e-04\n",
            "Epoch 30/50\n",
            "219/219 [==============================] - ETA: 0s - loss: 0.0011 - accuracy: 1.0000 - balanced_acc: 0.9993\n",
            "Epoch 30: val_balanced_acc did not improve from 0.63538\n",
            "219/219 [==============================] - 50s 229ms/step - loss: 0.0011 - accuracy: 1.0000 - balanced_acc: 0.9993 - val_loss: 1.1923 - val_accuracy: 0.7513 - val_balanced_acc: 0.4715 - lr: 5.0000e-04\n",
            "Epoch 31/50\n",
            "219/219 [==============================] - ETA: 0s - loss: 0.0010 - accuracy: 1.0000 - balanced_acc: 1.0000\n",
            "Epoch 31: val_balanced_acc did not improve from 0.63538\n",
            "219/219 [==============================] - 50s 229ms/step - loss: 0.0010 - accuracy: 1.0000 - balanced_acc: 1.0000 - val_loss: 1.1823 - val_accuracy: 0.7513 - val_balanced_acc: 0.4715 - lr: 5.0000e-04\n",
            "Epoch 32/50\n",
            "219/219 [==============================] - ETA: 0s - loss: 9.5902e-04 - accuracy: 1.0000 - balanced_acc: 1.0000\n",
            "Epoch 32: val_balanced_acc did not improve from 0.63538\n",
            "219/219 [==============================] - 50s 229ms/step - loss: 9.5902e-04 - accuracy: 1.0000 - balanced_acc: 1.0000 - val_loss: 1.1856 - val_accuracy: 0.7513 - val_balanced_acc: 0.4715 - lr: 5.0000e-04\n",
            "Epoch 33/50\n",
            "219/219 [==============================] - ETA: 0s - loss: 9.5126e-04 - accuracy: 1.0000 - balanced_acc: 1.0000\n",
            "Epoch 33: val_balanced_acc did not improve from 0.63538\n",
            "219/219 [==============================] - 50s 229ms/step - loss: 9.5126e-04 - accuracy: 1.0000 - balanced_acc: 1.0000 - val_loss: 1.1893 - val_accuracy: 0.7513 - val_balanced_acc: 0.4715 - lr: 5.0000e-04\n",
            "Epoch 34/50\n",
            "219/219 [==============================] - ETA: 0s - loss: 9.1331e-04 - accuracy: 1.0000 - balanced_acc: 1.0000\n",
            "Epoch 34: val_balanced_acc did not improve from 0.63538\n",
            "219/219 [==============================] - 50s 229ms/step - loss: 9.1331e-04 - accuracy: 1.0000 - balanced_acc: 1.0000 - val_loss: 1.2132 - val_accuracy: 0.7513 - val_balanced_acc: 0.4715 - lr: 5.0000e-04\n",
            "Epoch 35/50\n",
            "219/219 [==============================] - ETA: 0s - loss: 8.8226e-04 - accuracy: 1.0000 - balanced_acc: 0.9993\n",
            "Epoch 35: val_balanced_acc did not improve from 0.63538\n",
            "219/219 [==============================] - 50s 229ms/step - loss: 8.8226e-04 - accuracy: 1.0000 - balanced_acc: 0.9993 - val_loss: 1.2165 - val_accuracy: 0.7513 - val_balanced_acc: 0.4715 - lr: 5.0000e-04\n",
            "Epoch 36/50\n",
            "219/219 [==============================] - ETA: 0s - loss: 8.1514e-04 - accuracy: 1.0000 - balanced_acc: 1.0000\n",
            "Epoch 36: val_balanced_acc did not improve from 0.63538\n",
            "219/219 [==============================] - 50s 229ms/step - loss: 8.1514e-04 - accuracy: 1.0000 - balanced_acc: 1.0000 - val_loss: 1.2304 - val_accuracy: 0.7513 - val_balanced_acc: 0.4715 - lr: 5.0000e-04\n",
            "Epoch 37/50\n",
            "219/219 [==============================] - ETA: 0s - loss: 8.3411e-04 - accuracy: 1.0000 - balanced_acc: 0.9993\n",
            "Epoch 37: val_balanced_acc did not improve from 0.63538\n",
            "219/219 [==============================] - 50s 229ms/step - loss: 8.3411e-04 - accuracy: 1.0000 - balanced_acc: 0.9993 - val_loss: 1.2392 - val_accuracy: 0.7513 - val_balanced_acc: 0.4715 - lr: 5.0000e-04\n",
            "Epoch 38/50\n",
            "219/219 [==============================] - ETA: 0s - loss: 7.6829e-04 - accuracy: 1.0000 - balanced_acc: 1.0000\n",
            "Epoch 38: val_balanced_acc did not improve from 0.63538\n",
            "219/219 [==============================] - 50s 229ms/step - loss: 7.6829e-04 - accuracy: 1.0000 - balanced_acc: 1.0000 - val_loss: 1.2604 - val_accuracy: 0.7461 - val_balanced_acc: 0.4707 - lr: 5.0000e-04\n",
            "Epoch 39/50\n",
            "219/219 [==============================] - ETA: 0s - loss: 7.5886e-04 - accuracy: 1.0000 - balanced_acc: 1.0000\n",
            "Epoch 39: val_balanced_acc did not improve from 0.63538\n",
            "219/219 [==============================] - 50s 229ms/step - loss: 7.5886e-04 - accuracy: 1.0000 - balanced_acc: 1.0000 - val_loss: 1.2402 - val_accuracy: 0.7461 - val_balanced_acc: 0.4671 - lr: 5.0000e-04\n",
            "Epoch 40/50\n",
            "219/219 [==============================] - ETA: 0s - loss: 7.3358e-04 - accuracy: 1.0000 - balanced_acc: 1.0000\n",
            "Epoch 40: val_balanced_acc did not improve from 0.63538\n",
            "219/219 [==============================] - 50s 229ms/step - loss: 7.3358e-04 - accuracy: 1.0000 - balanced_acc: 1.0000 - val_loss: 1.2543 - val_accuracy: 0.7513 - val_balanced_acc: 0.4715 - lr: 5.0000e-04\n",
            "Epoch 41/50\n",
            "219/219 [==============================] - ETA: 0s - loss: 6.9965e-04 - accuracy: 1.0000 - balanced_acc: 1.0000\n",
            "Epoch 41: val_balanced_acc did not improve from 0.63538\n",
            "219/219 [==============================] - 50s 229ms/step - loss: 6.9965e-04 - accuracy: 1.0000 - balanced_acc: 1.0000 - val_loss: 1.2622 - val_accuracy: 0.7461 - val_balanced_acc: 0.4707 - lr: 5.0000e-04\n",
            "Epoch 42/50\n",
            "219/219 [==============================] - ETA: 0s - loss: 6.9428e-04 - accuracy: 1.0000 - balanced_acc: 1.0000\n",
            "Epoch 42: val_balanced_acc did not improve from 0.63538\n",
            "219/219 [==============================] - 50s 229ms/step - loss: 6.9428e-04 - accuracy: 1.0000 - balanced_acc: 1.0000 - val_loss: 1.2751 - val_accuracy: 0.7461 - val_balanced_acc: 0.4707 - lr: 5.0000e-04\n",
            "Epoch 43/50\n",
            "219/219 [==============================] - ETA: 0s - loss: 6.5160e-04 - accuracy: 1.0000 - balanced_acc: 1.0000\n",
            "Epoch 43: val_balanced_acc did not improve from 0.63538\n",
            "219/219 [==============================] - 50s 229ms/step - loss: 6.5160e-04 - accuracy: 1.0000 - balanced_acc: 1.0000 - val_loss: 1.2701 - val_accuracy: 0.7461 - val_balanced_acc: 0.4671 - lr: 5.0000e-04\n",
            "Epoch 44/50\n",
            "219/219 [==============================] - ETA: 0s - loss: 6.4738e-04 - accuracy: 1.0000 - balanced_acc: 1.0000\n",
            "Epoch 44: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "\n",
            "Epoch 44: val_balanced_acc did not improve from 0.63538\n",
            "219/219 [==============================] - 50s 229ms/step - loss: 6.4738e-04 - accuracy: 1.0000 - balanced_acc: 1.0000 - val_loss: 1.2743 - val_accuracy: 0.7513 - val_balanced_acc: 0.4715 - lr: 5.0000e-04\n",
            "Epoch 45/50\n",
            "219/219 [==============================] - ETA: 0s - loss: 6.1961e-04 - accuracy: 1.0000 - balanced_acc: 1.0000\n",
            "Epoch 45: val_balanced_acc did not improve from 0.63538\n",
            "219/219 [==============================] - 50s 229ms/step - loss: 6.1961e-04 - accuracy: 1.0000 - balanced_acc: 1.0000 - val_loss: 1.2878 - val_accuracy: 0.7461 - val_balanced_acc: 0.4707 - lr: 2.5000e-04\n",
            "Epoch 46/50\n",
            "219/219 [==============================] - ETA: 0s - loss: 6.1631e-04 - accuracy: 1.0000 - balanced_acc: 1.0000\n",
            "Epoch 46: val_balanced_acc did not improve from 0.63538\n",
            "219/219 [==============================] - 50s 229ms/step - loss: 6.1631e-04 - accuracy: 1.0000 - balanced_acc: 1.0000 - val_loss: 1.2842 - val_accuracy: 0.7461 - val_balanced_acc: 0.4707 - lr: 2.5000e-04\n",
            "Epoch 47/50\n",
            "219/219 [==============================] - ETA: 0s - loss: 5.8585e-04 - accuracy: 1.0000 - balanced_acc: 1.0000\n",
            "Epoch 47: val_balanced_acc did not improve from 0.63538\n",
            "219/219 [==============================] - 50s 229ms/step - loss: 5.8585e-04 - accuracy: 1.0000 - balanced_acc: 1.0000 - val_loss: 1.2834 - val_accuracy: 0.7461 - val_balanced_acc: 0.4707 - lr: 2.5000e-04\n",
            "Epoch 48/50\n",
            "219/219 [==============================] - ETA: 0s - loss: 5.9865e-04 - accuracy: 1.0000 - balanced_acc: 1.0000\n",
            "Epoch 48: val_balanced_acc did not improve from 0.63538\n",
            "219/219 [==============================] - 50s 229ms/step - loss: 5.9865e-04 - accuracy: 1.0000 - balanced_acc: 1.0000 - val_loss: 1.2827 - val_accuracy: 0.7513 - val_balanced_acc: 0.4715 - lr: 2.5000e-04\n",
            "Epoch 49/50\n",
            "219/219 [==============================] - ETA: 0s - loss: 5.8668e-04 - accuracy: 1.0000 - balanced_acc: 1.0000\n",
            "Epoch 49: val_balanced_acc did not improve from 0.63538\n",
            "219/219 [==============================] - 50s 229ms/step - loss: 5.8668e-04 - accuracy: 1.0000 - balanced_acc: 1.0000 - val_loss: 1.2868 - val_accuracy: 0.7513 - val_balanced_acc: 0.4715 - lr: 2.5000e-04\n",
            "Epoch 50/50\n",
            "219/219 [==============================] - ETA: 0s - loss: 5.7677e-04 - accuracy: 1.0000 - balanced_acc: 0.9993\n",
            "Epoch 50: val_balanced_acc did not improve from 0.63538\n",
            "219/219 [==============================] - 50s 229ms/step - loss: 5.7677e-04 - accuracy: 1.0000 - balanced_acc: 0.9993 - val_loss: 1.2892 - val_accuracy: 0.7461 - val_balanced_acc: 0.4707 - lr: 2.5000e-04\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# define model\n",
        "model = define_model_resnet()\n",
        "#Callbacks\n",
        "mc = ModelCheckpoint(best_model_fpath, monitor='val_balanced_acc', mode='max', verbose=1, save_best_only=True)\n",
        "learning_rate_reduction = ReduceLROnPlateau(monitor='val_balanced_acc', patience=20, verbose=1, factor=0.5, min_lr=0.00001)\n",
        "early_stopping_monitor = EarlyStopping(patience=40,monitor='val_balanced_acc')\n",
        "#model.summary()\n",
        "hst = model.fit(X_train, y_train, epochs=EPOCHS, batch_size=BATCH_SIZE, validation_data=(X_val, y_val), verbose=1,\n",
        "                    steps_per_epoch=X_train.shape[0] // BATCH_SIZE, \n",
        "                    #callbacks=[learning_rate_reduction,early_stopping_monitor, mc])\n",
        "                    callbacks=[learning_rate_reduction,mc])\n",
        "# learning curves\n",
        "summarize_diagnostics(hst)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "SPz8NH1Oylv9",
        "outputId": "6cf44dfe-94cb-4b60-febd-d9a67678e0da"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "model saved\n"
          ]
        }
      ],
      "source": [
        "#save last model\n",
        "last_model_fpath = '/content/drive/MyDrive/PHD/Model/last_model_'+exp_name+'_'+dataset_name+'.h5'\n",
        "model.save(last_model_fpath)\n",
        "print(\"model saved\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "vXnW3lmCgln3",
        "outputId": "ab24957f-ef7e-4df9-d907-df57d8bd6a5d"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# summarize history for accuracy\n",
        "plt.plot(hst.history['accuracy'])\n",
        "plt.plot(hst.history['balanced_acc'])\n",
        "plt.plot(hst.history['val_accuracy'])\n",
        "plt.plot(hst.history['val_balanced_acc'])\n",
        "plt.title('Model accuracy')\n",
        "plt.ylabel('Performance')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train accuracy', 'train balanced acc.', 'val. accuracy', 'val. balanced acc.'], loc='lower right')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "icgjmi-4UIT-"
      },
      "source": [
        "#Evaluate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lS3ewyxO_anU",
        "outputId": "c386b00c-4b91-45cb-aa27-9d493e668760"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "440/440 [==============================] - 17s 36ms/step\n",
            "7/7 [==============================] - 0s 35ms/step\n",
            "accuracy on training 1.0\n",
            "balanced accuracy on training 1.0\n",
            "accuracy on validation 0.7461139896373057\n",
            "balanced accuracy on validation 0.7112237356139796\n",
            "Score on val data:  (0.6428069021077099, 0.7112237356139796, 0.6539202603361896, None)\n"
          ]
        }
      ],
      "source": [
        "#last_model_fpath = '/content/drive/MyDrive/PHD/Model/last_model_'+exp_name+'_'+dataset_name+'.h5'\n",
        "last_model = load_model(last_model_fpath, custom_objects={'balanced_acc' : balanced_acc})\n",
        "y_train_pred = last_model.predict(X_train)\n",
        "y_val_pred = last_model.predict(X_val)\n",
        "\n",
        "#print('accuracy on training',accuracy_score(np.argmax(y_train, axis=1), np.argmax(y_train_pred, axis=1)))\n",
        "print('accuracy on training',accuracy_score(np.argmax(y_train, axis=1), np.argmax(y_train_pred, axis=1)))\n",
        "print('balanced accuracy on training',balanced_accuracy_score(np.argmax(y_train, axis=1), np.argmax(y_train_pred, axis=1)))\n",
        "print('accuracy on validation',accuracy_score(np.argmax(y_val, axis=1), np.argmax(y_val_pred, axis=1)))\n",
        "print('balanced accuracy on validation',balanced_accuracy_score(np.argmax(y_val, axis=1), np.argmax(y_val_pred, axis=1)))\n",
        "print('Score on val data: ',precision_recall_fscore_support(np.argmax(y_val, axis=1), np.argmax(y_val_pred, axis=1), average='macro'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0YBMT-j82Jws"
      },
      "source": [
        "79; 79"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "W3IyWjdGG4Xq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9a3f7ccc-42b9-4be7-b8a5-e22a83188d14"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "440/440 [==============================] - 25s 36ms/step\n",
            "7/7 [==============================] - 1s 82ms/step\n",
            "accuracy on training 0.8894650848902464\n",
            "balanced accuracy on training 0.8894650848902466\n",
            "accuracy on validation 0.7927461139896373\n",
            "balanced accuracy on validation 0.7565002941309562\n",
            "Score on val data:  (0.7298748870177442, 0.7565002941309562, 0.7251667987980134, None)\n"
          ]
        }
      ],
      "source": [
        "best_model = load_model(best_model_fpath, custom_objects={'balanced_acc' : balanced_acc})\n",
        "y_train_pred = best_model.predict(X_train)\n",
        "y_val_pred = best_model.predict(X_val)\n",
        "\n",
        "print('accuracy on training',accuracy_score(np.argmax(y_train, axis=1), np.argmax(y_train_pred, axis=1)))\n",
        "print('balanced accuracy on training',balanced_accuracy_score(np.argmax(y_train, axis=1), np.argmax(y_train_pred, axis=1)))\n",
        "print('accuracy on validation',accuracy_score(np.argmax(y_val, axis=1), np.argmax(y_val_pred, axis=1)))\n",
        "print('balanced accuracy on validation',balanced_accuracy_score(np.argmax(y_val, axis=1), np.argmax(y_val_pred, axis=1)))\n",
        "print('Score on val data: ',precision_recall_fscore_support(np.argmax(y_val, axis=1), np.argmax(y_val_pred, axis=1), average='macro'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7P6d2lVG2L_D"
      },
      "source": [
        "79;81"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iDRWiTnO0MGh"
      },
      "source": [
        "#Cut-off"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tGnCoIdLyDHS"
      },
      "outputs": [],
      "source": [
        "df_val_pred = pd.DataFrame(y_val_pred, columns = ['AKIEC', 'BCC', 'BKL', 'DF', 'MEL', 'NV', 'VASC'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QdyCbloQyWTC"
      },
      "outputs": [],
      "source": [
        "numbers = [float(x)/40 for x in range(11)]\n",
        "for i in numbers:\n",
        "    df_val_pred[i]= df_val_pred.MEL.map(lambda x: 1 if x > i else 0)\n",
        "df_val_pred.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G4SQsRx73kgk"
      },
      "outputs": [],
      "source": [
        "y_val_true= [1 if x == 4 else 0 for x in np.argmax(y_val, axis=1)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QcUISWFi0J05"
      },
      "outputs": [],
      "source": [
        "#num = [0.0,0.05,0.1,0.15,0.2,0.25,0.3,0.35,0.4,0.45,0.5]\n",
        "cutoff_df = pd.DataFrame( columns = ['Probability','Accuracy','Sensitivity','Specificity'])\n",
        "for i in numbers:\n",
        "    cm1 = confusion_matrix(y_val_true, df_val_pred[i])\n",
        "    total1=sum(sum(cm1))\n",
        "    Accuracy = (cm1[0,0]+cm1[1,1])/total1\n",
        "    Specificity = cm1[0,0]/(cm1[0,0]+cm1[0,1])\n",
        "    Sensitivity = cm1[1,1]/(cm1[1,0]+cm1[1,1])\n",
        "    cutoff_df.loc[i] =[ i ,Accuracy,Sensitivity,Specificity]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W31LSzov1tCt"
      },
      "outputs": [],
      "source": [
        "cutoff_df[['Accuracy','Sensitivity','Specificity']].plot()\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P6CIKT94Jqye"
      },
      "outputs": [],
      "source": [
        "i = 0.025\n",
        "cm1 = confusion_matrix(y_val_true, df_val_pred[i])\n",
        "total1=sum(sum(cm1))\n",
        "Accuracy = (cm1[0,0]+cm1[1,1])/total1\n",
        "Specificity = cm1[0,0]/(cm1[0,0]+cm1[0,1])\n",
        "Sensitivity = cm1[1,1]/(cm1[1,0]+cm1[1,1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3U2tkFebL_VC"
      },
      "outputs": [],
      "source": [
        "print('Accuracy: ', Accuracy)\n",
        "print('Sensitivity: ', Sensitivity)\n",
        "print('Specificity: ', Specificity)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eaK4zbtoaAaC"
      },
      "source": [
        "#Confusion Metric on Validation Set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YkPOFLehOmFg"
      },
      "outputs": [],
      "source": [
        "#change melanoma flag back to 4\n",
        "df_val_pred[df_val_pred[i] == 1] = 4\n",
        "#decode one-hot y_val_pred while use cut-off melanoma data\n",
        "condition = df_val_pred[i] == 4\n",
        "y_val_pred2 = np.where(condition, df_val_pred[i], np.argmax(y_val_pred, axis=1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LOVl6dWlTDLo"
      },
      "outputs": [],
      "source": [
        "print('Accuracy: ',accuracy_score(np.argmax(y_val, axis=1), y_val_pred2))\n",
        "print('Balanced accuracy: ',balanced_accuracy_score(np.argmax(y_val, axis=1), y_val_pred2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mqvYutTKRhR_"
      },
      "outputs": [],
      "source": [
        "#Get the confusion matrix\n",
        "cf_matrix = confusion_matrix(np.argmax(y_val, axis=1), y_val_pred2)\n",
        "print(cf_matrix)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gVtvW3YeaLlC"
      },
      "outputs": [],
      "source": [
        "ax = sns.heatmap(cf_matrix / cf_matrix.sum(axis=1, keepdims=True), annot=True, \n",
        "            cmap='Blues')\n",
        "\n",
        "ax.set_title('Confusion Matrix \\n');\n",
        "ax.set_xlabel('\\nPredicted')\n",
        "ax.set_ylabel('Actual ');\n",
        "\n",
        "## Ticket labels - List must be in alphabetical order\n",
        "ax.xaxis.set_ticklabels(['AKIEC', 'BCC', 'BKL', 'DF', 'MEL', 'NV', 'VASC'])\n",
        "ax.yaxis.set_ticklabels(['AKIEC', 'BCC', 'BKL', 'DF', 'MEL', 'NV', 'VASC'])\n",
        "\n",
        "plt.rcParams[\"figure.figsize\"] = (15,3)\n",
        "\n",
        "## Display the visualization of the Confusion Matrix.\n",
        "plt.xticks(rotation=45, ha='right')\n",
        "plt.yticks(rotation=0, ha='right')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ey-1yjWGeKs7"
      },
      "outputs": [],
      "source": [
        "# ordered count of rows per unique label\n",
        "#labels_count = df_val['Labels'].value_counts().sort_index()\n",
        "\n",
        "#f = plt.figure(figsize=(15, 6))\n",
        "#s = sns.barplot(x=labels_count.index,y=labels_count.values)\n",
        "#s.set_xticklabels(s.get_xticklabels(), rotation = 30)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3K908bbiYwbS"
      },
      "source": [
        "#Testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cN98sOWPyT3P",
        "outputId": "2316c488-05c7-4494-8159-333a4ec5c717"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(1512, 224, 224, 3)"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_test = pd.read_pickle(path+\"isic2018_test.pkl\")\n",
        "X_test = df_test.loc[:, df_test.columns != 'y_train'].to_numpy()\n",
        "X_test = X_test.reshape(-1,224,224,3)\n",
        "X_test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NeMY2yvMYxsC"
      },
      "outputs": [],
      "source": [
        "dir_test = '/content/drive/MyDrive/PHD/Datasets/isic2018/ISIC2018_Task3_Test_Input/'\n",
        "filepaths = sorted( filter( lambda x: (os.path.isfile(os.path.join(dir_test, x))) and (x.endswith('.jpg')),\n",
        "                        os.listdir(dir_test) ) )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6ic95mefkpG3"
      },
      "outputs": [],
      "source": [
        "df_test = pd.DataFrame(filepaths, columns =['image'])\n",
        "df_test['FilePaths'] = dir_test + df_test['image']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NBa1TxPuY8ni"
      },
      "outputs": [],
      "source": [
        "df_test['image_px'] = df_test['FilePaths'].map(lambda x: np.asarray(Image.open(x).resize(IMG_SIZE)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "60LYAT7VsNOZ",
        "outputId": "e2210f76-2e3a-4add-995e-79582acdab74"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(1512, 128, 128, 3)\n"
          ]
        }
      ],
      "source": [
        "X_test = np.asarray(df_test['image_px'].tolist())\n",
        "print(np.array(X_test).shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cXnnIIwC4cHE"
      },
      "outputs": [],
      "source": [
        "#preprocess\n",
        "X_test = preprocess_image_input(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JC17MArBxhSW"
      },
      "outputs": [],
      "source": [
        "df3 = pd.DataFrame(X_test.reshape(X_test.shape[0],-1))\n",
        "df3.to_pickle(path+\"isic2018_test_128px.pkl\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FF7ml90JZ8FK"
      },
      "source": [
        "Calculate y_pred from training and testing for analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KeDTXdaMLmyU",
        "outputId": "a6ea64da-79f0-424f-f913-5b0bd6c66170"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(1512, 2048)"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#FOR MAKING FEATURE SPACE DATA\n",
        "X_test = model1.predict(X_test)\n",
        "X_test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dIX0AmEFNv3Y",
        "outputId": "0ed9a370-faec-457b-8d99-7c7de11457df"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "48/48 [==============================] - 2s 46ms/step\n",
            "Y_pred2 (1512, 7)\n"
          ]
        }
      ],
      "source": [
        "# predicting\n",
        "#CHANGE THE MODEL IF NECESSARY\n",
        "Y_pred2 = best_model.predict(X_test)\n",
        "#Y_pred2 = model2.predict(X_test)\n",
        "print(\"Y_pred2\", Y_pred2.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7oeArO5CtxGb"
      },
      "outputs": [],
      "source": [
        "df_pred = pd.DataFrame(Y_pred2, columns = ['AKIEC', 'BCC', 'BKL', 'DF', 'MEL', 'NV', 'VASC'])\n",
        "df_pred['image'] = df_test['FilePaths'].map(lambda x: x.replace(dir_test, '').replace('.jpg', ''))\n",
        "df_pred = df_pred[['image', 'MEL', 'NV', 'BCC', 'AKIEC', 'BKL', 'DF', 'VASC']]\n",
        "df_pred.set_index(\"image\", inplace = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9ynyd8PjT589"
      },
      "outputs": [],
      "source": [
        "#update MEL data using cut-off value\n",
        "df_pred.MEL[df_pred.MEL > i] = 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fjRdONoQVMq0"
      },
      "outputs": [],
      "source": [
        "df_pred.loc[df_pred.MEL > i, ['NV', 'BCC', 'AKIEC', 'BKL', 'DF', 'VASC']] = 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K4Iv_3s4z0R9"
      },
      "outputs": [],
      "source": [
        "df_pred.head(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sOnjc3RJ0e4T"
      },
      "outputs": [],
      "source": [
        "df_pred.to_csv('/content/drive/MyDrive/PHD/Datasets/isic2018/response_50epochs-128px-SMOTE.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P0MghVs0tsGw"
      },
      "source": [
        "result: 0.601"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UswA0co2y1wl"
      },
      "source": [
        "#Exp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dnqJYIONy34l"
      },
      "outputs": [],
      "source": [
        "input_tensor = Input(shape=(IMAGE_H, IMAGE_W, 3))\n",
        "base_model = ResNet50(input_shape=(224,224,3), weights='imagenet', include_top=False)\n",
        "x = base_model(input_tensor, training=False)\n",
        "x = Attention(2048,2048,7,8)(x)\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "res50 = Model(inputs=input_tensor, outputs=x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kcn8hQg3J8yP"
      },
      "outputs": [],
      "source": [
        "#Train i-last layer\n",
        "# summarize feature map shapes\n",
        "for i in range(len(model.layers)):\n",
        "    layer = model.layers[i]\n",
        "    # summarize output shape\n",
        "    print(i, layer.name, layer.output.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UA7Af2Y73FUv"
      },
      "outputs": [],
      "source": [
        "X_train = res50.predict(X_train)\n",
        "X_val = res50.predict(X_val)\n",
        "print(X_train.shape)\n",
        "print(y_train.shape)\n",
        "print(X_val.shape)\n",
        "print(y_val.shape)\n",
        "print('Counter train data: ', Counter(np.argmax(y_train, axis=1)))\n",
        "print('Counter val data: ', Counter(np.argmax(y_val, axis=1)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "krJiAb1m3QNf"
      },
      "outputs": [],
      "source": [
        "X_train, y_train = SMOTE_Data2(X_train, y_train, True)\n",
        "print(X_train.shape)\n",
        "print(y_train.shape)\n",
        "print(X_val.shape)\n",
        "print(y_val.shape)\n",
        "print('Counter train data: ', Counter(np.argmax(y_train, axis=1)))\n",
        "print('Counter val data: ', Counter(np.argmax(y_val, axis=1)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LfcFpsBwM0d4"
      },
      "source": [
        "#Attention"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 398
        },
        "id": "C_s6OIGKM26a",
        "outputId": "371bd24a-4bf9-491a-e0ec-78b7eb06e6d9"
      },
      "outputs": [
        {
          "ename": "AttributeError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-ff488085aaa5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mConv2D\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mMaxPooling2D\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mAveragePooling2D\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mBatchNormalization\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mAdd\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mZeroPadding2D\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mFlatten\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mInput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mLeakyReLU\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mSoftmax\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mReLU\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAdam\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    471\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_current_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"keras\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    472\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 473\u001b[0;31m     \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    474\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    475\u001b[0m     \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/lazy_loader.py\u001b[0m in \u001b[0;36m_load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;34m\"\"\"Load the module and insert it into the parent's globals.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0;31m# Import the target module and insert it into the parent's namespace\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m     \u001b[0mmodule\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimportlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimport_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_module_globals\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_local_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/importlib/__init__.py\u001b[0m in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m    125\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m             \u001b[0mlevel\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_bootstrap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gcd_import\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpackage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;31m# See b/110718070#comment18 for more details about this import.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_layer\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mInput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/models.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv2\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmetrics\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmetrics_module\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0moptimizer_v1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfunctional\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/metrics.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mwarnings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mactivations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbase_layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/activations.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0madvanced_activations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgeneric_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdeserialize_keras_object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgeneric_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mserialize_keras_object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/layers/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_spec\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mInputSpec\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_layer\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLayer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_preprocessing_layer\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPreprocessingLayer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;31m# Image preprocessing layers.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/base_preprocessing_layer.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mabc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdata_adapter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_layer\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLayer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mversion_utils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m   \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m  \u001b[0;31m# pylint: disable=g-import-not-at-top\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m   \u001b[0mpd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tester\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 179\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtesting\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    180\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/testing.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m from pandas._testing import (\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0massert_extension_array_equal\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0massert_frame_equal\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/_testing/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    946\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    947\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 948\u001b[0;31m \u001b[0mcython_table\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommon\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cython_table\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    949\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    950\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: module 'pandas' has no attribute 'core'"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow.keras as tk\n",
        "from tensorflow.keras.layers import Conv2D,MaxPooling2D,AveragePooling2D,BatchNormalization,Add,ZeroPadding2D,Flatten,Dense,Input,LeakyReLU,Softmax,ReLU\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.models import Model\n",
        "import numpy as np\n",
        "import pickle\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "\n",
        "class Attention(tk.layers.Layer):\n",
        "    \n",
        "    def __init__(self,input_channels,output_channel,kernel_size,groups):\n",
        "        super().__init__()\n",
        "        self.input_channels = input_channels\n",
        "        self.output_channel = output_channel    \n",
        "        self.kernel_size = kernel_size\n",
        "        self.stride = 1\n",
        "        self.groups = groups\n",
        "\n",
        "        assert output_channel % groups == 0\n",
        "        \n",
        "        self.rel_h = tk.backend.variable(lambda : tk.backend.truncated_normal((1,1,kernel_size,1,output_channel//2),stddev = 0.1)) \n",
        "        #output_channels//2 is the number of channels on which the relative position will be considered,1 denotes the number of those filters and the one after that too and (kernel_size,1) denotes the size of that filter\n",
        "        self.rel_w = tk.backend.variable(lambda : tk.backend.truncated_normal((1,1,1,kernel_size,output_channel//2),stddev = 0.1)) \n",
        "\n",
        "        self.key_weights = Conv2D(self.output_channel,kernel_size = 1,strides = self.stride)\n",
        "        self.query_weights = Conv2D(self.output_channel,kernel_size = 1,strides = self.stride)\n",
        "        self.value_weights = Conv2D(self.output_channel,kernel_size = 1,strides = self.stride)\n",
        "\n",
        "    def call(self,x):\n",
        "        \n",
        "        batch,height,width,channels = x.shape\n",
        "        x_padded = ZeroPadding2D(padding=(self.kernel_size//2,self.kernel_size//2))(x)\n",
        "        query = self.query_weights(x)\n",
        "        value = self.value_weights(x_padded)\n",
        "        key = self.key_weights(x_padded)\n",
        "        #key,query and value will have the shape of (batch,height,width,depth)\n",
        "        keys = tf.image.extract_patches(images = key,sizes = [1,self.kernel_size,self.kernel_size,1],strides = [1,self.stride,self.stride,1],rates = [1,1,1,1], padding = \"VALID\")\n",
        "        value = tf.image.extract_patches(images = value,sizes = [1,self.kernel_size,self.kernel_size,1],strides = [1,self.stride,self.stride,1],rates = [1,1,1,1], padding = \"VALID\")\n",
        "        no_of_kernels = key.shape[-2] - self.kernel_size + 1\n",
        "        keys = tf.reshape(keys,shape = (-1,no_of_kernels, no_of_kernels,self.kernel_size,self.kernel_size,self.output_channel))\n",
        "        key_split_h,key_split_w = tf.split(keys,num_or_size_splits = 2,axis = -1)\n",
        "        key_with_rel = tk.layers.concatenate([key_split_h + self.rel_h,key_split_w + self.rel_w],axis = -1) \n",
        "        \n",
        "        #reshaping the query and key\n",
        "        key_with_rel = tf.reshape(key_with_rel,(-1,self.groups,no_of_kernels,no_of_kernels,self.kernel_size*self.kernel_size,self.output_channel//self.groups))\n",
        "        query  = tf.reshape(query,(-1,self.groups,no_of_kernels,no_of_kernels,1,self.output_channel//self.groups))        \n",
        "        value = tf.reshape(value,(-1,self.groups,no_of_kernels,no_of_kernels,self.kernel_size*self.kernel_size,self.output_channel//self.groups))\n",
        "        \n",
        "        #multiplication  of key and query\n",
        "        #assert key_with_rel.shape == query.shape        \n",
        "        key_prod_query = query*key_with_rel\n",
        "        \n",
        "        # Now the function is passed through the softmax and is multiplied with the values\n",
        "        s = Softmax(axis = -2)(key_prod_query)\n",
        "        y = tf.einsum('bnchwk,bnchwk->bnchk',s,value)\n",
        "        y = tf.reshape(y,(-1,height,width,self.output_channel))\n",
        "        return y\n",
        "\n",
        "    def get_config(self):\n",
        "        config = super().get_config().copy()\n",
        "        config.update({\n",
        "            \"input_channels\": self.input_channels, \n",
        "            \"output_channel\": self.output_channel, \n",
        "            \"kernel_size\": self.kernel_size, \n",
        "            \"stride\": self.stride, \n",
        "            \"groups\": self.groups, \n",
        "            \"rel_h\": self.rel_h, \n",
        "            \"rel_w\": self.rel_w, \n",
        "            \"key_weights\": self.key_weights, \n",
        "            \"query_weights\": self.query_weights, \n",
        "            \"value_weights\": self.value_weights\n",
        "        })\n",
        "        return config\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kE8Ziq-BlEP4"
      },
      "source": [
        "#Oversampling on feature map level"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wqfEP5L9BgcF"
      },
      "outputs": [],
      "source": [
        "model = best_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lm05Zet_B5am",
        "outputId": "fbfdf6eb-85ab-47da-dd67-9144153e76fe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0 input_1 [(None, 128, 128, 3)] True\n",
            "1 resnet50 (None, 4, 4, 2048) True\n",
            "2 global_average_pooling2d (None, 2048) True\n",
            "3 flatten (None, 2048) True\n",
            "4 dense (None, 1024) True\n",
            "5 dense_1 (None, 512) True\n",
            "6 dense_2 (None, 7) True\n"
          ]
        }
      ],
      "source": [
        "for i in range(len(model.layers)):\n",
        "  layer = model.layers[i]\n",
        "  print(i, layer.name, layer.output_shape, layer.trainable)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KqeSic6NmLsR"
      },
      "outputs": [],
      "source": [
        "# redefine model to output right after the first hidden layer\n",
        "end = 2\n",
        "model1 = Model(inputs=model.inputs, outputs=model.layers[end].output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZVHYG9Rwm28i",
        "outputId": "458bfcaa-caad-4ada-9451-8f940b72defa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "146/146 [==============================] - 6s 33ms/step\n",
            "7/7 [==============================] - 0s 31ms/step\n"
          ]
        }
      ],
      "source": [
        "# get feature map for first hidden layer\n",
        "X_train_fm = model1.predict(X_train)\n",
        "X_val_fm = model1.predict(X_val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xx0OnnZPl7_t",
        "outputId": "dfdab64b-92ae-4ca5-b79f-80072a38ff32"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(4651, 2048)\n",
            "(4651, 7)\n",
            "(193, 2048)\n",
            "(193, 7)\n",
            "Counter train data:  Counter({5: 1341, 4: 1113, 2: 1099, 1: 514, 0: 327, 6: 142, 3: 115})\n",
            "Counter val data:  Counter({5: 123, 2: 22, 4: 21, 1: 15, 0: 8, 6: 3, 3: 1})\n"
          ]
        }
      ],
      "source": [
        "print(X_train_fm.shape)\n",
        "print(y_train.shape)\n",
        "print(X_val_fm.shape)\n",
        "print(y_val.shape)\n",
        "print('Counter train data: ', Counter(np.argmax(y_train, axis=1)))\n",
        "print('Counter val data: ', Counter(np.argmax(y_val, axis=1)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "19hK7aQNeAQo",
        "outputId": "692063d8-a6c6-4ed3-d48b-ad35990afbaf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(9987, 2048)\n",
            "(9987, 7)\n",
            "(193, 2048)\n",
            "(193, 7)\n",
            "Counter train data:  Counter({5: 1441, 4: 1441, 2: 1441, 0: 1441, 1: 1441, 6: 1441, 3: 1341})\n",
            "Counter val data:  Counter({5: 123, 2: 22, 4: 21, 1: 15, 0: 8, 6: 3, 3: 1})\n"
          ]
        }
      ],
      "source": [
        "X_train_fm_ov, y_train_ov = SMOTE_Data2(X_train, y_train, True, 5, type=\"borderline\")\n",
        "print(X_train_fm_ov.shape)\n",
        "print(y_train_ov.shape)\n",
        "print(X_val_fm.shape)\n",
        "print(y_val.shape)\n",
        "print('Counter train data: ', Counter(np.argmax(y_train_ov, axis=1)))\n",
        "print('Counter val data: ', Counter(np.argmax(y_val, axis=1)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5qP4iyYcnAYa"
      },
      "outputs": [],
      "source": [
        "model2 = Model(inputs=model.layers[end+1].input, outputs=model.layers[len(model.layers)-1].output)\n",
        "#model2 = define_base_model(arch = 'dense')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pzdjs0WbvDB0",
        "outputId": "2f3c4624-af07-4c16-cfe6-295695195aff"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "best_model_fpath:/content/drive/MyDrive/PHD/Model/best_model_borderline_after_smote_on_featurespace_under80_128px.h5\n",
            "last_model_fpath:/content/drive/MyDrive/PHD/Model/last_model_borderline_after_smote_on_featurespace_under80_128px.h5\n",
            "Epoch 1/50\n",
            "153/156 [============================>.] - ETA: 0s - loss: 0.4016 - accuracy: 0.8682 - balanced_acc: 0.8692\n",
            "Epoch 1: val_balanced_acc improved from -inf to 0.42675, saving model to /content/drive/MyDrive/PHD/Model/best_model_borderline_after_smote_on_featurespace_under80_128px.h5\n",
            "156/156 [==============================] - 2s 6ms/step - loss: 0.4016 - accuracy: 0.8682 - balanced_acc: 0.8693 - val_loss: 0.6877 - val_accuracy: 0.7202 - val_balanced_acc: 0.4267 - lr: 0.0010\n",
            "Epoch 2/50\n",
            "149/156 [===========================>..] - ETA: 0s - loss: 0.3630 - accuracy: 0.8827 - balanced_acc: 0.8791\n",
            "Epoch 2: val_balanced_acc did not improve from 0.42675\n",
            "156/156 [==============================] - 1s 4ms/step - loss: 0.3636 - accuracy: 0.8818 - balanced_acc: 0.8785 - val_loss: 0.6546 - val_accuracy: 0.7617 - val_balanced_acc: 0.4160 - lr: 0.0010\n",
            "Epoch 3/50\n",
            "144/156 [==========================>...] - ETA: 0s - loss: 0.3374 - accuracy: 0.8924 - balanced_acc: 0.8888\n",
            "Epoch 3: val_balanced_acc did not improve from 0.42675\n",
            "156/156 [==============================] - 1s 4ms/step - loss: 0.3386 - accuracy: 0.8919 - balanced_acc: 0.8887 - val_loss: 0.6659 - val_accuracy: 0.7461 - val_balanced_acc: 0.4081 - lr: 0.0010\n",
            "Epoch 4/50\n",
            "153/156 [============================>.] - ETA: 0s - loss: 0.3193 - accuracy: 0.9011 - balanced_acc: 0.8976\n",
            "Epoch 4: val_balanced_acc improved from 0.42675 to 0.43782, saving model to /content/drive/MyDrive/PHD/Model/best_model_borderline_after_smote_on_featurespace_under80_128px.h5\n",
            "156/156 [==============================] - 1s 4ms/step - loss: 0.3201 - accuracy: 0.9005 - balanced_acc: 0.8972 - val_loss: 0.6597 - val_accuracy: 0.7513 - val_balanced_acc: 0.4378 - lr: 0.0010\n",
            "Epoch 5/50\n",
            "145/156 [==========================>...] - ETA: 0s - loss: 0.3072 - accuracy: 0.9042 - balanced_acc: 0.9002\n",
            "Epoch 5: val_balanced_acc did not improve from 0.43782\n",
            "156/156 [==============================] - 1s 4ms/step - loss: 0.3089 - accuracy: 0.9024 - balanced_acc: 0.8986 - val_loss: 0.6315 - val_accuracy: 0.7617 - val_balanced_acc: 0.4189 - lr: 0.0010\n",
            "Epoch 6/50\n",
            "155/156 [============================>.] - ETA: 0s - loss: 0.2947 - accuracy: 0.9071 - balanced_acc: 0.9065\n",
            "Epoch 6: val_balanced_acc did not improve from 0.43782\n",
            "156/156 [==============================] - 1s 4ms/step - loss: 0.2948 - accuracy: 0.9072 - balanced_acc: 0.9066 - val_loss: 0.6740 - val_accuracy: 0.7306 - val_balanced_acc: 0.4000 - lr: 0.0010\n",
            "Epoch 7/50\n",
            "143/156 [==========================>...] - ETA: 0s - loss: 0.2854 - accuracy: 0.9118 - balanced_acc: 0.9148\n",
            "Epoch 7: val_balanced_acc improved from 0.43782 to 0.45081, saving model to /content/drive/MyDrive/PHD/Model/best_model_borderline_after_smote_on_featurespace_under80_128px.h5\n",
            "156/156 [==============================] - 1s 4ms/step - loss: 0.2854 - accuracy: 0.9117 - balanced_acc: 0.9148 - val_loss: 0.6830 - val_accuracy: 0.7358 - val_balanced_acc: 0.4508 - lr: 0.0010\n",
            "Epoch 8/50\n",
            "155/156 [============================>.] - ETA: 0s - loss: 0.2753 - accuracy: 0.9149 - balanced_acc: 0.9115\n",
            "Epoch 8: val_balanced_acc improved from 0.45081 to 0.45762, saving model to /content/drive/MyDrive/PHD/Model/best_model_borderline_after_smote_on_featurespace_under80_128px.h5\n",
            "156/156 [==============================] - 1s 4ms/step - loss: 0.2757 - accuracy: 0.9147 - balanced_acc: 0.9113 - val_loss: 0.6377 - val_accuracy: 0.7617 - val_balanced_acc: 0.4576 - lr: 0.0010\n",
            "Epoch 9/50\n",
            "142/156 [==========================>...] - ETA: 0s - loss: 0.2705 - accuracy: 0.9157 - balanced_acc: 0.9120\n",
            "Epoch 9: val_balanced_acc improved from 0.45762 to 0.45975, saving model to /content/drive/MyDrive/PHD/Model/best_model_borderline_after_smote_on_featurespace_under80_128px.h5\n",
            "156/156 [==============================] - 1s 4ms/step - loss: 0.2666 - accuracy: 0.9174 - balanced_acc: 0.9136 - val_loss: 0.6718 - val_accuracy: 0.7617 - val_balanced_acc: 0.4597 - lr: 0.0010\n",
            "Epoch 10/50\n",
            "141/156 [==========================>...] - ETA: 0s - loss: 0.2623 - accuracy: 0.9206 - balanced_acc: 0.9167\n",
            "Epoch 10: val_balanced_acc did not improve from 0.45975\n",
            "156/156 [==============================] - 1s 3ms/step - loss: 0.2622 - accuracy: 0.9203 - balanced_acc: 0.9169 - val_loss: 0.6259 - val_accuracy: 0.7720 - val_balanced_acc: 0.4230 - lr: 0.0010\n",
            "Epoch 11/50\n",
            "143/156 [==========================>...] - ETA: 0s - loss: 0.2528 - accuracy: 0.9249 - balanced_acc: 0.9216\n",
            "Epoch 11: val_balanced_acc did not improve from 0.45975\n",
            "156/156 [==============================] - 1s 3ms/step - loss: 0.2522 - accuracy: 0.9248 - balanced_acc: 0.9220 - val_loss: 0.6355 - val_accuracy: 0.7617 - val_balanced_acc: 0.4208 - lr: 0.0010\n",
            "Epoch 12/50\n",
            "144/156 [==========================>...] - ETA: 0s - loss: 0.2451 - accuracy: 0.9258 - balanced_acc: 0.9233\n",
            "Epoch 12: val_balanced_acc did not improve from 0.45975\n",
            "156/156 [==============================] - 1s 3ms/step - loss: 0.2454 - accuracy: 0.9260 - balanced_acc: 0.9240 - val_loss: 0.6528 - val_accuracy: 0.7513 - val_balanced_acc: 0.4140 - lr: 0.0010\n",
            "Epoch 13/50\n",
            "144/156 [==========================>...] - ETA: 0s - loss: 0.2395 - accuracy: 0.9292 - balanced_acc: 0.9299\n",
            "Epoch 13: val_balanced_acc did not improve from 0.45975\n",
            "156/156 [==============================] - 1s 3ms/step - loss: 0.2394 - accuracy: 0.9296 - balanced_acc: 0.9300 - val_loss: 0.7099 - val_accuracy: 0.7409 - val_balanced_acc: 0.4123 - lr: 0.0010\n",
            "Epoch 14/50\n",
            "142/156 [==========================>...] - ETA: 0s - loss: 0.2288 - accuracy: 0.9325 - balanced_acc: 0.9293\n",
            "Epoch 14: val_balanced_acc did not improve from 0.45975\n",
            "156/156 [==============================] - 1s 3ms/step - loss: 0.2293 - accuracy: 0.9317 - balanced_acc: 0.9288 - val_loss: 0.7138 - val_accuracy: 0.7358 - val_balanced_acc: 0.4166 - lr: 0.0010\n",
            "Epoch 15/50\n",
            "145/156 [==========================>...] - ETA: 0s - loss: 0.2276 - accuracy: 0.9322 - balanced_acc: 0.9265\n",
            "Epoch 15: val_balanced_acc did not improve from 0.45975\n",
            "156/156 [==============================] - 1s 3ms/step - loss: 0.2278 - accuracy: 0.9316 - balanced_acc: 0.9264 - val_loss: 0.6547 - val_accuracy: 0.7565 - val_balanced_acc: 0.4214 - lr: 0.0010\n",
            "Epoch 16/50\n",
            "144/156 [==========================>...] - ETA: 0s - loss: 0.2190 - accuracy: 0.9349 - balanced_acc: 0.9314\n",
            "Epoch 16: val_balanced_acc did not improve from 0.45975\n",
            "156/156 [==============================] - 1s 3ms/step - loss: 0.2203 - accuracy: 0.9348 - balanced_acc: 0.9317 - val_loss: 0.6975 - val_accuracy: 0.7409 - val_balanced_acc: 0.4270 - lr: 0.0010\n",
            "Epoch 17/50\n",
            "142/156 [==========================>...] - ETA: 0s - loss: 0.2144 - accuracy: 0.9381 - balanced_acc: 0.9353\n",
            "Epoch 17: val_balanced_acc did not improve from 0.45975\n",
            "156/156 [==============================] - 1s 3ms/step - loss: 0.2142 - accuracy: 0.9375 - balanced_acc: 0.9354 - val_loss: 0.6577 - val_accuracy: 0.7617 - val_balanced_acc: 0.4202 - lr: 0.0010\n",
            "Epoch 18/50\n",
            "143/156 [==========================>...] - ETA: 0s - loss: 0.2134 - accuracy: 0.9384 - balanced_acc: 0.9353\n",
            "Epoch 18: val_balanced_acc improved from 0.45975 to 0.46312, saving model to /content/drive/MyDrive/PHD/Model/best_model_borderline_after_smote_on_featurespace_under80_128px.h5\n",
            "156/156 [==============================] - 1s 4ms/step - loss: 0.2152 - accuracy: 0.9370 - balanced_acc: 0.9347 - val_loss: 0.6686 - val_accuracy: 0.7617 - val_balanced_acc: 0.4631 - lr: 0.0010\n",
            "Epoch 19/50\n",
            "141/156 [==========================>...] - ETA: 0s - loss: 0.2042 - accuracy: 0.9408 - balanced_acc: 0.9396\n",
            "Epoch 19: val_balanced_acc did not improve from 0.46312\n",
            "156/156 [==============================] - 1s 3ms/step - loss: 0.2060 - accuracy: 0.9400 - balanced_acc: 0.9392 - val_loss: 0.6387 - val_accuracy: 0.7668 - val_balanced_acc: 0.4234 - lr: 0.0010\n",
            "Epoch 20/50\n",
            "143/156 [==========================>...] - ETA: 0s - loss: 0.2034 - accuracy: 0.9412 - balanced_acc: 0.9396\n",
            "Epoch 20: val_balanced_acc did not improve from 0.46312\n",
            "156/156 [==============================] - 1s 3ms/step - loss: 0.2032 - accuracy: 0.9409 - balanced_acc: 0.9390 - val_loss: 0.6606 - val_accuracy: 0.7565 - val_balanced_acc: 0.4151 - lr: 0.0010\n",
            "Epoch 21/50\n",
            "144/156 [==========================>...] - ETA: 0s - loss: 0.1987 - accuracy: 0.9410 - balanced_acc: 0.9373\n",
            "Epoch 21: val_balanced_acc did not improve from 0.46312\n",
            "156/156 [==============================] - 1s 3ms/step - loss: 0.1991 - accuracy: 0.9415 - balanced_acc: 0.9379 - val_loss: 0.7158 - val_accuracy: 0.7513 - val_balanced_acc: 0.4173 - lr: 0.0010\n",
            "Epoch 22/50\n",
            "146/156 [===========================>..] - ETA: 0s - loss: 0.1941 - accuracy: 0.9443 - balanced_acc: 0.9418\n",
            "Epoch 22: val_balanced_acc did not improve from 0.46312\n",
            "156/156 [==============================] - 1s 3ms/step - loss: 0.1933 - accuracy: 0.9444 - balanced_acc: 0.9421 - val_loss: 0.7183 - val_accuracy: 0.7409 - val_balanced_acc: 0.4561 - lr: 0.0010\n",
            "Epoch 23/50\n",
            "142/156 [==========================>...] - ETA: 0s - loss: 0.1896 - accuracy: 0.9484 - balanced_acc: 0.9475\n",
            "Epoch 23: val_balanced_acc did not improve from 0.46312\n",
            "156/156 [==============================] - 1s 3ms/step - loss: 0.1873 - accuracy: 0.9498 - balanced_acc: 0.9489 - val_loss: 0.6852 - val_accuracy: 0.7513 - val_balanced_acc: 0.4239 - lr: 0.0010\n",
            "Epoch 24/50\n",
            "143/156 [==========================>...] - ETA: 0s - loss: 0.1883 - accuracy: 0.9474 - balanced_acc: 0.9451\n",
            "Epoch 24: val_balanced_acc did not improve from 0.46312\n",
            "156/156 [==============================] - 1s 3ms/step - loss: 0.1875 - accuracy: 0.9482 - balanced_acc: 0.9459 - val_loss: 0.6669 - val_accuracy: 0.7617 - val_balanced_acc: 0.4225 - lr: 0.0010\n",
            "Epoch 25/50\n",
            "145/156 [==========================>...] - ETA: 0s - loss: 0.1822 - accuracy: 0.9491 - balanced_acc: 0.9462\n",
            "Epoch 25: val_balanced_acc did not improve from 0.46312\n",
            "156/156 [==============================] - 1s 3ms/step - loss: 0.1808 - accuracy: 0.9495 - balanced_acc: 0.9464 - val_loss: 0.6831 - val_accuracy: 0.7565 - val_balanced_acc: 0.4214 - lr: 0.0010\n",
            "Epoch 26/50\n",
            "141/156 [==========================>...] - ETA: 0s - loss: 0.1805 - accuracy: 0.9500 - balanced_acc: 0.9476\n",
            "Epoch 26: val_balanced_acc did not improve from 0.46312\n",
            "156/156 [==============================] - 1s 3ms/step - loss: 0.1815 - accuracy: 0.9497 - balanced_acc: 0.9475 - val_loss: 0.6915 - val_accuracy: 0.7461 - val_balanced_acc: 0.3955 - lr: 0.0010\n",
            "Epoch 27/50\n",
            "145/156 [==========================>...] - ETA: 0s - loss: 0.1762 - accuracy: 0.9516 - balanced_acc: 0.9482\n",
            "Epoch 27: val_balanced_acc did not improve from 0.46312\n",
            "156/156 [==============================] - 1s 3ms/step - loss: 0.1756 - accuracy: 0.9519 - balanced_acc: 0.9491 - val_loss: 0.6899 - val_accuracy: 0.7565 - val_balanced_acc: 0.4205 - lr: 0.0010\n",
            "Epoch 28/50\n",
            "144/156 [==========================>...] - ETA: 0s - loss: 0.1723 - accuracy: 0.9520 - balanced_acc: 0.9467\n",
            "Epoch 28: val_balanced_acc did not improve from 0.46312\n",
            "156/156 [==============================] - 1s 3ms/step - loss: 0.1720 - accuracy: 0.9524 - balanced_acc: 0.9477 - val_loss: 0.6772 - val_accuracy: 0.7668 - val_balanced_acc: 0.4315 - lr: 0.0010\n",
            "Epoch 29/50\n",
            "154/156 [============================>.] - ETA: 0s - loss: 0.1681 - accuracy: 0.9533 - balanced_acc: 0.9501\n",
            "Epoch 29: val_balanced_acc did not improve from 0.46312\n",
            "156/156 [==============================] - 1s 4ms/step - loss: 0.1691 - accuracy: 0.9530 - balanced_acc: 0.9498 - val_loss: 0.6537 - val_accuracy: 0.7565 - val_balanced_acc: 0.4154 - lr: 0.0010\n",
            "Epoch 30/50\n",
            "144/156 [==========================>...] - ETA: 0s - loss: 0.1652 - accuracy: 0.9552 - balanced_acc: 0.9526\n",
            "Epoch 30: val_balanced_acc did not improve from 0.46312\n",
            "156/156 [==============================] - 1s 3ms/step - loss: 0.1673 - accuracy: 0.9541 - balanced_acc: 0.9520 - val_loss: 0.6963 - val_accuracy: 0.7617 - val_balanced_acc: 0.4271 - lr: 0.0010\n",
            "Epoch 31/50\n",
            "145/156 [==========================>...] - ETA: 0s - loss: 0.1615 - accuracy: 0.9567 - balanced_acc: 0.9526\n",
            "Epoch 31: val_balanced_acc did not improve from 0.46312\n",
            "156/156 [==============================] - 1s 3ms/step - loss: 0.1616 - accuracy: 0.9566 - balanced_acc: 0.9528 - val_loss: 0.6431 - val_accuracy: 0.7668 - val_balanced_acc: 0.4197 - lr: 0.0010\n",
            "Epoch 32/50\n",
            "142/156 [==========================>...] - ETA: 0s - loss: 0.1595 - accuracy: 0.9564 - balanced_acc: 0.9530\n",
            "Epoch 32: val_balanced_acc did not improve from 0.46312\n",
            "156/156 [==============================] - 1s 3ms/step - loss: 0.1601 - accuracy: 0.9563 - balanced_acc: 0.9531 - val_loss: 0.6407 - val_accuracy: 0.7565 - val_balanced_acc: 0.4211 - lr: 0.0010\n",
            "Epoch 33/50\n",
            "143/156 [==========================>...] - ETA: 0s - loss: 0.1588 - accuracy: 0.9580 - balanced_acc: 0.9543\n",
            "Epoch 33: val_balanced_acc did not improve from 0.46312\n",
            "156/156 [==============================] - 1s 3ms/step - loss: 0.1600 - accuracy: 0.9578 - balanced_acc: 0.9544 - val_loss: 0.6802 - val_accuracy: 0.7565 - val_balanced_acc: 0.4199 - lr: 0.0010\n",
            "Epoch 34/50\n",
            "143/156 [==========================>...] - ETA: 0s - loss: 0.1540 - accuracy: 0.9602 - balanced_acc: 0.9573\n",
            "Epoch 34: val_balanced_acc did not improve from 0.46312\n",
            "156/156 [==============================] - 1s 3ms/step - loss: 0.1527 - accuracy: 0.9606 - balanced_acc: 0.9577 - val_loss: 0.7330 - val_accuracy: 0.7461 - val_balanced_acc: 0.4260 - lr: 0.0010\n",
            "Epoch 35/50\n",
            "142/156 [==========================>...] - ETA: 0s - loss: 0.1524 - accuracy: 0.9599 - balanced_acc: 0.9568\n",
            "Epoch 35: val_balanced_acc did not improve from 0.46312\n",
            "156/156 [==============================] - 1s 3ms/step - loss: 0.1535 - accuracy: 0.9593 - balanced_acc: 0.9565 - val_loss: 0.6659 - val_accuracy: 0.7617 - val_balanced_acc: 0.4193 - lr: 0.0010\n",
            "Epoch 36/50\n",
            "141/156 [==========================>...] - ETA: 0s - loss: 0.1563 - accuracy: 0.9592 - balanced_acc: 0.9549\n",
            "Epoch 36: val_balanced_acc did not improve from 0.46312\n",
            "156/156 [==============================] - 1s 3ms/step - loss: 0.1552 - accuracy: 0.9599 - balanced_acc: 0.9559 - val_loss: 0.6999 - val_accuracy: 0.7513 - val_balanced_acc: 0.4184 - lr: 0.0010\n",
            "Epoch 37/50\n",
            "144/156 [==========================>...] - ETA: 0s - loss: 0.1438 - accuracy: 0.9634 - balanced_acc: 0.9574\n",
            "Epoch 37: val_balanced_acc did not improve from 0.46312\n",
            "156/156 [==============================] - 1s 3ms/step - loss: 0.1435 - accuracy: 0.9633 - balanced_acc: 0.9578 - val_loss: 0.6781 - val_accuracy: 0.7617 - val_balanced_acc: 0.4318 - lr: 0.0010\n",
            "Epoch 38/50\n",
            "144/156 [==========================>...] - ETA: 0s - loss: 0.1485 - accuracy: 0.9625 - balanced_acc: 0.9597\n",
            "Epoch 38: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "\n",
            "Epoch 38: val_balanced_acc did not improve from 0.46312\n",
            "156/156 [==============================] - 1s 3ms/step - loss: 0.1475 - accuracy: 0.9626 - balanced_acc: 0.9601 - val_loss: 0.6438 - val_accuracy: 0.7668 - val_balanced_acc: 0.4279 - lr: 0.0010\n",
            "Epoch 39/50\n",
            "142/156 [==========================>...] - ETA: 0s - loss: 0.1377 - accuracy: 0.9659 - balanced_acc: 0.9649\n",
            "Epoch 39: val_balanced_acc did not improve from 0.46312\n",
            "156/156 [==============================] - 1s 3ms/step - loss: 0.1372 - accuracy: 0.9660 - balanced_acc: 0.9652 - val_loss: 0.6817 - val_accuracy: 0.7617 - val_balanced_acc: 0.4318 - lr: 5.0000e-04\n",
            "Epoch 40/50\n",
            "143/156 [==========================>...] - ETA: 0s - loss: 0.1378 - accuracy: 0.9672 - balanced_acc: 0.9644\n",
            "Epoch 40: val_balanced_acc did not improve from 0.46312\n",
            "156/156 [==============================] - 1s 3ms/step - loss: 0.1380 - accuracy: 0.9665 - balanced_acc: 0.9640 - val_loss: 0.7267 - val_accuracy: 0.7513 - val_balanced_acc: 0.4269 - lr: 5.0000e-04\n",
            "Epoch 41/50\n",
            "141/156 [==========================>...] - ETA: 0s - loss: 0.1341 - accuracy: 0.9698 - balanced_acc: 0.9659\n",
            "Epoch 41: val_balanced_acc did not improve from 0.46312\n",
            "156/156 [==============================] - 1s 4ms/step - loss: 0.1364 - accuracy: 0.9685 - balanced_acc: 0.9651 - val_loss: 0.7219 - val_accuracy: 0.7565 - val_balanced_acc: 0.4340 - lr: 5.0000e-04\n",
            "Epoch 42/50\n",
            "151/156 [============================>.] - ETA: 0s - loss: 0.1360 - accuracy: 0.9672 - balanced_acc: 0.9633\n",
            "Epoch 42: val_balanced_acc did not improve from 0.46312\n",
            "156/156 [==============================] - 1s 4ms/step - loss: 0.1355 - accuracy: 0.9676 - balanced_acc: 0.9637 - val_loss: 0.7055 - val_accuracy: 0.7565 - val_balanced_acc: 0.4307 - lr: 5.0000e-04\n",
            "Epoch 43/50\n",
            "142/156 [==========================>...] - ETA: 0s - loss: 0.1388 - accuracy: 0.9671 - balanced_acc: 0.9639\n",
            "Epoch 43: val_balanced_acc did not improve from 0.46312\n",
            "156/156 [==============================] - 1s 3ms/step - loss: 0.1370 - accuracy: 0.9679 - balanced_acc: 0.9651 - val_loss: 0.6786 - val_accuracy: 0.7668 - val_balanced_acc: 0.4279 - lr: 5.0000e-04\n",
            "Epoch 44/50\n",
            "143/156 [==========================>...] - ETA: 0s - loss: 0.1312 - accuracy: 0.9698 - balanced_acc: 0.9651\n",
            "Epoch 44: val_balanced_acc did not improve from 0.46312\n",
            "156/156 [==============================] - 1s 3ms/step - loss: 0.1307 - accuracy: 0.9699 - balanced_acc: 0.9659 - val_loss: 0.6860 - val_accuracy: 0.7668 - val_balanced_acc: 0.4360 - lr: 5.0000e-04\n",
            "Epoch 45/50\n",
            "154/156 [============================>.] - ETA: 0s - loss: 0.1339 - accuracy: 0.9676 - balanced_acc: 0.9647\n",
            "Epoch 45: val_balanced_acc did not improve from 0.46312\n",
            "156/156 [==============================] - 1s 4ms/step - loss: 0.1346 - accuracy: 0.9677 - balanced_acc: 0.9648 - val_loss: 0.6957 - val_accuracy: 0.7565 - val_balanced_acc: 0.4277 - lr: 5.0000e-04\n",
            "Epoch 46/50\n",
            "143/156 [==========================>...] - ETA: 0s - loss: 0.1300 - accuracy: 0.9692 - balanced_acc: 0.9671\n",
            "Epoch 46: val_balanced_acc did not improve from 0.46312\n",
            "156/156 [==============================] - 1s 3ms/step - loss: 0.1316 - accuracy: 0.9689 - balanced_acc: 0.9666 - val_loss: 0.6940 - val_accuracy: 0.7668 - val_balanced_acc: 0.4360 - lr: 5.0000e-04\n",
            "Epoch 47/50\n",
            "145/156 [==========================>...] - ETA: 0s - loss: 0.1289 - accuracy: 0.9720 - balanced_acc: 0.9673\n",
            "Epoch 47: val_balanced_acc did not improve from 0.46312\n",
            "156/156 [==============================] - 1s 3ms/step - loss: 0.1296 - accuracy: 0.9713 - balanced_acc: 0.9663 - val_loss: 0.6926 - val_accuracy: 0.7617 - val_balanced_acc: 0.4271 - lr: 5.0000e-04\n",
            "Epoch 48/50\n",
            "144/156 [==========================>...] - ETA: 0s - loss: 0.1280 - accuracy: 0.9719 - balanced_acc: 0.9697\n",
            "Epoch 48: val_balanced_acc did not improve from 0.46312\n",
            "156/156 [==============================] - 1s 3ms/step - loss: 0.1306 - accuracy: 0.9709 - balanced_acc: 0.9693 - val_loss: 0.7107 - val_accuracy: 0.7513 - val_balanced_acc: 0.4251 - lr: 5.0000e-04\n",
            "Epoch 49/50\n",
            "143/156 [==========================>...] - ETA: 0s - loss: 0.1296 - accuracy: 0.9705 - balanced_acc: 0.9673\n",
            "Epoch 49: val_balanced_acc did not improve from 0.46312\n",
            "156/156 [==============================] - 1s 3ms/step - loss: 0.1295 - accuracy: 0.9707 - balanced_acc: 0.9677 - val_loss: 0.7301 - val_accuracy: 0.7409 - val_balanced_acc: 0.4171 - lr: 5.0000e-04\n",
            "Epoch 50/50\n",
            "142/156 [==========================>...] - ETA: 0s - loss: 0.1249 - accuracy: 0.9724 - balanced_acc: 0.9694\n",
            "Epoch 50: val_balanced_acc did not improve from 0.46312\n",
            "156/156 [==============================] - 1s 3ms/step - loss: 0.1254 - accuracy: 0.9724 - balanced_acc: 0.9696 - val_loss: 0.6951 - val_accuracy: 0.7668 - val_balanced_acc: 0.4360 - lr: 5.0000e-04\n"
          ]
        }
      ],
      "source": [
        "best_model_fpath = '/content/drive/MyDrive/PHD/Model/best_model_'+exp_name+'_'+dataset_name+'.h5'\n",
        "print(\"best_model_fpath:\"+best_model_fpath)\n",
        "last_model_fpath = '/content/drive/MyDrive/PHD/Model/last_model_'+exp_name+'_'+dataset_name+'.h5'\n",
        "print(\"last_model_fpath:\"+last_model_fpath)\n",
        "mc1 = ModelCheckpoint(best_model_fpath, monitor='val_balanced_acc', mode='max', verbose=1, save_best_only=True)\n",
        "learning_rate_reduction = ReduceLROnPlateau(monitor='val_balanced_acc', patience=20, verbose=1, factor=0.5, min_lr=0.00001)\n",
        "early_stopping_monitor = EarlyStopping(patience=40,monitor='val_balanced_acc')\n",
        "model2.compile(optimizer = opt_SGD , loss = \"categorical_crossentropy\", metrics=['accuracy', balanced_acc])\n",
        "hst = model2.fit(X_train_fm_ov, y_train_ov, epochs=EPOCHS, batch_size=BATCH_SIZE, validation_data=(X_val_fm, y_val), verbose=1,\n",
        "                    steps_per_epoch=X_train_fm_ov.shape[0] // BATCH_SIZE, \n",
        "                    #callbacks=[learning_rate_reduction,early_stopping_monitor, mc1])\n",
        "                    callbacks=[learning_rate_reduction,mc1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "8XhlbWn--8Or",
        "outputId": "69127b4a-c638-4449-a068-fd80494a4008"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# summarize history for accuracy\n",
        "plt.plot(hst.history['accuracy'])\n",
        "plt.plot(hst.history['balanced_acc'])\n",
        "plt.plot(hst.history['val_accuracy'])\n",
        "plt.plot(hst.history['val_balanced_acc'])\n",
        "plt.title('Model accuracy')\n",
        "plt.ylabel('Performance')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train accuracy', 'train balanced acc.', 'val. accuracy', 'val. balanced acc.'], loc='lower right')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u-x0SENPGmm9"
      },
      "outputs": [],
      "source": [
        "#save last model\n",
        "model2.save(last_model_fpath)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U-e3ZaeeG1Bf",
        "outputId": "43185207-f891-4f63-85ec-9a590e61815f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 0s 1ms/step\n",
            "7/7 [==============================] - 0s 2ms/step\n",
            "accuracy on training 0.9733653749874838\n",
            "balanced accuracy on training 0.9736294240111035\n",
            "accuracy on validation 0.7668393782383419\n",
            "balanced accuracy on validation 0.5717909558501892\n",
            "Score on val data:  (0.5185897435897436, 0.5717909558501892, 0.5377159543062507, None)\n"
          ]
        }
      ],
      "source": [
        "last_model = load_model(last_model_fpath, custom_objects={'balanced_acc' : balanced_acc})\n",
        "y_train_pred = last_model.predict(X_train_fm_ov)\n",
        "y_val_pred = last_model.predict(X_val_fm)\n",
        "\n",
        "#print('accuracy on training',accuracy_score(np.argmax(y_train, axis=1), np.argmax(y_train_pred, axis=1)))\n",
        "print('accuracy on training',accuracy_score(np.argmax(y_train_ov, axis=1), np.argmax(y_train_pred, axis=1)))\n",
        "print('balanced accuracy on training',balanced_accuracy_score(np.argmax(y_train_ov, axis=1), np.argmax(y_train_pred, axis=1)))\n",
        "print('accuracy on validation',accuracy_score(np.argmax(y_val, axis=1), np.argmax(y_val_pred, axis=1)))\n",
        "print('balanced accuracy on validation',balanced_accuracy_score(np.argmax(y_val, axis=1), np.argmax(y_val_pred, axis=1)))\n",
        "print('Score on val data: ',precision_recall_fscore_support(np.argmax(y_val, axis=1), np.argmax(y_val_pred, axis=1), average='macro'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EQ3baQLsHLat",
        "outputId": "71206047-eb2f-4c68-fc42-a6301a8a48c7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 0s 1ms/step\n",
            "7/7 [==============================] - 0s 2ms/step\n",
            "accuracy on training 0.9419245018524082\n",
            "balanced accuracy on training 0.9424854622354494\n",
            "accuracy on validation 0.7616580310880829\n",
            "balanced accuracy on validation 0.6986307826900162\n",
            "Score on val data:  (0.5416475972540045, 0.6986307826900162, 0.5756277857054772, None)\n"
          ]
        }
      ],
      "source": [
        "best_model = load_model(best_model_fpath, custom_objects={'balanced_acc' : balanced_acc})\n",
        "y_train_pred = best_model.predict(X_train_fm_ov)\n",
        "y_val_pred = best_model.predict(X_val_fm)\n",
        "\n",
        "print('accuracy on training',accuracy_score(np.argmax(y_train_ov, axis=1), np.argmax(y_train_pred, axis=1)))\n",
        "print('balanced accuracy on training',balanced_accuracy_score(np.argmax(y_train_ov, axis=1), np.argmax(y_train_pred, axis=1)))\n",
        "print('accuracy on validation',accuracy_score(np.argmax(y_val, axis=1), np.argmax(y_val_pred, axis=1)))\n",
        "print('balanced accuracy on validation',balanced_accuracy_score(np.argmax(y_val, axis=1), np.argmax(y_val_pred, axis=1)))\n",
        "print('Score on val data: ',precision_recall_fscore_support(np.argmax(y_val, axis=1), np.argmax(y_val_pred, axis=1), average='macro'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RcRGeofw-8tK"
      },
      "source": [
        "#Load ISIC 2018 Challange Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l3P7IjyLuZGY"
      },
      "outputs": [],
      "source": [
        "X_train, y_train, X_val, y_val = load_isic2018_dataset(train_under_frac = train_under_frac)\n",
        "print(X_train.shape)\n",
        "print(y_train.shape)\n",
        "print(X_val.shape)\n",
        "print(y_val.shape)\n",
        "print('Counter train data: ', Counter(np.argmax(y_train, axis=1)))\n",
        "print('Counter val data: ', Counter(np.argmax(y_val, axis=1)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XT95XFaHQD6d"
      },
      "outputs": [],
      "source": [
        "X_train = preprocess_image_input(X_train, the_arch)\n",
        "X_val = preprocess_image_input(X_val, the_arch)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "APHFdj25vatJ"
      },
      "outputs": [],
      "source": [
        "path = '/content/drive/MyDrive/PHD/Datasets/isic2018/'\n",
        "df1 = pd.DataFrame(X_train.reshape(X_train.shape[0],-1))\n",
        "df1['y_train'] = np.argmax(y_train, axis=1).tolist()\n",
        "df2 = pd.DataFrame(X_val.reshape(X_val.shape[0],-1))\n",
        "df2['y_val'] = np.argmax(y_val, axis=1).tolist()\n",
        "df1.to_pickle(path+\"isic2018_train_\"+dataset_name+\".pkl\")\n",
        "df2.to_pickle(path+\"isic2018_val_\"+dataset_name+\".pkl\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NMEfVJy052YF",
        "outputId": "c9642a12-986c-40c8-cd08-7a3d23ae1736"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "dataset saved: under80_128px\n"
          ]
        }
      ],
      "source": [
        "print(\"dataset saved:\", dataset_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2IncA-_o_n5w"
      },
      "outputs": [],
      "source": [
        "# ordered count of rows per unique label\n",
        "labels_count = y_train.value_counts(ascending=True)\n",
        "\n",
        "f = plt.figure(figsize=(15, 6))\n",
        "s = sns.barplot(x=labels_count.index,y=labels_count.values)\n",
        "s.set_xticklabels(s.get_xticklabels(), rotation = 30)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AnKMKSb4Bkym"
      },
      "source": [
        "Plot 3 images per label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jdnVuqbFBW3K"
      },
      "outputs": [],
      "source": [
        "def plot_images_per_label(df, label, cols: int, size: tuple):\n",
        "    fig, axs = plt.subplots(nrows=1, ncols=cols, figsize=size)\n",
        "\n",
        "    cntMax = cols\n",
        "    cntCur = 0\n",
        "    for index, row in df.iterrows():\n",
        "        if(y_train == label and cntCur < cntMax):\n",
        "            axs[cntCur].imshow(plt.imread(df.FilePaths[index]))\n",
        "            axs[cntCur].set_title(df.Labels[index])\n",
        "\n",
        "            cntCur += 1\n",
        "        else:\n",
        "            if(cntCur >= cntMax):\n",
        "                break\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "# unique labels\n",
        "labels = sorted(df1['y_train'].unique())\n",
        "for label in range(7):\n",
        "    plot_images_per_label(df1, label, 3, (12,9))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "asV1O58Lrq-R"
      },
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "img = Image.fromarray(X_train[0], 'RGB')\n",
        "display(img)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qRKKrNacAZtl"
      },
      "source": [
        "Drop duplicate images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ERwfyPDHP-zC"
      },
      "outputs": [],
      "source": [
        "#df_group = pd.read_csv('/content/drive/MyDrive/PHD/Datasets/isic2018/ISIC2018_Task3_Training_LesionGroupings.csv') \n",
        "#df_train = df_train.set_index('image').join(df_group.set_index('image'))\n",
        "#df_train = df_train.drop_duplicates(subset=['lesion_id'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cNBXx28B9yGu"
      },
      "source": [
        "#DeepSMOTE Oversampling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YmX_Uqbmj-tN"
      },
      "outputs": [],
      "source": [
        "from numpy import moveaxis\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "max_el = np.inf\n",
        "\n",
        "args = {}\n",
        "args['dim_h'] = 64         # factor controlling size of hidden layers\n",
        "args['n_channel'] = 3#1    # number of channels in the input data \n",
        "args['n_z'] = 600 #300     # number of dimensions in latent space. \n",
        "args['sigma'] = 1.0        # variance in n_z\n",
        "args['lambda'] = 0.01      # hyper param for weight of discriminator loss\n",
        "args['lr'] = 0.0002        # learning rate for Adam optimizer .000\n",
        "args['epochs'] = 300       # how many epochs to run for\n",
        "args['batch_size'] = 100   # batch size for SGD\n",
        "args['save'] = True        # save weights at each epoch of training if True\n",
        "args['train'] = True       # train networks if True, else load networks from\n",
        "args['patience'] = 20"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NydOdPMajEfT"
      },
      "outputs": [],
      "source": [
        "class Encoder(nn.Module):\n",
        "    def __init__(self, args):\n",
        "        super(Encoder, self).__init__()\n",
        "\n",
        "        self.n_channel = args['n_channel']\n",
        "        self.dim_h = args['dim_h']\n",
        "        self.n_z = args['n_z']\n",
        "        \n",
        "        # convolutional filters, work excellent with image data\n",
        "        # [(WK+2P)/S]+1\n",
        "        self.conv = nn.Sequential(\n",
        "            nn.AvgPool2d(7, stride=7),\n",
        "            nn.Conv2d(self.n_channel, self.dim_h, 4, 2, 1, bias=False),# 16\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Conv2d(self.dim_h, self.dim_h * 2, 4, 2, 1, bias=False), # 8\n",
        "            nn.BatchNorm2d(self.dim_h * 2),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Conv2d(self.dim_h * 2, self.dim_h * 4, 4, 2, 1, bias=False),# 4\n",
        "            nn.BatchNorm2d(self.dim_h * 4),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Conv2d(self.dim_h * 4, self.dim_h * 8, 4, 2, 0, bias=False),#14\n",
        "            nn.BatchNorm2d(self.dim_h * 8),\n",
        "            nn.LeakyReLU(0.2, inplace=True))\n",
        "        self.fc = nn.Linear(self.dim_h * (2 ** 3), self.n_z)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv(x)\n",
        "        \n",
        "        x = x.squeeze()\n",
        "        x = self.fc(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self, args):\n",
        "        super(Decoder, self).__init__()\n",
        "\n",
        "        self.n_channel = args['n_channel']\n",
        "        self.dim_h = args['dim_h']\n",
        "        self.n_z = args['n_z']\n",
        "\n",
        "        # first layer is fully connected\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(self.n_z, self.dim_h * 2**3 * 7 * 7),\n",
        "            nn.ReLU())\n",
        "\n",
        "        # deconvolutional filters, essentially inverse of convolutional filters\n",
        "        # H_out = (H_in1)*stride[0]  2padding[0] + dilation[0](kernel_size[0]1) + output_padding[0] + 1\n",
        "        self.deconv = nn.Sequential(\n",
        "            nn.ConvTranspose2d(self.dim_h * 8, self.dim_h * 4, 4), #10\n",
        "            nn.BatchNorm2d(self.dim_h * 4),\n",
        "            nn.ReLU(True),\n",
        "            nn.ConvTranspose2d(self.dim_h * 4, self.dim_h * 2, 4), #13\n",
        "            nn.BatchNorm2d(self.dim_h * 2),\n",
        "            nn.ReLU(True),\n",
        "            nn.ConvTranspose2d(self.dim_h * 2, self.dim_h, 4),# 16\n",
        "            nn.BatchNorm2d(self.dim_h),\n",
        "            nn.ReLU(True),\n",
        "            nn.ConvTranspose2d(self.dim_h, 3, 4, 2, 1),# 32\n",
        "            nn.UpsamplingBilinear2d(scale_factor=7),\n",
        "            nn.Tanh())\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.fc(x)\n",
        "        x = x.view(-1, self.dim_h * 2**3, 7, 7)\n",
        "        x = self.deconv(x)\n",
        "        return x\n",
        "\n",
        "##############################################################################\n",
        "\"\"\"set models, loss functions\"\"\"\n",
        "# control which parameters are frozen / free for optimization\n",
        "def free_params(module: nn.Module):\n",
        "    for p in module.parameters():\n",
        "        p.requires_grad = True\n",
        "\n",
        "def frozen_params(module: nn.Module):\n",
        "    for p in module.parameters():\n",
        "        p.requires_grad = False\n",
        "\n",
        "def biased_get_class(X, y, c):\n",
        "    \n",
        "    xbeg = X[y == c]\n",
        "    ybeg = y[y == c]\n",
        "    \n",
        "    return xbeg, ybeg\n",
        "    #return xclass, yclass\n",
        "\n",
        "def G_SM(X, y,n_to_sample,cl):\n",
        "    n_neigh = 5\n",
        "    nn = NearestNeighbors(n_neighbors=n_neigh, n_jobs=1)\n",
        "    nn.fit(X)\n",
        "    dist, ind = nn.kneighbors(X)\n",
        "\n",
        "    # generating samples\n",
        "    base_indices = np.random.choice(list(range(len(X))),n_to_sample)\n",
        "    neighbor_indices = np.random.choice(list(range(1, n_neigh)),n_to_sample)\n",
        "\n",
        "    X_base = X[base_indices]\n",
        "    X_neighbor = X[ind[base_indices, neighbor_indices]]\n",
        "\n",
        "    samples = X_base + np.multiply(np.random.rand(n_to_sample,1),\n",
        "            X_neighbor - X_base)\n",
        "\n",
        "    #use 10 as label because 0 to 9 real classes and 1 fake/smoted = 10\n",
        "    return samples, [cl]*n_to_sample\n",
        "\n",
        "def DeepSMOTE_train(X_train, y_train, one_hot = False):\n",
        "  from torch.utils.data import TensorDataset\n",
        "  import os\n",
        "\n",
        "  max_el = np.max(X_train)\n",
        "  X_train = X_train / max_el\n",
        "  X_train = moveaxis(X_train, 3, 1)\n",
        "  if one_hot:\n",
        "    y_train = np.argmax(y_train, axis=1)\n",
        "  #X_train = X_train.astype('float32') / 255.\n",
        "  \n",
        "  batch_size = args['batch_size']\n",
        "  patience = args['patience']\n",
        "  encoder = Encoder(args)\n",
        "  decoder = Decoder(args)\n",
        "\n",
        "  device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "  print(device)\n",
        "  decoder = decoder.to(device)\n",
        "  encoder = encoder.to(device)\n",
        "\n",
        "  train_on_gpu = torch.cuda.is_available()\n",
        "\n",
        "  #decoder loss function\n",
        "  criterion = nn.MSELoss()\n",
        "  criterion = criterion.to(device)\n",
        "\n",
        "  num_workers = 0\n",
        "\n",
        "  #torch.Tensor returns float so if want long then use torch.tensor\n",
        "  tensor_x = torch.from_numpy(X_train.copy())#torch.Tensor(X_train)\n",
        "  tensor_y = torch.tensor(y_train,dtype=torch.long)\n",
        "  mnist_bal = TensorDataset(tensor_x,tensor_y) \n",
        "  train_loader = torch.utils.data.DataLoader(mnist_bal, \n",
        "      batch_size=batch_size,shuffle=True,num_workers=num_workers)\n",
        "\n",
        "  best_loss = np.inf\n",
        "\n",
        "  enc_optim = torch.optim.Adam(encoder.parameters(), lr = args['lr'])\n",
        "  dec_optim = torch.optim.Adam(decoder.parameters(), lr = args['lr'])\n",
        "\n",
        "  for epoch in range(args['epochs']):\n",
        "      train_loss = 0.0\n",
        "      tmse_loss = 0.0\n",
        "      tdiscr_loss = 0.0\n",
        "      # train for one epoch -- set nets to train mode\n",
        "      encoder.train()\n",
        "      decoder.train()\n",
        "  \n",
        "      for images,labs in train_loader:\n",
        "      \n",
        "          # zero gradients for each batch\n",
        "          encoder.zero_grad()\n",
        "          decoder.zero_grad()\n",
        "          images, labs = images.to(device), labs.to(device)\n",
        "          labsn = labs.detach().cpu().numpy()\n",
        "#            print('images shape', images.shape)\n",
        "          # run images\n",
        "          z_hat = encoder(images)\n",
        "#            print('images shape after encoding', z_hat.shape)\n",
        "      \n",
        "          x_hat = decoder(z_hat) #decoder outputs tanh\n",
        "#            print('images shape after decoding', x_hat.shape)\n",
        "          mse = criterion(x_hat,images)\n",
        "                  \n",
        "          resx = []\n",
        "          resy = []\n",
        "      \n",
        "          tc = np.random.choice(num_classes,1)\n",
        "          #tc = 9\n",
        "          xbeg = X_train[y_train == tc]\n",
        "          ybeg = y_train[y_train == tc] \n",
        "          xlen = len(xbeg)\n",
        "          nsamp = min(xlen, 100)\n",
        "          ind = np.random.choice(list(range(len(xbeg))),nsamp,replace=False)\n",
        "          xclass = xbeg[ind]\n",
        "          yclass = ybeg[ind]\n",
        "      \n",
        "          xclen = len(xclass)\n",
        "          xcminus = np.arange(1,xclen)\n",
        "          \n",
        "          xcplus = np.append(xcminus,0)\n",
        "          xcnew = (xclass[[xcplus],:])\n",
        "          xcnew = xcnew.reshape(xcnew.shape[1],xcnew.shape[2],xcnew.shape[3],xcnew.shape[4])\n",
        "      \n",
        "          xcnew = torch.Tensor(xcnew)\n",
        "          xcnew = xcnew.to(device)\n",
        "      \n",
        "          #encode xclass to feature space\n",
        "          xclass = torch.Tensor(xclass)\n",
        "          xclass = xclass.to(device)\n",
        "          xclass = encoder(xclass)\n",
        "      \n",
        "          xclass = xclass.detach().cpu().numpy()\n",
        "      \n",
        "          xc_enc = (xclass[[xcplus],:])\n",
        "          xc_enc = np.squeeze(xc_enc)\n",
        "      \n",
        "          xc_enc = torch.Tensor(xc_enc)\n",
        "          xc_enc = xc_enc.to(device)\n",
        "          \n",
        "          ximg = decoder(xc_enc)\n",
        "          \n",
        "          mse2 = criterion(ximg,xcnew)\n",
        "      \n",
        "          comb_loss = mse2 + mse\n",
        "          comb_loss.backward()\n",
        "      \n",
        "          enc_optim.step()\n",
        "          dec_optim.step()\n",
        "      \n",
        "          train_loss += comb_loss.item()*images.size(0)\n",
        "          tmse_loss += mse.item()*images.size(0)\n",
        "          tdiscr_loss += mse2.item()*images.size(0)\n",
        "\n",
        "      train_loss = train_loss/len(train_loader)\n",
        "      tmse_loss = tmse_loss/len(train_loader)\n",
        "      tdiscr_loss = tdiscr_loss/len(train_loader)\n",
        "      print('Epoch: {} \\tTrain Loss: {:.6f} \\tmse loss: {:.6f} \\tmse2 loss: {:.6f}'.format(epoch,\n",
        "              train_loss,tmse_loss,tdiscr_loss))\n",
        "      \n",
        "  \n",
        "  \n",
        "      #store the best encoder and decoder models\n",
        "      #here, /crs5 is a reference to 5 way cross validation, but is not\n",
        "      #necessary for illustration purposes\n",
        "      if train_loss < best_loss:\n",
        "          print('Saving..')\n",
        "          patience = args['patience']\n",
        "          path_enc = '/content/drive/MyDrive/PHD/Model/DeepSMOTE/32/bst_enc.pth'\n",
        "          path_dec = '/content/drive/MyDrive/PHD/Model/DeepSMOTE/32/bst_dec.pth'\n",
        "        \n",
        "          torch.save(encoder.state_dict(), path_enc)\n",
        "          torch.save(decoder.state_dict(), path_dec)\n",
        "  \n",
        "          best_loss = train_loss\n",
        "      else:\n",
        "          patience = patience - 1\n",
        "\n",
        "      if patience == 0:\n",
        "          print('Out of patience. \\n')\n",
        "          break\n",
        "\n",
        "def DeepSMOTE_Data(X_train, y_train, one_hot = False):\n",
        "  batch_size = args['batch_size']\n",
        "  max_el = np.max(X_train)\n",
        "  X_train = X_train / max_el\n",
        "  X_train = moveaxis(X_train, 3, 1)\n",
        "  if one_hot:\n",
        "    y_train = np.argmax(y_train, axis=1)\n",
        "  #Generate artificial images\n",
        "  import torch\n",
        "  np.printoptions(precision=5,suppress=True)\n",
        "\n",
        "  #path on the computer where the models are stored\n",
        "  modpth = '/content/drive/MyDrive/PHD/Model/DeepSMOTE/32/'\n",
        "\n",
        "  path_enc = modpth + '/bst_enc.pth'\n",
        "  path_dec = modpth + '/bst_dec.pth'\n",
        "  \n",
        "  train_on_gpu = torch.cuda.is_available()\n",
        "  device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "  encoder = Encoder(args)\n",
        "  encoder.load_state_dict(torch.load(path_enc), strict=False)\n",
        "  encoder = encoder.to(device)\n",
        "\n",
        "  decoder = Decoder(args)\n",
        "  decoder.load_state_dict(torch.load(path_dec), strict=False)\n",
        "  decoder = decoder.to(device)\n",
        "\n",
        "  encoder.eval()\n",
        "  decoder.eval()\n",
        "\n",
        "  resx = []\n",
        "  resy = []\n",
        "  \n",
        "  counter = Counter(y_train)\n",
        "  counter = sorted(counter.items())\n",
        "  counter = [value for _, value in counter]\n",
        "\n",
        "  for i in range(num_classes):\n",
        "      torch.cuda.empty_cache()\n",
        "\n",
        "      xclass, yclass = biased_get_class(X_train, y_train, i)\n",
        "      #encode xclass to feature space\n",
        "      xclass = torch.Tensor(xclass)\n",
        "      xclass = xclass.to(device)\n",
        "      xclass = encoder(xclass)\n",
        "          \n",
        "      xclass = xclass.detach().cpu().numpy()\n",
        "      n = np.max(counter) - counter[i]\n",
        "      if n == 0:\n",
        "        continue\n",
        "#        resx2 = []\n",
        "#        resy2 = []\n",
        "#        for j in range(batch_size, n+batch_size+1, batch_size):\n",
        "#          if j <= n:\n",
        "#            batch_size_max = batch_size\n",
        "#          elif n % batch_size != 0:\n",
        "#            batch_size_max = n%batch_size\n",
        "#          else:\n",
        "#            break\n",
        "#          xsamp, ysamp = G_SM(xclass,yclass,batch_size_max,i)\n",
        "      xsamp, ysamp = G_SM(xclass,yclass,n,i)\n",
        "      ysamp = np.array(ysamp)\n",
        "  \n",
        "      \"\"\"to generate samples for resnet\"\"\"   \n",
        "      xsamp = torch.Tensor(xsamp)\n",
        "      xsamp = xsamp.to(device)\n",
        "      ximg = decoder(xsamp)\n",
        "\n",
        "      ximn = ximg.detach().cpu().numpy()\n",
        "#        resx2.append(ximn)\n",
        "#        resy2.append(ysamp)\n",
        "#        \n",
        "#        resx2 = np.vstack(resx2)\n",
        "#        resy2 = np.hstack(resy2)\n",
        "      resx.append(ximn)\n",
        "      resy.append(ysamp)\n",
        "  \n",
        "  resx1 = np.vstack(resx)\n",
        "  resy1 = np.hstack(resy)\n",
        "  resx1 = resx1.reshape(resx1.shape[0],-1)\n",
        "  X_train = X_train.reshape(X_train.shape[0],-1)\n",
        "  X_train = np.vstack((resx1,X_train))\n",
        "  y_train = np.hstack((resy1,y_train))\n",
        "  y_train = to_categorical(y_train)\n",
        "  X_train = X_train.reshape(-1, 3, IMAGE_W, IMAGE_H)\n",
        "  X_train = moveaxis(X_train, 1, 3)\n",
        "  X_train = X_train * max_el\n",
        "  return X_train, y_train"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0jrJ33lUDkCM"
      },
      "source": [
        "#Split dataset to train and val"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e6qneWL_Bs2U"
      },
      "outputs": [],
      "source": [
        "# stratified train and rem (20%) datasets\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, stratify=y_train, random_state=1)\n",
        "\n",
        "print('Train Data: ', X_train.shape)\n",
        "print('Remaining Data: ', X_val.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8Kef4r_zxjgk"
      },
      "outputs": [],
      "source": [
        "#Data Augmentation\n",
        "dataaugment = ImageDataGenerator(\n",
        "        rotation_range=90,  # randomly rotate images in the range (degrees, 0 to 180)\n",
        "        zoom_range = 0.1, # Randomly zoom image \n",
        "        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
        "        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
        "        horizontal_flip=True,  # randomly flip images\n",
        "        vertical_flip=True,  # randomly flip images\n",
        "        shear_range = 10) \n",
        "\n",
        "dataaugment.fit(X_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B2PgksTFkOAq"
      },
      "source": [
        "#Fine Tune"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nr1jnSM7yzJc"
      },
      "outputs": [],
      "source": [
        "limit = 171\n",
        "for layer in model.layers[:limit]:\n",
        "   layer.trainable = False\n",
        "for layer in model.layers[limit:]:\n",
        "   layer.trainable = True\n",
        "\n",
        "optimizer_SGD = SGD(learning_rate=0.0001, momentum=0.9)\n",
        "model.compile(optimizer = optimizer_SGD , loss = \"categorical_crossentropy\", metrics=['accuracy', balanced_acc])\n",
        "hst2 = model.fit(train_data_batches,\n",
        "                    epochs = EPOCHS, validation_data = valid_data_batches,\n",
        "                    callbacks=[learning_rate_reduction,early_stopping_monitor, mc])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vO1aAQBmiy0K"
      },
      "outputs": [],
      "source": [
        "# summarize history for accuracy\n",
        "plt.plot(hst2.history['balanced_acc'])\n",
        "plt.plot(hst2.history['val_balanced_acc'])\n",
        "plt.title('model balance_acc after tunning')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'val'], loc='upper left')\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "E_x4c0_DTkaa",
        "BE9FCWBe8deT",
        "iDRWiTnO0MGh",
        "eaK4zbtoaAaC",
        "3K908bbiYwbS",
        "UswA0co2y1wl",
        "LfcFpsBwM0d4",
        "cNBXx28B9yGu",
        "0jrJ33lUDkCM",
        "B2PgksTFkOAq"
      ],
      "machine_shape": "hm",
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}