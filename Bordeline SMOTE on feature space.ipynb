{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/heroza/Inner-Borderline-SMOTE/blob/main/Bordeline%20SMOTE%20on%20feature%20space.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Eus_4tUgfEk9",
        "outputId": "ba039295-524c-4945-b094-db538a46f329"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E_x4c0_DTkaa"
      },
      "source": [
        "#Library, atribut, and function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "nR2MJBYq-oiB"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import os\n",
        "from collections import Counter\n",
        "from pathlib import Path\n",
        "from PIL import Image\n",
        "from sklearn import preprocessing\n",
        "from sklearn.metrics import precision_recall_fscore_support, balanced_accuracy_score, confusion_matrix, accuracy_score\n",
        "from keras.callbacks import ReduceLROnPlateau, EarlyStopping, ModelCheckpoint\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D, UpSampling2D\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.optimizers import Adam, SGD\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input, decode_predictions\n",
        "from tensorflow.keras.applications.inception_v3 import InceptionV3, preprocess_input\n",
        "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Input, Dropout, Flatten\n",
        "from tensorflow.keras.models import Model, load_model\n",
        "from keras.utils.np_utils import to_categorical\n",
        "import imblearn\n",
        "from imblearn.over_sampling import SMOTE, BorderlineSMOTE, SVMSMOTE, ADASYN, KMeansSMOTE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "9-c7Xghg4SB4"
      },
      "outputs": [],
      "source": [
        "# input image size\n",
        "IMAGE_W = 224\n",
        "IMAGE_H = 224\n",
        "IMG_SIZE = (IMAGE_W,IMAGE_H)\n",
        "num_classes = 7\n",
        "EPOCHS = 100\n",
        "BATCH_SIZE = 64\n",
        "opt_adam = Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
        "opt_SGD = SGD(learning_rate=0.001)\n",
        "the_arch = 'resnet50'\n",
        "\n",
        "#Callbacks\n",
        "best_model_fpath = '/content/drive/MyDrive/PHD/Model/best_model_attention.h5'\n",
        "last_model_fpath = '/content/drive/MyDrive/PHD/Model/last_model_attention.h5'\n",
        "mc = ModelCheckpoint(best_model_fpath, monitor='val_balanced_acc', mode='max', verbose=1, save_best_only=True)\n",
        "learning_rate_reduction = ReduceLROnPlateau(monitor='val_balanced_acc', patience=20, verbose=1, factor=0.5, min_lr=0.00001)\n",
        "early_stopping_monitor = EarlyStopping(patience=30,monitor='val_balanced_acc')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "JffFid9sOXeo"
      },
      "outputs": [],
      "source": [
        "# load train and test dataset\n",
        "def preprocess_image_input(input_images, arch = the_arch):\n",
        "  input_images = input_images.astype('float32')\n",
        "  if arch == 'inception_v3':\n",
        "    output_ims = tf.keras.applications.inception_v3.preprocess_input(input_images)\n",
        "  else:\n",
        "    output_ims = tf.keras.applications.resnet50.preprocess_input(input_images)\n",
        "  return output_ims\n",
        "\n",
        "def load_cifar10_dataset():\n",
        "  from keras.datasets import cifar10\n",
        "    # load dataset\n",
        "  (X_train, y_train), (X_val, y_val) = cifar10.load_data()\n",
        "    # one hot encode target values\n",
        "  y_train = to_categorical(y_train)\n",
        "  y_val = to_categorical(y_val)\n",
        "\n",
        "  return X_train, y_train, X_val, y_val\n",
        "\n",
        "def balanced_acc(y_true, y_pred):\n",
        "    from keras import backend as K\n",
        "\n",
        "    tensor1 = tf.math.argmax(y_true, axis=1)\n",
        "    tensor2 = tf.math.argmax(y_pred, axis=1)\n",
        "\n",
        "    cm = tf.math.confusion_matrix(tensor1, tensor2)\n",
        "    \n",
        "    diag = tf.linalg.tensor_diag_part (cm)\n",
        "    tpfn = tf.cast(K.sum(cm, axis = 1), tf.float32) + K.epsilon()\n",
        "    recall = tf.divide(tf.cast(diag, tf.float32),tpfn)\n",
        "    balanced_acc = K.mean(recall)\n",
        "    return balanced_acc\n",
        "\n",
        "def define_base_model(arch = the_arch, start_trainable_layer = 9999, attention=False):\n",
        "  #x = data_augmentation(input_tensor)\n",
        "  #x = layers.Rescaling(1.0 / 255)(input_tensor)  # Rescale inputs\n",
        "  if arch != 'dense':\n",
        "    input_tensor = Input(shape=(IMAGE_H, IMAGE_W, 3))\n",
        "    #if IMAGE_H == 32:\n",
        "      #x = UpSampling2D(size=(7,7))(input_tensor)\n",
        "    if arch == 'resnet50':\n",
        "      base_model = ResNet50(input_tensor=input_tensor, weights='imagenet', include_top=False)\n",
        "    elif arch == 'inception_v3':\n",
        "      base_model = InceptionV3(input_tensor=input_tensor, weights='imagenet', include_top=False)\n",
        "    elif arch == 'ResNet':\n",
        "      base_model = ResNet(classes ,image_shape)(input_tensor)\n",
        "    x = base_model.output\n",
        "    if attention:\n",
        "      x = Attention(1024,1024,7,8)(x)\n",
        "    x = GlobalAveragePooling2D()(x)\n",
        "    for layer in base_model.layers:\n",
        "      layer.trainable = False\n",
        "    if start_trainable_layer != 9999:\n",
        "      for layer in base_model.layers[start_trainable_layer:]:\n",
        "        layer.trainable = True\n",
        "  else:\n",
        "    input_tensor = Input(shape=(2048))\n",
        "    x = input_tensor\n",
        "  #x = Flatten()(x)\n",
        "  x = Dense(1024, activation='relu')(x)\n",
        "  #x = Dropout(0.2)(x)\n",
        "  x = Dense(512, activation='relu')(x)\n",
        "  predictions = Dense(num_classes, activation='softmax')(x)\n",
        "  model = Model(inputs=input_tensor, outputs=predictions)\n",
        "  model.compile(optimizer = opt_SGD , loss = \"categorical_crossentropy\", metrics=['accuracy', balanced_acc])\n",
        "  return model\n",
        "\n",
        "# plot diagnostic learning curves\n",
        "def summarize_diagnostics(history):\n",
        "    # plot loss\n",
        "    plt.subplot(211)\n",
        "    plt.title('Cross Entropy Loss')\n",
        "    plt.plot(history.history['loss'], color='blue', label='train')\n",
        "    plt.plot(history.history['val_loss'], color='orange', label='test')\n",
        "    # plot accuracy\n",
        "    plt.subplot(212)\n",
        "    plt.title('Classification Accuracy')\n",
        "    plt.plot(history.history['accuracy'], color='blue', label='train')\n",
        "    plt.plot(history.history['val_accuracy'], color='orange', label='test')\n",
        " \n",
        "# scale pixels\n",
        "def norm_pixels(train, test):\n",
        "    # convert from integers to floats\n",
        "    train_norm = train.astype('float32')\n",
        "    test_norm = test.astype('float32')\n",
        "    # normalize to range 0-1\n",
        "    train_norm = train_norm / 255.0\n",
        "    test_norm = test_norm / 255.0\n",
        "    # return normalized images\n",
        "    return train_norm, test_norm\n",
        "\n",
        "def load_isic2018_dataset(train_under_frac = 0):\n",
        "  df_train = pd.read_csv('/content/drive/MyDrive/PHD/Datasets/isic2018/ISIC2018_Task3_Training_GroundTruth/ISIC2018_Task3_Training_GroundTruth.csv') \n",
        "  df_val = pd.read_csv('/content/drive/MyDrive/PHD/Datasets/isic2018/ISIC2018_Task3_Validation_GroundTruth/ISIC2018_Task3_Validation_GroundTruth.csv') \n",
        "\n",
        "  #decode one hot label\n",
        "  df_train[\"Labels\"] = (df_train.iloc[:, 1:]).idxmax(axis=1)\n",
        "  df_val[\"Labels\"] = (df_val.iloc[:, 1:]).idxmax(axis=1)\n",
        "\n",
        "  #random undersampling for training dataset\n",
        "  if train_under_frac !=0:\n",
        "    df_train = df_train.drop(df_train[df_train['Labels'] == 'NV'].sample(frac=train_under_frac).index)\n",
        "\n",
        "  #drop one-hot column\n",
        "  df_train = df_train.drop(columns=['MEL', 'NV', 'BCC', 'AKIEC', 'BKL', 'DF', 'VASC'])\n",
        "  df_val = df_val.drop(columns=['MEL', 'NV', 'BCC', 'AKIEC', 'BKL', 'DF', 'VASC'])\n",
        "\n",
        "  #make filepaths of the image\n",
        "  dir_train = '/content/drive/MyDrive/PHD/Datasets/isic2018/ISIC2018_Task3_Training_Input/'\n",
        "  dir_val = '/content/drive/MyDrive/PHD/Datasets/isic2018/ISIC2018_Task3_Validation_Input/'\n",
        "  df_train['FilePaths'] = dir_train + df_train['image'] + '.jpg'\n",
        "  df_val['FilePaths'] = dir_val + df_val['image'] + '.jpg'\n",
        "  \n",
        "  #load image pixels to dataframe\n",
        "  df_train['image_px'] = df_train['FilePaths'].map(lambda x: np.asarray(Image.open(x).resize(IMG_SIZE)))\n",
        "  df_val['image_px'] = df_val['FilePaths'].map(lambda x: np.asarray(Image.open(x).resize(IMG_SIZE)))\n",
        "\n",
        "  X_train = np.asarray(df_train['image_px'].tolist())\n",
        "  X_val = np.asarray(df_val['image_px'].tolist())\n",
        "  y_train = np.array(df_train['Labels'].values)\n",
        "  y_val = np.array(df_val['Labels'].values)\n",
        "\n",
        "  label_encoder = preprocessing.LabelEncoder()\n",
        "  y_train = label_encoder.fit_transform(y_train)\n",
        "  y_val = label_encoder.fit_transform(y_val)\n",
        "  \n",
        "  y_train = to_categorical(y_train, num_classes = num_classes)\n",
        "  y_val = to_categorical(y_val, num_classes = num_classes)\n",
        "\n",
        "  return X_train, y_train, X_val, y_val\n",
        "\n",
        "def reset_dataset(df_train, df_val):\n",
        "  X_train = np.asarray(df_train['image_px'].tolist())\n",
        "  X_val = np.asarray(df_val['image_px'].tolist())\n",
        "  y_train = np.array(df_train['Labels'].values)\n",
        "  y_val = np.array(df_val['Labels'].values)\n",
        "\n",
        "  X_train = preprocess_image_input(X_train, the_arch)\n",
        "  X_val = preprocess_image_input(X_val, the_arch)\n",
        "\n",
        "  label_encoder = preprocessing.LabelEncoder()\n",
        "  y_train = label_encoder.fit_transform(y_train)\n",
        "  y_val = label_encoder.fit_transform(y_val)\n",
        "  \n",
        "  y_train = to_categorical(y_train, num_classes = num_classes)\n",
        "  y_val = to_categorical(y_val, num_classes = num_classes)\n",
        "  return X_train, y_train, X_val, y_val\n",
        "\n",
        "def SMOTE_Data(X, y, one_hot = False, k = 5, width = IMAGE_W, height = IMAGE_H, c = 3, type = 'smote'):\n",
        "  if one_hot:\n",
        "    y = np.argmax(y, axis=1)\n",
        "  if type == 'borderline':\n",
        "    sm = BorderlineSMOTE(random_state=42, k_neighbors=k)\n",
        "  elif type == 'svm':\n",
        "    sm = SVMSMOTE()\n",
        "  elif type == 'adasyn':\n",
        "    sm = ADASYN(random_state=42, n_neighbors=k)\n",
        "  elif type == 'kmeans':\n",
        "    sm = KMeansSMOTE(k_neighbors=k, kmeans_estimator=10)\n",
        "  else:\n",
        "    sm = SMOTE(random_state=42, k_neighbors=k)\n",
        "  X_resampled, y_resampled = sm.fit_resample(X.reshape((-1, width * height * c)), y)\n",
        "  X_resampled = X_resampled.reshape(-1, width, height, c)\n",
        "  if one_hot:\n",
        "    y_resampled = to_categorical(y_resampled, num_classes = num_classes)\n",
        "  else:\n",
        "    y_resampled = y_resampled.reshape(-1,1)\n",
        "  return X_resampled, y_resampled\n",
        "\n",
        "def SMOTE_Data2(X, y, one_hot = False, k = 5):\n",
        "  if one_hot:\n",
        "    y = np.argmax(y, axis=1)\n",
        "  sm = BorderlineSMOTE(random_state=42, k_neighbors=k)\n",
        "  X_resampled, y_resampled = sm.fit_resample(X, y)\n",
        "  if one_hot:\n",
        "    y_resampled = to_categorical(y_resampled, num_classes = num_classes)\n",
        "  else:\n",
        "    y_resampled = y_resampled.reshape(-1,1)\n",
        "  return X_resampled, y_resampled\n",
        "\n",
        "def Borderline_SMOTE(X, y):\n",
        "  #G_SM(X, y,n_to_sample,cl):\n",
        "  n_neigh = 5\n",
        "  nn = NearestNeighbors(n_neighbors=n_neigh, n_jobs=1)\n",
        "  nn.fit(X)\n",
        "  dist, ind = nn.kneighbors(X)\n",
        "\n",
        "  # generating samples\n",
        "  base_indices = np.random.choice(list(range(len(X))),n_to_sample)\n",
        "  neighbor_indices = np.random.choice(list(range(1, n_neigh)),n_to_sample)\n",
        "\n",
        "  X_base = X[base_indices]\n",
        "  X_neighbor = X[ind[base_indices, neighbor_indices]]\n",
        "\n",
        "  samples = X_base + np.multiply(np.random.rand(n_to_sample,1),\n",
        "          X_neighbor - X_base)\n",
        "\n",
        "  #use 10 as label because 0 to 9 real classes and 1 fake/smoted = 10\n",
        "  return samples, [cl]*n_to_sample"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5v7sLC2svMuJ"
      },
      "source": [
        "# Main"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qge6cnxQPnH6",
        "outputId": "bbf8fa00-17fd-43c9-c9d5-a93bd2edcd64"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(5321, 224, 224, 3)\n",
            "(5321, 7)\n",
            "(193, 224, 224, 3)\n",
            "(193, 7)\n",
            "Counter train data:  Counter({5: 2011, 4: 1113, 2: 1099, 1: 514, 0: 327, 6: 142, 3: 115})\n",
            "Counter val data:  Counter({5: 123, 2: 22, 4: 21, 1: 15, 0: 8, 6: 3, 3: 1})\n"
          ]
        }
      ],
      "source": [
        "path = '/content/drive/MyDrive/PHD/Datasets/isic2018/'\n",
        "df1 = pd.read_pickle(path+\"isic2018_train.pkl\")\n",
        "X_train = df1.loc[:, df1.columns != 'y_train'].to_numpy()\n",
        "X_train = X_train.reshape(-1,224,224,3)\n",
        "y_train = df1.loc[:, df1.columns == 'y_train'].to_numpy()\n",
        "y_train = to_categorical(y_train)\n",
        "\n",
        "df1 = pd.read_pickle(path+\"isic2018_val.pkl\")\n",
        "X_val = df1.loc[:, df1.columns != 'y_val'].to_numpy()\n",
        "X_val = X_val.reshape(-1,224,224,3)\n",
        "y_val = df1.loc[:, df1.columns == 'y_val'].to_numpy()\n",
        "y_val = to_categorical(y_val)\n",
        "\n",
        "print(X_train.shape)\n",
        "print(y_train.shape)\n",
        "print(X_val.shape)\n",
        "print(y_val.shape)\n",
        "print('Counter train data: ', Counter(np.argmax(y_train, axis=1)))\n",
        "print('Counter val data: ', Counter(np.argmax(y_val, axis=1)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xArGWuciBt_-",
        "outputId": "a2a8c7f4-f5a1-4af5-9a64-b272685ea624"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(14077, 32, 32, 3)\n",
            "(14077, 7)\n",
            "(193, 32, 32, 3)\n",
            "(193, 7)\n",
            "Counter train data:  Counter({5: 2011, 4: 2011, 2: 2011, 3: 2011, 0: 2011, 1: 2011, 6: 2011})\n",
            "Counter val data:  Counter({5: 123, 2: 22, 4: 21, 1: 15, 0: 8, 6: 3, 3: 1})\n"
          ]
        }
      ],
      "source": [
        "#X_train, y_train = SMOTE_Data(X_train, y_train, True)\n",
        "X_train, y_train = Borderline_SMOTE(X_train, y_train)\n",
        "print(X_train.shape)\n",
        "print(y_train.shape)\n",
        "print(X_val.shape)\n",
        "print(y_val.shape)\n",
        "print('Counter train data: ', Counter(np.argmax(y_train, axis=1)))\n",
        "print('Counter val data: ', Counter(np.argmax(y_val, axis=1)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "V7Z_nccu6QjB"
      },
      "outputs": [],
      "source": [
        "#path = '/content/drive/MyDrive/PHD/Datasets/isic2018/'\n",
        "#df1 = pd.DataFrame(X_train.reshape(X_train.shape[0],-1))\n",
        "#df1['y_train'] = np.argmax(y_train, axis=1).tolist()\n",
        "#df2 = pd.DataFrame(X_val.reshape(X_val.shape[0],-1))\n",
        "#df2['y_val'] = np.argmax(y_val, axis=1).tolist()\n",
        "#df1.to_pickle(path+\"isic2018_train_32.pkl\")\n",
        "#df2.to_pickle(path+\"isic2018_val_32.pkl\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "nAMBgWqIsAAB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aae3bd98-457d-41fb-a6d5-4cd90f9c5bbc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(5321, 32, 32, 3)\n",
            "(5321, 7)\n",
            "(193, 32, 32, 3)\n",
            "(193, 7)\n",
            "Counter train data:  Counter({5: 2011, 4: 1113, 2: 1099, 1: 514, 0: 327, 6: 142, 3: 115})\n",
            "Counter val data:  Counter({5: 123, 2: 22, 4: 21, 1: 15, 0: 8, 6: 3, 3: 1})\n"
          ]
        }
      ],
      "source": [
        "print(X_train.shape)\n",
        "print(y_train.shape)\n",
        "print(X_val.shape)\n",
        "print(y_val.shape)\n",
        "print('Counter train data: ', Counter(np.argmax(y_train, axis=1)))\n",
        "print('Counter val data: ', Counter(np.argmax(y_val, axis=1)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "vIygrW81Ln4z",
        "outputId": "952789f9-e874-4403-d721-bcc3b849a496"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "83/83 [==============================] - ETA: 0s - loss: 1.5232 - accuracy: 0.4226 - balanced_acc: 0.2066\n",
            "Epoch 1: val_balanced_acc improved from -inf to 0.21106, saving model to /content/drive/MyDrive/PHD/Model/best_model_attention.h5\n",
            "83/83 [==============================] - 34s 237ms/step - loss: 1.5232 - accuracy: 0.4226 - balanced_acc: 0.2066 - val_loss: 1.0507 - val_accuracy: 0.6684 - val_balanced_acc: 0.2111 - lr: 0.0010\n",
            "Epoch 2/100\n",
            "83/83 [==============================] - ETA: 0s - loss: 1.2565 - accuracy: 0.5100 - balanced_acc: 0.2778\n",
            "Epoch 2: val_balanced_acc improved from 0.21106 to 0.26719, saving model to /content/drive/MyDrive/PHD/Model/best_model_attention.h5\n",
            "83/83 [==============================] - 19s 221ms/step - loss: 1.2565 - accuracy: 0.5100 - balanced_acc: 0.2778 - val_loss: 0.9418 - val_accuracy: 0.6995 - val_balanced_acc: 0.2672 - lr: 0.0010\n",
            "Epoch 3/100\n",
            "83/83 [==============================] - ETA: 0s - loss: 1.1672 - accuracy: 0.5484 - balanced_acc: 0.3194\n",
            "Epoch 3: val_balanced_acc did not improve from 0.26719\n",
            "83/83 [==============================] - 17s 201ms/step - loss: 1.1672 - accuracy: 0.5484 - balanced_acc: 0.3194 - val_loss: 0.8990 - val_accuracy: 0.6839 - val_balanced_acc: 0.2412 - lr: 0.0010\n",
            "Epoch 4/100\n",
            "83/83 [==============================] - ETA: 0s - loss: 1.1050 - accuracy: 0.5758 - balanced_acc: 0.3474\n",
            "Epoch 4: val_balanced_acc did not improve from 0.26719\n",
            "83/83 [==============================] - 17s 210ms/step - loss: 1.1050 - accuracy: 0.5758 - balanced_acc: 0.3474 - val_loss: 0.8691 - val_accuracy: 0.6995 - val_balanced_acc: 0.2618 - lr: 0.0010\n",
            "Epoch 5/100\n",
            "83/83 [==============================] - ETA: 0s - loss: 1.0674 - accuracy: 0.5950 - balanced_acc: 0.3807\n",
            "Epoch 5: val_balanced_acc improved from 0.26719 to 0.27812, saving model to /content/drive/MyDrive/PHD/Model/best_model_attention.h5\n",
            "83/83 [==============================] - 19s 231ms/step - loss: 1.0674 - accuracy: 0.5950 - balanced_acc: 0.3807 - val_loss: 0.8321 - val_accuracy: 0.7150 - val_balanced_acc: 0.2781 - lr: 0.0010\n",
            "Epoch 6/100\n",
            "83/83 [==============================] - ETA: 0s - loss: 1.0303 - accuracy: 0.6041 - balanced_acc: 0.3932\n",
            "Epoch 6: val_balanced_acc improved from 0.27812 to 0.29385, saving model to /content/drive/MyDrive/PHD/Model/best_model_attention.h5\n",
            "83/83 [==============================] - 19s 226ms/step - loss: 1.0303 - accuracy: 0.6041 - balanced_acc: 0.3932 - val_loss: 0.8022 - val_accuracy: 0.7306 - val_balanced_acc: 0.2939 - lr: 0.0010\n",
            "Epoch 7/100\n",
            "83/83 [==============================] - ETA: 0s - loss: 1.0042 - accuracy: 0.6182 - balanced_acc: 0.4127\n",
            "Epoch 7: val_balanced_acc did not improve from 0.29385\n",
            "83/83 [==============================] - 17s 204ms/step - loss: 1.0042 - accuracy: 0.6182 - balanced_acc: 0.4127 - val_loss: 0.7979 - val_accuracy: 0.7202 - val_balanced_acc: 0.2919 - lr: 0.0010\n",
            "Epoch 8/100\n",
            "83/83 [==============================] - ETA: 0s - loss: 0.9816 - accuracy: 0.6302 - balanced_acc: 0.4217\n",
            "Epoch 8: val_balanced_acc improved from 0.29385 to 0.44139, saving model to /content/drive/MyDrive/PHD/Model/best_model_attention.h5\n",
            "83/83 [==============================] - 19s 228ms/step - loss: 0.9816 - accuracy: 0.6302 - balanced_acc: 0.4217 - val_loss: 0.7618 - val_accuracy: 0.7513 - val_balanced_acc: 0.4414 - lr: 0.0010\n",
            "Epoch 9/100\n",
            "83/83 [==============================] - ETA: 0s - loss: 0.9595 - accuracy: 0.6443 - balanced_acc: 0.4426\n",
            "Epoch 9: val_balanced_acc did not improve from 0.44139\n",
            "83/83 [==============================] - 17s 209ms/step - loss: 0.9595 - accuracy: 0.6443 - balanced_acc: 0.4426 - val_loss: 0.7556 - val_accuracy: 0.7617 - val_balanced_acc: 0.3064 - lr: 0.0010\n",
            "Epoch 10/100\n",
            "83/83 [==============================] - ETA: 0s - loss: 0.9328 - accuracy: 0.6494 - balanced_acc: 0.4612\n",
            "Epoch 10: val_balanced_acc did not improve from 0.44139\n",
            "83/83 [==============================] - 17s 209ms/step - loss: 0.9328 - accuracy: 0.6494 - balanced_acc: 0.4612 - val_loss: 0.7790 - val_accuracy: 0.7202 - val_balanced_acc: 0.4353 - lr: 0.0010\n",
            "Epoch 11/100\n",
            "83/83 [==============================] - ETA: 0s - loss: 0.9183 - accuracy: 0.6572 - balanced_acc: 0.4743\n",
            "Epoch 11: val_balanced_acc did not improve from 0.44139\n",
            "83/83 [==============================] - 17s 207ms/step - loss: 0.9183 - accuracy: 0.6572 - balanced_acc: 0.4743 - val_loss: 0.7385 - val_accuracy: 0.7358 - val_balanced_acc: 0.2947 - lr: 0.0010\n",
            "Epoch 12/100\n",
            "83/83 [==============================] - ETA: 0s - loss: 0.9060 - accuracy: 0.6627 - balanced_acc: 0.4848\n",
            "Epoch 12: val_balanced_acc did not improve from 0.44139\n",
            "83/83 [==============================] - 17s 207ms/step - loss: 0.9060 - accuracy: 0.6627 - balanced_acc: 0.4848 - val_loss: 0.7513 - val_accuracy: 0.7306 - val_balanced_acc: 0.3263 - lr: 0.0010\n",
            "Epoch 13/100\n",
            "83/83 [==============================] - ETA: 0s - loss: 0.8861 - accuracy: 0.6688 - balanced_acc: 0.4920\n",
            "Epoch 13: val_balanced_acc did not improve from 0.44139\n",
            "83/83 [==============================] - 17s 207ms/step - loss: 0.8861 - accuracy: 0.6688 - balanced_acc: 0.4920 - val_loss: 0.7091 - val_accuracy: 0.7668 - val_balanced_acc: 0.3240 - lr: 0.0010\n",
            "Epoch 14/100\n",
            "83/83 [==============================] - ETA: 0s - loss: 0.8854 - accuracy: 0.6692 - balanced_acc: 0.4940\n",
            "Epoch 14: val_balanced_acc did not improve from 0.44139\n",
            "83/83 [==============================] - 17s 207ms/step - loss: 0.8854 - accuracy: 0.6692 - balanced_acc: 0.4940 - val_loss: 0.7253 - val_accuracy: 0.7202 - val_balanced_acc: 0.3254 - lr: 0.0010\n",
            "Epoch 15/100\n",
            "83/83 [==============================] - ETA: 0s - loss: 0.8628 - accuracy: 0.6778 - balanced_acc: 0.4983\n",
            "Epoch 15: val_balanced_acc did not improve from 0.44139\n",
            "83/83 [==============================] - 17s 208ms/step - loss: 0.8628 - accuracy: 0.6778 - balanced_acc: 0.4983 - val_loss: 0.7131 - val_accuracy: 0.7409 - val_balanced_acc: 0.3202 - lr: 0.0010\n",
            "Epoch 16/100\n",
            "83/83 [==============================] - ETA: 0s - loss: 0.8478 - accuracy: 0.6797 - balanced_acc: 0.5047\n",
            "Epoch 16: val_balanced_acc did not improve from 0.44139\n",
            "83/83 [==============================] - 17s 208ms/step - loss: 0.8478 - accuracy: 0.6797 - balanced_acc: 0.5047 - val_loss: 0.6919 - val_accuracy: 0.7668 - val_balanced_acc: 0.3401 - lr: 0.0010\n",
            "Epoch 17/100\n",
            "83/83 [==============================] - ETA: 0s - loss: 0.8433 - accuracy: 0.6829 - balanced_acc: 0.5087\n",
            "Epoch 17: val_balanced_acc did not improve from 0.44139\n",
            "83/83 [==============================] - 17s 208ms/step - loss: 0.8433 - accuracy: 0.6829 - balanced_acc: 0.5087 - val_loss: 0.6717 - val_accuracy: 0.7720 - val_balanced_acc: 0.3797 - lr: 0.0010\n",
            "Epoch 18/100\n",
            "83/83 [==============================] - ETA: 0s - loss: 0.8270 - accuracy: 0.6916 - balanced_acc: 0.5175\n",
            "Epoch 18: val_balanced_acc did not improve from 0.44139\n",
            "83/83 [==============================] - 17s 207ms/step - loss: 0.8270 - accuracy: 0.6916 - balanced_acc: 0.5175 - val_loss: 0.6856 - val_accuracy: 0.7668 - val_balanced_acc: 0.3628 - lr: 0.0010\n",
            "Epoch 19/100\n",
            "83/83 [==============================] - ETA: 0s - loss: 0.8284 - accuracy: 0.6888 - balanced_acc: 0.5247\n",
            "Epoch 19: val_balanced_acc did not improve from 0.44139\n",
            "83/83 [==============================] - 17s 206ms/step - loss: 0.8284 - accuracy: 0.6888 - balanced_acc: 0.5247 - val_loss: 0.7016 - val_accuracy: 0.7358 - val_balanced_acc: 0.3767 - lr: 0.0010\n",
            "Epoch 20/100\n",
            "83/83 [==============================] - ETA: 0s - loss: 0.8060 - accuracy: 0.7105 - balanced_acc: 0.5531\n",
            "Epoch 20: val_balanced_acc did not improve from 0.44139\n",
            "83/83 [==============================] - 17s 207ms/step - loss: 0.8060 - accuracy: 0.7105 - balanced_acc: 0.5531 - val_loss: 0.6909 - val_accuracy: 0.7617 - val_balanced_acc: 0.3908 - lr: 0.0010\n",
            "Epoch 21/100\n",
            "83/83 [==============================] - ETA: 0s - loss: 0.8093 - accuracy: 0.6972 - balanced_acc: 0.5305\n",
            "Epoch 21: val_balanced_acc did not improve from 0.44139\n",
            "83/83 [==============================] - 17s 207ms/step - loss: 0.8093 - accuracy: 0.6972 - balanced_acc: 0.5305 - val_loss: 0.6792 - val_accuracy: 0.7668 - val_balanced_acc: 0.3246 - lr: 0.0010\n",
            "Epoch 22/100\n",
            "83/83 [==============================] - ETA: 0s - loss: 0.7997 - accuracy: 0.7042 - balanced_acc: 0.5490\n",
            "Epoch 22: val_balanced_acc did not improve from 0.44139\n",
            "83/83 [==============================] - 17s 207ms/step - loss: 0.7997 - accuracy: 0.7042 - balanced_acc: 0.5490 - val_loss: 0.6767 - val_accuracy: 0.7668 - val_balanced_acc: 0.3887 - lr: 0.0010\n",
            "Epoch 23/100\n",
            "83/83 [==============================] - ETA: 0s - loss: 0.7829 - accuracy: 0.7088 - balanced_acc: 0.5587\n",
            "Epoch 23: val_balanced_acc did not improve from 0.44139\n",
            "83/83 [==============================] - 17s 207ms/step - loss: 0.7829 - accuracy: 0.7088 - balanced_acc: 0.5587 - val_loss: 0.6697 - val_accuracy: 0.7720 - val_balanced_acc: 0.3870 - lr: 0.0010\n",
            "Epoch 24/100\n",
            "83/83 [==============================] - ETA: 0s - loss: 0.7711 - accuracy: 0.7139 - balanced_acc: 0.5458\n",
            "Epoch 24: val_balanced_acc did not improve from 0.44139\n",
            "83/83 [==============================] - 17s 207ms/step - loss: 0.7711 - accuracy: 0.7139 - balanced_acc: 0.5458 - val_loss: 0.6696 - val_accuracy: 0.7668 - val_balanced_acc: 0.3264 - lr: 0.0010\n",
            "Epoch 25/100\n",
            "83/83 [==============================] - ETA: 0s - loss: 0.7604 - accuracy: 0.7223 - balanced_acc: 0.5777\n",
            "Epoch 25: val_balanced_acc did not improve from 0.44139\n",
            "83/83 [==============================] - 17s 207ms/step - loss: 0.7604 - accuracy: 0.7223 - balanced_acc: 0.5777 - val_loss: 0.6685 - val_accuracy: 0.7772 - val_balanced_acc: 0.3920 - lr: 0.0010\n",
            "Epoch 26/100\n",
            "83/83 [==============================] - ETA: 0s - loss: 0.7694 - accuracy: 0.7179 - balanced_acc: 0.5651\n",
            "Epoch 26: val_balanced_acc did not improve from 0.44139\n",
            "83/83 [==============================] - 17s 207ms/step - loss: 0.7694 - accuracy: 0.7179 - balanced_acc: 0.5651 - val_loss: 0.6386 - val_accuracy: 0.7824 - val_balanced_acc: 0.3870 - lr: 0.0010\n",
            "Epoch 27/100\n",
            "83/83 [==============================] - ETA: 0s - loss: 0.7589 - accuracy: 0.7242 - balanced_acc: 0.5881\n",
            "Epoch 27: val_balanced_acc did not improve from 0.44139\n",
            "83/83 [==============================] - 17s 207ms/step - loss: 0.7589 - accuracy: 0.7242 - balanced_acc: 0.5881 - val_loss: 0.6706 - val_accuracy: 0.7565 - val_balanced_acc: 0.3911 - lr: 0.0010\n",
            "Epoch 28/100\n",
            "83/83 [==============================] - ETA: 0s - loss: 0.7485 - accuracy: 0.7276 - balanced_acc: 0.5906\n",
            "Epoch 28: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "\n",
            "Epoch 28: val_balanced_acc did not improve from 0.44139\n",
            "83/83 [==============================] - 17s 207ms/step - loss: 0.7485 - accuracy: 0.7276 - balanced_acc: 0.5906 - val_loss: 0.6509 - val_accuracy: 0.7720 - val_balanced_acc: 0.4051 - lr: 0.0010\n",
            "Epoch 29/100\n",
            "83/83 [==============================] - ETA: 0s - loss: 0.7346 - accuracy: 0.7365 - balanced_acc: 0.5858\n",
            "Epoch 29: val_balanced_acc did not improve from 0.44139\n",
            "83/83 [==============================] - 17s 208ms/step - loss: 0.7346 - accuracy: 0.7365 - balanced_acc: 0.5858 - val_loss: 0.6501 - val_accuracy: 0.7772 - val_balanced_acc: 0.3859 - lr: 5.0000e-04\n",
            "Epoch 30/100\n",
            "83/83 [==============================] - ETA: 0s - loss: 0.7448 - accuracy: 0.7249 - balanced_acc: 0.5902\n",
            "Epoch 30: val_balanced_acc did not improve from 0.44139\n",
            "83/83 [==============================] - 17s 208ms/step - loss: 0.7448 - accuracy: 0.7249 - balanced_acc: 0.5902 - val_loss: 0.6447 - val_accuracy: 0.7824 - val_balanced_acc: 0.3870 - lr: 5.0000e-04\n",
            "Epoch 31/100\n",
            "83/83 [==============================] - ETA: 0s - loss: 0.7338 - accuracy: 0.7354 - balanced_acc: 0.5929\n",
            "Epoch 31: val_balanced_acc did not improve from 0.44139\n",
            "83/83 [==============================] - 17s 208ms/step - loss: 0.7338 - accuracy: 0.7354 - balanced_acc: 0.5929 - val_loss: 0.6416 - val_accuracy: 0.7720 - val_balanced_acc: 0.3900 - lr: 5.0000e-04\n",
            "Epoch 32/100\n",
            "83/83 [==============================] - ETA: 0s - loss: 0.7159 - accuracy: 0.7453 - balanced_acc: 0.5998\n",
            "Epoch 32: val_balanced_acc did not improve from 0.44139\n",
            "83/83 [==============================] - 17s 208ms/step - loss: 0.7159 - accuracy: 0.7453 - balanced_acc: 0.5998 - val_loss: 0.6535 - val_accuracy: 0.7720 - val_balanced_acc: 0.3873 - lr: 5.0000e-04\n",
            "Epoch 33/100\n",
            "83/83 [==============================] - ETA: 0s - loss: 0.7319 - accuracy: 0.7318 - balanced_acc: 0.5965\n",
            "Epoch 33: val_balanced_acc did not improve from 0.44139\n",
            "83/83 [==============================] - 17s 207ms/step - loss: 0.7319 - accuracy: 0.7318 - balanced_acc: 0.5965 - val_loss: 0.6384 - val_accuracy: 0.7772 - val_balanced_acc: 0.3859 - lr: 5.0000e-04\n",
            "Epoch 34/100\n",
            "83/83 [==============================] - ETA: 0s - loss: 0.7273 - accuracy: 0.7362 - balanced_acc: 0.6015\n",
            "Epoch 34: val_balanced_acc did not improve from 0.44139\n",
            "83/83 [==============================] - 17s 208ms/step - loss: 0.7273 - accuracy: 0.7362 - balanced_acc: 0.6015 - val_loss: 0.6541 - val_accuracy: 0.7668 - val_balanced_acc: 0.3837 - lr: 5.0000e-04\n",
            "Epoch 35/100\n",
            "83/83 [==============================] - ETA: 0s - loss: 0.7082 - accuracy: 0.7438 - balanced_acc: 0.6210\n",
            "Epoch 35: val_balanced_acc did not improve from 0.44139\n",
            "83/83 [==============================] - 17s 207ms/step - loss: 0.7082 - accuracy: 0.7438 - balanced_acc: 0.6210 - val_loss: 0.6356 - val_accuracy: 0.7668 - val_balanced_acc: 0.3777 - lr: 5.0000e-04\n",
            "Epoch 36/100\n",
            "83/83 [==============================] - ETA: 0s - loss: 0.7142 - accuracy: 0.7405 - balanced_acc: 0.5929\n",
            "Epoch 36: val_balanced_acc did not improve from 0.44139\n",
            "83/83 [==============================] - 17s 207ms/step - loss: 0.7142 - accuracy: 0.7405 - balanced_acc: 0.5929 - val_loss: 0.6473 - val_accuracy: 0.7772 - val_balanced_acc: 0.3920 - lr: 5.0000e-04\n",
            "Epoch 37/100\n",
            "83/83 [==============================] - ETA: 0s - loss: 0.7225 - accuracy: 0.7388 - balanced_acc: 0.6181\n",
            "Epoch 37: val_balanced_acc did not improve from 0.44139\n",
            "83/83 [==============================] - 17s 207ms/step - loss: 0.7225 - accuracy: 0.7388 - balanced_acc: 0.6181 - val_loss: 0.6621 - val_accuracy: 0.7513 - val_balanced_acc: 0.3837 - lr: 5.0000e-04\n",
            "Epoch 38/100\n",
            "83/83 [==============================] - ETA: 0s - loss: 0.6994 - accuracy: 0.7466 - balanced_acc: 0.6158\n",
            "Epoch 38: val_balanced_acc did not improve from 0.44139\n",
            "83/83 [==============================] - 17s 207ms/step - loss: 0.6994 - accuracy: 0.7466 - balanced_acc: 0.6158 - val_loss: 0.6397 - val_accuracy: 0.7772 - val_balanced_acc: 0.3920 - lr: 5.0000e-04\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "# define model\n",
        "model = define_base_model('resnet50')\n",
        "#model.summary()\n",
        "hst = model.fit(X_train, y_train, epochs=EPOCHS, batch_size=BATCH_SIZE, validation_data=(X_val, y_val), verbose=1,\n",
        "                    steps_per_epoch=X_train.shape[0] // BATCH_SIZE, \n",
        "                    callbacks=[learning_rate_reduction,early_stopping_monitor, mc])\n",
        "# learning curves\n",
        "summarize_diagnostics(hst)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "vXnW3lmCgln3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "dcc24fbb-6a0a-4a65-cb3c-848a28b4daaf"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "# summarize history for accuracy\n",
        "plt.plot(hst.history['accuracy'])\n",
        "plt.plot(hst.history['balanced_acc'])\n",
        "plt.plot(hst.history['val_accuracy'])\n",
        "plt.plot(hst.history['val_balanced_acc'])\n",
        "plt.title('Model accuracy')\n",
        "plt.ylabel('Performance')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train accuracy', 'train balanced acc.', 'val. accuracy', 'val. balanced acc.'], loc='lower right')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rwwLiXUSG0IZ"
      },
      "outputs": [],
      "source": [
        "#Training\n",
        "#hst = model.fit(train_data_batches,\n",
        "#                    epochs = EPOCHS, validation_data = valid_data_batches,      \n",
        "                    #steps_per_epoch=X_train.shape[0] // BATCH_SIZE, \n",
        "#                    callbacks=[learning_rate_reduction,early_stopping_monitor, mc])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "icgjmi-4UIT-"
      },
      "source": [
        "#Evaluate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "SPz8NH1Oylv9"
      },
      "outputs": [],
      "source": [
        "#save last model\n",
        "model.save(last_model_fpath)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 398
        },
        "id": "lS3ewyxO_anU",
        "outputId": "6b64472d-366a-486a-8d10-6ef73380bb4a"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "InternalError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mInternalError\u001b[0m                             Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-f3831cbf62ab>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mlast_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlast_model_fpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'balanced_acc'\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mbalanced_acc\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0my_train_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlast_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0my_val_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlast_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#print('accuracy on training',accuracy_score(np.argmax(y_train, axis=1), np.argmax(y_train_pred, axis=1)))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconvert_to_eager_tensor\u001b[0;34m(value, ctx, dtype)\u001b[0m\n\u001b[1;32m    100\u001b[0m       \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_datatype_enum\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m   \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEagerTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mInternalError\u001b[0m: Failed copying input tensor from /job:localhost/replica:0/task:0/device:CPU:0 to /job:localhost/replica:0/task:0/device:GPU:0 in order to run _EagerConst: Dst tensor is not initialized."
          ]
        }
      ],
      "source": [
        "last_model = load_model(last_model_fpath, custom_objects={'balanced_acc' : balanced_acc})\n",
        "y_train_pred = last_model.predict(X_train)\n",
        "y_val_pred = last_model.predict(X_val)\n",
        "\n",
        "#print('accuracy on training',accuracy_score(np.argmax(y_train, axis=1), np.argmax(y_train_pred, axis=1)))\n",
        "print('accuracy on training',accuracy_score(np.argmax(y_train, axis=1), np.argmax(y_train_pred, axis=1)))\n",
        "print('balanced accuracy on training',balanced_accuracy_score(np.argmax(y_train, axis=1), np.argmax(y_train_pred, axis=1)))\n",
        "print('accuracy on validation',accuracy_score(np.argmax(y_val, axis=1), np.argmax(y_val_pred, axis=1)))\n",
        "print('balanced accuracy on validation',balanced_accuracy_score(np.argmax(y_val, axis=1), np.argmax(y_val_pred, axis=1)))\n",
        "print('Score on val data: ',precision_recall_fscore_support(np.argmax(y_val, axis=1), np.argmax(y_val_pred, axis=1), average='macro'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W3IyWjdGG4Xq"
      },
      "outputs": [],
      "source": [
        "best_model = load_model(best_model_fpath, custom_objects={'balanced_acc' : balanced_acc})\n",
        "y_train_pred = best_model.predict(X_train)\n",
        "y_val_pred = best_model.predict(X_val)\n",
        "\n",
        "print('accuracy on training',accuracy_score(np.argmax(y_train, axis=1), np.argmax(y_train_pred, axis=1)))\n",
        "print('balanced accuracy on training',balanced_accuracy_score(np.argmax(y_train, axis=1), np.argmax(y_train_pred, axis=1)))\n",
        "print('accuracy on validation',accuracy_score(np.argmax(y_val, axis=1), np.argmax(y_val_pred, axis=1)))\n",
        "print('balanced accuracy on validation',balanced_accuracy_score(np.argmax(y_val, axis=1), np.argmax(y_val_pred, axis=1)))\n",
        "print('Score on val data: ',precision_recall_fscore_support(np.argmax(y_val, axis=1), np.argmax(y_val_pred, axis=1), average='macro'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iDRWiTnO0MGh"
      },
      "source": [
        "#Cut-off"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tGnCoIdLyDHS"
      },
      "outputs": [],
      "source": [
        "df_val_pred = pd.DataFrame(y_val_pred, columns = ['AKIEC', 'BCC', 'BKL', 'DF', 'MEL', 'NV', 'VASC'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QdyCbloQyWTC"
      },
      "outputs": [],
      "source": [
        "numbers = [float(x)/40 for x in range(11)]\n",
        "for i in numbers:\n",
        "    df_val_pred[i]= df_val_pred.MEL.map(lambda x: 1 if x > i else 0)\n",
        "df_val_pred.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G4SQsRx73kgk"
      },
      "outputs": [],
      "source": [
        "y_val_true= [1 if x == 4 else 0 for x in np.argmax(y_val, axis=1)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QcUISWFi0J05"
      },
      "outputs": [],
      "source": [
        "#num = [0.0,0.05,0.1,0.15,0.2,0.25,0.3,0.35,0.4,0.45,0.5]\n",
        "cutoff_df = pd.DataFrame( columns = ['Probability','Accuracy','Sensitivity','Specificity'])\n",
        "for i in numbers:\n",
        "    cm1 = confusion_matrix(y_val_true, df_val_pred[i])\n",
        "    total1=sum(sum(cm1))\n",
        "    Accuracy = (cm1[0,0]+cm1[1,1])/total1\n",
        "    Specificity = cm1[0,0]/(cm1[0,0]+cm1[0,1])\n",
        "    Sensitivity = cm1[1,1]/(cm1[1,0]+cm1[1,1])\n",
        "    cutoff_df.loc[i] =[ i ,Accuracy,Sensitivity,Specificity]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W31LSzov1tCt"
      },
      "outputs": [],
      "source": [
        "cutoff_df[['Accuracy','Sensitivity','Specificity']].plot()\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P6CIKT94Jqye"
      },
      "outputs": [],
      "source": [
        "i = 0.025\n",
        "cm1 = confusion_matrix(y_val_true, df_val_pred[i])\n",
        "total1=sum(sum(cm1))\n",
        "Accuracy = (cm1[0,0]+cm1[1,1])/total1\n",
        "Specificity = cm1[0,0]/(cm1[0,0]+cm1[0,1])\n",
        "Sensitivity = cm1[1,1]/(cm1[1,0]+cm1[1,1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3U2tkFebL_VC"
      },
      "outputs": [],
      "source": [
        "print('Accuracy: ', Accuracy)\n",
        "print('Sensitivity: ', Sensitivity)\n",
        "print('Specificity: ', Specificity)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eaK4zbtoaAaC"
      },
      "source": [
        "#Confusion Metric on Validation Set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YkPOFLehOmFg"
      },
      "outputs": [],
      "source": [
        "#change melanoma flag back to 4\n",
        "df_val_pred[df_val_pred[i] == 1] = 4\n",
        "#decode one-hot y_val_pred while use cut-off melanoma data\n",
        "condition = df_val_pred[i] == 4\n",
        "y_val_pred2 = np.where(condition, df_val_pred[i], np.argmax(y_val_pred, axis=1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LOVl6dWlTDLo"
      },
      "outputs": [],
      "source": [
        "print('Accuracy: ',accuracy_score(np.argmax(y_val, axis=1), y_val_pred2))\n",
        "print('Balanced accuracy: ',balanced_accuracy_score(np.argmax(y_val, axis=1), y_val_pred2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mqvYutTKRhR_"
      },
      "outputs": [],
      "source": [
        "#Get the confusion matrix\n",
        "cf_matrix = confusion_matrix(np.argmax(y_val, axis=1), y_val_pred2)\n",
        "print(cf_matrix)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gVtvW3YeaLlC"
      },
      "outputs": [],
      "source": [
        "ax = sns.heatmap(cf_matrix / cf_matrix.sum(axis=1, keepdims=True), annot=True, \n",
        "            cmap='Blues')\n",
        "\n",
        "ax.set_title('Confusion Matrix \\n');\n",
        "ax.set_xlabel('\\nPredicted')\n",
        "ax.set_ylabel('Actual ');\n",
        "\n",
        "## Ticket labels - List must be in alphabetical order\n",
        "ax.xaxis.set_ticklabels(['AKIEC', 'BCC', 'BKL', 'DF', 'MEL', 'NV', 'VASC'])\n",
        "ax.yaxis.set_ticklabels(['AKIEC', 'BCC', 'BKL', 'DF', 'MEL', 'NV', 'VASC'])\n",
        "\n",
        "plt.rcParams[\"figure.figsize\"] = (15,3)\n",
        "\n",
        "## Display the visualization of the Confusion Matrix.\n",
        "plt.xticks(rotation=45, ha='right')\n",
        "plt.yticks(rotation=0, ha='right')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ey-1yjWGeKs7"
      },
      "outputs": [],
      "source": [
        "# ordered count of rows per unique label\n",
        "#labels_count = df_val['Labels'].value_counts().sort_index()\n",
        "\n",
        "#f = plt.figure(figsize=(15, 6))\n",
        "#s = sns.barplot(x=labels_count.index,y=labels_count.values)\n",
        "#s.set_xticklabels(s.get_xticklabels(), rotation = 30)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3K908bbiYwbS"
      },
      "source": [
        "#Testing"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_test = pd.read_pickle(path+\"isic2018_test.pkl\")\n",
        "X_train = df_test.loc[:, df_test.columns != 'y_train'].to_numpy()\n",
        "X_train = X_train.reshape(-1,224,224,3)"
      ],
      "metadata": {
        "id": "cN98sOWPyT3P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "NeMY2yvMYxsC"
      },
      "outputs": [],
      "source": [
        "#dir_test = '/content/drive/MyDrive/PHD/Datasets/isic2018/ISIC2018_Task3_Test_Input/'\n",
        "#filepaths = sorted( filter( lambda x: (os.path.isfile(os.path.join(dir_test, x))) and (x.endswith('.jpg')),\n",
        "#                        os.listdir(dir_test) ) )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "6ic95mefkpG3"
      },
      "outputs": [],
      "source": [
        "#df_test = pd.DataFrame(filepaths, columns =['image'])\n",
        "#df_test['FilePaths'] = dir_test + df_test['image']\n",
        "#df_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "NBa1TxPuY8ni"
      },
      "outputs": [],
      "source": [
        "#df_test['image_px'] = df_test['FilePaths'].map(lambda x: np.asarray(Image.open(x).resize(IMG_SIZE)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "60LYAT7VsNOZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "33bd32fe-fac9-4d07-87a9-2cce7336b6dd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1512, 224, 224, 3)\n"
          ]
        }
      ],
      "source": [
        "#X_test = np.asarray(df_test['image_px'].tolist())\n",
        "#print(np.array(X_test).shape)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#df3 = pd.DataFrame(X_test.reshape(X_test.shape[0],-1))\n",
        "#df3.to_pickle(path+\"isic2018_test.pkl\")"
      ],
      "metadata": {
        "id": "JC17MArBxhSW"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "cXnnIIwC4cHE"
      },
      "outputs": [],
      "source": [
        "#preprocess\n",
        "#X_test = preprocess_image_input(X_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FF7ml90JZ8FK"
      },
      "source": [
        "Calculate y_pred from training and testing for analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "KeDTXdaMLmyU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a6ea64da-79f0-424f-f913-5b0bd6c66170"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1512, 2048)"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ],
      "source": [
        "X_test = model1.predict(X_test)\n",
        "X_test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "dIX0AmEFNv3Y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3b58601a-b55c-4ef2-b817-f788416ed73c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Y_pred2 (1512, 7)\n"
          ]
        }
      ],
      "source": [
        "# predicting\n",
        "#CHANGE THE MODEL IF NECESSARY\n",
        "Y_test2 = model.predict(X_test)\n",
        "#Y_pred2 = model2.predict(X_test)\n",
        "print(\"Y_pred2\", Y_pred2.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "7oeArO5CtxGb"
      },
      "outputs": [],
      "source": [
        "df_pred = pd.DataFrame(Y_pred2, columns = ['AKIEC', 'BCC', 'BKL', 'DF', 'MEL', 'NV', 'VASC'])\n",
        "df_pred['image'] = df_test['FilePaths'].map(lambda x: x.replace(dir_test, '').replace('.jpg', ''))\n",
        "df_pred = df_pred[['image', 'MEL', 'NV', 'BCC', 'AKIEC', 'BKL', 'DF', 'VASC']]\n",
        "df_pred.set_index(\"image\", inplace = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9ynyd8PjT589"
      },
      "outputs": [],
      "source": [
        "#update MEL data using cut-off value\n",
        "df_pred.MEL[df_pred.MEL > i] = 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fjRdONoQVMq0"
      },
      "outputs": [],
      "source": [
        "df_pred.loc[df_pred.MEL > i, ['NV', 'BCC', 'AKIEC', 'BKL', 'DF', 'VASC']] = 0"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_pred.head(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "id": "K4Iv_3s4z0R9",
        "outputId": "a7dca29b-4c36-4693-d619-9bd440e6a18f"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                   MEL        NV       BCC     AKIEC       BKL        DF  \\\n",
              "image                                                                      \n",
              "ISIC_0034524  0.002193  0.930769  0.003427  0.000460  0.036592  0.004333   \n",
              "ISIC_0034525  0.122186  0.828252  0.002661  0.010148  0.009148  0.021819   \n",
              "ISIC_0034526  0.020197  0.003637  0.000938  0.028031  0.947131  0.000066   \n",
              "ISIC_0034527  0.131679  0.808747  0.000006  0.000279  0.059272  0.000017   \n",
              "ISIC_0034528  0.005777  0.840918  0.000002  0.000037  0.151937  0.001316   \n",
              "\n",
              "                      VASC  \n",
              "image                       \n",
              "ISIC_0034524  2.222793e-02  \n",
              "ISIC_0034525  5.786379e-03  \n",
              "ISIC_0034526  1.199605e-08  \n",
              "ISIC_0034527  6.856867e-08  \n",
              "ISIC_0034528  1.348875e-05  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5268f553-0d89-461e-9c87-fc1271d7e6d5\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>MEL</th>\n",
              "      <th>NV</th>\n",
              "      <th>BCC</th>\n",
              "      <th>AKIEC</th>\n",
              "      <th>BKL</th>\n",
              "      <th>DF</th>\n",
              "      <th>VASC</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>image</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>ISIC_0034524</th>\n",
              "      <td>0.002193</td>\n",
              "      <td>0.930769</td>\n",
              "      <td>0.003427</td>\n",
              "      <td>0.000460</td>\n",
              "      <td>0.036592</td>\n",
              "      <td>0.004333</td>\n",
              "      <td>2.222793e-02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ISIC_0034525</th>\n",
              "      <td>0.122186</td>\n",
              "      <td>0.828252</td>\n",
              "      <td>0.002661</td>\n",
              "      <td>0.010148</td>\n",
              "      <td>0.009148</td>\n",
              "      <td>0.021819</td>\n",
              "      <td>5.786379e-03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ISIC_0034526</th>\n",
              "      <td>0.020197</td>\n",
              "      <td>0.003637</td>\n",
              "      <td>0.000938</td>\n",
              "      <td>0.028031</td>\n",
              "      <td>0.947131</td>\n",
              "      <td>0.000066</td>\n",
              "      <td>1.199605e-08</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ISIC_0034527</th>\n",
              "      <td>0.131679</td>\n",
              "      <td>0.808747</td>\n",
              "      <td>0.000006</td>\n",
              "      <td>0.000279</td>\n",
              "      <td>0.059272</td>\n",
              "      <td>0.000017</td>\n",
              "      <td>6.856867e-08</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ISIC_0034528</th>\n",
              "      <td>0.005777</td>\n",
              "      <td>0.840918</td>\n",
              "      <td>0.000002</td>\n",
              "      <td>0.000037</td>\n",
              "      <td>0.151937</td>\n",
              "      <td>0.001316</td>\n",
              "      <td>1.348875e-05</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5268f553-0d89-461e-9c87-fc1271d7e6d5')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-5268f553-0d89-461e-9c87-fc1271d7e6d5 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-5268f553-0d89-461e-9c87-fc1271d7e6d5');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "sOnjc3RJ0e4T"
      },
      "outputs": [],
      "source": [
        "df_pred.to_csv('/content/drive/MyDrive/PHD/Datasets/isic2018/response_Borderline-SMOTE.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P0MghVs0tsGw"
      },
      "source": [
        "result: 0.656"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UswA0co2y1wl"
      },
      "source": [
        "#Exp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dnqJYIONy34l"
      },
      "outputs": [],
      "source": [
        "input_tensor = Input(shape=(IMAGE_H, IMAGE_W, 3))\n",
        "base_model = ResNet50(input_shape=(224,224,3), weights='imagenet', include_top=False)\n",
        "x = base_model(input_tensor, training=False)\n",
        "x = Attention(2048,2048,7,8)(x)\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "res50 = Model(inputs=input_tensor, outputs=x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kcn8hQg3J8yP"
      },
      "outputs": [],
      "source": [
        "#Train i-last layer\n",
        "# summarize feature map shapes\n",
        "for i in range(len(model.layers)):\n",
        "    layer = model.layers[i]\n",
        "    # summarize output shape\n",
        "    print(i, layer.name, layer.output.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UA7Af2Y73FUv"
      },
      "outputs": [],
      "source": [
        "X_train = res50.predict(X_train)\n",
        "X_val = res50.predict(X_val)\n",
        "print(X_train.shape)\n",
        "print(y_train.shape)\n",
        "print(X_val.shape)\n",
        "print(y_val.shape)\n",
        "print('Counter train data: ', Counter(np.argmax(y_train, axis=1)))\n",
        "print('Counter val data: ', Counter(np.argmax(y_val, axis=1)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "krJiAb1m3QNf"
      },
      "outputs": [],
      "source": [
        "X_train, y_train = SMOTE_Data2(X_train, y_train, True)\n",
        "print(X_train.shape)\n",
        "print(y_train.shape)\n",
        "print(X_val.shape)\n",
        "print(y_val.shape)\n",
        "print('Counter train data: ', Counter(np.argmax(y_train, axis=1)))\n",
        "print('Counter val data: ', Counter(np.argmax(y_val, axis=1)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LfcFpsBwM0d4"
      },
      "source": [
        "#Attention"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C_s6OIGKM26a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 398
        },
        "outputId": "371bd24a-4bf9-491a-e0ec-78b7eb06e6d9"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-ff488085aaa5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mConv2D\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mMaxPooling2D\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mAveragePooling2D\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mBatchNormalization\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mAdd\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mZeroPadding2D\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mFlatten\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mInput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mLeakyReLU\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mSoftmax\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mReLU\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAdam\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    471\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_current_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"keras\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    472\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 473\u001b[0;31m     \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    474\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    475\u001b[0m     \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/lazy_loader.py\u001b[0m in \u001b[0;36m_load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;34m\"\"\"Load the module and insert it into the parent's globals.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0;31m# Import the target module and insert it into the parent's namespace\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m     \u001b[0mmodule\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimportlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimport_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_module_globals\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_local_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/importlib/__init__.py\u001b[0m in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m    125\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m             \u001b[0mlevel\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_bootstrap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gcd_import\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpackage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;31m# See b/110718070#comment18 for more details about this import.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_layer\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mInput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/models.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv2\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmetrics\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmetrics_module\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0moptimizer_v1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfunctional\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/metrics.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mwarnings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mactivations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbase_layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/activations.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0madvanced_activations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgeneric_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdeserialize_keras_object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgeneric_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mserialize_keras_object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/layers/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_spec\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mInputSpec\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_layer\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLayer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_preprocessing_layer\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPreprocessingLayer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;31m# Image preprocessing layers.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/base_preprocessing_layer.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mabc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdata_adapter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_layer\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLayer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mversion_utils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m   \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m  \u001b[0;31m# pylint: disable=g-import-not-at-top\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m   \u001b[0mpd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tester\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 179\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtesting\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    180\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/testing.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m from pandas._testing import (\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0massert_extension_array_equal\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0massert_frame_equal\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/_testing/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    946\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    947\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 948\u001b[0;31m \u001b[0mcython_table\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommon\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cython_table\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    949\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    950\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: module 'pandas' has no attribute 'core'"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow.keras as tk\n",
        "from tensorflow.keras.layers import Conv2D,MaxPooling2D,AveragePooling2D,BatchNormalization,Add,ZeroPadding2D,Flatten,Dense,Input,LeakyReLU,Softmax,ReLU\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.models import Model\n",
        "import numpy as np\n",
        "import pickle\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "\n",
        "class Attention(tk.layers.Layer):\n",
        "    \n",
        "    def __init__(self,input_channels,output_channel,kernel_size,groups):\n",
        "        super().__init__()\n",
        "        self.input_channels = input_channels\n",
        "        self.output_channel = output_channel    \n",
        "        self.kernel_size = kernel_size\n",
        "        self.stride = 1\n",
        "        self.groups = groups\n",
        "\n",
        "        assert output_channel % groups == 0\n",
        "        \n",
        "        self.rel_h = tk.backend.variable(lambda : tk.backend.truncated_normal((1,1,kernel_size,1,output_channel//2),stddev = 0.1)) \n",
        "        #output_channels//2 is the number of channels on which the relative position will be considered,1 denotes the number of those filters and the one after that too and (kernel_size,1) denotes the size of that filter\n",
        "        self.rel_w = tk.backend.variable(lambda : tk.backend.truncated_normal((1,1,1,kernel_size,output_channel//2),stddev = 0.1)) \n",
        "\n",
        "        self.key_weights = Conv2D(self.output_channel,kernel_size = 1,strides = self.stride)\n",
        "        self.query_weights = Conv2D(self.output_channel,kernel_size = 1,strides = self.stride)\n",
        "        self.value_weights = Conv2D(self.output_channel,kernel_size = 1,strides = self.stride)\n",
        "\n",
        "    def call(self,x):\n",
        "        \n",
        "        batch,height,width,channels = x.shape\n",
        "        x_padded = ZeroPadding2D(padding=(self.kernel_size//2,self.kernel_size//2))(x)\n",
        "        query = self.query_weights(x)\n",
        "        value = self.value_weights(x_padded)\n",
        "        key = self.key_weights(x_padded)\n",
        "        #key,query and value will have the shape of (batch,height,width,depth)\n",
        "        keys = tf.image.extract_patches(images = key,sizes = [1,self.kernel_size,self.kernel_size,1],strides = [1,self.stride,self.stride,1],rates = [1,1,1,1], padding = \"VALID\")\n",
        "        value = tf.image.extract_patches(images = value,sizes = [1,self.kernel_size,self.kernel_size,1],strides = [1,self.stride,self.stride,1],rates = [1,1,1,1], padding = \"VALID\")\n",
        "        no_of_kernels = key.shape[-2] - self.kernel_size + 1\n",
        "        keys = tf.reshape(keys,shape = (-1,no_of_kernels, no_of_kernels,self.kernel_size,self.kernel_size,self.output_channel))\n",
        "        key_split_h,key_split_w = tf.split(keys,num_or_size_splits = 2,axis = -1)\n",
        "        key_with_rel = tk.layers.concatenate([key_split_h + self.rel_h,key_split_w + self.rel_w],axis = -1) \n",
        "        \n",
        "        #reshaping the query and key\n",
        "        key_with_rel = tf.reshape(key_with_rel,(-1,self.groups,no_of_kernels,no_of_kernels,self.kernel_size*self.kernel_size,self.output_channel//self.groups))\n",
        "        query  = tf.reshape(query,(-1,self.groups,no_of_kernels,no_of_kernels,1,self.output_channel//self.groups))        \n",
        "        value = tf.reshape(value,(-1,self.groups,no_of_kernels,no_of_kernels,self.kernel_size*self.kernel_size,self.output_channel//self.groups))\n",
        "        \n",
        "        #multiplication  of key and query\n",
        "        #assert key_with_rel.shape == query.shape        \n",
        "        key_prod_query = query*key_with_rel\n",
        "        \n",
        "        # Now the function is passed through the softmax and is multiplied with the values\n",
        "        s = Softmax(axis = -2)(key_prod_query)\n",
        "        y = tf.einsum('bnchwk,bnchwk->bnchk',s,value)\n",
        "        y = tf.reshape(y,(-1,height,width,self.output_channel))\n",
        "        return y\n",
        "\n",
        "    def get_config(self):\n",
        "        config = super().get_config().copy()\n",
        "        config.update({\n",
        "            \"input_channels\": self.input_channels, \n",
        "            \"output_channel\": self.output_channel, \n",
        "            \"kernel_size\": self.kernel_size, \n",
        "            \"stride\": self.stride, \n",
        "            \"groups\": self.groups, \n",
        "            \"rel_h\": self.rel_h, \n",
        "            \"rel_w\": self.rel_w, \n",
        "            \"key_weights\": self.key_weights, \n",
        "            \"query_weights\": self.query_weights, \n",
        "            \"value_weights\": self.value_weights\n",
        "        })\n",
        "        return config\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kE8Ziq-BlEP4"
      },
      "source": [
        "#Oversampling on feature map level"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "Lm05Zet_B5am",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "81b00112-bfdc-41d4-aa2f-da035d40a9d8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 input_2 [(None, 224, 224, 3)] False\n",
            "1 conv1_pad (None, 230, 230, 3) False\n",
            "2 conv1_conv (None, 112, 112, 64) False\n",
            "3 conv1_bn (None, 112, 112, 64) False\n",
            "4 conv1_relu (None, 112, 112, 64) False\n",
            "5 pool1_pad (None, 114, 114, 64) False\n",
            "6 pool1_pool (None, 56, 56, 64) False\n",
            "7 conv2_block1_1_conv (None, 56, 56, 64) False\n",
            "8 conv2_block1_1_bn (None, 56, 56, 64) False\n",
            "9 conv2_block1_1_relu (None, 56, 56, 64) False\n",
            "10 conv2_block1_2_conv (None, 56, 56, 64) False\n",
            "11 conv2_block1_2_bn (None, 56, 56, 64) False\n",
            "12 conv2_block1_2_relu (None, 56, 56, 64) False\n",
            "13 conv2_block1_0_conv (None, 56, 56, 256) False\n",
            "14 conv2_block1_3_conv (None, 56, 56, 256) False\n",
            "15 conv2_block1_0_bn (None, 56, 56, 256) False\n",
            "16 conv2_block1_3_bn (None, 56, 56, 256) False\n",
            "17 conv2_block1_add (None, 56, 56, 256) False\n",
            "18 conv2_block1_out (None, 56, 56, 256) False\n",
            "19 conv2_block2_1_conv (None, 56, 56, 64) False\n",
            "20 conv2_block2_1_bn (None, 56, 56, 64) False\n",
            "21 conv2_block2_1_relu (None, 56, 56, 64) False\n",
            "22 conv2_block2_2_conv (None, 56, 56, 64) False\n",
            "23 conv2_block2_2_bn (None, 56, 56, 64) False\n",
            "24 conv2_block2_2_relu (None, 56, 56, 64) False\n",
            "25 conv2_block2_3_conv (None, 56, 56, 256) False\n",
            "26 conv2_block2_3_bn (None, 56, 56, 256) False\n",
            "27 conv2_block2_add (None, 56, 56, 256) False\n",
            "28 conv2_block2_out (None, 56, 56, 256) False\n",
            "29 conv2_block3_1_conv (None, 56, 56, 64) False\n",
            "30 conv2_block3_1_bn (None, 56, 56, 64) False\n",
            "31 conv2_block3_1_relu (None, 56, 56, 64) False\n",
            "32 conv2_block3_2_conv (None, 56, 56, 64) False\n",
            "33 conv2_block3_2_bn (None, 56, 56, 64) False\n",
            "34 conv2_block3_2_relu (None, 56, 56, 64) False\n",
            "35 conv2_block3_3_conv (None, 56, 56, 256) False\n",
            "36 conv2_block3_3_bn (None, 56, 56, 256) False\n",
            "37 conv2_block3_add (None, 56, 56, 256) False\n",
            "38 conv2_block3_out (None, 56, 56, 256) False\n",
            "39 conv3_block1_1_conv (None, 28, 28, 128) False\n",
            "40 conv3_block1_1_bn (None, 28, 28, 128) False\n",
            "41 conv3_block1_1_relu (None, 28, 28, 128) False\n",
            "42 conv3_block1_2_conv (None, 28, 28, 128) False\n",
            "43 conv3_block1_2_bn (None, 28, 28, 128) False\n",
            "44 conv3_block1_2_relu (None, 28, 28, 128) False\n",
            "45 conv3_block1_0_conv (None, 28, 28, 512) False\n",
            "46 conv3_block1_3_conv (None, 28, 28, 512) False\n",
            "47 conv3_block1_0_bn (None, 28, 28, 512) False\n",
            "48 conv3_block1_3_bn (None, 28, 28, 512) False\n",
            "49 conv3_block1_add (None, 28, 28, 512) False\n",
            "50 conv3_block1_out (None, 28, 28, 512) False\n",
            "51 conv3_block2_1_conv (None, 28, 28, 128) False\n",
            "52 conv3_block2_1_bn (None, 28, 28, 128) False\n",
            "53 conv3_block2_1_relu (None, 28, 28, 128) False\n",
            "54 conv3_block2_2_conv (None, 28, 28, 128) False\n",
            "55 conv3_block2_2_bn (None, 28, 28, 128) False\n",
            "56 conv3_block2_2_relu (None, 28, 28, 128) False\n",
            "57 conv3_block2_3_conv (None, 28, 28, 512) False\n",
            "58 conv3_block2_3_bn (None, 28, 28, 512) False\n",
            "59 conv3_block2_add (None, 28, 28, 512) False\n",
            "60 conv3_block2_out (None, 28, 28, 512) False\n",
            "61 conv3_block3_1_conv (None, 28, 28, 128) False\n",
            "62 conv3_block3_1_bn (None, 28, 28, 128) False\n",
            "63 conv3_block3_1_relu (None, 28, 28, 128) False\n",
            "64 conv3_block3_2_conv (None, 28, 28, 128) False\n",
            "65 conv3_block3_2_bn (None, 28, 28, 128) False\n",
            "66 conv3_block3_2_relu (None, 28, 28, 128) False\n",
            "67 conv3_block3_3_conv (None, 28, 28, 512) False\n",
            "68 conv3_block3_3_bn (None, 28, 28, 512) False\n",
            "69 conv3_block3_add (None, 28, 28, 512) False\n",
            "70 conv3_block3_out (None, 28, 28, 512) False\n",
            "71 conv3_block4_1_conv (None, 28, 28, 128) False\n",
            "72 conv3_block4_1_bn (None, 28, 28, 128) False\n",
            "73 conv3_block4_1_relu (None, 28, 28, 128) False\n",
            "74 conv3_block4_2_conv (None, 28, 28, 128) False\n",
            "75 conv3_block4_2_bn (None, 28, 28, 128) False\n",
            "76 conv3_block4_2_relu (None, 28, 28, 128) False\n",
            "77 conv3_block4_3_conv (None, 28, 28, 512) False\n",
            "78 conv3_block4_3_bn (None, 28, 28, 512) False\n",
            "79 conv3_block4_add (None, 28, 28, 512) False\n",
            "80 conv3_block4_out (None, 28, 28, 512) False\n",
            "81 conv4_block1_1_conv (None, 14, 14, 256) False\n",
            "82 conv4_block1_1_bn (None, 14, 14, 256) False\n",
            "83 conv4_block1_1_relu (None, 14, 14, 256) False\n",
            "84 conv4_block1_2_conv (None, 14, 14, 256) False\n",
            "85 conv4_block1_2_bn (None, 14, 14, 256) False\n",
            "86 conv4_block1_2_relu (None, 14, 14, 256) False\n",
            "87 conv4_block1_0_conv (None, 14, 14, 1024) False\n",
            "88 conv4_block1_3_conv (None, 14, 14, 1024) False\n",
            "89 conv4_block1_0_bn (None, 14, 14, 1024) False\n",
            "90 conv4_block1_3_bn (None, 14, 14, 1024) False\n",
            "91 conv4_block1_add (None, 14, 14, 1024) False\n",
            "92 conv4_block1_out (None, 14, 14, 1024) False\n",
            "93 conv4_block2_1_conv (None, 14, 14, 256) False\n",
            "94 conv4_block2_1_bn (None, 14, 14, 256) False\n",
            "95 conv4_block2_1_relu (None, 14, 14, 256) False\n",
            "96 conv4_block2_2_conv (None, 14, 14, 256) False\n",
            "97 conv4_block2_2_bn (None, 14, 14, 256) False\n",
            "98 conv4_block2_2_relu (None, 14, 14, 256) False\n",
            "99 conv4_block2_3_conv (None, 14, 14, 1024) False\n",
            "100 conv4_block2_3_bn (None, 14, 14, 1024) False\n",
            "101 conv4_block2_add (None, 14, 14, 1024) False\n",
            "102 conv4_block2_out (None, 14, 14, 1024) False\n",
            "103 conv4_block3_1_conv (None, 14, 14, 256) False\n",
            "104 conv4_block3_1_bn (None, 14, 14, 256) False\n",
            "105 conv4_block3_1_relu (None, 14, 14, 256) False\n",
            "106 conv4_block3_2_conv (None, 14, 14, 256) False\n",
            "107 conv4_block3_2_bn (None, 14, 14, 256) False\n",
            "108 conv4_block3_2_relu (None, 14, 14, 256) False\n",
            "109 conv4_block3_3_conv (None, 14, 14, 1024) False\n",
            "110 conv4_block3_3_bn (None, 14, 14, 1024) False\n",
            "111 conv4_block3_add (None, 14, 14, 1024) False\n",
            "112 conv4_block3_out (None, 14, 14, 1024) False\n",
            "113 conv4_block4_1_conv (None, 14, 14, 256) False\n",
            "114 conv4_block4_1_bn (None, 14, 14, 256) False\n",
            "115 conv4_block4_1_relu (None, 14, 14, 256) False\n",
            "116 conv4_block4_2_conv (None, 14, 14, 256) False\n",
            "117 conv4_block4_2_bn (None, 14, 14, 256) False\n",
            "118 conv4_block4_2_relu (None, 14, 14, 256) False\n",
            "119 conv4_block4_3_conv (None, 14, 14, 1024) False\n",
            "120 conv4_block4_3_bn (None, 14, 14, 1024) False\n",
            "121 conv4_block4_add (None, 14, 14, 1024) False\n",
            "122 conv4_block4_out (None, 14, 14, 1024) False\n",
            "123 conv4_block5_1_conv (None, 14, 14, 256) False\n",
            "124 conv4_block5_1_bn (None, 14, 14, 256) False\n",
            "125 conv4_block5_1_relu (None, 14, 14, 256) False\n",
            "126 conv4_block5_2_conv (None, 14, 14, 256) False\n",
            "127 conv4_block5_2_bn (None, 14, 14, 256) False\n",
            "128 conv4_block5_2_relu (None, 14, 14, 256) False\n",
            "129 conv4_block5_3_conv (None, 14, 14, 1024) False\n",
            "130 conv4_block5_3_bn (None, 14, 14, 1024) False\n",
            "131 conv4_block5_add (None, 14, 14, 1024) False\n",
            "132 conv4_block5_out (None, 14, 14, 1024) False\n",
            "133 conv4_block6_1_conv (None, 14, 14, 256) False\n",
            "134 conv4_block6_1_bn (None, 14, 14, 256) False\n",
            "135 conv4_block6_1_relu (None, 14, 14, 256) False\n",
            "136 conv4_block6_2_conv (None, 14, 14, 256) False\n",
            "137 conv4_block6_2_bn (None, 14, 14, 256) False\n",
            "138 conv4_block6_2_relu (None, 14, 14, 256) False\n",
            "139 conv4_block6_3_conv (None, 14, 14, 1024) False\n",
            "140 conv4_block6_3_bn (None, 14, 14, 1024) False\n",
            "141 conv4_block6_add (None, 14, 14, 1024) False\n",
            "142 conv4_block6_out (None, 14, 14, 1024) False\n",
            "143 conv5_block1_1_conv (None, 7, 7, 512) False\n",
            "144 conv5_block1_1_bn (None, 7, 7, 512) False\n",
            "145 conv5_block1_1_relu (None, 7, 7, 512) False\n",
            "146 conv5_block1_2_conv (None, 7, 7, 512) False\n",
            "147 conv5_block1_2_bn (None, 7, 7, 512) False\n",
            "148 conv5_block1_2_relu (None, 7, 7, 512) False\n",
            "149 conv5_block1_0_conv (None, 7, 7, 2048) False\n",
            "150 conv5_block1_3_conv (None, 7, 7, 2048) False\n",
            "151 conv5_block1_0_bn (None, 7, 7, 2048) False\n",
            "152 conv5_block1_3_bn (None, 7, 7, 2048) False\n",
            "153 conv5_block1_add (None, 7, 7, 2048) False\n",
            "154 conv5_block1_out (None, 7, 7, 2048) False\n",
            "155 conv5_block2_1_conv (None, 7, 7, 512) False\n",
            "156 conv5_block2_1_bn (None, 7, 7, 512) False\n",
            "157 conv5_block2_1_relu (None, 7, 7, 512) False\n",
            "158 conv5_block2_2_conv (None, 7, 7, 512) False\n",
            "159 conv5_block2_2_bn (None, 7, 7, 512) False\n",
            "160 conv5_block2_2_relu (None, 7, 7, 512) False\n",
            "161 conv5_block2_3_conv (None, 7, 7, 2048) False\n",
            "162 conv5_block2_3_bn (None, 7, 7, 2048) False\n",
            "163 conv5_block2_add (None, 7, 7, 2048) False\n",
            "164 conv5_block2_out (None, 7, 7, 2048) False\n",
            "165 conv5_block3_1_conv (None, 7, 7, 512) False\n",
            "166 conv5_block3_1_bn (None, 7, 7, 512) False\n",
            "167 conv5_block3_1_relu (None, 7, 7, 512) False\n",
            "168 conv5_block3_2_conv (None, 7, 7, 512) False\n",
            "169 conv5_block3_2_bn (None, 7, 7, 512) False\n",
            "170 conv5_block3_2_relu (None, 7, 7, 512) False\n",
            "171 conv5_block3_3_conv (None, 7, 7, 2048) False\n",
            "172 conv5_block3_3_bn (None, 7, 7, 2048) False\n",
            "173 conv5_block3_add (None, 7, 7, 2048) False\n",
            "174 conv5_block3_out (None, 7, 7, 2048) False\n",
            "175 global_average_pooling2d_1 (None, 2048) True\n",
            "176 dense_3 (None, 1024) True\n",
            "177 dense_4 (None, 512) True\n",
            "178 dense_5 (None, 7) True\n"
          ]
        }
      ],
      "source": [
        "for i in range(len(model.layers)):\n",
        "  layer = model.layers[i]\n",
        "  print(i, layer.name, layer.output_shape, layer.trainable)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "KqeSic6NmLsR"
      },
      "outputs": [],
      "source": [
        "# redefine model to output right after the first hidden layer\n",
        "end = 175\n",
        "model1 = Model(inputs=model.inputs, outputs=model.layers[end].output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "ZVHYG9Rwm28i"
      },
      "outputs": [],
      "source": [
        "# get feature map for first hidden layer\n",
        "X_train_fm = model1.predict(X_train)\n",
        "X_val_fm = model1.predict(X_val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "VNozN8-wDUNL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "54bb793f-cdc5-49df-d893-a4882d26670a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(193, 2048)\n"
          ]
        }
      ],
      "source": [
        "print(X_val_fm.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "19hK7aQNeAQo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "913b6cac-b79b-4e38-b094-7ac5b4ce6fb1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(14077, 2048)\n",
            "(14077, 7)\n",
            "(193, 224, 224, 3)\n",
            "(193, 7)\n",
            "Counter train data:  Counter({5: 2011, 4: 2011, 2: 2011, 3: 2011, 0: 2011, 1: 2011, 6: 2011})\n",
            "Counter val data:  Counter({5: 123, 2: 22, 4: 21, 1: 15, 0: 8, 6: 3, 3: 1})\n"
          ]
        }
      ],
      "source": [
        "X_train_fm_ov, y_train_ov = SMOTE_Data2(X_train_fm, y_train, True, 5)\n",
        "print(X_train_fm_ov.shape)\n",
        "print(y_train_ov.shape)\n",
        "print(X_val_fm.shape)\n",
        "print(y_val.shape)\n",
        "print('Counter train data: ', Counter(np.argmax(y_train_ov, axis=1)))\n",
        "print('Counter val data: ', Counter(np.argmax(y_val, axis=1)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "5qP4iyYcnAYa"
      },
      "outputs": [],
      "source": [
        "model2 = Model(inputs=model.layers[end+1].input, outputs=model.layers[len(model.layers)-1].output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "Pzdjs0WbvDB0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b2dc9a2f-35cd-4c8b-9a69-0e3103876a5e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "217/219 [============================>.] - ETA: 0s - loss: 0.7611 - accuracy: 0.7544 - balanced_acc: 0.7542\n",
            "Epoch 1: val_balanced_acc did not improve from 0.44139\n",
            "219/219 [==============================] - 2s 4ms/step - loss: 0.7608 - accuracy: 0.7548 - balanced_acc: 0.7544 - val_loss: 0.7893 - val_accuracy: 0.7202 - val_balanced_acc: 0.3897 - lr: 5.0000e-04\n",
            "Epoch 2/100\n",
            "218/219 [============================>.] - ETA: 0s - loss: 0.7207 - accuracy: 0.7688 - balanced_acc: 0.7687\n",
            "Epoch 2: val_balanced_acc did not improve from 0.44139\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.7210 - accuracy: 0.7689 - balanced_acc: 0.7688 - val_loss: 0.8056 - val_accuracy: 0.7202 - val_balanced_acc: 0.4013 - lr: 5.0000e-04\n",
            "Epoch 3/100\n",
            "218/219 [============================>.] - ETA: 0s - loss: 0.6956 - accuracy: 0.7750 - balanced_acc: 0.7741\n",
            "Epoch 3: val_balanced_acc did not improve from 0.44139\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.6954 - accuracy: 0.7749 - balanced_acc: 0.7741 - val_loss: 0.8024 - val_accuracy: 0.7150 - val_balanced_acc: 0.3888 - lr: 5.0000e-04\n",
            "Epoch 4/100\n",
            "218/219 [============================>.] - ETA: 0s - loss: 0.6748 - accuracy: 0.7836 - balanced_acc: 0.7847\n",
            "Epoch 4: val_balanced_acc did not improve from 0.44139\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.6747 - accuracy: 0.7836 - balanced_acc: 0.7848 - val_loss: 0.7801 - val_accuracy: 0.7150 - val_balanced_acc: 0.3951 - lr: 5.0000e-04\n",
            "Epoch 5/100\n",
            "219/219 [==============================] - ETA: 0s - loss: 0.6547 - accuracy: 0.7923 - balanced_acc: 0.7924\n",
            "Epoch 5: val_balanced_acc did not improve from 0.44139\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.6547 - accuracy: 0.7923 - balanced_acc: 0.7924 - val_loss: 0.8027 - val_accuracy: 0.7047 - val_balanced_acc: 0.3892 - lr: 5.0000e-04\n",
            "Epoch 6/100\n",
            "218/219 [============================>.] - ETA: 0s - loss: 0.6403 - accuracy: 0.7975 - balanced_acc: 0.7968\n",
            "Epoch 6: val_balanced_acc did not improve from 0.44139\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.6402 - accuracy: 0.7973 - balanced_acc: 0.7967 - val_loss: 0.7869 - val_accuracy: 0.7098 - val_balanced_acc: 0.3838 - lr: 5.0000e-04\n",
            "Epoch 7/100\n",
            "210/219 [===========================>..] - ETA: 0s - loss: 0.6250 - accuracy: 0.8024 - balanced_acc: 0.8032\n",
            "Epoch 7: val_balanced_acc did not improve from 0.44139\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.6252 - accuracy: 0.8025 - balanced_acc: 0.8030 - val_loss: 0.8063 - val_accuracy: 0.7047 - val_balanced_acc: 0.3892 - lr: 5.0000e-04\n",
            "Epoch 8/100\n",
            "219/219 [==============================] - ETA: 0s - loss: 0.6120 - accuracy: 0.8075 - balanced_acc: 0.8076\n",
            "Epoch 8: val_balanced_acc did not improve from 0.44139\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.6120 - accuracy: 0.8075 - balanced_acc: 0.8076 - val_loss: 0.7607 - val_accuracy: 0.7254 - val_balanced_acc: 0.3927 - lr: 5.0000e-04\n",
            "Epoch 9/100\n",
            "218/219 [============================>.] - ETA: 0s - loss: 0.5990 - accuracy: 0.8125 - balanced_acc: 0.8114\n",
            "Epoch 9: val_balanced_acc did not improve from 0.44139\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.5989 - accuracy: 0.8125 - balanced_acc: 0.8114 - val_loss: 0.7482 - val_accuracy: 0.7358 - val_balanced_acc: 0.3908 - lr: 5.0000e-04\n",
            "Epoch 10/100\n",
            "210/219 [===========================>..] - ETA: 0s - loss: 0.5875 - accuracy: 0.8177 - balanced_acc: 0.8174\n",
            "Epoch 10: val_balanced_acc did not improve from 0.44139\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.5881 - accuracy: 0.8175 - balanced_acc: 0.8174 - val_loss: 0.7348 - val_accuracy: 0.7461 - val_balanced_acc: 0.3961 - lr: 5.0000e-04\n",
            "Epoch 11/100\n",
            "212/219 [============================>.] - ETA: 0s - loss: 0.5722 - accuracy: 0.8213 - balanced_acc: 0.8211\n",
            "Epoch 11: val_balanced_acc did not improve from 0.44139\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.5734 - accuracy: 0.8210 - balanced_acc: 0.8209 - val_loss: 0.7276 - val_accuracy: 0.7461 - val_balanced_acc: 0.3884 - lr: 5.0000e-04\n",
            "Epoch 12/100\n",
            "214/219 [============================>.] - ETA: 0s - loss: 0.5693 - accuracy: 0.8222 - balanced_acc: 0.8220\n",
            "Epoch 12: val_balanced_acc did not improve from 0.44139\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.5697 - accuracy: 0.8219 - balanced_acc: 0.8213 - val_loss: 0.7368 - val_accuracy: 0.7306 - val_balanced_acc: 0.3899 - lr: 5.0000e-04\n",
            "Epoch 13/100\n",
            "216/219 [============================>.] - ETA: 0s - loss: 0.5545 - accuracy: 0.8268 - balanced_acc: 0.8273\n",
            "Epoch 13: val_balanced_acc did not improve from 0.44139\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.5549 - accuracy: 0.8264 - balanced_acc: 0.8270 - val_loss: 0.7274 - val_accuracy: 0.7565 - val_balanced_acc: 0.3979 - lr: 5.0000e-04\n",
            "Epoch 14/100\n",
            "213/219 [============================>.] - ETA: 0s - loss: 0.5468 - accuracy: 0.8305 - balanced_acc: 0.8315\n",
            "Epoch 14: val_balanced_acc did not improve from 0.44139\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.5477 - accuracy: 0.8301 - balanced_acc: 0.8308 - val_loss: 0.7584 - val_accuracy: 0.7098 - val_balanced_acc: 0.4181 - lr: 5.0000e-04\n",
            "Epoch 15/100\n",
            "205/219 [===========================>..] - ETA: 0s - loss: 0.5403 - accuracy: 0.8311 - balanced_acc: 0.8291\n",
            "Epoch 15: val_balanced_acc did not improve from 0.44139\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.5383 - accuracy: 0.8319 - balanced_acc: 0.8301 - val_loss: 0.7276 - val_accuracy: 0.7306 - val_balanced_acc: 0.4190 - lr: 5.0000e-04\n",
            "Epoch 16/100\n",
            "216/219 [============================>.] - ETA: 0s - loss: 0.5278 - accuracy: 0.8380 - balanced_acc: 0.8376\n",
            "Epoch 16: val_balanced_acc did not improve from 0.44139\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.5277 - accuracy: 0.8377 - balanced_acc: 0.8371 - val_loss: 0.7613 - val_accuracy: 0.6995 - val_balanced_acc: 0.4111 - lr: 5.0000e-04\n",
            "Epoch 17/100\n",
            "218/219 [============================>.] - ETA: 0s - loss: 0.5253 - accuracy: 0.8367 - balanced_acc: 0.8374\n",
            "Epoch 17: val_balanced_acc did not improve from 0.44139\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.5258 - accuracy: 0.8362 - balanced_acc: 0.8369 - val_loss: 0.7530 - val_accuracy: 0.7150 - val_balanced_acc: 0.4221 - lr: 5.0000e-04\n",
            "Epoch 18/100\n",
            "218/219 [============================>.] - ETA: 0s - loss: 0.5143 - accuracy: 0.8408 - balanced_acc: 0.8417\n",
            "Epoch 18: val_balanced_acc did not improve from 0.44139\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.5138 - accuracy: 0.8410 - balanced_acc: 0.8419 - val_loss: 0.7256 - val_accuracy: 0.7513 - val_balanced_acc: 0.4242 - lr: 5.0000e-04\n",
            "Epoch 19/100\n",
            "219/219 [==============================] - ETA: 0s - loss: 0.5082 - accuracy: 0.8443 - balanced_acc: 0.8436\n",
            "Epoch 19: val_balanced_acc improved from 0.44139 to 0.45244, saving model to /content/drive/MyDrive/PHD/Model/best_model_attention.h5\n",
            "219/219 [==============================] - 2s 8ms/step - loss: 0.5082 - accuracy: 0.8443 - balanced_acc: 0.8436 - val_loss: 0.7413 - val_accuracy: 0.7202 - val_balanced_acc: 0.4524 - lr: 5.0000e-04\n",
            "Epoch 20/100\n",
            "216/219 [============================>.] - ETA: 0s - loss: 0.5010 - accuracy: 0.8469 - balanced_acc: 0.8487\n",
            "Epoch 20: val_balanced_acc did not improve from 0.45244\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.5011 - accuracy: 0.8470 - balanced_acc: 0.8489 - val_loss: 0.7558 - val_accuracy: 0.7202 - val_balanced_acc: 0.4519 - lr: 5.0000e-04\n",
            "Epoch 21/100\n",
            "217/219 [============================>.] - ETA: 0s - loss: 0.4910 - accuracy: 0.8516 - balanced_acc: 0.8528\n",
            "Epoch 21: val_balanced_acc did not improve from 0.45244\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.4908 - accuracy: 0.8518 - balanced_acc: 0.8530 - val_loss: 0.7313 - val_accuracy: 0.7461 - val_balanced_acc: 0.4275 - lr: 5.0000e-04\n",
            "Epoch 22/100\n",
            "213/219 [============================>.] - ETA: 0s - loss: 0.4873 - accuracy: 0.8519 - balanced_acc: 0.8511\n",
            "Epoch 22: val_balanced_acc did not improve from 0.45244\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.4878 - accuracy: 0.8516 - balanced_acc: 0.8510 - val_loss: 0.7409 - val_accuracy: 0.7150 - val_balanced_acc: 0.4516 - lr: 5.0000e-04\n",
            "Epoch 23/100\n",
            "216/219 [============================>.] - ETA: 0s - loss: 0.4786 - accuracy: 0.8562 - balanced_acc: 0.8562\n",
            "Epoch 23: val_balanced_acc did not improve from 0.45244\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.4781 - accuracy: 0.8562 - balanced_acc: 0.8563 - val_loss: 0.7368 - val_accuracy: 0.7202 - val_balanced_acc: 0.4504 - lr: 5.0000e-04\n",
            "Epoch 24/100\n",
            "215/219 [============================>.] - ETA: 0s - loss: 0.4743 - accuracy: 0.8579 - balanced_acc: 0.8546\n",
            "Epoch 24: val_balanced_acc improved from 0.45244 to 0.45973, saving model to /content/drive/MyDrive/PHD/Model/best_model_attention.h5\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.4753 - accuracy: 0.8575 - balanced_acc: 0.8545 - val_loss: 0.7293 - val_accuracy: 0.7358 - val_balanced_acc: 0.4597 - lr: 5.0000e-04\n",
            "Epoch 25/100\n",
            "214/219 [============================>.] - ETA: 0s - loss: 0.4721 - accuracy: 0.8580 - balanced_acc: 0.8571\n",
            "Epoch 25: val_balanced_acc did not improve from 0.45973\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.4713 - accuracy: 0.8581 - balanced_acc: 0.8570 - val_loss: 0.7299 - val_accuracy: 0.7461 - val_balanced_acc: 0.4551 - lr: 5.0000e-04\n",
            "Epoch 26/100\n",
            "214/219 [============================>.] - ETA: 0s - loss: 0.4622 - accuracy: 0.8627 - balanced_acc: 0.8626\n",
            "Epoch 26: val_balanced_acc did not improve from 0.45973\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.4615 - accuracy: 0.8630 - balanced_acc: 0.8627 - val_loss: 0.7382 - val_accuracy: 0.7254 - val_balanced_acc: 0.4557 - lr: 5.0000e-04\n",
            "Epoch 27/100\n",
            "217/219 [============================>.] - ETA: 0s - loss: 0.4552 - accuracy: 0.8666 - balanced_acc: 0.8666\n",
            "Epoch 27: val_balanced_acc did not improve from 0.45973\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.4560 - accuracy: 0.8663 - balanced_acc: 0.8661 - val_loss: 0.7232 - val_accuracy: 0.7409 - val_balanced_acc: 0.4518 - lr: 5.0000e-04\n",
            "Epoch 28/100\n",
            "210/219 [===========================>..] - ETA: 0s - loss: 0.4531 - accuracy: 0.8645 - balanced_acc: 0.8640\n",
            "Epoch 28: val_balanced_acc did not improve from 0.45973\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.4516 - accuracy: 0.8648 - balanced_acc: 0.8641 - val_loss: 0.7336 - val_accuracy: 0.7461 - val_balanced_acc: 0.4590 - lr: 5.0000e-04\n",
            "Epoch 29/100\n",
            "212/219 [============================>.] - ETA: 0s - loss: 0.4471 - accuracy: 0.8673 - balanced_acc: 0.8659\n",
            "Epoch 29: val_balanced_acc did not improve from 0.45973\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.4467 - accuracy: 0.8669 - balanced_acc: 0.8656 - val_loss: 0.7095 - val_accuracy: 0.7513 - val_balanced_acc: 0.4578 - lr: 5.0000e-04\n",
            "Epoch 30/100\n",
            "213/219 [============================>.] - ETA: 0s - loss: 0.4420 - accuracy: 0.8712 - balanced_acc: 0.8728\n",
            "Epoch 30: val_balanced_acc did not improve from 0.45973\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.4419 - accuracy: 0.8710 - balanced_acc: 0.8723 - val_loss: 0.7241 - val_accuracy: 0.7254 - val_balanced_acc: 0.4578 - lr: 5.0000e-04\n",
            "Epoch 31/100\n",
            "218/219 [============================>.] - ETA: 0s - loss: 0.4378 - accuracy: 0.8715 - balanced_acc: 0.8722\n",
            "Epoch 31: val_balanced_acc did not improve from 0.45973\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.4378 - accuracy: 0.8715 - balanced_acc: 0.8724 - val_loss: 0.7181 - val_accuracy: 0.7461 - val_balanced_acc: 0.4565 - lr: 5.0000e-04\n",
            "Epoch 32/100\n",
            "212/219 [============================>.] - ETA: 0s - loss: 0.4325 - accuracy: 0.8738 - balanced_acc: 0.8723\n",
            "Epoch 32: val_balanced_acc did not improve from 0.45973\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.4316 - accuracy: 0.8740 - balanced_acc: 0.8723 - val_loss: 0.7410 - val_accuracy: 0.7150 - val_balanced_acc: 0.4516 - lr: 5.0000e-04\n",
            "Epoch 33/100\n",
            "216/219 [============================>.] - ETA: 0s - loss: 0.4263 - accuracy: 0.8740 - balanced_acc: 0.8737\n",
            "Epoch 33: val_balanced_acc did not improve from 0.45973\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.4266 - accuracy: 0.8740 - balanced_acc: 0.8736 - val_loss: 0.7264 - val_accuracy: 0.7254 - val_balanced_acc: 0.4557 - lr: 5.0000e-04\n",
            "Epoch 34/100\n",
            "218/219 [============================>.] - ETA: 0s - loss: 0.4199 - accuracy: 0.8793 - balanced_acc: 0.8787\n",
            "Epoch 34: val_balanced_acc did not improve from 0.45973\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.4191 - accuracy: 0.8796 - balanced_acc: 0.8789 - val_loss: 0.7544 - val_accuracy: 0.7150 - val_balanced_acc: 0.4538 - lr: 5.0000e-04\n",
            "Epoch 35/100\n",
            "215/219 [============================>.] - ETA: 0s - loss: 0.4178 - accuracy: 0.8780 - balanced_acc: 0.8778\n",
            "Epoch 35: val_balanced_acc did not improve from 0.45973\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.4174 - accuracy: 0.8784 - balanced_acc: 0.8781 - val_loss: 0.7436 - val_accuracy: 0.7254 - val_balanced_acc: 0.4557 - lr: 5.0000e-04\n",
            "Epoch 36/100\n",
            "213/219 [============================>.] - ETA: 0s - loss: 0.4155 - accuracy: 0.8795 - balanced_acc: 0.8804\n",
            "Epoch 36: val_balanced_acc did not improve from 0.45973\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.4158 - accuracy: 0.8791 - balanced_acc: 0.8797 - val_loss: 0.7196 - val_accuracy: 0.7358 - val_balanced_acc: 0.4528 - lr: 5.0000e-04\n",
            "Epoch 37/100\n",
            "214/219 [============================>.] - ETA: 0s - loss: 0.4117 - accuracy: 0.8787 - balanced_acc: 0.8786\n",
            "Epoch 37: val_balanced_acc did not improve from 0.45973\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.4113 - accuracy: 0.8790 - balanced_acc: 0.8792 - val_loss: 0.7267 - val_accuracy: 0.7358 - val_balanced_acc: 0.4503 - lr: 5.0000e-04\n",
            "Epoch 38/100\n",
            "217/219 [============================>.] - ETA: 0s - loss: 0.4012 - accuracy: 0.8854 - balanced_acc: 0.8854\n",
            "Epoch 38: val_balanced_acc did not improve from 0.45973\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.4010 - accuracy: 0.8855 - balanced_acc: 0.8854 - val_loss: 0.7066 - val_accuracy: 0.7513 - val_balanced_acc: 0.4573 - lr: 5.0000e-04\n",
            "Epoch 39/100\n",
            "218/219 [============================>.] - ETA: 0s - loss: 0.3998 - accuracy: 0.8828 - balanced_acc: 0.8837\n",
            "Epoch 39: val_balanced_acc improved from 0.45973 to 0.46289, saving model to /content/drive/MyDrive/PHD/Model/best_model_attention.h5\n",
            "219/219 [==============================] - 2s 7ms/step - loss: 0.4006 - accuracy: 0.8824 - balanced_acc: 0.8834 - val_loss: 0.7339 - val_accuracy: 0.7306 - val_balanced_acc: 0.4629 - lr: 5.0000e-04\n",
            "Epoch 40/100\n",
            "214/219 [============================>.] - ETA: 0s - loss: 0.3946 - accuracy: 0.8869 - balanced_acc: 0.8871\n",
            "Epoch 40: val_balanced_acc improved from 0.46289 to 0.46484, saving model to /content/drive/MyDrive/PHD/Model/best_model_attention.h5\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.3944 - accuracy: 0.8869 - balanced_acc: 0.8868 - val_loss: 0.7275 - val_accuracy: 0.7409 - val_balanced_acc: 0.4648 - lr: 5.0000e-04\n",
            "Epoch 41/100\n",
            "207/219 [===========================>..] - ETA: 0s - loss: 0.3931 - accuracy: 0.8898 - balanced_acc: 0.8907\n",
            "Epoch 41: val_balanced_acc did not improve from 0.46484\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.3919 - accuracy: 0.8902 - balanced_acc: 0.8910 - val_loss: 0.7216 - val_accuracy: 0.7358 - val_balanced_acc: 0.4577 - lr: 5.0000e-04\n",
            "Epoch 42/100\n",
            "214/219 [============================>.] - ETA: 0s - loss: 0.3915 - accuracy: 0.8875 - balanced_acc: 0.8881\n",
            "Epoch 42: val_balanced_acc did not improve from 0.46484\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.3922 - accuracy: 0.8874 - balanced_acc: 0.8883 - val_loss: 0.7028 - val_accuracy: 0.7565 - val_balanced_acc: 0.4624 - lr: 5.0000e-04\n",
            "Epoch 43/100\n",
            "218/219 [============================>.] - ETA: 0s - loss: 0.3827 - accuracy: 0.8920 - balanced_acc: 0.8925\n",
            "Epoch 43: val_balanced_acc did not improve from 0.46484\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.3822 - accuracy: 0.8921 - balanced_acc: 0.8926 - val_loss: 0.7282 - val_accuracy: 0.7409 - val_balanced_acc: 0.4608 - lr: 5.0000e-04\n",
            "Epoch 44/100\n",
            "214/219 [============================>.] - ETA: 0s - loss: 0.3832 - accuracy: 0.8923 - balanced_acc: 0.8921\n",
            "Epoch 44: val_balanced_acc did not improve from 0.46484\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.3833 - accuracy: 0.8924 - balanced_acc: 0.8924 - val_loss: 0.7037 - val_accuracy: 0.7358 - val_balanced_acc: 0.4530 - lr: 5.0000e-04\n",
            "Epoch 45/100\n",
            "218/219 [============================>.] - ETA: 0s - loss: 0.3790 - accuracy: 0.8938 - balanced_acc: 0.8943\n",
            "Epoch 45: val_balanced_acc did not improve from 0.46484\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.3790 - accuracy: 0.8939 - balanced_acc: 0.8944 - val_loss: 0.7065 - val_accuracy: 0.7409 - val_balanced_acc: 0.4581 - lr: 5.0000e-04\n",
            "Epoch 46/100\n",
            "215/219 [============================>.] - ETA: 0s - loss: 0.3708 - accuracy: 0.8954 - balanced_acc: 0.8965\n",
            "Epoch 46: val_balanced_acc did not improve from 0.46484\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.3711 - accuracy: 0.8954 - balanced_acc: 0.8967 - val_loss: 0.7274 - val_accuracy: 0.7358 - val_balanced_acc: 0.4613 - lr: 5.0000e-04\n",
            "Epoch 47/100\n",
            "213/219 [============================>.] - ETA: 0s - loss: 0.3682 - accuracy: 0.8979 - balanced_acc: 0.8974\n",
            "Epoch 47: val_balanced_acc did not improve from 0.46484\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.3704 - accuracy: 0.8970 - balanced_acc: 0.8970 - val_loss: 0.7095 - val_accuracy: 0.7409 - val_balanced_acc: 0.4648 - lr: 5.0000e-04\n",
            "Epoch 48/100\n",
            "216/219 [============================>.] - ETA: 0s - loss: 0.3655 - accuracy: 0.8987 - balanced_acc: 0.8986\n",
            "Epoch 48: val_balanced_acc did not improve from 0.46484\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.3657 - accuracy: 0.8987 - balanced_acc: 0.8986 - val_loss: 0.7118 - val_accuracy: 0.7409 - val_balanced_acc: 0.4539 - lr: 5.0000e-04\n",
            "Epoch 49/100\n",
            "207/219 [===========================>..] - ETA: 0s - loss: 0.3675 - accuracy: 0.8988 - balanced_acc: 0.8971\n",
            "Epoch 49: val_balanced_acc did not improve from 0.46484\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.3675 - accuracy: 0.8988 - balanced_acc: 0.8977 - val_loss: 0.6959 - val_accuracy: 0.7461 - val_balanced_acc: 0.4590 - lr: 5.0000e-04\n",
            "Epoch 50/100\n",
            "211/219 [===========================>..] - ETA: 0s - loss: 0.3553 - accuracy: 0.9010 - balanced_acc: 0.9030\n",
            "Epoch 50: val_balanced_acc did not improve from 0.46484\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.3569 - accuracy: 0.9002 - balanced_acc: 0.9017 - val_loss: 0.7085 - val_accuracy: 0.7409 - val_balanced_acc: 0.4608 - lr: 5.0000e-04\n",
            "Epoch 51/100\n",
            "217/219 [============================>.] - ETA: 0s - loss: 0.3575 - accuracy: 0.9017 - balanced_acc: 0.9020\n",
            "Epoch 51: val_balanced_acc did not improve from 0.46484\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.3575 - accuracy: 0.9017 - balanced_acc: 0.9021 - val_loss: 0.7068 - val_accuracy: 0.7461 - val_balanced_acc: 0.4632 - lr: 5.0000e-04\n",
            "Epoch 52/100\n",
            "210/219 [===========================>..] - ETA: 0s - loss: 0.3531 - accuracy: 0.9025 - balanced_acc: 0.9024\n",
            "Epoch 52: val_balanced_acc improved from 0.46484 to 0.46491, saving model to /content/drive/MyDrive/PHD/Model/best_model_attention.h5\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.3545 - accuracy: 0.9014 - balanced_acc: 0.9012 - val_loss: 0.6835 - val_accuracy: 0.7565 - val_balanced_acc: 0.4649 - lr: 5.0000e-04\n",
            "Epoch 53/100\n",
            "210/219 [===========================>..] - ETA: 0s - loss: 0.3497 - accuracy: 0.9038 - balanced_acc: 0.9042\n",
            "Epoch 53: val_balanced_acc did not improve from 0.46491\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.3514 - accuracy: 0.9029 - balanced_acc: 0.9034 - val_loss: 0.6702 - val_accuracy: 0.7565 - val_balanced_acc: 0.4582 - lr: 5.0000e-04\n",
            "Epoch 54/100\n",
            "216/219 [============================>.] - ETA: 0s - loss: 0.3491 - accuracy: 0.9049 - balanced_acc: 0.9053\n",
            "Epoch 54: val_balanced_acc did not improve from 0.46491\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.3490 - accuracy: 0.9046 - balanced_acc: 0.9049 - val_loss: 0.7076 - val_accuracy: 0.7358 - val_balanced_acc: 0.4579 - lr: 5.0000e-04\n",
            "Epoch 55/100\n",
            "214/219 [============================>.] - ETA: 0s - loss: 0.3434 - accuracy: 0.9059 - balanced_acc: 0.9067\n",
            "Epoch 55: val_balanced_acc did not improve from 0.46491\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.3443 - accuracy: 0.9054 - balanced_acc: 0.9061 - val_loss: 0.7172 - val_accuracy: 0.7409 - val_balanced_acc: 0.4648 - lr: 5.0000e-04\n",
            "Epoch 56/100\n",
            "217/219 [============================>.] - ETA: 0s - loss: 0.3413 - accuracy: 0.9077 - balanced_acc: 0.9067\n",
            "Epoch 56: val_balanced_acc improved from 0.46491 to 0.46576, saving model to /content/drive/MyDrive/PHD/Model/best_model_attention.h5\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.3414 - accuracy: 0.9076 - balanced_acc: 0.9067 - val_loss: 0.6852 - val_accuracy: 0.7617 - val_balanced_acc: 0.4658 - lr: 5.0000e-04\n",
            "Epoch 57/100\n",
            "219/219 [==============================] - ETA: 0s - loss: 0.3398 - accuracy: 0.9069 - balanced_acc: 0.9059\n",
            "Epoch 57: val_balanced_acc did not improve from 0.46576\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.3398 - accuracy: 0.9069 - balanced_acc: 0.9059 - val_loss: 0.6840 - val_accuracy: 0.7617 - val_balanced_acc: 0.4658 - lr: 5.0000e-04\n",
            "Epoch 58/100\n",
            "218/219 [============================>.] - ETA: 0s - loss: 0.3344 - accuracy: 0.9096 - balanced_acc: 0.9091\n",
            "Epoch 58: val_balanced_acc did not improve from 0.46576\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.3343 - accuracy: 0.9097 - balanced_acc: 0.9091 - val_loss: 0.7152 - val_accuracy: 0.7461 - val_balanced_acc: 0.4632 - lr: 5.0000e-04\n",
            "Epoch 59/100\n",
            "204/219 [==========================>...] - ETA: 0s - loss: 0.3325 - accuracy: 0.9099 - balanced_acc: 0.9101\n",
            "Epoch 59: val_balanced_acc improved from 0.46576 to 0.46593, saving model to /content/drive/MyDrive/PHD/Model/best_model_attention.h5\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.3346 - accuracy: 0.9089 - balanced_acc: 0.9087 - val_loss: 0.7102 - val_accuracy: 0.7461 - val_balanced_acc: 0.4659 - lr: 5.0000e-04\n",
            "Epoch 60/100\n",
            "216/219 [============================>.] - ETA: 0s - loss: 0.3318 - accuracy: 0.9088 - balanced_acc: 0.9082\n",
            "Epoch 60: val_balanced_acc did not improve from 0.46593\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.3318 - accuracy: 0.9088 - balanced_acc: 0.9083 - val_loss: 0.7138 - val_accuracy: 0.7254 - val_balanced_acc: 0.4560 - lr: 5.0000e-04\n",
            "Epoch 61/100\n",
            "214/219 [============================>.] - ETA: 0s - loss: 0.3257 - accuracy: 0.9140 - balanced_acc: 0.9138\n",
            "Epoch 61: val_balanced_acc did not improve from 0.46593\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.3252 - accuracy: 0.9140 - balanced_acc: 0.9137 - val_loss: 0.7153 - val_accuracy: 0.7409 - val_balanced_acc: 0.4648 - lr: 5.0000e-04\n",
            "Epoch 62/100\n",
            "208/219 [===========================>..] - ETA: 0s - loss: 0.3248 - accuracy: 0.9107 - balanced_acc: 0.9101\n",
            "Epoch 62: val_balanced_acc did not improve from 0.46593\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.3254 - accuracy: 0.9095 - balanced_acc: 0.9089 - val_loss: 0.6975 - val_accuracy: 0.7461 - val_balanced_acc: 0.4590 - lr: 5.0000e-04\n",
            "Epoch 63/100\n",
            "210/219 [===========================>..] - ETA: 0s - loss: 0.3242 - accuracy: 0.9124 - balanced_acc: 0.9137\n",
            "Epoch 63: val_balanced_acc improved from 0.46593 to 0.47274, saving model to /content/drive/MyDrive/PHD/Model/best_model_attention.h5\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.3223 - accuracy: 0.9134 - balanced_acc: 0.9145 - val_loss: 0.6916 - val_accuracy: 0.7565 - val_balanced_acc: 0.4727 - lr: 5.0000e-04\n",
            "Epoch 64/100\n",
            "212/219 [============================>.] - ETA: 0s - loss: 0.3161 - accuracy: 0.9163 - balanced_acc: 0.9168\n",
            "Epoch 64: val_balanced_acc did not improve from 0.47274\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.3158 - accuracy: 0.9170 - balanced_acc: 0.9175 - val_loss: 0.7060 - val_accuracy: 0.7409 - val_balanced_acc: 0.4651 - lr: 5.0000e-04\n",
            "Epoch 65/100\n",
            "214/219 [============================>.] - ETA: 0s - loss: 0.3190 - accuracy: 0.9127 - balanced_acc: 0.9124\n",
            "Epoch 65: val_balanced_acc did not improve from 0.47274\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.3188 - accuracy: 0.9132 - balanced_acc: 0.9127 - val_loss: 0.7074 - val_accuracy: 0.7461 - val_balanced_acc: 0.4659 - lr: 5.0000e-04\n",
            "Epoch 66/100\n",
            "212/219 [============================>.] - ETA: 0s - loss: 0.3138 - accuracy: 0.9153 - balanced_acc: 0.9146\n",
            "Epoch 66: val_balanced_acc did not improve from 0.47274\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.3143 - accuracy: 0.9151 - balanced_acc: 0.9144 - val_loss: 0.7076 - val_accuracy: 0.7358 - val_balanced_acc: 0.4579 - lr: 5.0000e-04\n",
            "Epoch 67/100\n",
            "214/219 [============================>.] - ETA: 0s - loss: 0.3122 - accuracy: 0.9165 - balanced_acc: 0.9161\n",
            "Epoch 67: val_balanced_acc did not improve from 0.47274\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.3134 - accuracy: 0.9162 - balanced_acc: 0.9161 - val_loss: 0.7015 - val_accuracy: 0.7461 - val_balanced_acc: 0.4632 - lr: 5.0000e-04\n",
            "Epoch 68/100\n",
            "215/219 [============================>.] - ETA: 0s - loss: 0.3101 - accuracy: 0.9175 - balanced_acc: 0.9172\n",
            "Epoch 68: val_balanced_acc did not improve from 0.47274\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.3112 - accuracy: 0.9166 - balanced_acc: 0.9160 - val_loss: 0.6830 - val_accuracy: 0.7565 - val_balanced_acc: 0.4586 - lr: 5.0000e-04\n",
            "Epoch 69/100\n",
            "212/219 [============================>.] - ETA: 0s - loss: 0.3041 - accuracy: 0.9197 - balanced_acc: 0.9200\n",
            "Epoch 69: val_balanced_acc did not improve from 0.47274\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.3043 - accuracy: 0.9192 - balanced_acc: 0.9195 - val_loss: 0.6770 - val_accuracy: 0.7617 - val_balanced_acc: 0.4658 - lr: 5.0000e-04\n",
            "Epoch 70/100\n",
            "206/219 [===========================>..] - ETA: 0s - loss: 0.3030 - accuracy: 0.9198 - balanced_acc: 0.9213\n",
            "Epoch 70: val_balanced_acc did not improve from 0.47274\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.3021 - accuracy: 0.9200 - balanced_acc: 0.9212 - val_loss: 0.6834 - val_accuracy: 0.7565 - val_balanced_acc: 0.4622 - lr: 5.0000e-04\n",
            "Epoch 71/100\n",
            "214/219 [============================>.] - ETA: 0s - loss: 0.3005 - accuracy: 0.9202 - balanced_acc: 0.9202\n",
            "Epoch 71: val_balanced_acc did not improve from 0.47274\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.3009 - accuracy: 0.9199 - balanced_acc: 0.9200 - val_loss: 0.6959 - val_accuracy: 0.7617 - val_balanced_acc: 0.4700 - lr: 5.0000e-04\n",
            "Epoch 72/100\n",
            "216/219 [============================>.] - ETA: 0s - loss: 0.3049 - accuracy: 0.9175 - balanced_acc: 0.9175\n",
            "Epoch 72: val_balanced_acc did not improve from 0.47274\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.3044 - accuracy: 0.9178 - balanced_acc: 0.9178 - val_loss: 0.6702 - val_accuracy: 0.7617 - val_balanced_acc: 0.4646 - lr: 5.0000e-04\n",
            "Epoch 73/100\n",
            "215/219 [============================>.] - ETA: 0s - loss: 0.2950 - accuracy: 0.9224 - balanced_acc: 0.9219\n",
            "Epoch 73: val_balanced_acc did not improve from 0.47274\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.2954 - accuracy: 0.9220 - balanced_acc: 0.9217 - val_loss: 0.6965 - val_accuracy: 0.7409 - val_balanced_acc: 0.4624 - lr: 5.0000e-04\n",
            "Epoch 74/100\n",
            "213/219 [============================>.] - ETA: 0s - loss: 0.2940 - accuracy: 0.9233 - balanced_acc: 0.9224\n",
            "Epoch 74: val_balanced_acc did not improve from 0.47274\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.2941 - accuracy: 0.9234 - balanced_acc: 0.9225 - val_loss: 0.6882 - val_accuracy: 0.7461 - val_balanced_acc: 0.4605 - lr: 5.0000e-04\n",
            "Epoch 75/100\n",
            "214/219 [============================>.] - ETA: 0s - loss: 0.2929 - accuracy: 0.9210 - balanced_acc: 0.9199\n",
            "Epoch 75: val_balanced_acc did not improve from 0.47274\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.2924 - accuracy: 0.9211 - balanced_acc: 0.9201 - val_loss: 0.6878 - val_accuracy: 0.7565 - val_balanced_acc: 0.4649 - lr: 5.0000e-04\n",
            "Epoch 76/100\n",
            "212/219 [============================>.] - ETA: 0s - loss: 0.2904 - accuracy: 0.9243 - balanced_acc: 0.9258\n",
            "Epoch 76: val_balanced_acc did not improve from 0.47274\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.2902 - accuracy: 0.9239 - balanced_acc: 0.9253 - val_loss: 0.6962 - val_accuracy: 0.7409 - val_balanced_acc: 0.4588 - lr: 5.0000e-04\n",
            "Epoch 77/100\n",
            "209/219 [===========================>..] - ETA: 0s - loss: 0.2919 - accuracy: 0.9219 - balanced_acc: 0.9213\n",
            "Epoch 77: val_balanced_acc did not improve from 0.47274\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.2912 - accuracy: 0.9221 - balanced_acc: 0.9213 - val_loss: 0.6975 - val_accuracy: 0.7461 - val_balanced_acc: 0.4605 - lr: 5.0000e-04\n",
            "Epoch 78/100\n",
            "207/219 [===========================>..] - ETA: 0s - loss: 0.2791 - accuracy: 0.9274 - balanced_acc: 0.9280\n",
            "Epoch 78: val_balanced_acc did not improve from 0.47274\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.2793 - accuracy: 0.9272 - balanced_acc: 0.9277 - val_loss: 0.6786 - val_accuracy: 0.7513 - val_balanced_acc: 0.4605 - lr: 5.0000e-04\n",
            "Epoch 79/100\n",
            "206/219 [===========================>..] - ETA: 0s - loss: 0.2913 - accuracy: 0.9215 - balanced_acc: 0.9199\n",
            "Epoch 79: val_balanced_acc did not improve from 0.47274\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.2902 - accuracy: 0.9224 - balanced_acc: 0.9211 - val_loss: 0.6853 - val_accuracy: 0.7461 - val_balanced_acc: 0.4542 - lr: 5.0000e-04\n",
            "Epoch 80/100\n",
            "206/219 [===========================>..] - ETA: 0s - loss: 0.2793 - accuracy: 0.9257 - balanced_acc: 0.9252\n",
            "Epoch 80: val_balanced_acc did not improve from 0.47274\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.2810 - accuracy: 0.9250 - balanced_acc: 0.9249 - val_loss: 0.6997 - val_accuracy: 0.7358 - val_balanced_acc: 0.4579 - lr: 5.0000e-04\n",
            "Epoch 81/100\n",
            "206/219 [===========================>..] - ETA: 0s - loss: 0.2818 - accuracy: 0.9263 - balanced_acc: 0.9276\n",
            "Epoch 81: val_balanced_acc did not improve from 0.47274\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.2815 - accuracy: 0.9264 - balanced_acc: 0.9280 - val_loss: 0.6753 - val_accuracy: 0.7617 - val_balanced_acc: 0.4673 - lr: 5.0000e-04\n",
            "Epoch 82/100\n",
            "208/219 [===========================>..] - ETA: 0s - loss: 0.2754 - accuracy: 0.9261 - balanced_acc: 0.9251\n",
            "Epoch 82: val_balanced_acc did not improve from 0.47274\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.2750 - accuracy: 0.9264 - balanced_acc: 0.9253 - val_loss: 0.6990 - val_accuracy: 0.7461 - val_balanced_acc: 0.4639 - lr: 5.0000e-04\n",
            "Epoch 83/100\n",
            "210/219 [===========================>..] - ETA: 0s - loss: 0.2744 - accuracy: 0.9296 - balanced_acc: 0.9293\n",
            "Epoch 83: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "\n",
            "Epoch 83: val_balanced_acc did not improve from 0.47274\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.2737 - accuracy: 0.9298 - balanced_acc: 0.9294 - val_loss: 0.6966 - val_accuracy: 0.7461 - val_balanced_acc: 0.4632 - lr: 5.0000e-04\n",
            "Epoch 84/100\n",
            "207/219 [===========================>..] - ETA: 0s - loss: 0.2749 - accuracy: 0.9282 - balanced_acc: 0.9277\n",
            "Epoch 84: val_balanced_acc did not improve from 0.47274\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.2739 - accuracy: 0.9292 - balanced_acc: 0.9289 - val_loss: 0.6815 - val_accuracy: 0.7513 - val_balanced_acc: 0.4620 - lr: 2.5000e-04\n",
            "Epoch 85/100\n",
            "209/219 [===========================>..] - ETA: 0s - loss: 0.2742 - accuracy: 0.9276 - balanced_acc: 0.9272\n",
            "Epoch 85: val_balanced_acc did not improve from 0.47274\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.2739 - accuracy: 0.9277 - balanced_acc: 0.9269 - val_loss: 0.6936 - val_accuracy: 0.7461 - val_balanced_acc: 0.4596 - lr: 2.5000e-04\n",
            "Epoch 86/100\n",
            "207/219 [===========================>..] - ETA: 0s - loss: 0.2679 - accuracy: 0.9312 - balanced_acc: 0.9301\n",
            "Epoch 86: val_balanced_acc did not improve from 0.47274\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.2675 - accuracy: 0.9315 - balanced_acc: 0.9299 - val_loss: 0.6855 - val_accuracy: 0.7461 - val_balanced_acc: 0.4569 - lr: 2.5000e-04\n",
            "Epoch 87/100\n",
            "209/219 [===========================>..] - ETA: 0s - loss: 0.2659 - accuracy: 0.9314 - balanced_acc: 0.9318\n",
            "Epoch 87: val_balanced_acc did not improve from 0.47274\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.2678 - accuracy: 0.9306 - balanced_acc: 0.9310 - val_loss: 0.6833 - val_accuracy: 0.7513 - val_balanced_acc: 0.4613 - lr: 2.5000e-04\n",
            "Epoch 88/100\n",
            "209/219 [===========================>..] - ETA: 0s - loss: 0.2687 - accuracy: 0.9314 - balanced_acc: 0.9318\n",
            "Epoch 88: val_balanced_acc did not improve from 0.47274\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.2688 - accuracy: 0.9318 - balanced_acc: 0.9320 - val_loss: 0.6699 - val_accuracy: 0.7513 - val_balanced_acc: 0.4578 - lr: 2.5000e-04\n",
            "Epoch 89/100\n",
            "208/219 [===========================>..] - ETA: 0s - loss: 0.2678 - accuracy: 0.9303 - balanced_acc: 0.9322\n",
            "Epoch 89: val_balanced_acc did not improve from 0.47274\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.2689 - accuracy: 0.9301 - balanced_acc: 0.9318 - val_loss: 0.6909 - val_accuracy: 0.7461 - val_balanced_acc: 0.4569 - lr: 2.5000e-04\n",
            "Epoch 90/100\n",
            "216/219 [============================>.] - ETA: 0s - loss: 0.2715 - accuracy: 0.9303 - balanced_acc: 0.9301\n",
            "Epoch 90: val_balanced_acc did not improve from 0.47274\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.2719 - accuracy: 0.9302 - balanced_acc: 0.9298 - val_loss: 0.6821 - val_accuracy: 0.7461 - val_balanced_acc: 0.4542 - lr: 2.5000e-04\n",
            "Epoch 91/100\n",
            "210/219 [===========================>..] - ETA: 0s - loss: 0.2622 - accuracy: 0.9326 - balanced_acc: 0.9316\n",
            "Epoch 91: val_balanced_acc did not improve from 0.47274\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.2623 - accuracy: 0.9325 - balanced_acc: 0.9313 - val_loss: 0.6980 - val_accuracy: 0.7409 - val_balanced_acc: 0.4588 - lr: 2.5000e-04\n",
            "Epoch 92/100\n",
            "209/219 [===========================>..] - ETA: 0s - loss: 0.2637 - accuracy: 0.9331 - balanced_acc: 0.9339\n",
            "Epoch 92: val_balanced_acc did not improve from 0.47274\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.2629 - accuracy: 0.9333 - balanced_acc: 0.9335 - val_loss: 0.6957 - val_accuracy: 0.7409 - val_balanced_acc: 0.4588 - lr: 2.5000e-04\n",
            "Epoch 93/100\n",
            "214/219 [============================>.] - ETA: 0s - loss: 0.2676 - accuracy: 0.9314 - balanced_acc: 0.9311\n",
            "Epoch 93: val_balanced_acc did not improve from 0.47274\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.2675 - accuracy: 0.9316 - balanced_acc: 0.9314 - val_loss: 0.6966 - val_accuracy: 0.7409 - val_balanced_acc: 0.4630 - lr: 2.5000e-04\n"
          ]
        }
      ],
      "source": [
        "best_model_fpath = '/content/drive/MyDrive/PHD/Model/Feature-Map-Ov/best_model_no.h5'\n",
        "last_model_fpath = '/content/drive/MyDrive/PHD/Model/Feature-Map-Ov/last_model_no.h5'\n",
        "model2.compile(optimizer = opt_SGD , loss = \"categorical_crossentropy\", metrics=['accuracy', balanced_acc])\n",
        "hst = model2.fit(X_train_fm_ov, y_train_ov, epochs=EPOCHS, batch_size=BATCH_SIZE, validation_data=(X_val_fm, y_val), verbose=1,\n",
        "                    steps_per_epoch=X_train_fm_ov.shape[0] // BATCH_SIZE, \n",
        "                    callbacks=[learning_rate_reduction,early_stopping_monitor, mc])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "8XhlbWn--8Or",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "cc2db38f-c4b1-46d1-cebb-1d292045017f"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "# summarize history for accuracy\n",
        "plt.plot(hst.history['accuracy'])\n",
        "plt.plot(hst.history['balanced_acc'])\n",
        "plt.plot(hst.history['val_accuracy'])\n",
        "plt.plot(hst.history['val_balanced_acc'])\n",
        "plt.title('Model accuracy')\n",
        "plt.ylabel('Performance')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train accuracy', 'train balanced acc.', 'val. accuracy', 'val. balanced acc.'], loc='lower right')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "IW-_U6vFpIci"
      },
      "outputs": [],
      "source": [
        "# get feature map for first hidden layer\n",
        "y_train_pred = model2.predict(X_train_fm_ov)\n",
        "y_val_pred = model2.predict(X_val_fm)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "OLop0YK-ZK40",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3733507c-9883-4a46-d215-8ba49e778389"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy on training 0.9326561057043404\n",
            "balanced accuracy on training 0.9326561057043404\n",
            "accuracy on validation 0.7409326424870466\n",
            "balanced accuracy on validation 0.7154754362942517\n",
            "Score on val data:  (0.5704461396208969, 0.7154754362942517, 0.6059867124026416, None)\n"
          ]
        }
      ],
      "source": [
        "print('accuracy on training',accuracy_score(np.argmax(y_train_ov, axis=1), np.argmax(y_train_pred, axis=1)))\n",
        "print('balanced accuracy on training',balanced_accuracy_score(np.argmax(y_train_ov, axis=1), np.argmax(y_train_pred, axis=1)))\n",
        "print('accuracy on validation',accuracy_score(np.argmax(y_val, axis=1), np.argmax(y_val_pred, axis=1)))\n",
        "print('balanced accuracy on validation',balanced_accuracy_score(np.argmax(y_val, axis=1), np.argmax(y_val_pred, axis=1)))\n",
        "print('Score on val data: ',precision_recall_fscore_support(np.argmax(y_val, axis=1), np.argmax(y_val_pred, axis=1), average='macro'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RcRGeofw-8tK"
      },
      "source": [
        "#Load ISIC 2018 Challange Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "l3P7IjyLuZGY"
      },
      "outputs": [],
      "source": [
        "X_train, y_train, X_val, y_val = load_isic2018_dataset(train_under_frac = 0.7)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2IncA-_o_n5w"
      },
      "outputs": [],
      "source": [
        "# ordered count of rows per unique label\n",
        "labels_count = y_train.value_counts(ascending=True)\n",
        "\n",
        "f = plt.figure(figsize=(15, 6))\n",
        "s = sns.barplot(x=labels_count.index,y=labels_count.values)\n",
        "s.set_xticklabels(s.get_xticklabels(), rotation = 30)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AnKMKSb4Bkym"
      },
      "source": [
        "Plot 3 images per label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jdnVuqbFBW3K"
      },
      "outputs": [],
      "source": [
        "def plot_images_per_label(df, label, cols: int, size: tuple):\n",
        "    fig, axs = plt.subplots(nrows=1, ncols=cols, figsize=size)\n",
        "\n",
        "    cntMax = cols\n",
        "    cntCur = 0\n",
        "    for index, row in df.iterrows():\n",
        "        if(y_train == label and cntCur < cntMax):\n",
        "            axs[cntCur].imshow(plt.imread(df.FilePaths[index]))\n",
        "            axs[cntCur].set_title(df.Labels[index])\n",
        "\n",
        "            cntCur += 1\n",
        "        else:\n",
        "            if(cntCur >= cntMax):\n",
        "                break\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "# unique labels\n",
        "labels = sorted(df1['y_train'].unique())\n",
        "for label in range(7):\n",
        "    plot_images_per_label(df1, label, 3, (12,9))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "asV1O58Lrq-R"
      },
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "img = Image.fromarray(X_train[0], 'RGB')\n",
        "display(img)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qRKKrNacAZtl"
      },
      "source": [
        "Drop duplicate images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ERwfyPDHP-zC"
      },
      "outputs": [],
      "source": [
        "#df_group = pd.read_csv('/content/drive/MyDrive/PHD/Datasets/isic2018/ISIC2018_Task3_Training_LesionGroupings.csv') \n",
        "#df_train = df_train.set_index('image').join(df_group.set_index('image'))\n",
        "#df_train = df_train.drop_duplicates(subset=['lesion_id'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cNBXx28B9yGu"
      },
      "source": [
        "#DeepSMOTE Oversampling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YmX_Uqbmj-tN"
      },
      "outputs": [],
      "source": [
        "from numpy import moveaxis\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "max_el = np.inf\n",
        "\n",
        "args = {}\n",
        "args['dim_h'] = 64         # factor controlling size of hidden layers\n",
        "args['n_channel'] = 3#1    # number of channels in the input data \n",
        "args['n_z'] = 600 #300     # number of dimensions in latent space. \n",
        "args['sigma'] = 1.0        # variance in n_z\n",
        "args['lambda'] = 0.01      # hyper param for weight of discriminator loss\n",
        "args['lr'] = 0.0002        # learning rate for Adam optimizer .000\n",
        "args['epochs'] = 300       # how many epochs to run for\n",
        "args['batch_size'] = 100   # batch size for SGD\n",
        "args['save'] = True        # save weights at each epoch of training if True\n",
        "args['train'] = True       # train networks if True, else load networks from\n",
        "args['patience'] = 20"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NydOdPMajEfT"
      },
      "outputs": [],
      "source": [
        "class Encoder(nn.Module):\n",
        "    def __init__(self, args):\n",
        "        super(Encoder, self).__init__()\n",
        "\n",
        "        self.n_channel = args['n_channel']\n",
        "        self.dim_h = args['dim_h']\n",
        "        self.n_z = args['n_z']\n",
        "        \n",
        "        # convolutional filters, work excellent with image data\n",
        "        # [(WK+2P)/S]+1\n",
        "        self.conv = nn.Sequential(\n",
        "            nn.AvgPool2d(7, stride=7),\n",
        "            nn.Conv2d(self.n_channel, self.dim_h, 4, 2, 1, bias=False),# 16\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Conv2d(self.dim_h, self.dim_h * 2, 4, 2, 1, bias=False), # 8\n",
        "            nn.BatchNorm2d(self.dim_h * 2),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Conv2d(self.dim_h * 2, self.dim_h * 4, 4, 2, 1, bias=False),# 4\n",
        "            nn.BatchNorm2d(self.dim_h * 4),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Conv2d(self.dim_h * 4, self.dim_h * 8, 4, 2, 0, bias=False),#14\n",
        "            nn.BatchNorm2d(self.dim_h * 8),\n",
        "            nn.LeakyReLU(0.2, inplace=True))\n",
        "        self.fc = nn.Linear(self.dim_h * (2 ** 3), self.n_z)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv(x)\n",
        "        \n",
        "        x = x.squeeze()\n",
        "        x = self.fc(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self, args):\n",
        "        super(Decoder, self).__init__()\n",
        "\n",
        "        self.n_channel = args['n_channel']\n",
        "        self.dim_h = args['dim_h']\n",
        "        self.n_z = args['n_z']\n",
        "\n",
        "        # first layer is fully connected\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(self.n_z, self.dim_h * 2**3 * 7 * 7),\n",
        "            nn.ReLU())\n",
        "\n",
        "        # deconvolutional filters, essentially inverse of convolutional filters\n",
        "        # H_out = (H_in1)*stride[0]  2padding[0] + dilation[0](kernel_size[0]1) + output_padding[0] + 1\n",
        "        self.deconv = nn.Sequential(\n",
        "            nn.ConvTranspose2d(self.dim_h * 8, self.dim_h * 4, 4), #10\n",
        "            nn.BatchNorm2d(self.dim_h * 4),\n",
        "            nn.ReLU(True),\n",
        "            nn.ConvTranspose2d(self.dim_h * 4, self.dim_h * 2, 4), #13\n",
        "            nn.BatchNorm2d(self.dim_h * 2),\n",
        "            nn.ReLU(True),\n",
        "            nn.ConvTranspose2d(self.dim_h * 2, self.dim_h, 4),# 16\n",
        "            nn.BatchNorm2d(self.dim_h),\n",
        "            nn.ReLU(True),\n",
        "            nn.ConvTranspose2d(self.dim_h, 3, 4, 2, 1),# 32\n",
        "            nn.UpsamplingBilinear2d(scale_factor=7),\n",
        "            nn.Tanh())\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.fc(x)\n",
        "        x = x.view(-1, self.dim_h * 2**3, 7, 7)\n",
        "        x = self.deconv(x)\n",
        "        return x\n",
        "\n",
        "##############################################################################\n",
        "\"\"\"set models, loss functions\"\"\"\n",
        "# control which parameters are frozen / free for optimization\n",
        "def free_params(module: nn.Module):\n",
        "    for p in module.parameters():\n",
        "        p.requires_grad = True\n",
        "\n",
        "def frozen_params(module: nn.Module):\n",
        "    for p in module.parameters():\n",
        "        p.requires_grad = False\n",
        "\n",
        "def biased_get_class(X, y, c):\n",
        "    \n",
        "    xbeg = X[y == c]\n",
        "    ybeg = y[y == c]\n",
        "    \n",
        "    return xbeg, ybeg\n",
        "    #return xclass, yclass\n",
        "\n",
        "def G_SM(X, y,n_to_sample,cl):\n",
        "    n_neigh = 5\n",
        "    nn = NearestNeighbors(n_neighbors=n_neigh, n_jobs=1)\n",
        "    nn.fit(X)\n",
        "    dist, ind = nn.kneighbors(X)\n",
        "\n",
        "    # generating samples\n",
        "    base_indices = np.random.choice(list(range(len(X))),n_to_sample)\n",
        "    neighbor_indices = np.random.choice(list(range(1, n_neigh)),n_to_sample)\n",
        "\n",
        "    X_base = X[base_indices]\n",
        "    X_neighbor = X[ind[base_indices, neighbor_indices]]\n",
        "\n",
        "    samples = X_base + np.multiply(np.random.rand(n_to_sample,1),\n",
        "            X_neighbor - X_base)\n",
        "\n",
        "    #use 10 as label because 0 to 9 real classes and 1 fake/smoted = 10\n",
        "    return samples, [cl]*n_to_sample\n",
        "\n",
        "def DeepSMOTE_train(X_train, y_train, one_hot = False):\n",
        "  from torch.utils.data import TensorDataset\n",
        "  import os\n",
        "\n",
        "  max_el = np.max(X_train)\n",
        "  X_train = X_train / max_el\n",
        "  X_train = moveaxis(X_train, 3, 1)\n",
        "  if one_hot:\n",
        "    y_train = np.argmax(y_train, axis=1)\n",
        "  #X_train = X_train.astype('float32') / 255.\n",
        "  \n",
        "  batch_size = args['batch_size']\n",
        "  patience = args['patience']\n",
        "  encoder = Encoder(args)\n",
        "  decoder = Decoder(args)\n",
        "\n",
        "  device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "  print(device)\n",
        "  decoder = decoder.to(device)\n",
        "  encoder = encoder.to(device)\n",
        "\n",
        "  train_on_gpu = torch.cuda.is_available()\n",
        "\n",
        "  #decoder loss function\n",
        "  criterion = nn.MSELoss()\n",
        "  criterion = criterion.to(device)\n",
        "\n",
        "  num_workers = 0\n",
        "\n",
        "  #torch.Tensor returns float so if want long then use torch.tensor\n",
        "  tensor_x = torch.from_numpy(X_train.copy())#torch.Tensor(X_train)\n",
        "  tensor_y = torch.tensor(y_train,dtype=torch.long)\n",
        "  mnist_bal = TensorDataset(tensor_x,tensor_y) \n",
        "  train_loader = torch.utils.data.DataLoader(mnist_bal, \n",
        "      batch_size=batch_size,shuffle=True,num_workers=num_workers)\n",
        "\n",
        "  best_loss = np.inf\n",
        "\n",
        "  enc_optim = torch.optim.Adam(encoder.parameters(), lr = args['lr'])\n",
        "  dec_optim = torch.optim.Adam(decoder.parameters(), lr = args['lr'])\n",
        "\n",
        "  for epoch in range(args['epochs']):\n",
        "      train_loss = 0.0\n",
        "      tmse_loss = 0.0\n",
        "      tdiscr_loss = 0.0\n",
        "      # train for one epoch -- set nets to train mode\n",
        "      encoder.train()\n",
        "      decoder.train()\n",
        "  \n",
        "      for images,labs in train_loader:\n",
        "      \n",
        "          # zero gradients for each batch\n",
        "          encoder.zero_grad()\n",
        "          decoder.zero_grad()\n",
        "          images, labs = images.to(device), labs.to(device)\n",
        "          labsn = labs.detach().cpu().numpy()\n",
        "#            print('images shape', images.shape)\n",
        "          # run images\n",
        "          z_hat = encoder(images)\n",
        "#            print('images shape after encoding', z_hat.shape)\n",
        "      \n",
        "          x_hat = decoder(z_hat) #decoder outputs tanh\n",
        "#            print('images shape after decoding', x_hat.shape)\n",
        "          mse = criterion(x_hat,images)\n",
        "                  \n",
        "          resx = []\n",
        "          resy = []\n",
        "      \n",
        "          tc = np.random.choice(num_classes,1)\n",
        "          #tc = 9\n",
        "          xbeg = X_train[y_train == tc]\n",
        "          ybeg = y_train[y_train == tc] \n",
        "          xlen = len(xbeg)\n",
        "          nsamp = min(xlen, 100)\n",
        "          ind = np.random.choice(list(range(len(xbeg))),nsamp,replace=False)\n",
        "          xclass = xbeg[ind]\n",
        "          yclass = ybeg[ind]\n",
        "      \n",
        "          xclen = len(xclass)\n",
        "          xcminus = np.arange(1,xclen)\n",
        "          \n",
        "          xcplus = np.append(xcminus,0)\n",
        "          xcnew = (xclass[[xcplus],:])\n",
        "          xcnew = xcnew.reshape(xcnew.shape[1],xcnew.shape[2],xcnew.shape[3],xcnew.shape[4])\n",
        "      \n",
        "          xcnew = torch.Tensor(xcnew)\n",
        "          xcnew = xcnew.to(device)\n",
        "      \n",
        "          #encode xclass to feature space\n",
        "          xclass = torch.Tensor(xclass)\n",
        "          xclass = xclass.to(device)\n",
        "          xclass = encoder(xclass)\n",
        "      \n",
        "          xclass = xclass.detach().cpu().numpy()\n",
        "      \n",
        "          xc_enc = (xclass[[xcplus],:])\n",
        "          xc_enc = np.squeeze(xc_enc)\n",
        "      \n",
        "          xc_enc = torch.Tensor(xc_enc)\n",
        "          xc_enc = xc_enc.to(device)\n",
        "          \n",
        "          ximg = decoder(xc_enc)\n",
        "          \n",
        "          mse2 = criterion(ximg,xcnew)\n",
        "      \n",
        "          comb_loss = mse2 + mse\n",
        "          comb_loss.backward()\n",
        "      \n",
        "          enc_optim.step()\n",
        "          dec_optim.step()\n",
        "      \n",
        "          train_loss += comb_loss.item()*images.size(0)\n",
        "          tmse_loss += mse.item()*images.size(0)\n",
        "          tdiscr_loss += mse2.item()*images.size(0)\n",
        "\n",
        "      train_loss = train_loss/len(train_loader)\n",
        "      tmse_loss = tmse_loss/len(train_loader)\n",
        "      tdiscr_loss = tdiscr_loss/len(train_loader)\n",
        "      print('Epoch: {} \\tTrain Loss: {:.6f} \\tmse loss: {:.6f} \\tmse2 loss: {:.6f}'.format(epoch,\n",
        "              train_loss,tmse_loss,tdiscr_loss))\n",
        "      \n",
        "  \n",
        "  \n",
        "      #store the best encoder and decoder models\n",
        "      #here, /crs5 is a reference to 5 way cross validation, but is not\n",
        "      #necessary for illustration purposes\n",
        "      if train_loss < best_loss:\n",
        "          print('Saving..')\n",
        "          patience = args['patience']\n",
        "          path_enc = '/content/drive/MyDrive/PHD/Model/DeepSMOTE/32/bst_enc.pth'\n",
        "          path_dec = '/content/drive/MyDrive/PHD/Model/DeepSMOTE/32/bst_dec.pth'\n",
        "        \n",
        "          torch.save(encoder.state_dict(), path_enc)\n",
        "          torch.save(decoder.state_dict(), path_dec)\n",
        "  \n",
        "          best_loss = train_loss\n",
        "      else:\n",
        "          patience = patience - 1\n",
        "\n",
        "      if patience == 0:\n",
        "          print('Out of patience. \\n')\n",
        "          break\n",
        "\n",
        "def DeepSMOTE_Data(X_train, y_train, one_hot = False):\n",
        "  batch_size = args['batch_size']\n",
        "  max_el = np.max(X_train)\n",
        "  X_train = X_train / max_el\n",
        "  X_train = moveaxis(X_train, 3, 1)\n",
        "  if one_hot:\n",
        "    y_train = np.argmax(y_train, axis=1)\n",
        "  #Generate artificial images\n",
        "  import torch\n",
        "  np.printoptions(precision=5,suppress=True)\n",
        "\n",
        "  #path on the computer where the models are stored\n",
        "  modpth = '/content/drive/MyDrive/PHD/Model/DeepSMOTE/32/'\n",
        "\n",
        "  path_enc = modpth + '/bst_enc.pth'\n",
        "  path_dec = modpth + '/bst_dec.pth'\n",
        "  \n",
        "  train_on_gpu = torch.cuda.is_available()\n",
        "  device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "  encoder = Encoder(args)\n",
        "  encoder.load_state_dict(torch.load(path_enc), strict=False)\n",
        "  encoder = encoder.to(device)\n",
        "\n",
        "  decoder = Decoder(args)\n",
        "  decoder.load_state_dict(torch.load(path_dec), strict=False)\n",
        "  decoder = decoder.to(device)\n",
        "\n",
        "  encoder.eval()\n",
        "  decoder.eval()\n",
        "\n",
        "  resx = []\n",
        "  resy = []\n",
        "  \n",
        "  counter = Counter(y_train)\n",
        "  counter = sorted(counter.items())\n",
        "  counter = [value for _, value in counter]\n",
        "\n",
        "  for i in range(num_classes):\n",
        "      torch.cuda.empty_cache()\n",
        "\n",
        "      xclass, yclass = biased_get_class(X_train, y_train, i)\n",
        "      #encode xclass to feature space\n",
        "      xclass = torch.Tensor(xclass)\n",
        "      xclass = xclass.to(device)\n",
        "      xclass = encoder(xclass)\n",
        "          \n",
        "      xclass = xclass.detach().cpu().numpy()\n",
        "      n = np.max(counter) - counter[i]\n",
        "      if n == 0:\n",
        "        continue\n",
        "#        resx2 = []\n",
        "#        resy2 = []\n",
        "#        for j in range(batch_size, n+batch_size+1, batch_size):\n",
        "#          if j <= n:\n",
        "#            batch_size_max = batch_size\n",
        "#          elif n % batch_size != 0:\n",
        "#            batch_size_max = n%batch_size\n",
        "#          else:\n",
        "#            break\n",
        "#          xsamp, ysamp = G_SM(xclass,yclass,batch_size_max,i)\n",
        "      xsamp, ysamp = G_SM(xclass,yclass,n,i)\n",
        "      ysamp = np.array(ysamp)\n",
        "  \n",
        "      \"\"\"to generate samples for resnet\"\"\"   \n",
        "      xsamp = torch.Tensor(xsamp)\n",
        "      xsamp = xsamp.to(device)\n",
        "      ximg = decoder(xsamp)\n",
        "\n",
        "      ximn = ximg.detach().cpu().numpy()\n",
        "#        resx2.append(ximn)\n",
        "#        resy2.append(ysamp)\n",
        "#        \n",
        "#        resx2 = np.vstack(resx2)\n",
        "#        resy2 = np.hstack(resy2)\n",
        "      resx.append(ximn)\n",
        "      resy.append(ysamp)\n",
        "  \n",
        "  resx1 = np.vstack(resx)\n",
        "  resy1 = np.hstack(resy)\n",
        "  resx1 = resx1.reshape(resx1.shape[0],-1)\n",
        "  X_train = X_train.reshape(X_train.shape[0],-1)\n",
        "  X_train = np.vstack((resx1,X_train))\n",
        "  y_train = np.hstack((resy1,y_train))\n",
        "  y_train = to_categorical(y_train)\n",
        "  X_train = X_train.reshape(-1, 3, IMAGE_W, IMAGE_H)\n",
        "  X_train = moveaxis(X_train, 1, 3)\n",
        "  X_train = X_train * max_el\n",
        "  return X_train, y_train"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0jrJ33lUDkCM"
      },
      "source": [
        "#Split dataset to train and val"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e6qneWL_Bs2U"
      },
      "outputs": [],
      "source": [
        "# stratified train and rem (20%) datasets\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, stratify=y_train, random_state=1)\n",
        "\n",
        "print('Train Data: ', X_train.shape)\n",
        "print('Remaining Data: ', X_val.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8Kef4r_zxjgk"
      },
      "outputs": [],
      "source": [
        "#Data Augmentation\n",
        "dataaugment = ImageDataGenerator(\n",
        "        rotation_range=90,  # randomly rotate images in the range (degrees, 0 to 180)\n",
        "        zoom_range = 0.1, # Randomly zoom image \n",
        "        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
        "        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
        "        horizontal_flip=True,  # randomly flip images\n",
        "        vertical_flip=True,  # randomly flip images\n",
        "        shear_range = 10) \n",
        "\n",
        "dataaugment.fit(X_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B2PgksTFkOAq"
      },
      "source": [
        "#Fine Tune"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nr1jnSM7yzJc"
      },
      "outputs": [],
      "source": [
        "limit = 171\n",
        "for layer in model.layers[:limit]:\n",
        "   layer.trainable = False\n",
        "for layer in model.layers[limit:]:\n",
        "   layer.trainable = True\n",
        "\n",
        "optimizer_SGD = SGD(learning_rate=0.0001, momentum=0.9)\n",
        "model.compile(optimizer = optimizer_SGD , loss = \"categorical_crossentropy\", metrics=['accuracy', balanced_acc])\n",
        "hst2 = model.fit(train_data_batches,\n",
        "                    epochs = EPOCHS, validation_data = valid_data_batches,\n",
        "                    callbacks=[learning_rate_reduction,early_stopping_monitor, mc])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vO1aAQBmiy0K"
      },
      "outputs": [],
      "source": [
        "# summarize history for accuracy\n",
        "plt.plot(hst2.history['balanced_acc'])\n",
        "plt.plot(hst2.history['val_balanced_acc'])\n",
        "plt.title('model balance_acc after tunning')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'val'], loc='upper left')\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "UswA0co2y1wl",
        "iDRWiTnO0MGh",
        "eaK4zbtoaAaC",
        "3K908bbiYwbS",
        "kE8Ziq-BlEP4",
        "RcRGeofw-8tK",
        "cNBXx28B9yGu",
        "0jrJ33lUDkCM",
        "B2PgksTFkOAq"
      ],
      "machine_shape": "hm",
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}