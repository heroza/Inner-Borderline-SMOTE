{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/heroza/Inner-Borderline-SMOTE/blob/main/Borderline%20after%20SMOTE%20in%20Feature%20Space.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Eus_4tUgfEk9",
        "outputId": "0afa2754-4e66-44bd-ff1b-7a62090f0d16"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E_x4c0_DTkaa"
      },
      "source": [
        "#Library, atribut, and function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "nR2MJBYq-oiB"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import os\n",
        "from collections import Counter\n",
        "from pathlib import Path\n",
        "from PIL import Image\n",
        "from sklearn import preprocessing\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "from sklearn.metrics import precision_recall_fscore_support, balanced_accuracy_score, confusion_matrix, accuracy_score\n",
        "from keras.callbacks import ReduceLROnPlateau, EarlyStopping, ModelCheckpoint\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D, UpSampling2D\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.optimizers import Adam, SGD\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input, decode_predictions\n",
        "from tensorflow.keras.applications.inception_v3 import InceptionV3, preprocess_input\n",
        "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Input, Dropout, Flatten\n",
        "from tensorflow.keras.models import Model, load_model\n",
        "from keras.utils.np_utils import to_categorical\n",
        "import imblearn\n",
        "from imblearn.over_sampling import SMOTE, BorderlineSMOTE, SVMSMOTE, ADASYN, KMeansSMOTE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "9-c7Xghg4SB4"
      },
      "outputs": [],
      "source": [
        "# input image size\n",
        "IMAGE_W = 128\n",
        "IMAGE_H = 128\n",
        "IMG_SIZE = (IMAGE_W,IMAGE_H)\n",
        "num_classes = 7\n",
        "EPOCHS = 50\n",
        "BATCH_SIZE = 64\n",
        "opt_adam = Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
        "opt_SGD = SGD(learning_rate=0.001)\n",
        "the_arch = 'resnet50'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "JffFid9sOXeo"
      },
      "outputs": [],
      "source": [
        "# load train and test dataset\n",
        "def preprocess_image_input(input_images, arch = the_arch):\n",
        "  input_images = input_images.astype('float32')\n",
        "  if arch == 'inception_v3':\n",
        "    output_ims = tf.keras.applications.inception_v3.preprocess_input(input_images)\n",
        "  else:\n",
        "    output_ims = tf.keras.applications.resnet50.preprocess_input(input_images)\n",
        "  return output_ims\n",
        "\n",
        "def load_cifar10_dataset():\n",
        "  from keras.datasets import cifar10\n",
        "    # load dataset\n",
        "  (X_train, y_train), (X_val, y_val) = cifar10.load_data()\n",
        "    # one hot encode target values\n",
        "  y_train = to_categorical(y_train)\n",
        "  y_val = to_categorical(y_val)\n",
        "\n",
        "  return X_train, y_train, X_val, y_val\n",
        "\n",
        "def true_positive(l1,l2):\n",
        "  tp = 0\n",
        "  for i in range(len(l1)):\n",
        "    tp = tf.cond(l1[i]==l2[i]==1, lambda: tp+1)\n",
        "  return tp\n",
        "\n",
        "def true_negative(l1,l2):\n",
        "  tn = 0\n",
        "  for i in range(len(l1)):\n",
        "    tn = tf.cond(l1[i]==l2[i]==0, lambda: tn+1)\n",
        "  return tn\n",
        "\n",
        "def false_positive(l1,l2):\n",
        "  fp = 0\n",
        "  for i in range(len(l1)):\n",
        "    fp = tf.cond(l1[i] != l2[i] and l2[i]==1, lambda: fp+1)\n",
        "  return fp\n",
        "\n",
        "def false_negative(l1,l2):\n",
        "  fn = 0\n",
        "  for i in range(len(l1)):\n",
        "    fn = tf.cond(l1[i] != l2[i] and l2[i] == 0, lambda: fn+1)\n",
        "  return fn\n",
        "\n",
        "def balanced_acc(y_true,y_pred):\n",
        "    from keras import backend as K\n",
        "    tensor1 = tf.math.argmax(y_true, axis=1)\n",
        "    tensor2 = tf.math.argmax(y_pred, axis=1)\n",
        "    cm = tf.math.confusion_matrix(tensor1, tensor2)\n",
        "    diag = tf.linalg.tensor_diag_part (cm)\n",
        "    tpfn = tf.cast(K.sum(cm, axis = 1), tf.float32) + K.epsilon()\n",
        "    recall = tf.divide(tf.cast(diag, tf.float32),tpfn)\n",
        "    balanced_acc = K.mean(recall)\n",
        "    balanced_acc = K.mean(balanced_acc)\n",
        "\n",
        "    return balanced_acc\n",
        "\n",
        "def define_base_model(arch = the_arch, start_trainable_layer = 9999, attention=False):\n",
        "  #x = data_augmentation(input_tensor)\n",
        "  #x = layers.Rescaling(1.0 / 255)(input_tensor)  # Rescale inputs\n",
        "  if arch != 'dense':\n",
        "    input_tensor = Input(shape=(IMAGE_H, IMAGE_W, 3))\n",
        "    #x = UpSampling2D(size=(7,7))(input_tensor)\n",
        "    if arch == 'resnet50':\n",
        "      base_model = ResNet50(input_tensor=input_tensor, weights='imagenet', include_top=False)\n",
        "    elif arch == 'inception_v3':\n",
        "      base_model = InceptionV3(input_tensor=input_tensor, weights='imagenet', include_top=False)\n",
        "    elif arch == 'ResNet':\n",
        "      base_model = ResNet(classes ,image_shape)(input_tensor)\n",
        "    \n",
        "    for layer in base_model.layers:\n",
        "      layer.trainable = False\n",
        "    if start_trainable_layer != 9999:\n",
        "      for layer in base_model.layers[start_trainable_layer:]:\n",
        "        layer.trainable = True\n",
        "    \n",
        "    x = base_model.output\n",
        "    if attention:\n",
        "      x = Attention(1024,1024,7,8)(x)\n",
        "    \n",
        "    x = GlobalAveragePooling2D()(x)\n",
        "    x = Flatten()(x)\n",
        "  else:\n",
        "    input_tensor = Input(shape=(2048))\n",
        "    x = input_tensor\n",
        "  #x = Flatten()(x)\n",
        "  x = Dense(1024, activation='relu')(x)\n",
        "  #x = Dropout(0.2)(x)\n",
        "  x = Dense(512, activation='relu')(x)\n",
        "  predictions = Dense(num_classes, activation='softmax')(x)\n",
        "  model = Model(inputs=input_tensor, outputs=predictions)\n",
        "  model.compile(optimizer = opt_SGD , loss = \"categorical_crossentropy\", metrics=['accuracy', balanced_acc])\n",
        "  return model\n",
        "\n",
        "def define_model_resnet():\n",
        "  input_shape = (IMAGE_H, IMAGE_W, 3)\n",
        "  input_tensor = Input(shape=input_shape)\n",
        "  x = ResNet50(input_shape=input_shape, weights='imagenet', include_top=False)(input_tensor, training=False)\n",
        "  x = GlobalAveragePooling2D()(x)\n",
        "  x = Flatten()(x)\n",
        "  x = Dense(1024, activation='relu')(x)\n",
        "  x = Dense(512, activation='relu')(x)\n",
        "  predictions = Dense(num_classes, activation='softmax')(x)\n",
        "  model = Model(inputs=input_tensor, outputs=predictions)\n",
        "  model.compile(optimizer = opt_SGD , loss = \"categorical_crossentropy\", metrics=['accuracy', balanced_acc])\n",
        "  return model\n",
        "\n",
        "# plot diagnostic learning curves\n",
        "def summarize_diagnostics(history):\n",
        "    # plot loss\n",
        "    plt.subplot(211)\n",
        "    plt.title('Cross Entropy Loss')\n",
        "    plt.plot(history.history['loss'], color='blue', label='train')\n",
        "    plt.plot(history.history['val_loss'], color='orange', label='test')\n",
        "    # plot accuracy\n",
        "    plt.subplot(212)\n",
        "    plt.title('Classification Accuracy')\n",
        "    plt.plot(history.history['accuracy'], color='blue', label='train')\n",
        "    plt.plot(history.history['val_accuracy'], color='orange', label='test')\n",
        " \n",
        "# scale pixels\n",
        "def norm_pixels(train, test):\n",
        "    # convert from integers to floats\n",
        "    train_norm = train.astype('float32')\n",
        "    test_norm = test.astype('float32')\n",
        "    # normalize to range 0-1\n",
        "    train_norm = train_norm / 255.0\n",
        "    test_norm = test_norm / 255.0\n",
        "    # return normalized images\n",
        "    return train_norm, test_norm\n",
        "\n",
        "def load_isic2018_dataset(train_under_frac = 0):\n",
        "  df_train = pd.read_csv('/content/drive/MyDrive/PHD/Datasets/isic2018/ISIC2018_Task3_Training_GroundTruth/ISIC2018_Task3_Training_GroundTruth.csv') \n",
        "  df_val = pd.read_csv('/content/drive/MyDrive/PHD/Datasets/isic2018/ISIC2018_Task3_Validation_GroundTruth/ISIC2018_Task3_Validation_GroundTruth.csv') \n",
        "\n",
        "  #decode one hot label\n",
        "  df_train[\"Labels\"] = (df_train.iloc[:, 1:]).idxmax(axis=1)\n",
        "  df_val[\"Labels\"] = (df_val.iloc[:, 1:]).idxmax(axis=1)\n",
        "\n",
        "  #random undersampling for training dataset\n",
        "  if train_under_frac !=0:\n",
        "    df_train = df_train.drop(df_train[df_train['Labels'] == 'NV'].sample(frac=train_under_frac).index)\n",
        "\n",
        "  #drop one-hot column\n",
        "  df_train = df_train.drop(columns=['MEL', 'NV', 'BCC', 'AKIEC', 'BKL', 'DF', 'VASC'])\n",
        "  df_val = df_val.drop(columns=['MEL', 'NV', 'BCC', 'AKIEC', 'BKL', 'DF', 'VASC'])\n",
        "\n",
        "  #make filepaths of the image\n",
        "  dir_train = '/content/drive/MyDrive/PHD/Datasets/isic2018/ISIC2018_Task3_Training_Input/'\n",
        "  dir_val = '/content/drive/MyDrive/PHD/Datasets/isic2018/ISIC2018_Task3_Validation_Input/'\n",
        "  df_train['FilePaths'] = dir_train + df_train['image'] + '.jpg'\n",
        "  df_val['FilePaths'] = dir_val + df_val['image'] + '.jpg'\n",
        "  \n",
        "  #load image pixels to dataframe\n",
        "  df_train['image_px'] = df_train['FilePaths'].map(lambda x: np.asarray(Image.open(x).resize(IMG_SIZE)))\n",
        "  df_val['image_px'] = df_val['FilePaths'].map(lambda x: np.asarray(Image.open(x).resize(IMG_SIZE)))\n",
        "\n",
        "  X_train = np.asarray(df_train['image_px'].tolist())\n",
        "  X_val = np.asarray(df_val['image_px'].tolist())\n",
        "  y_train = np.array(df_train['Labels'].values)\n",
        "  y_val = np.array(df_val['Labels'].values)\n",
        "\n",
        "  label_encoder = preprocessing.LabelEncoder()\n",
        "  y_train = label_encoder.fit_transform(y_train)\n",
        "  y_val = label_encoder.fit_transform(y_val)\n",
        "  \n",
        "  y_train = to_categorical(y_train, num_classes = num_classes)\n",
        "  y_val = to_categorical(y_val, num_classes = num_classes)\n",
        "\n",
        "  return X_train, y_train, X_val, y_val\n",
        "\n",
        "def reset_dataset(df_train, df_val):\n",
        "  X_train = np.asarray(df_train['image_px'].tolist())\n",
        "  X_val = np.asarray(df_val['image_px'].tolist())\n",
        "  y_train = np.array(df_train['Labels'].values)\n",
        "  y_val = np.array(df_val['Labels'].values)\n",
        "\n",
        "  X_train = preprocess_image_input(X_train, the_arch)\n",
        "  X_val = preprocess_image_input(X_val, the_arch)\n",
        "\n",
        "  label_encoder = preprocessing.LabelEncoder()\n",
        "  y_train = label_encoder.fit_transform(y_train)\n",
        "  y_val = label_encoder.fit_transform(y_val)\n",
        "  \n",
        "  y_train = to_categorical(y_train, num_classes = num_classes)\n",
        "  y_val = to_categorical(y_val, num_classes = num_classes)\n",
        "  return X_train, y_train, X_val, y_val\n",
        "\n",
        "def SMOTE_Data(X, y, one_hot = False, k = 5, width = IMAGE_W, height = IMAGE_H, c = 3, type = 'smote'):\n",
        "  if one_hot:\n",
        "    y = np.argmax(y, axis=1)\n",
        "  if type == 'borderline':\n",
        "    sm = BorderlineSMOTE(random_state=42, k_neighbors=k)\n",
        "  elif type == 'svm':\n",
        "    sm = SVMSMOTE()\n",
        "  elif type == 'adasyn':\n",
        "    sm = ADASYN(random_state=42, n_neighbors=k)\n",
        "  elif type == 'kmeans':\n",
        "    sm = KMeansSMOTE(k_neighbors=k, kmeans_estimator=10)\n",
        "  else:\n",
        "    sm = SMOTE(random_state=42, k_neighbors=k)\n",
        "  X_resampled, y_resampled = sm.fit_resample(X.reshape((-1, width * height * c)), y)\n",
        "  X_resampled = X_resampled.reshape(-1, width, height, c)\n",
        "  if one_hot:\n",
        "    y_resampled = to_categorical(y_resampled, num_classes = num_classes)\n",
        "  else:\n",
        "    y_resampled = y_resampled.reshape(-1,1)\n",
        "  return X_resampled, y_resampled\n",
        "\n",
        "def SMOTE_Data2(X, y, one_hot = False, k = 5, type = 'smote'):\n",
        "  if one_hot:\n",
        "    y = np.argmax(y, axis=1)\n",
        "  if type == 'borderline':\n",
        "    sm = BorderlineSMOTE(random_state=42, k_neighbors=k)\n",
        "  elif type == 'svm':\n",
        "    sm = SVMSMOTE()\n",
        "  elif type == 'adasyn':\n",
        "    sm = ADASYN(random_state=42, n_neighbors=k)\n",
        "  elif type == 'kmeans':\n",
        "    sm = KMeansSMOTE(k_neighbors=k, kmeans_estimator=10)\n",
        "  else:\n",
        "    sm = SMOTE(random_state=42, k_neighbors=k)\n",
        "  X_resampled, y_resampled = sm.fit_resample(X, y)\n",
        "  if one_hot:\n",
        "    y_resampled = to_categorical(y_resampled, num_classes = num_classes)\n",
        "  else:\n",
        "    y_resampled = y_resampled.reshape(-1,1)\n",
        "  return X_resampled, y_resampled"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BE9FCWBe8deT"
      },
      "source": [
        "#Inner-Borderline SMOTE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s3UnuaKz8kzJ"
      },
      "outputs": [],
      "source": [
        "def get_class(X, y, c):\n",
        "    xbeg = X[y == c]\n",
        "    ybeg = y[y == c]\n",
        "    \n",
        "    return xbeg, ybeg\n",
        "def find_border(xclass, yclass, X, y, cli, n_neigh=5):\n",
        "    nn = NearestNeighbors(n_neighbors=n_neigh, n_jobs=1)\n",
        "    nn.fit(X)\n",
        "    dist, ind = nn.kneighbors(xclass)\n",
        "    ret = []\n",
        "    for i in range(len(ind)):\n",
        "      ret.append(sum(y[ind[i,j]] != cli for j in range(1,len(ind[i]))))\n",
        "    ret = np.array(ret)\n",
        "    xclass = xclass[np.logical_and(ret < (n_neigh-1),ret > ((n_neigh-1)/2))]\n",
        "    yclass = yclass[np.logical_and(ret < (n_neigh-1),ret > ((n_neigh-1)/2))]\n",
        "\n",
        "    return xclass, yclass\n",
        "def find_inner_border(xclass, yclass, X, y, cli, n_neigh=5):\n",
        "    nn = NearestNeighbors(n_neighbors=n_neigh, n_jobs=1)\n",
        "    nn.fit(X)\n",
        "    dist, ind = nn.kneighbors(X)\n",
        "    ret = []\n",
        "    for i in range(len(ind)):\n",
        "      if y[i] != cli:\n",
        "        ret.append(n_neigh)  \n",
        "      else:\n",
        "        ret.append(sum(y[ind[i,j]] != cli for j in range(1,len(ind[i]))))\n",
        "    ret = np.array(ret)\n",
        "    is_border = np.logical_and(ret < (n_neigh-1),ret > ((n_neigh-1)/2))\n",
        "    \n",
        "    ret = []\n",
        "    for i in range(len(ind)):\n",
        "      ret.append(sum(is_border[ind[i,j]] for j in range(1,len(ind[i]))))\n",
        "    ret = np.array(ret)\n",
        "    xclass = X[np.logical_and(np.logical_not(is_border),ret > 0)]\n",
        "    yclass = y[np.logical_and(np.logical_not(is_border),ret > 0)]\n",
        "    return xclass, yclass\n",
        "\n",
        "def G_SM(xclass,n_to_sample,cl, n_neigh = 6):\n",
        "    \n",
        "    nn = NearestNeighbors(n_neighbors=n_neigh, n_jobs=1)\n",
        "    nn.fit(xclass)\n",
        "    dist, ind = nn.kneighbors(xclass)\n",
        "\n",
        "    # generating samples\n",
        "    base_indices = np.random.choice(list(range(len(xclass))),n_to_sample)\n",
        "    neighbor_indices = np.random.choice(list(range(1, n_neigh)),n_to_sample)\n",
        "\n",
        "    X_base = xclass[base_indices]\n",
        "    X_neighbor = xclass[ind[base_indices, neighbor_indices]]\n",
        "\n",
        "    samples = X_base + np.multiply(np.random.rand(n_to_sample,1),\n",
        "            X_neighbor - X_base)\n",
        "\n",
        "    #use 10 as label because 0 to 9 real classes and 1 fake/smoted = 10\n",
        "    return samples, [cl]*n_to_sample\n",
        "\n",
        "def Borderline_SMOTE(X_train, y_train, random_state=42, k_neighbors=5, start=0, n=7):\n",
        "  #reshape X_train\n",
        "  X_train = X_train.reshape(-1, IMAGE_W * IMAGE_H * 3)\n",
        "  #decode y_train from one-hot encoding\n",
        "  y_train = np.argmax(y_train, axis=1) \n",
        "\n",
        "  counter = Counter(y_train)\n",
        "  key_max = max(counter, key=counter.get)\n",
        "  class_max = counter[key_max]\n",
        "  resx=[]\n",
        "  resy=[]\n",
        "\n",
        "  for i in range(start,n):\n",
        "      xclass, yclass = get_class(X_train, y_train, i)\n",
        "      if xclass.shape[0] == class_max:\n",
        "        continue\n",
        "      xclass_bdr, yclass_bdr = find_inner_border(xclass, yclass, X_train, y_train, i, n_neigh=k_neighbors)\n",
        "      n = class_max - xclass.shape[0]\n",
        "      xsamp, ysamp = G_SM(xclass_bdr,n,i, n_neigh=k_neighbors)\n",
        "      ysamp = np.array(ysamp)\n",
        "      resx.append(xsamp)\n",
        "      resy.append(ysamp)\n",
        "  \n",
        "  resx = np.vstack(resx)\n",
        "  resy = np.hstack(resy)\n",
        "  X_train = np.vstack((resx,X_train))\n",
        "  y_train = np.hstack((resy,y_train))\n",
        "  y_train = to_categorical(y_train)\n",
        "  X_train = X_train.reshape(-1, IMAGE_W, IMAGE_H, 3)\n",
        "  return X_train, y_train"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5v7sLC2svMuJ"
      },
      "source": [
        "# Main"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "exp_name=\"borderline_after_smote_on_featurespace\"\n",
        "dataset_name=\"under80_128px\"\n",
        "train_under_frac = 0.8"
      ],
      "metadata": {
        "id": "udkMXcZHXglm"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qge6cnxQPnH6",
        "outputId": "be685f11-cf91-433e-f253-a980907d6d9d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(4651, 128, 128, 3)\n",
            "(4651, 7)\n",
            "(193, 128, 128, 3)\n",
            "(193, 7)\n",
            "Counter train data:  Counter({5: 1341, 4: 1113, 2: 1099, 1: 514, 0: 327, 6: 142, 3: 115})\n",
            "Counter val data:  Counter({5: 123, 2: 22, 4: 21, 1: 15, 0: 8, 6: 3, 3: 1})\n"
          ]
        }
      ],
      "source": [
        "path = '/content/drive/MyDrive/PHD/Datasets/isic2018/'\n",
        "df1 = pd.read_pickle(path+\"isic2018_train_\"+dataset_name+\".pkl\")\n",
        "X_train = df1.loc[:, df1.columns != 'y_train'].to_numpy()\n",
        "X_train = X_train.reshape(-1,IMAGE_W,IMAGE_H,3)\n",
        "y_train = df1.loc[:, df1.columns == 'y_train'].to_numpy()\n",
        "y_train = to_categorical(y_train)\n",
        "\n",
        "df1 = pd.read_pickle(path+\"isic2018_val_\"+dataset_name+\".pkl\")\n",
        "X_val = df1.loc[:, df1.columns != 'y_val'].to_numpy()\n",
        "X_val = X_val.reshape(-1,IMAGE_W,IMAGE_H,3)\n",
        "y_val = df1.loc[:, df1.columns == 'y_val'].to_numpy()\n",
        "y_val = to_categorical(y_val)\n",
        "\n",
        "print(X_train.shape)\n",
        "print(y_train.shape)\n",
        "print(X_val.shape)\n",
        "print(y_val.shape)\n",
        "print('Counter train data: ', Counter(np.argmax(y_train, axis=1)))\n",
        "print('Counter val data: ', Counter(np.argmax(y_val, axis=1)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xArGWuciBt_-"
      },
      "outputs": [],
      "source": [
        "X_train, y_train = SMOTE_Data(X_train, y_train, True, type = 'smote')\n",
        "#X_train, y_train = Borderline_SMOTE(X_train, y_train)\n",
        "print(X_train.shape)\n",
        "print(y_train.shape)\n",
        "print(X_val.shape)\n",
        "print(y_val.shape)\n",
        "print('Counter train data: ', Counter(np.argmax(y_train, axis=1)))\n",
        "print('Counter val data: ', Counter(np.argmax(y_val, axis=1)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "0V5PjA7jFhVU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "38b5f38e-272e-483a-fa48-6186f4b7efcd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(9487, 2048)\n",
            "(9487, 7)\n",
            "Counter train data:  Counter({0: 1441, 5: 1341, 4: 1341, 2: 1341, 3: 1341, 1: 1341, 6: 1341})\n"
          ]
        }
      ],
      "source": [
        "n_new_samples = 100\n",
        "X_train = np.append(X_train_fm_ov, np.zeros(shape=(n_new_samples, 2048), dtype='object'), axis=0)\n",
        "y_train = np.argmax(y_train_ov, axis=1) \n",
        "y_train = y_train.reshape(-1,1)\n",
        "y_train = np.append(y_train, np.zeros(shape=(n_new_samples, 1), dtype='object'))\n",
        "y_train = to_categorical(y_train)\n",
        "print(X_train.shape)\n",
        "print(y_train.shape)\n",
        "print('Counter train data: ', Counter(np.argmax(y_train, axis=1)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0lFpLlexMUaM",
        "outputId": "137599b4-6ee6-49de-8cd9-13e82b8c2c89"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(9887, 2048)\n",
            "(9887, 7)\n",
            "Counter train data:  Counter({5: 1441, 4: 1441, 2: 1441, 1: 1441, 6: 1441, 3: 1341, 0: 1341})\n"
          ]
        }
      ],
      "source": [
        "# remove rows having all zeroes\n",
        "index = range(9387,9487)\n",
        "y_train = np.delete(y_train_ov, index, axis = 0)\n",
        "X_train = np.delete(X_train_fm_ov, index, axis = 0)\n",
        "print(X_train.shape)\n",
        "print(y_train.shape)\n",
        "print('Counter train data: ', Counter(np.argmax(y_train, axis=1)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V7Z_nccu6QjB"
      },
      "outputs": [],
      "source": [
        "#path = '/content/drive/MyDrive/PHD/Datasets/isic2018/'\n",
        "#df1 = pd.DataFrame(X_train.reshape(X_train.shape[0],-1))\n",
        "#df1['y_train'] = np.argmax(y_train, axis=1).tolist()\n",
        "#df2 = pd.DataFrame(X_val.reshape(X_val.shape[0],-1))\n",
        "#df2['y_val'] = np.argmax(y_val, axis=1).tolist()\n",
        "#df1.to_pickle(path+\"isic2018_train_under83.pkl\")\n",
        "#df2.to_pickle(path+\"isic2018_val.pkl\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "vIygrW81Ln4z",
        "outputId": "c91e8fed-8853-4a0b-e6ad-101cf7c0ed50"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "94765736/94765736 [==============================] - 0s 0us/step\n",
            "best_model_fpath:/content/drive/MyDrive/PHD/Model/best_model_no_smote_under80_128px.h5\n",
            "Epoch 1/50\n",
            "72/72 [==============================] - ETA: 0s - loss: 1.3413 - accuracy: 0.4868 - balanced_acc: 0.3249\n",
            "Epoch 1: val_balanced_acc improved from -inf to 0.45679, saving model to /content/drive/MyDrive/PHD/Model/best_model_no_smote_under80_128px.h5\n",
            "72/72 [==============================] - 32s 261ms/step - loss: 1.3413 - accuracy: 0.4868 - balanced_acc: 0.3249 - val_loss: 0.7563 - val_accuracy: 0.7150 - val_balanced_acc: 0.4568 - lr: 0.0010\n",
            "Epoch 2/50\n",
            "72/72 [==============================] - ETA: 0s - loss: 1.0527 - accuracy: 0.5949 - balanced_acc: 0.4446\n",
            "Epoch 2: val_balanced_acc did not improve from 0.45679\n",
            "72/72 [==============================] - 17s 223ms/step - loss: 1.0527 - accuracy: 0.5949 - balanced_acc: 0.4446 - val_loss: 0.7728 - val_accuracy: 0.7047 - val_balanced_acc: 0.4366 - lr: 0.0010\n",
            "Epoch 3/50\n",
            "72/72 [==============================] - ETA: 0s - loss: 0.9200 - accuracy: 0.6422 - balanced_acc: 0.5244\n",
            "Epoch 3: val_balanced_acc improved from 0.45679 to 0.45886, saving model to /content/drive/MyDrive/PHD/Model/best_model_no_smote_under80_128px.h5\n",
            "72/72 [==============================] - 18s 247ms/step - loss: 0.9200 - accuracy: 0.6422 - balanced_acc: 0.5244 - val_loss: 1.0033 - val_accuracy: 0.6477 - val_balanced_acc: 0.4589 - lr: 0.0010\n",
            "Epoch 4/50\n",
            "72/72 [==============================] - ETA: 0s - loss: 0.8268 - accuracy: 0.6797 - balanced_acc: 0.5825\n",
            "Epoch 4: val_balanced_acc improved from 0.45886 to 0.55128, saving model to /content/drive/MyDrive/PHD/Model/best_model_no_smote_under80_128px.h5\n",
            "72/72 [==============================] - 18s 251ms/step - loss: 0.8268 - accuracy: 0.6797 - balanced_acc: 0.5825 - val_loss: 0.7637 - val_accuracy: 0.7202 - val_balanced_acc: 0.5513 - lr: 0.0010\n",
            "Epoch 5/50\n",
            "72/72 [==============================] - ETA: 0s - loss: 0.7481 - accuracy: 0.7111 - balanced_acc: 0.6285\n",
            "Epoch 5: val_balanced_acc did not improve from 0.55128\n",
            "72/72 [==============================] - 17s 231ms/step - loss: 0.7481 - accuracy: 0.7111 - balanced_acc: 0.6285 - val_loss: 0.7742 - val_accuracy: 0.7202 - val_balanced_acc: 0.5425 - lr: 0.0010\n",
            "Epoch 6/50\n",
            "72/72 [==============================] - ETA: 0s - loss: 0.7064 - accuracy: 0.7266 - balanced_acc: 0.6639\n",
            "Epoch 6: val_balanced_acc did not improve from 0.55128\n",
            "72/72 [==============================] - 17s 235ms/step - loss: 0.7064 - accuracy: 0.7266 - balanced_acc: 0.6639 - val_loss: 0.8117 - val_accuracy: 0.6839 - val_balanced_acc: 0.5393 - lr: 0.0010\n",
            "Epoch 7/50\n",
            "72/72 [==============================] - ETA: 0s - loss: 0.6588 - accuracy: 0.7493 - balanced_acc: 0.6988\n",
            "Epoch 7: val_balanced_acc did not improve from 0.55128\n",
            "72/72 [==============================] - 17s 235ms/step - loss: 0.6588 - accuracy: 0.7493 - balanced_acc: 0.6988 - val_loss: 0.7215 - val_accuracy: 0.7150 - val_balanced_acc: 0.5377 - lr: 0.0010\n",
            "Epoch 8/50\n",
            "72/72 [==============================] - ETA: 0s - loss: 0.5654 - accuracy: 0.7864 - balanced_acc: 0.7363\n",
            "Epoch 8: val_balanced_acc improved from 0.55128 to 0.56798, saving model to /content/drive/MyDrive/PHD/Model/best_model_no_smote_under80_128px.h5\n",
            "72/72 [==============================] - 18s 254ms/step - loss: 0.5654 - accuracy: 0.7864 - balanced_acc: 0.7363 - val_loss: 0.5452 - val_accuracy: 0.7876 - val_balanced_acc: 0.5680 - lr: 0.0010\n",
            "Epoch 9/50\n",
            "72/72 [==============================] - ETA: 0s - loss: 0.5233 - accuracy: 0.8106 - balanced_acc: 0.7656\n",
            "Epoch 9: val_balanced_acc did not improve from 0.56798\n",
            "72/72 [==============================] - 17s 231ms/step - loss: 0.5233 - accuracy: 0.8106 - balanced_acc: 0.7656 - val_loss: 0.6531 - val_accuracy: 0.7772 - val_balanced_acc: 0.4426 - lr: 0.0010\n",
            "Epoch 10/50\n",
            "72/72 [==============================] - ETA: 0s - loss: 0.4870 - accuracy: 0.8197 - balanced_acc: 0.7738\n",
            "Epoch 10: val_balanced_acc did not improve from 0.56798\n",
            "72/72 [==============================] - 17s 233ms/step - loss: 0.4870 - accuracy: 0.8197 - balanced_acc: 0.7738 - val_loss: 0.6001 - val_accuracy: 0.7565 - val_balanced_acc: 0.5434 - lr: 0.0010\n",
            "Epoch 11/50\n",
            "72/72 [==============================] - ETA: 0s - loss: 0.4572 - accuracy: 0.8328 - balanced_acc: 0.7953\n",
            "Epoch 11: val_balanced_acc did not improve from 0.56798\n",
            "72/72 [==============================] - 17s 234ms/step - loss: 0.4572 - accuracy: 0.8328 - balanced_acc: 0.7953 - val_loss: 0.5754 - val_accuracy: 0.7979 - val_balanced_acc: 0.5651 - lr: 0.0010\n",
            "Epoch 12/50\n",
            "72/72 [==============================] - ETA: 0s - loss: 0.4019 - accuracy: 0.8511 - balanced_acc: 0.8135\n",
            "Epoch 12: val_balanced_acc did not improve from 0.56798\n",
            "72/72 [==============================] - 17s 233ms/step - loss: 0.4019 - accuracy: 0.8511 - balanced_acc: 0.8135 - val_loss: 0.6062 - val_accuracy: 0.7565 - val_balanced_acc: 0.3587 - lr: 0.0010\n",
            "Epoch 13/50\n",
            "72/72 [==============================] - ETA: 0s - loss: 0.3631 - accuracy: 0.8722 - balanced_acc: 0.8446\n",
            "Epoch 13: val_balanced_acc did not improve from 0.56798\n",
            "72/72 [==============================] - 17s 233ms/step - loss: 0.3631 - accuracy: 0.8722 - balanced_acc: 0.8446 - val_loss: 0.7509 - val_accuracy: 0.7513 - val_balanced_acc: 0.4285 - lr: 0.0010\n",
            "Epoch 14/50\n",
            "72/72 [==============================] - ETA: 0s - loss: 0.3263 - accuracy: 0.8829 - balanced_acc: 0.8465\n",
            "Epoch 14: val_balanced_acc did not improve from 0.56798\n",
            "72/72 [==============================] - 17s 233ms/step - loss: 0.3263 - accuracy: 0.8829 - balanced_acc: 0.8465 - val_loss: 0.6383 - val_accuracy: 0.7927 - val_balanced_acc: 0.4355 - lr: 0.0010\n",
            "Epoch 15/50\n",
            "72/72 [==============================] - ETA: 0s - loss: 0.2832 - accuracy: 0.9080 - balanced_acc: 0.8708\n",
            "Epoch 15: val_balanced_acc did not improve from 0.56798\n",
            "72/72 [==============================] - 17s 234ms/step - loss: 0.2832 - accuracy: 0.9080 - balanced_acc: 0.8708 - val_loss: 0.7346 - val_accuracy: 0.7565 - val_balanced_acc: 0.4420 - lr: 0.0010\n",
            "Epoch 16/50\n",
            "72/72 [==============================] - ETA: 0s - loss: 0.2828 - accuracy: 0.9169 - balanced_acc: 0.8900\n",
            "Epoch 16: val_balanced_acc did not improve from 0.56798\n",
            "72/72 [==============================] - 17s 234ms/step - loss: 0.2828 - accuracy: 0.9169 - balanced_acc: 0.8900 - val_loss: 0.7208 - val_accuracy: 0.7565 - val_balanced_acc: 0.4434 - lr: 0.0010\n",
            "Epoch 17/50\n",
            "72/72 [==============================] - ETA: 0s - loss: 0.2733 - accuracy: 0.9213 - balanced_acc: 0.9030\n",
            "Epoch 17: val_balanced_acc did not improve from 0.56798\n",
            "72/72 [==============================] - 17s 234ms/step - loss: 0.2733 - accuracy: 0.9213 - balanced_acc: 0.9030 - val_loss: 0.6782 - val_accuracy: 0.7772 - val_balanced_acc: 0.4531 - lr: 0.0010\n",
            "Epoch 18/50\n",
            "72/72 [==============================] - ETA: 0s - loss: 0.2242 - accuracy: 0.9359 - balanced_acc: 0.8980\n",
            "Epoch 18: val_balanced_acc did not improve from 0.56798\n",
            "72/72 [==============================] - 17s 233ms/step - loss: 0.2242 - accuracy: 0.9359 - balanced_acc: 0.8980 - val_loss: 0.8037 - val_accuracy: 0.7254 - val_balanced_acc: 0.4336 - lr: 0.0010\n",
            "Epoch 19/50\n",
            "72/72 [==============================] - ETA: 0s - loss: 0.2179 - accuracy: 0.9383 - balanced_acc: 0.9174\n",
            "Epoch 19: val_balanced_acc did not improve from 0.56798\n",
            "72/72 [==============================] - 17s 234ms/step - loss: 0.2179 - accuracy: 0.9383 - balanced_acc: 0.9174 - val_loss: 1.0061 - val_accuracy: 0.6995 - val_balanced_acc: 0.5017 - lr: 0.0010\n",
            "Epoch 20/50\n",
            "72/72 [==============================] - ETA: 0s - loss: 0.1659 - accuracy: 0.9577 - balanced_acc: 0.9210\n",
            "Epoch 20: val_balanced_acc did not improve from 0.56798\n",
            "72/72 [==============================] - 17s 233ms/step - loss: 0.1659 - accuracy: 0.9577 - balanced_acc: 0.9210 - val_loss: 0.7180 - val_accuracy: 0.7824 - val_balanced_acc: 0.4524 - lr: 0.0010\n",
            "Epoch 21/50\n",
            "72/72 [==============================] - ETA: 0s - loss: 0.2024 - accuracy: 0.9451 - balanced_acc: 0.9113\n",
            "Epoch 21: val_balanced_acc did not improve from 0.56798\n",
            "72/72 [==============================] - 17s 233ms/step - loss: 0.2024 - accuracy: 0.9451 - balanced_acc: 0.9113 - val_loss: 0.7363 - val_accuracy: 0.7513 - val_balanced_acc: 0.4415 - lr: 0.0010\n",
            "Epoch 22/50\n",
            "72/72 [==============================] - ETA: 0s - loss: 0.1045 - accuracy: 0.9745 - balanced_acc: 0.9500\n",
            "Epoch 22: val_balanced_acc did not improve from 0.56798\n",
            "72/72 [==============================] - 17s 234ms/step - loss: 0.1045 - accuracy: 0.9745 - balanced_acc: 0.9500 - val_loss: 0.9148 - val_accuracy: 0.7461 - val_balanced_acc: 0.4374 - lr: 0.0010\n",
            "Epoch 23/50\n",
            "72/72 [==============================] - ETA: 0s - loss: 0.0549 - accuracy: 0.9913 - balanced_acc: 0.9493\n",
            "Epoch 23: val_balanced_acc did not improve from 0.56798\n",
            "72/72 [==============================] - 17s 234ms/step - loss: 0.0549 - accuracy: 0.9913 - balanced_acc: 0.9493 - val_loss: 0.8589 - val_accuracy: 0.7772 - val_balanced_acc: 0.4096 - lr: 0.0010\n",
            "Epoch 24/50\n",
            "72/72 [==============================] - ETA: 0s - loss: 0.0339 - accuracy: 0.9963 - balanced_acc: 0.9721\n",
            "Epoch 24: val_balanced_acc did not improve from 0.56798\n",
            "72/72 [==============================] - 17s 234ms/step - loss: 0.0339 - accuracy: 0.9963 - balanced_acc: 0.9721 - val_loss: 0.8787 - val_accuracy: 0.7772 - val_balanced_acc: 0.4405 - lr: 0.0010\n",
            "Epoch 25/50\n",
            "72/72 [==============================] - ETA: 0s - loss: 0.2120 - accuracy: 0.9514 - balanced_acc: 0.9159\n",
            "Epoch 25: val_balanced_acc did not improve from 0.56798\n",
            "72/72 [==============================] - 17s 233ms/step - loss: 0.2120 - accuracy: 0.9514 - balanced_acc: 0.9159 - val_loss: 0.8101 - val_accuracy: 0.7720 - val_balanced_acc: 0.4018 - lr: 0.0010\n",
            "Epoch 26/50\n",
            "72/72 [==============================] - ETA: 0s - loss: 0.0267 - accuracy: 0.9987 - balanced_acc: 0.9696\n",
            "Epoch 26: val_balanced_acc did not improve from 0.56798\n",
            "72/72 [==============================] - 17s 233ms/step - loss: 0.0267 - accuracy: 0.9987 - balanced_acc: 0.9696 - val_loss: 0.8723 - val_accuracy: 0.7772 - val_balanced_acc: 0.3954 - lr: 0.0010\n",
            "Epoch 27/50\n",
            "72/72 [==============================] - ETA: 0s - loss: 0.0163 - accuracy: 0.9998 - balanced_acc: 0.9791\n",
            "Epoch 27: val_balanced_acc did not improve from 0.56798\n",
            "72/72 [==============================] - 17s 233ms/step - loss: 0.0163 - accuracy: 0.9998 - balanced_acc: 0.9791 - val_loss: 0.9092 - val_accuracy: 0.7876 - val_balanced_acc: 0.4136 - lr: 0.0010\n",
            "Epoch 28/50\n",
            "72/72 [==============================] - ETA: 0s - loss: 0.0126 - accuracy: 1.0000 - balanced_acc: 0.9735\n",
            "Epoch 28: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "\n",
            "Epoch 28: val_balanced_acc did not improve from 0.56798\n",
            "72/72 [==============================] - 17s 233ms/step - loss: 0.0126 - accuracy: 1.0000 - balanced_acc: 0.9735 - val_loss: 0.9484 - val_accuracy: 0.7824 - val_balanced_acc: 0.4059 - lr: 0.0010\n",
            "Epoch 29/50\n",
            "72/72 [==============================] - ETA: 0s - loss: 0.0089 - accuracy: 1.0000 - balanced_acc: 0.9620\n",
            "Epoch 29: val_balanced_acc did not improve from 0.56798\n",
            "72/72 [==============================] - 17s 234ms/step - loss: 0.0089 - accuracy: 1.0000 - balanced_acc: 0.9620 - val_loss: 1.0442 - val_accuracy: 0.7409 - val_balanced_acc: 0.3877 - lr: 5.0000e-04\n",
            "Epoch 30/50\n",
            "72/72 [==============================] - ETA: 0s - loss: 0.0084 - accuracy: 1.0000 - balanced_acc: 0.9772\n",
            "Epoch 30: val_balanced_acc did not improve from 0.56798\n",
            "72/72 [==============================] - 17s 233ms/step - loss: 0.0084 - accuracy: 1.0000 - balanced_acc: 0.9772 - val_loss: 1.0085 - val_accuracy: 0.7668 - val_balanced_acc: 0.4063 - lr: 5.0000e-04\n",
            "Epoch 31/50\n",
            "72/72 [==============================] - ETA: 0s - loss: 0.0074 - accuracy: 1.0000 - balanced_acc: 0.9610\n",
            "Epoch 31: val_balanced_acc did not improve from 0.56798\n",
            "72/72 [==============================] - 17s 234ms/step - loss: 0.0074 - accuracy: 1.0000 - balanced_acc: 0.9610 - val_loss: 1.0099 - val_accuracy: 0.7617 - val_balanced_acc: 0.3908 - lr: 5.0000e-04\n",
            "Epoch 32/50\n",
            "72/72 [==============================] - ETA: 0s - loss: 0.0070 - accuracy: 1.0000 - balanced_acc: 0.9640\n",
            "Epoch 32: val_balanced_acc did not improve from 0.56798\n",
            "72/72 [==============================] - 17s 233ms/step - loss: 0.0070 - accuracy: 1.0000 - balanced_acc: 0.9640 - val_loss: 1.0340 - val_accuracy: 0.7617 - val_balanced_acc: 0.4055 - lr: 5.0000e-04\n",
            "Epoch 33/50\n",
            "72/72 [==============================] - ETA: 0s - loss: 0.0062 - accuracy: 1.0000 - balanced_acc: 0.9633\n",
            "Epoch 33: val_balanced_acc did not improve from 0.56798\n",
            "72/72 [==============================] - 17s 233ms/step - loss: 0.0062 - accuracy: 1.0000 - balanced_acc: 0.9633 - val_loss: 1.0641 - val_accuracy: 0.7720 - val_balanced_acc: 0.4108 - lr: 5.0000e-04\n",
            "Epoch 34/50\n",
            "72/72 [==============================] - ETA: 0s - loss: 0.0061 - accuracy: 1.0000 - balanced_acc: 0.9719\n",
            "Epoch 34: val_balanced_acc did not improve from 0.56798\n",
            "72/72 [==============================] - 17s 233ms/step - loss: 0.0061 - accuracy: 1.0000 - balanced_acc: 0.9719 - val_loss: 1.0799 - val_accuracy: 0.7565 - val_balanced_acc: 0.4013 - lr: 5.0000e-04\n",
            "Epoch 35/50\n",
            "72/72 [==============================] - ETA: 0s - loss: 0.0058 - accuracy: 1.0000 - balanced_acc: 0.9778\n",
            "Epoch 35: val_balanced_acc did not improve from 0.56798\n",
            "72/72 [==============================] - 17s 234ms/step - loss: 0.0058 - accuracy: 1.0000 - balanced_acc: 0.9778 - val_loss: 1.1024 - val_accuracy: 0.7668 - val_balanced_acc: 0.4099 - lr: 5.0000e-04\n",
            "Epoch 36/50\n",
            "72/72 [==============================] - ETA: 0s - loss: 0.0051 - accuracy: 1.0000 - balanced_acc: 0.9633\n",
            "Epoch 36: val_balanced_acc did not improve from 0.56798\n",
            "72/72 [==============================] - 17s 233ms/step - loss: 0.0051 - accuracy: 1.0000 - balanced_acc: 0.9633 - val_loss: 1.1148 - val_accuracy: 0.7513 - val_balanced_acc: 0.3924 - lr: 5.0000e-04\n",
            "Epoch 37/50\n",
            "72/72 [==============================] - ETA: 0s - loss: 0.0049 - accuracy: 1.0000 - balanced_acc: 0.9663\n",
            "Epoch 37: val_balanced_acc did not improve from 0.56798\n",
            "72/72 [==============================] - 17s 233ms/step - loss: 0.0049 - accuracy: 1.0000 - balanced_acc: 0.9663 - val_loss: 1.1091 - val_accuracy: 0.7565 - val_balanced_acc: 0.3995 - lr: 5.0000e-04\n",
            "Epoch 38/50\n",
            "72/72 [==============================] - ETA: 0s - loss: 0.0047 - accuracy: 1.0000 - balanced_acc: 0.9606\n",
            "Epoch 38: val_balanced_acc did not improve from 0.56798\n",
            "72/72 [==============================] - 17s 234ms/step - loss: 0.0047 - accuracy: 1.0000 - balanced_acc: 0.9606 - val_loss: 1.1319 - val_accuracy: 0.7565 - val_balanced_acc: 0.4013 - lr: 5.0000e-04\n",
            "Epoch 39/50\n",
            "72/72 [==============================] - ETA: 0s - loss: 0.0045 - accuracy: 1.0000 - balanced_acc: 0.9659\n",
            "Epoch 39: val_balanced_acc did not improve from 0.56798\n",
            "72/72 [==============================] - 17s 233ms/step - loss: 0.0045 - accuracy: 1.0000 - balanced_acc: 0.9659 - val_loss: 1.1337 - val_accuracy: 0.7617 - val_balanced_acc: 0.4055 - lr: 5.0000e-04\n",
            "Epoch 40/50\n",
            "72/72 [==============================] - ETA: 0s - loss: 0.0043 - accuracy: 1.0000 - balanced_acc: 0.9534\n",
            "Epoch 40: val_balanced_acc did not improve from 0.56798\n",
            "72/72 [==============================] - 17s 233ms/step - loss: 0.0043 - accuracy: 1.0000 - balanced_acc: 0.9534 - val_loss: 1.1600 - val_accuracy: 0.7617 - val_balanced_acc: 0.4055 - lr: 5.0000e-04\n",
            "Epoch 41/50\n",
            "72/72 [==============================] - ETA: 0s - loss: 0.0040 - accuracy: 1.0000 - balanced_acc: 0.9610\n",
            "Epoch 41: val_balanced_acc did not improve from 0.56798\n",
            "72/72 [==============================] - 17s 233ms/step - loss: 0.0040 - accuracy: 1.0000 - balanced_acc: 0.9610 - val_loss: 1.1679 - val_accuracy: 0.7617 - val_balanced_acc: 0.4055 - lr: 5.0000e-04\n",
            "Epoch 42/50\n",
            "72/72 [==============================] - ETA: 0s - loss: 0.0038 - accuracy: 1.0000 - balanced_acc: 0.9673\n",
            "Epoch 42: val_balanced_acc did not improve from 0.56798\n",
            "72/72 [==============================] - 17s 235ms/step - loss: 0.0038 - accuracy: 1.0000 - balanced_acc: 0.9673 - val_loss: 1.1634 - val_accuracy: 0.7617 - val_balanced_acc: 0.4055 - lr: 5.0000e-04\n",
            "Epoch 43/50\n",
            "72/72 [==============================] - ETA: 0s - loss: 0.0037 - accuracy: 1.0000 - balanced_acc: 0.9666\n",
            "Epoch 43: val_balanced_acc did not improve from 0.56798\n",
            "72/72 [==============================] - 17s 233ms/step - loss: 0.0037 - accuracy: 1.0000 - balanced_acc: 0.9666 - val_loss: 1.1595 - val_accuracy: 0.7668 - val_balanced_acc: 0.4063 - lr: 5.0000e-04\n",
            "Epoch 44/50\n",
            "72/72 [==============================] - ETA: 0s - loss: 0.0034 - accuracy: 1.0000 - balanced_acc: 0.9679\n",
            "Epoch 44: val_balanced_acc did not improve from 0.56798\n",
            "72/72 [==============================] - 17s 233ms/step - loss: 0.0034 - accuracy: 1.0000 - balanced_acc: 0.9679 - val_loss: 1.1913 - val_accuracy: 0.7565 - val_balanced_acc: 0.3995 - lr: 5.0000e-04\n",
            "Epoch 45/50\n",
            "72/72 [==============================] - ETA: 0s - loss: 0.0034 - accuracy: 1.0000 - balanced_acc: 0.9659\n",
            "Epoch 45: val_balanced_acc did not improve from 0.56798\n",
            "72/72 [==============================] - 17s 233ms/step - loss: 0.0034 - accuracy: 1.0000 - balanced_acc: 0.9659 - val_loss: 1.1851 - val_accuracy: 0.7617 - val_balanced_acc: 0.4055 - lr: 5.0000e-04\n",
            "Epoch 46/50\n",
            "72/72 [==============================] - ETA: 0s - loss: 0.0032 - accuracy: 1.0000 - balanced_acc: 0.9696\n",
            "Epoch 46: val_balanced_acc did not improve from 0.56798\n",
            "72/72 [==============================] - 17s 234ms/step - loss: 0.0032 - accuracy: 1.0000 - balanced_acc: 0.9696 - val_loss: 1.1965 - val_accuracy: 0.7617 - val_balanced_acc: 0.4055 - lr: 5.0000e-04\n",
            "Epoch 47/50\n",
            "72/72 [==============================] - ETA: 0s - loss: 0.0030 - accuracy: 1.0000 - balanced_acc: 0.9798\n",
            "Epoch 47: val_balanced_acc did not improve from 0.56798\n",
            "72/72 [==============================] - 17s 233ms/step - loss: 0.0030 - accuracy: 1.0000 - balanced_acc: 0.9798 - val_loss: 1.2180 - val_accuracy: 0.7565 - val_balanced_acc: 0.3995 - lr: 5.0000e-04\n",
            "Epoch 48/50\n",
            "72/72 [==============================] - ETA: 0s - loss: 0.0030 - accuracy: 1.0000 - balanced_acc: 0.9775\n",
            "Epoch 48: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "\n",
            "Epoch 48: val_balanced_acc did not improve from 0.56798\n",
            "72/72 [==============================] - 17s 234ms/step - loss: 0.0030 - accuracy: 1.0000 - balanced_acc: 0.9775 - val_loss: 1.2284 - val_accuracy: 0.7513 - val_balanced_acc: 0.3936 - lr: 5.0000e-04\n",
            "Epoch 49/50\n",
            "72/72 [==============================] - ETA: 0s - loss: 0.0028 - accuracy: 1.0000 - balanced_acc: 0.9778\n",
            "Epoch 49: val_balanced_acc did not improve from 0.56798\n",
            "72/72 [==============================] - 17s 233ms/step - loss: 0.0028 - accuracy: 1.0000 - balanced_acc: 0.9778 - val_loss: 1.2097 - val_accuracy: 0.7565 - val_balanced_acc: 0.3995 - lr: 2.5000e-04\n",
            "Epoch 50/50\n",
            "72/72 [==============================] - ETA: 0s - loss: 0.0027 - accuracy: 1.0000 - balanced_acc: 0.9716\n",
            "Epoch 50: val_balanced_acc did not improve from 0.56798\n",
            "72/72 [==============================] - 17s 233ms/step - loss: 0.0027 - accuracy: 1.0000 - balanced_acc: 0.9716 - val_loss: 1.2258 - val_accuracy: 0.7617 - val_balanced_acc: 0.4055 - lr: 2.5000e-04\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAEICAYAAABPgw/pAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO2dd3gV1fOH30lCDb2XAKGJICoqoiIigiiIil2wV9SfvWP72nvvir03VERRERQREJUiSpcivYXeSZvfH7Mxl5Debu7NvM+zT/bunt2ds7n3s2fnzJkjqorjOI4T+cSE2wDHcRyneHBBdxzHiRJc0B3HcaIEF3THcZwowQXdcRwnSnBBdxzHiRJc0B3HcaIEF3Sn0IjIWSIyWUS2ishKEflORLqF0Z5FIrIjsCdjeSGfx/4sIpeUtI35QUQuEJHx4bbDiTziwm2AE5mIyA3AYOByYCSQDPQB+gN7iJGIxKlqaimYdoKqji7uk5ai/Y5TaLyF7hQYEakJ3AdcqapfqOo2VU1R1a9V9eagzD0iMlRE3heRzcAFItJERIaLyHoRmS8il4acs0vQ2t8sIqtF5Klge+XgHOtEZKOITBKRhoWw+QIRGS8iT4jIBhH5V0T6BvseBI4AXght1YuIisiVIjIPmBdsuzSwfX1QlyYh11ARuUZEForIWhF5XERiRKRiUH7fkLINRGS7iNQvYD26BvdgU/C3a5Y6LhSRLUH9zg62txGRscExa0Xkk4LePydCUFVffCnQgrXEU4G4XMrcA6QAJ2ENhyrAL8BLQGWgE5AE9AzKTwTODdarAYcG65cBXwNVgVjgIKBGDtdcBBydw74LAnsuDc5zBbACkGD/z8AlWY5RYBRQJ7C/J7AWOBCoBDwP/JKl/JigfHPgn4xzBvV+NKTstcDXudg6PpvtdYANwLnY2/XA4HNdIB7YDLQLyjYG9gnWPwLuCP4PlYFu4f4O+VIyi7fQncJQF1irebsgJqrqMFVNB+oBhwO3qupOVZ0GvA6cF5RNAdqISD1V3aqqv4Vsrwu0UdU0VZ2iqptzueawoCWfsVwasm+xqr6mqmnAO5jo5dXaf1hV16vqDuBs4E1Vnaqqu4DbgMNEJDGk/KNB+SXAM5joElxvoIhI8Plc4L08rp2VfsA8VX1PVVNV9SNgDnBCsD8d6CgiVVR1parODLanAC2AJsG9d/98lOKC7hSGdUA9EcmrD2ZpyHoTYL2qbgnZthhoGqxfDOwFzAlcCccH29/DfPQfi8gKEXlMRCrkcs2TVLVWyPJayL5VGSuquj1YrVbAOiwOOcdW7F40zaH84uAYVPV3YDvQQ0T2BtoAw/O4dlZ2u37INZqq6jbgTKxPY6WIjAiuA3ALIMAfIjJTRC4q4HWdCMEF3SkME4FdmDslN0JTea4A6ohI9ZBtzYHlAKo6T1UHAg2AR4GhIhKv5pu/V1U7AF2B48ls1RcnOaUdzVqHFhkfRCQee3tYHlKmWch68+CYDN4BzsFa50NVdWcBbdzt+iHXyLiHI1W1N/bmMQd4Ldi+SlUvVdUmmAvrJRFpU8BrOxGAC7pTYFR1E/A/4EUROUlEqopIBRHpKyKP5XDMUuBX4OGgo3M/rFX+PoCInCMi9QP3zMbgsHQROUpE9hWRWMxHnIK5Foqb1UCrPMp8BFwoIp1EpBLwEPC7qi4KKXOziNQWkWaYnzy0A/J94GRM1N/N41oS3Kf/FuBbYC+xcNE4ETkT6AB8IyINRaR/8JDZBWwluE8icrqIJATn3YA9pEriHjrhJtxOfF8id8F8ypOBbZg7YwTQNdh3D/B+lvIJwDfAemABcHnIvveBNZgQzcRcJ2A+6LnBNVYDz5FDZyzWKbojOEfG8mWw7wKydDRiwtYmWD8M68TcADyXdX/IMZcHtq8P6pKQ5XzXAAsxV8yTQGyW40cHdkou9/WC4FxZlzigGzAF2BT87RYc0xgYG2zfiHXydgj2PYa14rcGtg8K93fHl5JZMnr4HccpIiKiQFtVnZ9LmTeBFap6Z+lZ5pQXfGCR45QSQTTMKcAB4bXEiVbch+44pYCI3A/MAB5X1X/DbY8TnbjLxXEcJ0rwFrrjOE6UEDYfer169TQxMTFcl3ccx4lIpkyZslZVs80BFDZBT0xMZPLkyeG6vOM4TkQiIllHC/+Hu1wcx3GihIgU9FTPSu04jrMHESfoL74IzZrBrl3htsRxHKdsEXGC3rIlrFoFP/0Ubkscx3HKFhEn6L16QfXq8MUX4bbEcRynbBFxgl6pEhx/PAwbBmlp4bbGcRyn7BBxgg5w6qmwdi2M93lXHMdx/iMiBb1PH6hc2d0ujuM4oUSkoMfHm6h/8QV4KhrHcRwjIgUd4JRTYNkymDQp3JY4jlPuSEuGrf/CmnGw6kfYuTZ/x2m6HbdrfYmYFbH50I8/HuLirJXepUu4rXEcJypJ3ghrJ0LSeNg0G7Yvhe3LYOdq9piGNr4F1OkMdQ6yv9XbwtaFsHE6bJoR/J0JqVuhy6vQZlCxmxuxgl67NvTsCZ9/Dg8/DCLhtshxnIgmbRdsWwTrJkHShEDEZwIKEgvV94KqzaD2/va3aoL9lVhYPxXWT4H1k2Hp53ueu1JdqLkvtLoQanWEhr1KpAoRK+hgbpfLL4eZM6Fjx3Bb4zhOmUAV1v4Giz82UY6Lh4q1g6WO/a1QHXaugm2LYesi2L4YdqzMPEdcdajfFZqfAQ26Qd0udp6caBQi0MkbTOC3zIfqrU3IKzcolVZnRAt6//5wxRXmdnFBd5wIRhVSNsLONbBrLRBjohtXzZYK1SGmYs6iqAobppmIL/nEhDqmEjQ4AtJT7fOGP01sU7faMTEVoGpzc5U07mt/41tA7U5QsyPExBauLhVrm8A3KplWeG5EtKA3agSHH26C/r//hdsax3HyRNV8ySu/h9U/w44VsGsN7EwCzSPrnsQFAl/VWssZS2y8uUq2/GNlGh8D+90PCf2hQo09z5OeAilboGItkIiNC8mWiBZ0MLfLDTfAggXQunW4rXEcZw+SN8Kq0SbiK76HHctte82OUK0l1O0MlRqYW6JyA6hUz6JBUrea8KZuhdQtwfq2zCVtu/1N2QTxidD+Jmh2ivmrcyOmAlSqU+LVDgcRL+gnn2yC/uWXcNNN4bbGccoR6SnWEbhmLKweC1sX2DZNgfRkW09PMdFFoUJNaz037mNL1SbhrkHUEfGCnpgIBx5obhcXdMcpBOkpsG2JCfLWhbZsW2Tui4q1oEKt4G9NW7bONxFP+tVayQA12pvvOaaStYAzFqlgxzbsCfUOhZiIl5wyTVTc3VNOgTvvhBUroIk/9B0nZ1Rh81xI+gXW/GIx1tsWmYsjg5hKEN/ctqVsMpdJVv92rX2h9UXQ4Eho0N1cJU7YiSpBHzYM/u//wm2N45QhkjdaLPX6KSbga36BXUm2r3IjqN8NWpxl4XXVWtlSpcnunYWq1hJP3mSRKJUb5u2ndsJCVAh6+/aw997mdnFBd8otm/+Btb/CxhnByMQZmR2QYB2HTfpmtqqrtc5fbLRIZkQJ/gpclokKQQdrpT/6qKXVrVcv3NY4Timgaq3vJUNtdOKmGbY9trL5tBv2tFGJNTtC7f1sZKMT1USNoA8cCI88AoMHw+uvh9saxwlBFf6+0wa9tBhovudqrQp3rvQ02DAVlg0zId/yDyDmOjnwGWjSB6q1KfygGCeiyVPQReRN4HhgjaruMR5TRAR4FjgO2A5coKpTi9vQvOjYEW691fK6nHCCjSJ1nDLB9Lth5kNQcx+Y9TDMfBAaHgWtLra46bgqOR+rCptnW0a/1T/ZYJyUjZY/pEEP2Pt6SDgJqjQqrdo4ZRjRPBKKi0h3YCvwbg6CfhxwNSbohwDPquoheV24c+fOOnny5EIZnRPJyXDooZZWd/p0aNgw2LF9hfXCe8hU+Nm22IZf1+4UbktKh5kPwV93QOtLLMPejhWw8G1Y8CZs+9fCABNOsqHt6akWTaKptp623UIDd66yc8W3tOHkDXtCo95Q2X2L5RERmaKqnbPdl5egBydIBL7JQdBfBX5W1Y+Cz3OBHqq6MmvZUEpC0AFmzbK49N69YfhwkJ0rYXhr2OcO6HhHsV/PKQCqMLKLhcmdvDL6H7Czn4I/b4TEc+DQt3d3g2i6xXIveANWfGfbYuIs9lvibD2mAtQ+MFPEq7UMSzWcskVugl4cv6imwNKQz8uCbXsIuogMAgYBNG/evBguvScdOljn6HXXwWuvwaCub0LaDpg/BDoMdt9iOFnzs6UXBUgaZ26HaOWfl0zMm58Oh7615/dOYqz+0XwPnFKnVDPTqOoQVe2sqp3r169fYte5+mo4+mi48YY0Uua8ZiPdti+B1T+W2DWdfDDrcahUH2KrwNIonhB2wZsw+UpoegJ0/SD630ScMkNxCPpyoFnI54RgW9iIiYG33oJj9x9FheTFpB3wnA2EWPBGOM0q32ycASu/g3bXWB6PpV/uPjoxGkjdAXOegd8vgcbHQrfPzG3iOKVEcQj6cOA8MQ4FNuXlPy8NEhLgmStfZc2m+jzy0Znmx1w2DHatC7dp5ZPZT0BsVWh7hUV27FhuM8NEA9sWw7TB8FUzmHo9NDoajvgCYiuF2zKnnJGnoIvIR8BEoJ2ILBORi0XkchG5PCjyLbAQmA+8BpSNsZrbV5AgX/P72gu5+96KTNtysWWA+/f9cFtW/ti+HBZ/CK0vtjelpsdbx192U3UVhC0Lgkx+YUDVQgl/ORmGt4LZj9sIzF5j4KiRlrPbcUqZPJ17qjowj/0KXFlsFhUXC94ATaP7hZfS4m3ocdK+LH+jM/EL37DXfp+EtPSY+yxomsVMg2Xfa9TL/OidHi3c/2LLfBjRwfKKHPg0NDu1dP6nu9bDv+9aJ/vm2Za7u/2t0PZyS2jlOGEkuqbryCA9DRa8Do2OpmZCG376ySaVvuvti222lPXFHy7p5EDKZpj/KjQ7ffewu2anWrrWjdMLd97p9wTpXevC+NNhTB/LZVISqMKacfDrOfBlE3OrVKhpoYgnLYVOD7mYO2WC6BT0lSMtqqXNZQC0aAFjxsCofwayPbkKSb+/GWYDyxHzh5iod7h59+0J/QEpXLTLxhmw6EN70+ozGQ56Ftb9Bt/uC3/dCanbM8vuTILlI+Dv/5no/3IKbFua87lDSUuGOc/am8Do7rD8axsg1HcaHDsRWp1veVMcp4yQr4FFJUFJDSwCYGx/+4H3XwqxFf/bvGgRTHnhPHq3/4qFnVbS6SD3c5YoacnmX66xF/T6ac/9o480F0a/ArbSx51qU5qduDAzjeuOVfDnzbDofZvot+6hsO4PG40JFvdds6NN3hBTEQ57x3z5ObF+Kvx2gb1B1D0U2l5mMeW5zfzuOKVAbgOLoq+Fvn0ZrPgGWl20m5iDzW7U9ZyLqVFlM6/e8Tl//RUeE8sNiz+2aJb2N2e/P+EUyxBYEFfJ+inWqt/7ht1zcldpBF3fg6PHmhtm7a9Q5yDo9JhtO30zHPcX9Jli7pGxJ8DUG+2hE0paMvx9D4w8xGafP/LroDV+gYu5U+aJPkFf8KbFN7e5NNvdjffvTkrlNpx3+Bv06oWLekmhCnOesFZx4z7Zl2l2iv1d9mX+z/vXnVCxTmYHa1YadIe+U+CkJXDEZ+bqadA9U4xr7AXHTIS9roI5T8GobtZqB9jwF/xwCMy4F1oMgONm5N6Kd5wyRnQJ+n+docfknJ5UhArtLuSw1mNpnzCf7t1h5Mh8nn/nGpsMN0xuqohi5UhzV7S/Kefok/hmUOfg/PvR14y3meM73AoVahTettjK0Pl5OOJz2DIPvjsA/rgcvu8MO1ZC92HW2o/SmeGd6CW6BH3ld7B9qfk7c6Pl+SAxjHj+TRIToV8/eOWVHMqqwuoxMH4ADEuAH3tYbmsX9ZzRdEsRW6Wp5f/OjWanBL7uPDoqM3KKV25krevioNkp0PdPmwxi/qvmI+83M+iwdZzII7oEff4Q+8E3PSH3clWbQuO+1Fj7NuN/SaVPH7jiCrjhBkhLC8rsWg9znoYR7eHHntbibHsltLrQUqL+ebOLek7MfhKSxsO+d+/Rj7EH+XW7rBpt2Qn3uaN4B+1US4Te48y9cviHPlemE9FEdtaglK02BdfG6bDxb1gxIsiomI/8Ga0vhnEjqL76Vb56KYFhHyxhwfSlTHhsKYcfsJTYjZMhfRfUOwwOfSeIcKhiIh4XD3OetJGnBz3rg5RCWfsb/HW7xZm3viTv8jX2Mj/70i8sDDE7VC2neNXmOfaNFImYClBrn+I/r+OUMpEn6MtHmJ9843QbmJJBXDWbwWWvq/N3nqbH26QXk68iFji1BaQ1r8iiNQn8Oa0Z7Q4dRPX9L4ba++9+nAgc9JyFvs15ykT94Jd2nyW9rLB9uXUg5jYjTnGSvBEmDLS5Kw95Pf8PumanwMwHrI+icoM99y//GtZPsnN6fhTHyZHIE/QdK23IdZ0DzRdeez+ota/NaF4QUY2pAEeNsodC1WZQtRmxleszb2QMZ5xhGRsHDYJrrrFEX7shAgc8ATGVbEqx9GTo8lrZyrW+bTGM6Ag1O1jYXn4GwKhaH0SVxgXPEqhqWQa3LzMXRsVa+T+22Skw4z5YNhzaZGnV71gJf98F1dva/9txnByJzoFFRWT2bLjnHhg61IR9wAC48UbolHXWNFWYfq+FuSWeHcxKUwaekarwcz9YMwbSdkLiuTaQJrcWc1qyDaFfPtzmq6zWCqq3M5dI9b1sPsz6XXN+aM57BSZdYblZOtxScHu/bmMulb2vs1jz9VPtb8b0a4d/Ai3OKNh5HScKKekZi6KO9u3hk09sZOmzz8Lrr8P770PPnnDTTdCnT6CNIrDfPdbx99cdULdLzn7g0mTxxxbxc+AzNux++v/sLSbr8PsM0lNh4jkm5u1vttb55n9sRvnVo+2hAFCjne1PPGd318eGv2HKdZYDvP1NBbdXxHzusx+3WY0kxiJPGh9jU7DV7wp1Dy74eR2nnOEt9HywcSMMGQLPPQfLl8Mhh8D999usSCJYC/OnXtZBe8ICqFAtfMbuXGuROdVaQe9fTRwnnAlLhsKR30DT43Yvr+kw8QJY9B4c8CS0v2HP/duXWXKqOU/Chj8tkmjv6yxXTkwFi99O3mgjMbPzgeeHXetg2Vcm5LX39/SzjpMD5WvofwlQqxbccgssXGjzlK5cCcccAz16wLhxmKrv/5B16s19NrzG/nmjieshr5tPX8TmtKzdCX4dCJtmZ5ZVNTfJovdgv/v3FHOwB0J8c2h5tg2b7znKWvvTBsOw5jD6KNg8F7q+X3gxBwsXbH0R1D/MxdxxCokLegGoWBEuuQT++QdeeMH+du8Oxx4Lfyw8FJqeaG6DXevDY+DKUZaru8NgE90M4uJt9GNsZRh7otmnamlg5w+BDrdZfHdeiNhsPD1/gD5TLVJowxTo+D/Lb+44Tlhxl0sR2L4dXn4ZHnkE1q6Ft56ezgUN9rdOwU6P5H7w3OcgeYMlmapQvejGpG6DEfuaP7/vtOyjWpJ+hR+PstwmdTrDrEeg3bU2QURhY+lTtobXxeQ45Qx3uZQQVata9MvChXDGGXDh9fsye8dZJtY7cplWdf5rMOVam6Th671g4dtFnzD577stVWyX13IOUazfFQ5+xUZdznoE2gwqmpiDi7njlCFc0IuB6tXhgw/g9NPh+NvvJS01BWY8kH3hlaPMb924D/SeYPHzv10II7tY8qnCsH4KzH3aOikbHJF72dYXWmhh+5vg4Jd9lKvjRBHucilGUlJg4EDoVeMKBvV6ndj+c3fP+rhxJozqahMw9B5vGQNVYfFHMO1WiyZpfoa5a0Kna8sJTYe1v8Okyyx3d7/ZULFmyVXQcZyw4y6XUqJCBfjoI5iy806SU+KY89k9mTt3rIKx/ayD8sgRmelfRSDxLDh+DnS824a5D29l/vAp18Pyb81PnYGmmy98yvXwVQt7QGz+x1wtLuaOU67xFnoJkJwMIx64hf57PcGn26Yz4OKWMLqHxan3/sVm0smJbUth8YdBdsFxliBM4ixJWI12sOI7mwUopqK5bZqfbtklXcwdp1yQWwvdBb2ESN6yjtQvWjLq76NokRjH/nW/RLp/WbBc26k7bCq1VaNM4DfPsbDBZqdDwglFm+TBcZyIxIf+h4GK1esSs/9N9K9wNwA3fPA0q77pz003wYEH5vMkcVUsvttjvB3HyQf58qGLSB8RmSsi80VkcDb7LxCRJBGZFiz5SIQd/cTtcz3UaMeWpjcQ0/5avvkGDjoIevWC777z+TEcxyle8nS5iEgs8A/QG1gGTAIGquqskDIXAJ1VNd9zg0W7y+U/VP8LDdy0yXLCPPus5YRp185Gnp53HjQowqh5x3HKD0WNcukCzFfVhaqaDHwM+KSL+SUkzrtmTbj5ZhuI9O67ULeufU5IsBj2kSMhvYjjixzHKb/kR9CbAqEz+C4LtmXlVBH5W0SGikiz7E4kIoNEZLKITE5KSiqEudFBxYpw7rkwYQLMnAlXXw1jxlha3lat4O67Yfp0d8k4jlMwiisO/WsgUVX3A0YB72RXSFWHqGpnVe1cv379Yrp0ZNOhAzz5pLlgPvkE2ra11Lz77WcumcGDYdIkF3fHcfImP4K+HAhtcScE2/5DVdep6q7g4+tALoHWTnZUqmT5YEaNghUr4JVXIDHRxL5LF2jRwvLGrF4dbksdxymr5EfQJwFtRaSliFQEBgDDQwuISOOQjycCs3EKTaNGcNll8MMPJuBvvw0HHGATbLRrB88/D6mp4bbScZyyRp6CrqqpwFXASEyoP1XVmSJyn4icGBS7RkRmishfwDXABSVlcHmjTh04/3z46iuYMcNa69dcY+GP4wuZy8txnOjER4pGGKrwxRdw/fWwdKl1rj72mLXqHceJfjw5VxQhAqeeCrNnw+23W0dqu3Zw6602qbXjOOUXF/QIJT4eHnzQ3DDHHGOdp61awYknwvffezy745RHXNAjnLZt4bPPrHV+xx3w++/Qt6+12p96CjZsCLeFjuOUFi7oUUJCgsWvL1lisyc1aGBhjk2aWGqB8eM9lt1xoh0X9CijUiU46ywbhfrnn3DhhTBsGBxxBOyzDzz9NKxbF24rHccpCVzQo5hOneCll2DlSnjzTcslc8MNma326dPDbaHjOMWJC3o5ID7eWuoTJ8Jff8Gll1ro4377wfHHw7hx7o5xnGjABb2csd9+8MIL5mu/7z7rRO3eHQ4/3AYveXSM40QuPrConLN9O7z1FjzxhEXK1K9vLXoRW2Ji7G9cHDRsCE2bmssmY0lIgIMPtgmyHccpeXxOUSdPUlPh008tOVh6ui2qtqSn28TXq1db4rAVK2DXrsxj27aFBx6A006zB4DjOCWHC7pTrKhafPvy5ZbPPWOA04EHwsMPQ+/eu83r4ThOMeJD/51iRcSShu27LwwYANOmwXvvwfr1cOyxNmfq77+H20rHKX/EhdsAJ/KJjYVzzrF87kOG2ACnQw+1fO61a9tSp07meqdOVjY2NtyWZ7Jrl8XwO04k4y10p9ioWBGuugoWLLAMkEccYZ2oO3eaa+brr+GZZ2zgU+fONu1eXixZYp2227eXnN3vvGMPnHnzSu4ajlMauA/dKVVULUPkrbeaWJ94ool/u3aZZVJS4Jtv4LXXLNGYqiUgGz68+FvRO3dap+6yZZZ3/u23i/f8jlPcuA/dKTOImN99zhzrQB0zBjp2hGuvhalT4bbboFkzOOUUGwR1xx2WSfKHH6xlX9wzNb3yion5EUfA++/D/PnFe37HKU28he6ElTVr4O67zfeenm5+9X794JJLLGtkXNDL8+yzcN11lrLgrbeKJzxy61ZLObzvvpbQrFUr8+17K90py3gL3SmzNGgAL78Mf/9tfxcvthGrJ5yQKeZgLfj774d337Up+IqjHfLcc5CUZGGXjRrBFVd4K92JbLyF7kQMqnDLLTaq9bbb4KGHCn+ujRuhZUvo1s06awFWrfJWulP28Ra6ExWIWAfqoEHmf3/kkcKf64knTNTvvz9zW6NGcPnl3kp3IhcXdCeiELGUwGedZa30q64yP3xBWLPGwifPOMNi4kO55RbLS/PAA8Vns+OUFi7oTsQRG2sukSuvtCiV1q3h3nthy5b8Hf/II7Bjhx2TFfelO5GMC7oTkVSoYGmAZ860dAP33GPC/vzzlkgsJ5Ytsxb+eefB3ntnXyajlf7ggyViuuOUGC7oTkTTrh0MHWq5Yzp2tAiYvfc2H/lvv+0p7g88YOGRd9+d8zkzWunvveetdCeycEF3ooIuXeDHH21kaZ06cPPNcNhhUKOGDRq69VYb4v/GGzZjU2Ji7ufzVroTieQrOZeI9AGeBWKB11X1kSz7KwHvAgcB64AzVXVR8ZrqOLkjYu6XY4+1nO0TJ8Kvv9ry9NOWUqByZRt9mhcZrfTnnrOHQvPmNoK1WTOb1KNx493j5B2nLJBnHLqIxAL/AL2BZcAkYKCqzgop83/Afqp6uYgMAE5W1TNzO6/HoTulyc6dMHkyVK1qedvzw+rVmSkItm3bfV9MjAl91aq2xMdnrme3LT7eHiahs0BlrGcssbG2hK5nlMs6g1TW4zLWM8plkHU943PWc2a35HaerOcI3VbQvzktuR2XHTkdn9Mx2ZXJ7f7ldv287lXW9UqVLJldYcgtDj0/bYwuwHxVXRic7GOgPzArpEx/4J5gfSjwgoiIhmvUkuNkoXJlG0RUEBo2hAkTbEDTpk2wdKkty5bZ382bTei3b7dl2zZb1q3L/JyxL3SGJ8d5+WUb81Dc5EfQmwJLQz4vAw7JqYyqporIJqAusDa0kIgMAgYBNG/evJAmO07pIgK1atmy776FO0damr0lhE7rl7GelpY57V/GelqaLdmVz1gPLR+6ZBDanMo4Nut66LlCl7S0nM8Teo6s5y3o35yW3I7LjpyOz+mY7MpkLZ/12LzOld91sP6dkqBUvYCqOgQYAuZyKc1rO044iY01t4vjlCT5iXJZDjQL+ZwQbMu2jIjEATWxzlHHcRynlMiPoE8C2opISxGpCAwAhmcpMxw4P1g/DfjJ/TShKQEAACAASURBVOeO4zilS76yLYrIccAzWNjim6r6oIjcB0xW1eEiUhl4DzgAWA8MyOhEzeWcScDiQtpdjyz++XJCea03lN+6e73LF/mpdwtVrZ/djrClzy0KIjI5p7CdaKa81hvKb9293uWLotbbR4o6juNECS7ojuM4UUKkCvqQcBsQJsprvaH81t3rXb4oUr0j0ofulC4icg/QRlXPKaHzzwSuVNWfRUSAN4GTgHnAjVj+oHbFfM3m2Gjnmqqalld5x4kEIrWF7hQzInKWiEwWka0islJEvhORAg6WLxyquo+q/hx87IblDUpQ1S6qOq44xFxEFonI0SHXXKKq1UpKzMVYKCKz8i7tOMWDC7qDiNyAhaU+BDQEmgMvYTl6SpsWwCJV3ZZnybJNd6AB0EpEDi7NCweD+5zyiKpG1AL0AeYC84HB4banBOv5JrAGmBGyrQ4wCnNFjAJqF8N1agJbgdNzKXMP8H7I58+AVcAm4Bdgn5B9x2GujC3YCOKbgu31gG+AjdhYhXFATLBvEXA0cDGwE1AgPaj/81j+oIy6/wusxmJ11wEvBOdoDfwUbFsLfADUCva9F5xvR1DXW4DE4DpxQZkm2AC59cF369Is9f8USxG9BZgJdM7H/+8D4IsMG0P27RPUZX1Ql9uBysAfwEogGdgFTAG6An8Gtn4KVAzO8TNwSbB+ATABeDqo/wO53Y/gmGaBbUkZ9xGoGNi0b0i5BsB2oH4Jf99jg3p+E3xuCfwe/C8+yah3NC3B9346MA0b0wNF/I1HVAs9SOX7ItAX6AAMFJEO4bWqxHgbe3iFMhj4UVXbAj8Gn4vKYZiYfFmAY74D2mI/9qmYWGTwBnCZqlYHOmKiAuYLXwbUx94CbsdE6j9U9Q3gVmCaqsZgonQSlnNocHCuzVg653expHAfB4cL8DAmzO0xwbonOO+5wBLgBDU3y2PZ1OnjwL4m2Gjnh0SkZ8j+E4MytTDhfyGnmyMiVYNzfBAsA4JR1ohIdWA08H1wrTbY/3IX8BUmvgdgP/KnsYfPm8GpN2APvew4BFiI3dsHc7sfwe/oG2xgXyLBfVTV5KCOoX0lA7HvXFJO9S0mrgVmh3x+FHhaVduQe70jnaNUtZNmxp4X7Tce7qdUAZ9ohwEjQz7fBtwWbrtKsL6J7N5Cnws0DtYbA3OL4RpnA6vyKHMPIS30LPtqYcJcM/i8BLgMqJGl3H2YYLXJ5hyLgKOD9QuA8SH7xmOtyLnA8cF6Ql51xx4Ef2Z3jZB7q9jDohmQBlQP2f8w8HZI/UeH7OsA7Mjl2ucEdsZhD8tN2BwBYAL5Zw7HzcXcXFWxB+UhmMC3DmztlvH9Z88W+pL83o/gd5RE8HaSpdwhwf8wI2BiMnBGCX/PEzDx6ok9aCSod1yIvSNL0oZwLMF3sl4234FC/8YjqoVO9ql8m4bJlnDQUFVXBuursNZYUVkH1Muv31VEYkXkERFZICKbsS8lmEsF4FTM7bJYRMaKSEai0Mex1+cfgs7CPFseIpKIvQkkY3WtirUql5Ol7iLSUEQ+FpHlgV3vh9iUF02A9aq6JWTbYnb/bq0KWd8OVM7lnp0PfKqqqaq6E/iczFxHzYAFORzXDGuZrsFetxdgLqqMjtvcvu+hv4u87kczYLGqpmY9iar+HtSvh4jsjb1BZM3dVNw8g72JZCT/rQtsDLEvWn/niv0epgSpxaGIv/FIE3QnQO0RXhwxpxOx1/2T8ln+LKwVeTTmf08Mtktg1yRV7Y+5Y4Zhfl9UdYuq3qiqrTD3xQ0i0iuni4hINUwIXyCznkuxDttY9qz7Q8G2fVW1BtZKDp1fJrd7tQKoE7hDMmjOnllF80REErCW5jkiskpEVmHul+NEpF5Qh1Y5HL4UczklYBPL7B1sz+ggrhJStlGWYwtyP5YCzXN5IL0TlD8XGBo8lEoEETkeWKOqU0rqGmWYbqp6IOZCvlJEuofuLMxvPNIEPT+pfKOZ1SLSGCD4u6aoJ1TVTcD/gBdF5CQRqSoiFUSkr4hk52uujj0A1mEt5ocydohIRRE5W0RqqmoK5u9OD/YdLyJtgjjzTVirM32PswenwsT8A6zzFKzzcAnWafg8kCQilUXk8BC7tgKbRKQpcHOWc64mByFV1aXAr8DDwTn3w3y27+dgX26ci/n42wGdgmUvrJU5EHMpNBaR60SkkohUF5GMCWNeB+7H+hnGACcDtTEf8nLgImC5iFyEuWFyI7f7kdH5+oiIxGe5jwT1PhkT9XcLcQ8KwuHAiSKyCPPf98TmL64V8sCJyt+5qi4P/q7B+rC6UMTfeKQJen5S+UYzoWmKz8d80kVGVZ8EbgDuxHyrS4GrsBZ2Vt4l0+0xC/gty/5zgUXBa/7lmI8ezHUyGhOZicBLqjomB5PaALNV9amQbcODc5+AhQQ2w0QyY+7ae4EDsYfFCCyCI5SHgTtFZKOI3JTNNQdibxsrsB/X3ao6Ogf7cuN8rG6rQhfgFeD8wK3TO6jHKiya4SgRqY91KH+KuVv+F5SZiLXwL8X6Jo7AomR+zcOOHO+HWuz9Cdh9XsLu9zHjATcVax2OowRR1dtUNUFVE7Hf80+qejb2QDstKFZs3/WyQvAgrZ6xDhwDzKCIv/GIGymaXSrfMJtUIojIR0APzO+5GribTBdGc0xUz1DV9eGysSQIBjONw8K5Mlrwt2MhbFFb9+Ct4B3sex2D+eDvE5FWWMu1DhbWd46qlvgMpSLyJrBCVe8s6WuFXLMHFuZ6fLjqXVoE9cuILIsDPlRLS16XInzPI07QHccpWYLO6GnAAar6b3itcQpCpLlcHMcpQUTkfuzV/3EX88jDW+iO4zhRgrfQHcdxooSwJfGpV6+eJiYmhuvyjuM4EcmUKVPWag5ziuYp6EFvd0bwf8ds9gsWN3ocNsLsAlWdmtd5ExMTmTx5cl7FHMdxnBBEZHFO+/LjcnmbPZNEhdIXizFuCwwCXi6IcY7jOE7xkGcLXVV/CcKYcqI/8G4wTPU3EaklIo1D8hE4TsSyfTts2gQ7d8KuXfY3Yz01FVQhPd2WjHXHyYuOHaFFi+I/b3H40HNKmLWHoAcJaAYBNG/evBgu7Tg5k5oKixfD/Pm2zJsHrVrB1VeDSN7HjxsHffvCtkifasMpc7z8Mlx+efGft1Q7RVV1CMEkqJ07d/Z4SafYmTEDnngCJkyARYtM1DOoVMla1iIm6rmRlAQDB0LjxnDjjVC5cuZSqZItcXEQE2OLSObf/DwsnPJNSbTOoXgEvbwnzHLKABMnwsMPw9dfQ3y8tazPOAPatIG2be1vgwZw8slwww3QqRMccUT250pPh/POg7Vr7bwHHFC6dXGcwlIcgj4cuEpEPsaS429y/7lTGqjCqFHw0EMwdizUqQP33ANXXQV162Z/zLvvwsEHw+mnw9Sp0KTJnmUeewy+/95ei13MnUgiP2GL/yWJEpFlWJKoCgCq+grwLRayOB8LW7ywpIx1nAwWL4YBA+C336BpU3jqKbj0UqhWLffjataEL7+EQw6B006Dn3+GihUz948bB3feCWeeCZddVqJVcJxiJ2xD/zt37qweh+4UhgkTzHWSnGz+8nPPNZ92QfjsM3PJXHEFvPSSbUtKshZ5lSowZQrUqFH8tjtOURGRKZo5B+lu+NB/J6J4+2046iioVQt+/x0uuaTgYg7mcrn5ZnOrvPXW7n7zTz91MXciExd0J+ysW2eRJAceaO6O2bP3LJOWBjfdBBdeCN27m6ulXbuiXfehh6BXL2ulX3KJ+c2fecb95k7k4oLuhI0dO6wDsnVrE9K4OItU6dDBxP3JJ2HFChvYc+KJ9vnKK+G776wDtKjExcFHH0HDhtZKd7+5E+m4oDulTnq6RZu0awe33grdusFff8Eff8CyZfD00xAbay3yhAQLOxw50nzdL7wAFSoUny3168Pw4dZKHzLEY8idyMY7RZ0SITkZVq2C9ethwwZb1q+35cMPTcA7d7YW+lFHZX+OuXPhgw/MV37LLeYecZzyTm6domFLn+tEJ3PmWEfjO++YqyQ7WrUyV8cZZ9joypxo1w7uu69k7HScaMQF3SkyKSnw1VfmEhkzxlwip50GPXuar7tOHahd25Y6dWwkp7s2HKf4cUF3CkRysvm5Fy+2XCmzZ8P778PKlZCYaJ2aF11kw+wdxyldXNCdHNmyBcaPt9GUEyfCv//C8uU25D6DmBjLm3LFFdCnj3VmOo4THlzQnf9ISYGffjIBHzMGJk+2+O8KFawDs1cvyxKXmGh/W7SAZs12HzrvOE74cEF3AHOdnH02/PmnxWcfcggMHmwRKIcdBlWrhttCx3HywgW9nKNqUSk33miJrT780AbxxMeH2zLHcQqKC3o5ZvVquPhiGDHC/N9vvQWNGoXbKsdxCouPFC2nfPMN7LsvjB4Nzz0H337rYu44kY630MsRSUkm3F9+aXHj++9vnZ/77BNuyxzHKQ5c0KMYVZg1y6Zl+/prCz1UtVl67rgD7rqrcKlnHccpm7igRymjR8P119ukyQAHHQR33w0nnGDpYX2kpuNEHy7oUcaSJRaxMnSo5Ux5+WUT8aZNw22Z4zgljQt6lLBrl+ULf/BBc6vcf7+ln61cOdyWOY5TWrigRziqNtPOtdfCvHk21+bTT9soTsdxyhcethjBTJhgGQ2PO8584t9/D1984WLuOOUVF/QIZPJkS4jVrZsN2X/2Wfj7bzj22HBb5jhOOHFBjyBmzIBTToGDD7bp2h59FBYsgGuu8fBDx3Hch17m2brV3CjvvGODgKpXh3vvheuugxo1wm2d4zhlCRf0Mkhamon3u+/C55/D9u3QurUJ+ZVXFs+M947jRB8u6GWEdetg7FjLR/7VVzYrUM2acM45cN550LWrDwZyHCd38iXoItIHeBaIBV5X1Uey7G8OvAPUCsoMVtVvi9nWqGL7dptI4qefbJk2zUIQ4+MtB/mTT9qAoCpVwm2p4ziRQp6CLiKxwItAb2AZMElEhqvqrJBidwKfqurLItIB+BZILAF7o4Lvv7e0tStW2Gw/XbuaO6VnT+vw9BmAHMcpDPlpoXcB5qvqQgAR+RjoD4QKugIZXXQ1gRXFaWS0sHWrjd589VXo0AFefx169PBWuOM4xUN+whabAktDPi8LtoVyD3COiCzDWudXZ3ciERkkIpNFZHJSUlIhzI1cfvkF9tsPhgwxUZ8yxWLJ8y3my7+B7w6CjTOKbozq7jM9O44TFRRXHPpA4G1VTQCOA94TkT3OrapDVLWzqnauX79+MV26bLNz205uujGNHj2sU/OXX+DxxwuYY2X9FBh/JmyYCmOPhx2rCm9Qegr8chKM7g7JGwt/nvJOylZISw63FY6zG/lxuSwHmoV8Tgi2hXIx0AdAVSeKSGWgHrCmOIyMVJJWbEK+acetbdM4/am+7N+3H5VbHgPUzv9Jti2FsSdApXpw8Msw/nQYeyIc/TPEFXDmZlWYdCUsHw4SC2P6QM8foEIZCGhXhV1roXIZfdCrwqYZsHwErBgBa3+17fGJUL0tVN8r+NsW6nctG/fUKXfkR9AnAW1FpCUm5AOAs7KUWQL0At4WkfZAZaB8+VSysH49fHzfC1zdfTWrKpzCITHfwpT3YGos1OsKTftB8zOhWmLOJ0nZYi3y1G3QewLU6giHfwi/nAwTz4Nun8KeL0I5M/sJWPAadLgN6h0C406DMX3hqJFQoVrBK6kKG6ZBzX0gtog9ubMfh79ug84vQdvLinaubYth48zs98XFQ/U2UKVJ7nGg6amwbZG5uFZ+Dyu+he2B57H2AdBhsD0UN/8DW+ZB0q+QusX2V2sFx/xWdh9OTtQimg9fqogcBzyDhSS+qaoPish9wGRVHR5EtrwGVMM6SG9R1R9yO2fnzp118uTJRa5AWWTzZjix7xY+Pz+R9DpdqX/a15CeBuv+sNbdihEmhDEVYe8bYJ879hTU9FRria/6AXp8C42Pydw352mYegO0vwUOeDR/Ri39wgS8+Wlw+Mf2IFgyFCYMgPqH2zXi4vNfyU2zYcp1Zl+ri+DQN/J/bFbSU+CrRGuhpyebWO7/YMEeVhks/xYmnGEPwdyIi4dqbaxFXWMvqNTABHzLPNjyD2z9FzQ1KFsNGvW2h3DjvlC1yZ7nU4Wda2DtRPh1INQ+EHr9CLGllL84PQWSJthDpn43H7QQxYjIFFXtnO2+/Ah6SRCtgr5tG/TpA4fXeYxHzrwVjvkd6nXJpuBi+Pt/8O+71lrs9BgknmU/RFWYfDXMexG6vAptBu1+rCpMvhLmvQxdhkCbS3M3at0kGH0k1Nofev0EcSE9sYs+holnQ4MecOQ3u+/LjuRNMP1e+Od5E8V6h8LKkdB9OCSckK97tAeLP7EHS/dh1hKePwRaDIRD34LYAiSpmT8EJv2f1fOgZ+2BmZWUTYFoB8K9ZV6meMdWzXSb1Ngr05VS56CC2bFkqLnGWgyArh/k/mDamQRLPoXKDYPrtcn/g3XHalj5nbmBVv0AKZtte82OsPd1kHh2zg+UjAbGxmnQpB/EN89//coCqrBzdeb/UNOg0TG5v/FGCS7opcTOnTYYaOL47ax9oyWVG3WCniNzPyhpIky5BtZPNldM5+dgzXiYeh20vwkOeDz749JTzbe+ahT0+A4a986+3LbFMPIQiK0Cx/4OlRvsWebf92Di+dYKPfKr7EVA02HhWzDtNmtJt7kU9nvAfMUju9iP67gZULle7vXNjh8Ot+NP+AcQmPUI/HU7NDgSun8JFfPoc1CFv++EmQ9Bk+Pg8E8K5kJKT4HkDVCpfvG1bGc9CtMGwz53wv73Z19m1Y/w6zmwM0snd5Wm9kCp1sb+b1nRNFj3u31nwBoETY4zYU7eAHOfgY1/W33aXg5tr4AqjWHXenv4rhhhbqRd6+x4iYVmp0K76+wBXdR7kLYTti7MdEftWF5MUVXBW1DGwzh1655Fanaw+9Ckn/VlxFSw7elp5jILfQNLT8n+MlUahvSLFOABm6PZ6bB9WebDZ/M8aH461D+sUKdzQS8FUlLg1FNtMubf33mGLnHXQ+/x5s7IC02HhW+bD3ln0PWQcBIcMTT31l3KZhjVzUS7zaDdO+eqNMncv30pHPOrfdlzYsGb8PvF5iqo3mbP/ZvnmEjU6wqdn4c6B2bu2/A3jOwMTfsHfv0CCML6KfB9ZzjwaWtVZrDoQ/jtAhO1o76D+BySvKftgt8ugsUfQutL4eCXIKYMZLRQhT8uhQVvwKFvQ6vzM/elp8Dfd9uDq0Y72x9TMZs3hwU5R9LUbG+i1bSfvZGE3nNVWPMzzHkGln9t96PmvtYa13TrYG/c1x4CtfaFf9+B+a9Bykao28WEvflpJoapO2Dr/BDb5lnfTnYkbzDbty3BPK8BcdXtoVEcVKoT0gG9V+bbVHqyvd0tHwFJv9g9rlAT6h4MO1bAlvlWJoPYyhCT3dtLeuabTgZVmuze6Z3x9latdeabm6o9mDPuUcbDbMs8u39pO0OuXcV+Q60vLtQtcEEvYXbuhPPPh08/hVde3MlljVtBjb3NvVEQkjfBjPth279w2Hv5i2LZtiQIafwT0ndlbo+Ltx/SrrUmiI2OzvtcC9+2jlNN23NfbFVof6O5QrIT7JmP2AOp6wfmOsovEy+ApUPhpOVQsebu+1b/bCGWsZVMgGqE/Kiqt7Uf6C+nmHjt/6B19pYl33F6inU6J/0CR/0ADXvA1kUwYSCs+81+0Ac9W/QWYG5smQ9zn7OQ1wZH2QOgzsEQk0VgU7aa+2/usybKlRuZoG9funu5yg1zfmOKq7a7yGb8nyrWKpm65UTKZlg12gR+/Z/mTvrve5PR4Gmc83clZWvmQ+w/YQ7+7lobUlCsoVGhpj18Q98YYiqY4Gf3IKjSpHD9QxlXdUEvOcaNg0svhblz4bHH4Ob+L8Lkq0zMGx5Veoakp8GOZbu3DLb9C4nnWGurNK4/+gjrLO03A6rmY1bqnWtgWDNofQkc/GL2ZTbNginXW8jgjiwDkGOrmO/7kDeh5TlFr0NJkLwRfuhqrbeOd8P0uwG1vo8WZ4bbuj3RdFjxvbnXYiuHCHQgSuU9HDN5g7lMQt+mUjbtLt412kLV5iX2puiCXgJs2gSDB8Mrr9iUb6++CscenQxft7EWwdHjylZrsTTYPA++6wQNjjC/fl71n/Gg+b77zTIXQl5kbTltX2Idfw26F4/9JcXWf60fY1cS1D3EQk+rtQq3VU6EkpuglwFnY+QxbJjlJV+1Cq6/Hu67D6pVA+a/Y6+oXV4rf2IO1jI54HGLwJn/qnXI5UR6Csx7yTpi8yPmYB2dtTvZEklUawk9R8OasXZPMjrqHKeY8SnoCsD8+XDaaXDyyVCvHvz2Gzz1VCDm6Skw82HzT4bGjJc32l5hIj31RvPf5sTSL82F0u6a0rMtnNTeD9pd7WLulCjlu4W+eR5symFEYY29oebeqFq+8meegREjLLXtQw9Zgq0Kob/NRR+Yz7rzc+WzdZ6BCBz6JozoCD/2tE7SBkfsWe6f58zt0Lhv6dvoOFFK5An6xhk2UKZJX6jSqPDnSd1hCaqyxgAHaExFRu4Yzs1PHcuMGVC/Ptx1F1x+OTRunKVweorFQNc+wELJyjtVE2yU5Pgz4cce1hm4zx2ZkRXrp9qoxgOf2jPawnGcQhN5gr70c5h+j63X6Zw5oKJu54KFAi14zcS864d7+HC//CKFNusGcWSDkzis5TfceGMvBgzIIUNiylYYf4Z11HX/qny3zkOpcxD0nWojN6ffDat/gq7vm9hnjDJtdWG4rXScqCLyolxUYeNfIVnvfgPURkA2PREOeGLPeOaspO2C4a2hems4eux/m9PT4fbb4dFHoX+ftbx/YU/idT7S4ztoeOSe59mxEn4+3uw5+KU9h+g7xsJ3YfL/QUwlOPBJ+ONyaH2R3TPHcQpEdEW5iGRGOnS8A3auzRzOvPAta6V3eTX3cyx8y4YjH/b2f5uSk+Gii+CDD+Cyy+CFF+oRlzoafjwKxvazjIShoz43zYKfj7OBBt2HQ9PjSqa+0UCr82xI+YQB8FvQKt/rqvDa5DhRSORHuVSuBy3PttjedtdZgqakX3Mun5Zs0Sj1DoOGvQCLKe/b18T8wQfh5ZchLg5r9ff80XJrjOkbvA0Aq8da/pG0XXD0Ly7m+aHGXnDMRMuk2P7m3NMQOI5TKCLP5ZIbKVthRAcbitt3avYhYgvegN8vsXSxTfqybBkcdxzMng1vvAHnnZfNebcvt2yFu5JMjGbcbyPDcssx4jiOUwLk5nKJ/BZ6KBWqQecXbJj4nKf23J+eatEodTpD4z7MnAmHHQaLFsG33+Yg5mDD2HuNgYp14e+7rHV/zAQXc8dxyhTRJegACSdCwsmWs3vrv7vvW/yRpfXseCczZwlHHglpaTbPZ+8css/+R3wz60A96Fnzp+eV0tVxHKeUiT5Bh2BwT6zNn5nhUkpPgxkPQK39WLDzRHr3tkFC48ZBp/yOJI9vZiMbCzLZgeM4TikRnYJeNQH2u99mc1k61LYt+Qy2/MO6xndydG8hORlGjYLWrcNrquM4TnERnYIOFhZX+0CYcq2lMJ35AKnxHeg28FTWrYORI2GffcJtpOM4TvERvYIeE2fx6DtXW06RTTO56+M7WLwkhhEj4KCDwm2g4zhO8RK9gg6WDqDtlbDhT5ZsbMszX57JsGFwRDa5ohzHcSKd6BZ0IKXDA0xadixXvv4MH34UyzHlOLOt4zjRTeQN/S8gd91Xg0cf/Z633rI85o7jONFKVLfQv/3WEm1dfjlccEG4rXEcxylZolbQly61kZ/77w9PPx1uaxzHcUqeqBT0lBQYMAB27YLPPsshj7njOE6UkS9BF5E+IjJXROaLyOAcypwhIrNEZKaIfFi8ZhaMu+6CX3+F116Dtm3DaYnjOE7pkWenqIjEAi8CvYFlwCQRGa6qs0LKtAVuAw5X1Q0i0qCkDM6LUL/5gAHhssJxHKf0yU8LvQswX1UXqmoy8DHQP0uZS4EXVXUDgKquKV4z84f7zR3HKc/kR9CbAktDPi8LtoWyF7CXiEwQkd9EpE92JxKRQSIyWUQmJyUlFc7iHEhNdb+54zjlm+LqFI0D2gI9gIHAayJSK2shVR2iqp1VtXP9+vWL6dLGsGHmN3/5ZfebO45TPsmPoC8HmoV8Tgi2hbIMGK6qKar6L/APJvClxtChUL8+DBxYmld1HMcpO+RH0CcBbUWkpYhUBAYAw7OUGYa1zhGRepgLZmEx2pkrO3bAN9/AKadAbGxpXdVxHKdskaegq2oqcBUwEpgNfKqqM0XkPhE5MSg2ElgnIrOAMcDNqrqupIzOysiRsG0bnHZaaV3RcRyn7BEVk0Sfcw58/z2sXAkVspkX2nEcJ1qI6kmid+2C4cPhpJNczB3HKd9EvKCPGgVbtri7xXEcJ+IFfehQqFULevYMtyWO4zjhJaIFPTkZvvoK+veHihXDbY3jOE54iWhB/+kn2LjR3S2O4zgQ4YI+dChUrw69e4fbEsdxnPATsYKekgJffgknngiVKoXbGsdxnPATsYI+diysX+/uFsdxnAwiVtCHDoX4eDj22HBb4jiOUzaISEFPS4MvvoB+/aBKlXBb4ziOUzaISEEfNw6Sktzd4jiOE0pECvrQodYy79s33JY4juOUHSJO0NPT4fPPTcyrVQu3NY7jOGWHiBP0X3+FVavc3eI4jpOViBP0n3+2uPN+/cJtieM4Ttki4gT9zjth/nyoUSPcljiO45QtIk7QARISwm2B4zhO2SMiBd1xHMfZExd0x3GcKCFsc4qKSBKwuJCH1wPWFqM5kUJ5rTeU37p7vcsX+al3C1Wtn92OsAl6URCRyTlNkhrNlNd6Q/mtu9e7fFHUervLxXEcJ0pwQXccx4kSIlXQh4TbgDBRXusN5bfu8Ngu3QAAA1FJREFUXu/yRZHqHZE+dMdxHGdPIrWF7jiO42TBBd1xHCdKiDhBF5E+IjJXROaLyOBw21NSiMibIrJGRGaEbKsjIqNEZF7wt3Y4bSwJRKSZiIwRkVkiMlNErg22R3XdRaSyiPwhIn8F9b432N5SRH4Pvu+fiEjFcNtaEohIrIj8KSLfBJ+jvt4iskhEpovINBGZHGwr0vc8ogRdRGKBF4G+QAdgoIh0CK9VJcbbQJ8s2wYDP6pqW+DH4HO0kQrcqKodgEOBK4P/cbTXfRfQU1X3BzoBfUTkUOBR4GlVbQNsAC4Oo40lybXA7JDP5aXeR6lqp5DY8yJ9zyNK0IEuwHxVXaiqycDHQP8w21QiqOovwPosm/sD7wTr7wAnlapRpYCqrlTVqcH6FuxH3pQor7saW4OPFYJFgZ7A0GB71NUbQEQSgH7A68FnoRzUOweK9D2PNEFvCiwN+bws2FZeaKiqK4P1VUDDcBpT0ohIInAA8DvloO6B22EasAYYBSwANqpqalAkWr/vzwC3AOnB57qUj3or8IOITBGRQcG2In3P44rTOqf0UFUVkaiNORWRasDnwHWqutkabUa01l1V04BOIlIL+BLYO8wmlTgicjywRlWniEiPcNtTynRT1eUi0gAYJSJzQncW5nseaS305UCzkM8JwbbywmoRaQwQ/F0TZntKBBGpgIn5B6r6RbC5XNQdQFU3AmOAw4BaIpLR8IrG7/vhwIkisghzofYEniX6642qLg/+rsEe4F0o4vc80gR9EtA26AGvCAwAhofZptJkOHB+sH4+8FUYbSkRAv/pG8BsVX0qZFdU111E6gctc0SkCtAb6z8YA2TMoBt19VbV21Q1QVUTsd/zT6p6NlFebxGJF5HqGevAMcAMivg9j7iRoiJyHOZziwXeVNUHw2xSiSAiHwE9sHSaq4G7gWHAp0BzLPXwGaqateM0ohGRbsA4YDqZPtXbMT961NZdRPbDOsFisYbWp6p6n4i0wlqudYA/gXNUdVf4LC05ApfLTap6fLTXO6jfl8HHOOBDVX1QROpShO95xAm64ziOkz2R5nJxHMdxcsAF3XEcJ0pwQXccx4kSXNAdx3GiBBd0x3GcKMEF3XEcJ0pwQXccx4kS/h/VZvbUvgU9VQAAAABJRU5ErkJggg==\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "# define model\n",
        "model = define_model_resnet()\n",
        "#Callbacks\n",
        "best_model_fpath = '/content/drive/MyDrive/PHD/Model/best_model_'+'no_smote'+'_'+dataset_name+'.h5'\n",
        "print(\"best_model_fpath:\"+best_model_fpath)\n",
        "mc = ModelCheckpoint(best_model_fpath, monitor='val_balanced_acc', mode='max', verbose=1, save_best_only=True)\n",
        "learning_rate_reduction = ReduceLROnPlateau(monitor='val_balanced_acc', patience=20, verbose=1, factor=0.5, min_lr=0.00001)\n",
        "early_stopping_monitor = EarlyStopping(patience=40,monitor='val_balanced_acc')\n",
        "#model.summary()\n",
        "hst = model.fit(X_train, y_train, epochs=EPOCHS, batch_size=BATCH_SIZE, validation_data=(X_val, y_val), verbose=1,\n",
        "                    steps_per_epoch=X_train.shape[0] // BATCH_SIZE, \n",
        "                    #callbacks=[learning_rate_reduction,early_stopping_monitor, mc])\n",
        "                    callbacks=[learning_rate_reduction,mc])\n",
        "# learning curves\n",
        "summarize_diagnostics(hst)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "SPz8NH1Oylv9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2435b5a4-4041-4c26-ac2d-7b6c756e7249"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "model saved\n"
          ]
        }
      ],
      "source": [
        "#save last model\n",
        "last_model_fpath = '/content/drive/MyDrive/PHD/Model/last_model_'+'no_smote'+'_'+dataset_name+'.h5'\n",
        "model.save(last_model_fpath)\n",
        "print(\"model saved\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "vXnW3lmCgln3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "5bd7ef76-34bf-456a-c0f9-30b6d4a02a98"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "# summarize history for accuracy\n",
        "plt.plot(hst.history['accuracy'])\n",
        "plt.plot(hst.history['balanced_acc'])\n",
        "plt.plot(hst.history['val_accuracy'])\n",
        "plt.plot(hst.history['val_balanced_acc'])\n",
        "plt.title('Model accuracy')\n",
        "plt.ylabel('Performance')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train accuracy', 'train balanced acc.', 'val. accuracy', 'val. balanced acc.'], loc='lower right')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "icgjmi-4UIT-"
      },
      "source": [
        "#Evaluate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "lS3ewyxO_anU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "123a6dd4-d3d8-4ab6-f912-43e55e3b9987"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "146/146 [==============================] - 14s 36ms/step\n",
            "7/7 [==============================] - 0s 79ms/step\n",
            "accuracy on training 1.0\n",
            "balanced accuracy on training 1.0\n",
            "accuracy on validation 0.7616580310880829\n",
            "balanced accuracy on validation 0.5959677662639334\n",
            "Score on val data:  (0.5411025796457196, 0.5959677662639334, 0.5599896928468356, None)\n"
          ]
        }
      ],
      "source": [
        "last_model_fpath = '/content/drive/MyDrive/PHD/Model/last_model_'+'no_smote'+'_'+dataset_name+'.h5'\n",
        "last_model = load_model(last_model_fpath, custom_objects={'balanced_acc' : balanced_acc})\n",
        "y_train_pred = last_model.predict(X_train)\n",
        "y_val_pred = last_model.predict(X_val)\n",
        "\n",
        "#print('accuracy on training',accuracy_score(np.argmax(y_train, axis=1), np.argmax(y_train_pred, axis=1)))\n",
        "print('accuracy on training',accuracy_score(np.argmax(y_train, axis=1), np.argmax(y_train_pred, axis=1)))\n",
        "print('balanced accuracy on training',balanced_accuracy_score(np.argmax(y_train, axis=1), np.argmax(y_train_pred, axis=1)))\n",
        "print('accuracy on validation',accuracy_score(np.argmax(y_val, axis=1), np.argmax(y_val_pred, axis=1)))\n",
        "print('balanced accuracy on validation',balanced_accuracy_score(np.argmax(y_val, axis=1), np.argmax(y_val_pred, axis=1)))\n",
        "print('Score on val data: ',precision_recall_fscore_support(np.argmax(y_val, axis=1), np.argmax(y_val_pred, axis=1), average='macro'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "W3IyWjdGG4Xq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "942881e5-c409-4161-daa3-4df2e9712010"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "146/146 [==============================] - 6s 35ms/step\n",
            "7/7 [==============================] - 0s 33ms/step\n",
            "accuracy on training 0.8230488067082348\n",
            "balanced accuracy on training 0.8018799784103777\n",
            "accuracy on validation 0.7875647668393783\n",
            "balanced accuracy on validation 0.5634998567054316\n",
            "Score on val data:  (0.5756124609335619, 0.5634998567054316, 0.5467512437794833, None)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ],
      "source": [
        "best_model = load_model(best_model_fpath, custom_objects={'balanced_acc' : balanced_acc})\n",
        "y_train_pred = best_model.predict(X_train)\n",
        "y_val_pred = best_model.predict(X_val)\n",
        "\n",
        "print('accuracy on training',accuracy_score(np.argmax(y_train, axis=1), np.argmax(y_train_pred, axis=1)))\n",
        "print('balanced accuracy on training',balanced_accuracy_score(np.argmax(y_train, axis=1), np.argmax(y_train_pred, axis=1)))\n",
        "print('accuracy on validation',accuracy_score(np.argmax(y_val, axis=1), np.argmax(y_val_pred, axis=1)))\n",
        "print('balanced accuracy on validation',balanced_accuracy_score(np.argmax(y_val, axis=1), np.argmax(y_val_pred, axis=1)))\n",
        "print('Score on val data: ',precision_recall_fscore_support(np.argmax(y_val, axis=1), np.argmax(y_val_pred, axis=1), average='macro'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iDRWiTnO0MGh"
      },
      "source": [
        "#Cut-off"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tGnCoIdLyDHS"
      },
      "outputs": [],
      "source": [
        "df_val_pred = pd.DataFrame(y_val_pred, columns = ['AKIEC', 'BCC', 'BKL', 'DF', 'MEL', 'NV', 'VASC'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QdyCbloQyWTC"
      },
      "outputs": [],
      "source": [
        "numbers = [float(x)/40 for x in range(11)]\n",
        "for i in numbers:\n",
        "    df_val_pred[i]= df_val_pred.MEL.map(lambda x: 1 if x > i else 0)\n",
        "df_val_pred.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G4SQsRx73kgk"
      },
      "outputs": [],
      "source": [
        "y_val_true= [1 if x == 4 else 0 for x in np.argmax(y_val, axis=1)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QcUISWFi0J05"
      },
      "outputs": [],
      "source": [
        "#num = [0.0,0.05,0.1,0.15,0.2,0.25,0.3,0.35,0.4,0.45,0.5]\n",
        "cutoff_df = pd.DataFrame( columns = ['Probability','Accuracy','Sensitivity','Specificity'])\n",
        "for i in numbers:\n",
        "    cm1 = confusion_matrix(y_val_true, df_val_pred[i])\n",
        "    total1=sum(sum(cm1))\n",
        "    Accuracy = (cm1[0,0]+cm1[1,1])/total1\n",
        "    Specificity = cm1[0,0]/(cm1[0,0]+cm1[0,1])\n",
        "    Sensitivity = cm1[1,1]/(cm1[1,0]+cm1[1,1])\n",
        "    cutoff_df.loc[i] =[ i ,Accuracy,Sensitivity,Specificity]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W31LSzov1tCt"
      },
      "outputs": [],
      "source": [
        "cutoff_df[['Accuracy','Sensitivity','Specificity']].plot()\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P6CIKT94Jqye"
      },
      "outputs": [],
      "source": [
        "i = 0.025\n",
        "cm1 = confusion_matrix(y_val_true, df_val_pred[i])\n",
        "total1=sum(sum(cm1))\n",
        "Accuracy = (cm1[0,0]+cm1[1,1])/total1\n",
        "Specificity = cm1[0,0]/(cm1[0,0]+cm1[0,1])\n",
        "Sensitivity = cm1[1,1]/(cm1[1,0]+cm1[1,1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3U2tkFebL_VC"
      },
      "outputs": [],
      "source": [
        "print('Accuracy: ', Accuracy)\n",
        "print('Sensitivity: ', Sensitivity)\n",
        "print('Specificity: ', Specificity)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eaK4zbtoaAaC"
      },
      "source": [
        "#Confusion Metric on Validation Set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YkPOFLehOmFg"
      },
      "outputs": [],
      "source": [
        "#change melanoma flag back to 4\n",
        "df_val_pred[df_val_pred[i] == 1] = 4\n",
        "#decode one-hot y_val_pred while use cut-off melanoma data\n",
        "condition = df_val_pred[i] == 4\n",
        "y_val_pred2 = np.where(condition, df_val_pred[i], np.argmax(y_val_pred, axis=1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LOVl6dWlTDLo"
      },
      "outputs": [],
      "source": [
        "print('Accuracy: ',accuracy_score(np.argmax(y_val, axis=1), y_val_pred2))\n",
        "print('Balanced accuracy: ',balanced_accuracy_score(np.argmax(y_val, axis=1), y_val_pred2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mqvYutTKRhR_"
      },
      "outputs": [],
      "source": [
        "#Get the confusion matrix\n",
        "cf_matrix = confusion_matrix(np.argmax(y_val, axis=1), y_val_pred2)\n",
        "print(cf_matrix)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gVtvW3YeaLlC"
      },
      "outputs": [],
      "source": [
        "ax = sns.heatmap(cf_matrix / cf_matrix.sum(axis=1, keepdims=True), annot=True, \n",
        "            cmap='Blues')\n",
        "\n",
        "ax.set_title('Confusion Matrix \\n');\n",
        "ax.set_xlabel('\\nPredicted')\n",
        "ax.set_ylabel('Actual ');\n",
        "\n",
        "## Ticket labels - List must be in alphabetical order\n",
        "ax.xaxis.set_ticklabels(['AKIEC', 'BCC', 'BKL', 'DF', 'MEL', 'NV', 'VASC'])\n",
        "ax.yaxis.set_ticklabels(['AKIEC', 'BCC', 'BKL', 'DF', 'MEL', 'NV', 'VASC'])\n",
        "\n",
        "plt.rcParams[\"figure.figsize\"] = (15,3)\n",
        "\n",
        "## Display the visualization of the Confusion Matrix.\n",
        "plt.xticks(rotation=45, ha='right')\n",
        "plt.yticks(rotation=0, ha='right')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ey-1yjWGeKs7"
      },
      "outputs": [],
      "source": [
        "# ordered count of rows per unique label\n",
        "#labels_count = df_val['Labels'].value_counts().sort_index()\n",
        "\n",
        "#f = plt.figure(figsize=(15, 6))\n",
        "#s = sns.barplot(x=labels_count.index,y=labels_count.values)\n",
        "#s.set_xticklabels(s.get_xticklabels(), rotation = 30)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3K908bbiYwbS"
      },
      "source": [
        "#Testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cN98sOWPyT3P",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2316c488-05c7-4494-8159-333a4ec5c717"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1512, 224, 224, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "df_test = pd.read_pickle(path+\"isic2018_test.pkl\")\n",
        "X_test = df_test.loc[:, df_test.columns != 'y_train'].to_numpy()\n",
        "X_test = X_test.reshape(-1,224,224,3)\n",
        "X_test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NeMY2yvMYxsC"
      },
      "outputs": [],
      "source": [
        "dir_test = '/content/drive/MyDrive/PHD/Datasets/isic2018/ISIC2018_Task3_Test_Input/'\n",
        "filepaths = sorted( filter( lambda x: (os.path.isfile(os.path.join(dir_test, x))) and (x.endswith('.jpg')),\n",
        "                        os.listdir(dir_test) ) )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6ic95mefkpG3"
      },
      "outputs": [],
      "source": [
        "df_test = pd.DataFrame(filepaths, columns =['image'])\n",
        "df_test['FilePaths'] = dir_test + df_test['image']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NBa1TxPuY8ni"
      },
      "outputs": [],
      "source": [
        "df_test['image_px'] = df_test['FilePaths'].map(lambda x: np.asarray(Image.open(x).resize(IMG_SIZE)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "60LYAT7VsNOZ",
        "outputId": "e2210f76-2e3a-4add-995e-79582acdab74"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1512, 128, 128, 3)\n"
          ]
        }
      ],
      "source": [
        "X_test = np.asarray(df_test['image_px'].tolist())\n",
        "print(np.array(X_test).shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cXnnIIwC4cHE"
      },
      "outputs": [],
      "source": [
        "#preprocess\n",
        "X_test = preprocess_image_input(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JC17MArBxhSW"
      },
      "outputs": [],
      "source": [
        "df3 = pd.DataFrame(X_test.reshape(X_test.shape[0],-1))\n",
        "df3.to_pickle(path+\"isic2018_test_128px.pkl\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FF7ml90JZ8FK"
      },
      "source": [
        "Calculate y_pred from training and testing for analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KeDTXdaMLmyU",
        "outputId": "a6ea64da-79f0-424f-f913-5b0bd6c66170"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(1512, 2048)"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#FOR MAKING FEATURE SPACE DATA\n",
        "X_test = model1.predict(X_test)\n",
        "X_test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dIX0AmEFNv3Y",
        "outputId": "0ed9a370-faec-457b-8d99-7c7de11457df"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "48/48 [==============================] - 2s 46ms/step\n",
            "Y_pred2 (1512, 7)\n"
          ]
        }
      ],
      "source": [
        "# predicting\n",
        "#CHANGE THE MODEL IF NECESSARY\n",
        "Y_pred2 = best_model.predict(X_test)\n",
        "#Y_pred2 = model2.predict(X_test)\n",
        "print(\"Y_pred2\", Y_pred2.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7oeArO5CtxGb"
      },
      "outputs": [],
      "source": [
        "df_pred = pd.DataFrame(Y_pred2, columns = ['AKIEC', 'BCC', 'BKL', 'DF', 'MEL', 'NV', 'VASC'])\n",
        "df_pred['image'] = df_test['FilePaths'].map(lambda x: x.replace(dir_test, '').replace('.jpg', ''))\n",
        "df_pred = df_pred[['image', 'MEL', 'NV', 'BCC', 'AKIEC', 'BKL', 'DF', 'VASC']]\n",
        "df_pred.set_index(\"image\", inplace = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9ynyd8PjT589"
      },
      "outputs": [],
      "source": [
        "#update MEL data using cut-off value\n",
        "df_pred.MEL[df_pred.MEL > i] = 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fjRdONoQVMq0"
      },
      "outputs": [],
      "source": [
        "df_pred.loc[df_pred.MEL > i, ['NV', 'BCC', 'AKIEC', 'BKL', 'DF', 'VASC']] = 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K4Iv_3s4z0R9"
      },
      "outputs": [],
      "source": [
        "df_pred.head(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sOnjc3RJ0e4T"
      },
      "outputs": [],
      "source": [
        "df_pred.to_csv('/content/drive/MyDrive/PHD/Datasets/isic2018/response_50epochs-128px-SMOTE.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P0MghVs0tsGw"
      },
      "source": [
        "result: 0.601"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UswA0co2y1wl"
      },
      "source": [
        "#Exp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dnqJYIONy34l"
      },
      "outputs": [],
      "source": [
        "input_tensor = Input(shape=(IMAGE_H, IMAGE_W, 3))\n",
        "base_model = ResNet50(input_shape=(224,224,3), weights='imagenet', include_top=False)\n",
        "x = base_model(input_tensor, training=False)\n",
        "x = Attention(2048,2048,7,8)(x)\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "res50 = Model(inputs=input_tensor, outputs=x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kcn8hQg3J8yP"
      },
      "outputs": [],
      "source": [
        "#Train i-last layer\n",
        "# summarize feature map shapes\n",
        "for i in range(len(model.layers)):\n",
        "    layer = model.layers[i]\n",
        "    # summarize output shape\n",
        "    print(i, layer.name, layer.output.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UA7Af2Y73FUv"
      },
      "outputs": [],
      "source": [
        "X_train = res50.predict(X_train)\n",
        "X_val = res50.predict(X_val)\n",
        "print(X_train.shape)\n",
        "print(y_train.shape)\n",
        "print(X_val.shape)\n",
        "print(y_val.shape)\n",
        "print('Counter train data: ', Counter(np.argmax(y_train, axis=1)))\n",
        "print('Counter val data: ', Counter(np.argmax(y_val, axis=1)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "krJiAb1m3QNf"
      },
      "outputs": [],
      "source": [
        "X_train, y_train = SMOTE_Data2(X_train, y_train, True)\n",
        "print(X_train.shape)\n",
        "print(y_train.shape)\n",
        "print(X_val.shape)\n",
        "print(y_val.shape)\n",
        "print('Counter train data: ', Counter(np.argmax(y_train, axis=1)))\n",
        "print('Counter val data: ', Counter(np.argmax(y_val, axis=1)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LfcFpsBwM0d4"
      },
      "source": [
        "#Attention"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 398
        },
        "id": "C_s6OIGKM26a",
        "outputId": "371bd24a-4bf9-491a-e0ec-78b7eb06e6d9"
      },
      "outputs": [
        {
          "ename": "AttributeError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-ff488085aaa5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mConv2D\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mMaxPooling2D\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mAveragePooling2D\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mBatchNormalization\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mAdd\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mZeroPadding2D\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mFlatten\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mInput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mLeakyReLU\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mSoftmax\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mReLU\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAdam\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    471\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_current_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"keras\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    472\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 473\u001b[0;31m     \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    474\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    475\u001b[0m     \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/lazy_loader.py\u001b[0m in \u001b[0;36m_load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;34m\"\"\"Load the module and insert it into the parent's globals.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0;31m# Import the target module and insert it into the parent's namespace\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m     \u001b[0mmodule\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimportlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimport_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_module_globals\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_local_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/importlib/__init__.py\u001b[0m in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m    125\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m             \u001b[0mlevel\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_bootstrap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gcd_import\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpackage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;31m# See b/110718070#comment18 for more details about this import.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_layer\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mInput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/models.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv2\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmetrics\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmetrics_module\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0moptimizer_v1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfunctional\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/metrics.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mwarnings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mactivations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbase_layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/activations.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0madvanced_activations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgeneric_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdeserialize_keras_object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgeneric_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mserialize_keras_object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/layers/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_spec\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mInputSpec\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_layer\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLayer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_preprocessing_layer\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPreprocessingLayer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;31m# Image preprocessing layers.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/base_preprocessing_layer.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mabc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdata_adapter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_layer\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLayer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mversion_utils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m   \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m  \u001b[0;31m# pylint: disable=g-import-not-at-top\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m   \u001b[0mpd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tester\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 179\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtesting\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    180\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/testing.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m from pandas._testing import (\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0massert_extension_array_equal\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0massert_frame_equal\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/_testing/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    946\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    947\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 948\u001b[0;31m \u001b[0mcython_table\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommon\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cython_table\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    949\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    950\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: module 'pandas' has no attribute 'core'"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow.keras as tk\n",
        "from tensorflow.keras.layers import Conv2D,MaxPooling2D,AveragePooling2D,BatchNormalization,Add,ZeroPadding2D,Flatten,Dense,Input,LeakyReLU,Softmax,ReLU\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.models import Model\n",
        "import numpy as np\n",
        "import pickle\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "\n",
        "class Attention(tk.layers.Layer):\n",
        "    \n",
        "    def __init__(self,input_channels,output_channel,kernel_size,groups):\n",
        "        super().__init__()\n",
        "        self.input_channels = input_channels\n",
        "        self.output_channel = output_channel    \n",
        "        self.kernel_size = kernel_size\n",
        "        self.stride = 1\n",
        "        self.groups = groups\n",
        "\n",
        "        assert output_channel % groups == 0\n",
        "        \n",
        "        self.rel_h = tk.backend.variable(lambda : tk.backend.truncated_normal((1,1,kernel_size,1,output_channel//2),stddev = 0.1)) \n",
        "        #output_channels//2 is the number of channels on which the relative position will be considered,1 denotes the number of those filters and the one after that too and (kernel_size,1) denotes the size of that filter\n",
        "        self.rel_w = tk.backend.variable(lambda : tk.backend.truncated_normal((1,1,1,kernel_size,output_channel//2),stddev = 0.1)) \n",
        "\n",
        "        self.key_weights = Conv2D(self.output_channel,kernel_size = 1,strides = self.stride)\n",
        "        self.query_weights = Conv2D(self.output_channel,kernel_size = 1,strides = self.stride)\n",
        "        self.value_weights = Conv2D(self.output_channel,kernel_size = 1,strides = self.stride)\n",
        "\n",
        "    def call(self,x):\n",
        "        \n",
        "        batch,height,width,channels = x.shape\n",
        "        x_padded = ZeroPadding2D(padding=(self.kernel_size//2,self.kernel_size//2))(x)\n",
        "        query = self.query_weights(x)\n",
        "        value = self.value_weights(x_padded)\n",
        "        key = self.key_weights(x_padded)\n",
        "        #key,query and value will have the shape of (batch,height,width,depth)\n",
        "        keys = tf.image.extract_patches(images = key,sizes = [1,self.kernel_size,self.kernel_size,1],strides = [1,self.stride,self.stride,1],rates = [1,1,1,1], padding = \"VALID\")\n",
        "        value = tf.image.extract_patches(images = value,sizes = [1,self.kernel_size,self.kernel_size,1],strides = [1,self.stride,self.stride,1],rates = [1,1,1,1], padding = \"VALID\")\n",
        "        no_of_kernels = key.shape[-2] - self.kernel_size + 1\n",
        "        keys = tf.reshape(keys,shape = (-1,no_of_kernels, no_of_kernels,self.kernel_size,self.kernel_size,self.output_channel))\n",
        "        key_split_h,key_split_w = tf.split(keys,num_or_size_splits = 2,axis = -1)\n",
        "        key_with_rel = tk.layers.concatenate([key_split_h + self.rel_h,key_split_w + self.rel_w],axis = -1) \n",
        "        \n",
        "        #reshaping the query and key\n",
        "        key_with_rel = tf.reshape(key_with_rel,(-1,self.groups,no_of_kernels,no_of_kernels,self.kernel_size*self.kernel_size,self.output_channel//self.groups))\n",
        "        query  = tf.reshape(query,(-1,self.groups,no_of_kernels,no_of_kernels,1,self.output_channel//self.groups))        \n",
        "        value = tf.reshape(value,(-1,self.groups,no_of_kernels,no_of_kernels,self.kernel_size*self.kernel_size,self.output_channel//self.groups))\n",
        "        \n",
        "        #multiplication  of key and query\n",
        "        #assert key_with_rel.shape == query.shape        \n",
        "        key_prod_query = query*key_with_rel\n",
        "        \n",
        "        # Now the function is passed through the softmax and is multiplied with the values\n",
        "        s = Softmax(axis = -2)(key_prod_query)\n",
        "        y = tf.einsum('bnchwk,bnchwk->bnchk',s,value)\n",
        "        y = tf.reshape(y,(-1,height,width,self.output_channel))\n",
        "        return y\n",
        "\n",
        "    def get_config(self):\n",
        "        config = super().get_config().copy()\n",
        "        config.update({\n",
        "            \"input_channels\": self.input_channels, \n",
        "            \"output_channel\": self.output_channel, \n",
        "            \"kernel_size\": self.kernel_size, \n",
        "            \"stride\": self.stride, \n",
        "            \"groups\": self.groups, \n",
        "            \"rel_h\": self.rel_h, \n",
        "            \"rel_w\": self.rel_w, \n",
        "            \"key_weights\": self.key_weights, \n",
        "            \"query_weights\": self.query_weights, \n",
        "            \"value_weights\": self.value_weights\n",
        "        })\n",
        "        return config\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kE8Ziq-BlEP4"
      },
      "source": [
        "#Oversampling on feature map level"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = best_model"
      ],
      "metadata": {
        "id": "wqfEP5L9BgcF"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lm05Zet_B5am",
        "outputId": "fbfdf6eb-85ab-47da-dd67-9144153e76fe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 input_1 [(None, 128, 128, 3)] True\n",
            "1 resnet50 (None, 4, 4, 2048) True\n",
            "2 global_average_pooling2d (None, 2048) True\n",
            "3 flatten (None, 2048) True\n",
            "4 dense (None, 1024) True\n",
            "5 dense_1 (None, 512) True\n",
            "6 dense_2 (None, 7) True\n"
          ]
        }
      ],
      "source": [
        "for i in range(len(model.layers)):\n",
        "  layer = model.layers[i]\n",
        "  print(i, layer.name, layer.output_shape, layer.trainable)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "KqeSic6NmLsR"
      },
      "outputs": [],
      "source": [
        "# redefine model to output right after the first hidden layer\n",
        "end = 2\n",
        "model1 = Model(inputs=model.inputs, outputs=model.layers[end].output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "ZVHYG9Rwm28i",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "458bfcaa-caad-4ada-9451-8f940b72defa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "146/146 [==============================] - 6s 33ms/step\n",
            "7/7 [==============================] - 0s 31ms/step\n"
          ]
        }
      ],
      "source": [
        "# get feature map for first hidden layer\n",
        "X_train_fm = model1.predict(X_train)\n",
        "X_val_fm = model1.predict(X_val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "Xx0OnnZPl7_t",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dfdab64b-92ae-4ca5-b79f-80072a38ff32"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(4651, 2048)\n",
            "(4651, 7)\n",
            "(193, 2048)\n",
            "(193, 7)\n",
            "Counter train data:  Counter({5: 1341, 4: 1113, 2: 1099, 1: 514, 0: 327, 6: 142, 3: 115})\n",
            "Counter val data:  Counter({5: 123, 2: 22, 4: 21, 1: 15, 0: 8, 6: 3, 3: 1})\n"
          ]
        }
      ],
      "source": [
        "print(X_train_fm.shape)\n",
        "print(y_train.shape)\n",
        "print(X_val_fm.shape)\n",
        "print(y_val.shape)\n",
        "print('Counter train data: ', Counter(np.argmax(y_train, axis=1)))\n",
        "print('Counter val data: ', Counter(np.argmax(y_val, axis=1)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "19hK7aQNeAQo",
        "outputId": "692063d8-a6c6-4ed3-d48b-ad35990afbaf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(9987, 2048)\n",
            "(9987, 7)\n",
            "(193, 2048)\n",
            "(193, 7)\n",
            "Counter train data:  Counter({5: 1441, 4: 1441, 2: 1441, 0: 1441, 1: 1441, 6: 1441, 3: 1341})\n",
            "Counter val data:  Counter({5: 123, 2: 22, 4: 21, 1: 15, 0: 8, 6: 3, 3: 1})\n"
          ]
        }
      ],
      "source": [
        "X_train_fm_ov, y_train_ov = SMOTE_Data2(X_train, y_train, True, 5, type=\"borderline\")\n",
        "print(X_train_fm_ov.shape)\n",
        "print(y_train_ov.shape)\n",
        "print(X_val_fm.shape)\n",
        "print(y_val.shape)\n",
        "print('Counter train data: ', Counter(np.argmax(y_train_ov, axis=1)))\n",
        "print('Counter val data: ', Counter(np.argmax(y_val, axis=1)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "5qP4iyYcnAYa"
      },
      "outputs": [],
      "source": [
        "model2 = Model(inputs=model.layers[end+1].input, outputs=model.layers[len(model.layers)-1].output)\n",
        "#model2 = define_base_model(arch = 'dense')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pzdjs0WbvDB0",
        "outputId": "2f3c4624-af07-4c16-cfe6-295695195aff"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "best_model_fpath:/content/drive/MyDrive/PHD/Model/best_model_borderline_after_smote_on_featurespace_under80_128px.h5\n",
            "last_model_fpath:/content/drive/MyDrive/PHD/Model/last_model_borderline_after_smote_on_featurespace_under80_128px.h5\n",
            "Epoch 1/50\n",
            "153/156 [============================>.] - ETA: 0s - loss: 0.4016 - accuracy: 0.8682 - balanced_acc: 0.8692\n",
            "Epoch 1: val_balanced_acc improved from -inf to 0.42675, saving model to /content/drive/MyDrive/PHD/Model/best_model_borderline_after_smote_on_featurespace_under80_128px.h5\n",
            "156/156 [==============================] - 2s 6ms/step - loss: 0.4016 - accuracy: 0.8682 - balanced_acc: 0.8693 - val_loss: 0.6877 - val_accuracy: 0.7202 - val_balanced_acc: 0.4267 - lr: 0.0010\n",
            "Epoch 2/50\n",
            "149/156 [===========================>..] - ETA: 0s - loss: 0.3630 - accuracy: 0.8827 - balanced_acc: 0.8791\n",
            "Epoch 2: val_balanced_acc did not improve from 0.42675\n",
            "156/156 [==============================] - 1s 4ms/step - loss: 0.3636 - accuracy: 0.8818 - balanced_acc: 0.8785 - val_loss: 0.6546 - val_accuracy: 0.7617 - val_balanced_acc: 0.4160 - lr: 0.0010\n",
            "Epoch 3/50\n",
            "144/156 [==========================>...] - ETA: 0s - loss: 0.3374 - accuracy: 0.8924 - balanced_acc: 0.8888\n",
            "Epoch 3: val_balanced_acc did not improve from 0.42675\n",
            "156/156 [==============================] - 1s 4ms/step - loss: 0.3386 - accuracy: 0.8919 - balanced_acc: 0.8887 - val_loss: 0.6659 - val_accuracy: 0.7461 - val_balanced_acc: 0.4081 - lr: 0.0010\n",
            "Epoch 4/50\n",
            "153/156 [============================>.] - ETA: 0s - loss: 0.3193 - accuracy: 0.9011 - balanced_acc: 0.8976\n",
            "Epoch 4: val_balanced_acc improved from 0.42675 to 0.43782, saving model to /content/drive/MyDrive/PHD/Model/best_model_borderline_after_smote_on_featurespace_under80_128px.h5\n",
            "156/156 [==============================] - 1s 4ms/step - loss: 0.3201 - accuracy: 0.9005 - balanced_acc: 0.8972 - val_loss: 0.6597 - val_accuracy: 0.7513 - val_balanced_acc: 0.4378 - lr: 0.0010\n",
            "Epoch 5/50\n",
            "145/156 [==========================>...] - ETA: 0s - loss: 0.3072 - accuracy: 0.9042 - balanced_acc: 0.9002\n",
            "Epoch 5: val_balanced_acc did not improve from 0.43782\n",
            "156/156 [==============================] - 1s 4ms/step - loss: 0.3089 - accuracy: 0.9024 - balanced_acc: 0.8986 - val_loss: 0.6315 - val_accuracy: 0.7617 - val_balanced_acc: 0.4189 - lr: 0.0010\n",
            "Epoch 6/50\n",
            "155/156 [============================>.] - ETA: 0s - loss: 0.2947 - accuracy: 0.9071 - balanced_acc: 0.9065\n",
            "Epoch 6: val_balanced_acc did not improve from 0.43782\n",
            "156/156 [==============================] - 1s 4ms/step - loss: 0.2948 - accuracy: 0.9072 - balanced_acc: 0.9066 - val_loss: 0.6740 - val_accuracy: 0.7306 - val_balanced_acc: 0.4000 - lr: 0.0010\n",
            "Epoch 7/50\n",
            "143/156 [==========================>...] - ETA: 0s - loss: 0.2854 - accuracy: 0.9118 - balanced_acc: 0.9148\n",
            "Epoch 7: val_balanced_acc improved from 0.43782 to 0.45081, saving model to /content/drive/MyDrive/PHD/Model/best_model_borderline_after_smote_on_featurespace_under80_128px.h5\n",
            "156/156 [==============================] - 1s 4ms/step - loss: 0.2854 - accuracy: 0.9117 - balanced_acc: 0.9148 - val_loss: 0.6830 - val_accuracy: 0.7358 - val_balanced_acc: 0.4508 - lr: 0.0010\n",
            "Epoch 8/50\n",
            "155/156 [============================>.] - ETA: 0s - loss: 0.2753 - accuracy: 0.9149 - balanced_acc: 0.9115\n",
            "Epoch 8: val_balanced_acc improved from 0.45081 to 0.45762, saving model to /content/drive/MyDrive/PHD/Model/best_model_borderline_after_smote_on_featurespace_under80_128px.h5\n",
            "156/156 [==============================] - 1s 4ms/step - loss: 0.2757 - accuracy: 0.9147 - balanced_acc: 0.9113 - val_loss: 0.6377 - val_accuracy: 0.7617 - val_balanced_acc: 0.4576 - lr: 0.0010\n",
            "Epoch 9/50\n",
            "142/156 [==========================>...] - ETA: 0s - loss: 0.2705 - accuracy: 0.9157 - balanced_acc: 0.9120\n",
            "Epoch 9: val_balanced_acc improved from 0.45762 to 0.45975, saving model to /content/drive/MyDrive/PHD/Model/best_model_borderline_after_smote_on_featurespace_under80_128px.h5\n",
            "156/156 [==============================] - 1s 4ms/step - loss: 0.2666 - accuracy: 0.9174 - balanced_acc: 0.9136 - val_loss: 0.6718 - val_accuracy: 0.7617 - val_balanced_acc: 0.4597 - lr: 0.0010\n",
            "Epoch 10/50\n",
            "141/156 [==========================>...] - ETA: 0s - loss: 0.2623 - accuracy: 0.9206 - balanced_acc: 0.9167\n",
            "Epoch 10: val_balanced_acc did not improve from 0.45975\n",
            "156/156 [==============================] - 1s 3ms/step - loss: 0.2622 - accuracy: 0.9203 - balanced_acc: 0.9169 - val_loss: 0.6259 - val_accuracy: 0.7720 - val_balanced_acc: 0.4230 - lr: 0.0010\n",
            "Epoch 11/50\n",
            "143/156 [==========================>...] - ETA: 0s - loss: 0.2528 - accuracy: 0.9249 - balanced_acc: 0.9216\n",
            "Epoch 11: val_balanced_acc did not improve from 0.45975\n",
            "156/156 [==============================] - 1s 3ms/step - loss: 0.2522 - accuracy: 0.9248 - balanced_acc: 0.9220 - val_loss: 0.6355 - val_accuracy: 0.7617 - val_balanced_acc: 0.4208 - lr: 0.0010\n",
            "Epoch 12/50\n",
            "144/156 [==========================>...] - ETA: 0s - loss: 0.2451 - accuracy: 0.9258 - balanced_acc: 0.9233\n",
            "Epoch 12: val_balanced_acc did not improve from 0.45975\n",
            "156/156 [==============================] - 1s 3ms/step - loss: 0.2454 - accuracy: 0.9260 - balanced_acc: 0.9240 - val_loss: 0.6528 - val_accuracy: 0.7513 - val_balanced_acc: 0.4140 - lr: 0.0010\n",
            "Epoch 13/50\n",
            "144/156 [==========================>...] - ETA: 0s - loss: 0.2395 - accuracy: 0.9292 - balanced_acc: 0.9299\n",
            "Epoch 13: val_balanced_acc did not improve from 0.45975\n",
            "156/156 [==============================] - 1s 3ms/step - loss: 0.2394 - accuracy: 0.9296 - balanced_acc: 0.9300 - val_loss: 0.7099 - val_accuracy: 0.7409 - val_balanced_acc: 0.4123 - lr: 0.0010\n",
            "Epoch 14/50\n",
            "142/156 [==========================>...] - ETA: 0s - loss: 0.2288 - accuracy: 0.9325 - balanced_acc: 0.9293\n",
            "Epoch 14: val_balanced_acc did not improve from 0.45975\n",
            "156/156 [==============================] - 1s 3ms/step - loss: 0.2293 - accuracy: 0.9317 - balanced_acc: 0.9288 - val_loss: 0.7138 - val_accuracy: 0.7358 - val_balanced_acc: 0.4166 - lr: 0.0010\n",
            "Epoch 15/50\n",
            "145/156 [==========================>...] - ETA: 0s - loss: 0.2276 - accuracy: 0.9322 - balanced_acc: 0.9265\n",
            "Epoch 15: val_balanced_acc did not improve from 0.45975\n",
            "156/156 [==============================] - 1s 3ms/step - loss: 0.2278 - accuracy: 0.9316 - balanced_acc: 0.9264 - val_loss: 0.6547 - val_accuracy: 0.7565 - val_balanced_acc: 0.4214 - lr: 0.0010\n",
            "Epoch 16/50\n",
            "144/156 [==========================>...] - ETA: 0s - loss: 0.2190 - accuracy: 0.9349 - balanced_acc: 0.9314\n",
            "Epoch 16: val_balanced_acc did not improve from 0.45975\n",
            "156/156 [==============================] - 1s 3ms/step - loss: 0.2203 - accuracy: 0.9348 - balanced_acc: 0.9317 - val_loss: 0.6975 - val_accuracy: 0.7409 - val_balanced_acc: 0.4270 - lr: 0.0010\n",
            "Epoch 17/50\n",
            "142/156 [==========================>...] - ETA: 0s - loss: 0.2144 - accuracy: 0.9381 - balanced_acc: 0.9353\n",
            "Epoch 17: val_balanced_acc did not improve from 0.45975\n",
            "156/156 [==============================] - 1s 3ms/step - loss: 0.2142 - accuracy: 0.9375 - balanced_acc: 0.9354 - val_loss: 0.6577 - val_accuracy: 0.7617 - val_balanced_acc: 0.4202 - lr: 0.0010\n",
            "Epoch 18/50\n",
            "143/156 [==========================>...] - ETA: 0s - loss: 0.2134 - accuracy: 0.9384 - balanced_acc: 0.9353\n",
            "Epoch 18: val_balanced_acc improved from 0.45975 to 0.46312, saving model to /content/drive/MyDrive/PHD/Model/best_model_borderline_after_smote_on_featurespace_under80_128px.h5\n",
            "156/156 [==============================] - 1s 4ms/step - loss: 0.2152 - accuracy: 0.9370 - balanced_acc: 0.9347 - val_loss: 0.6686 - val_accuracy: 0.7617 - val_balanced_acc: 0.4631 - lr: 0.0010\n",
            "Epoch 19/50\n",
            "141/156 [==========================>...] - ETA: 0s - loss: 0.2042 - accuracy: 0.9408 - balanced_acc: 0.9396\n",
            "Epoch 19: val_balanced_acc did not improve from 0.46312\n",
            "156/156 [==============================] - 1s 3ms/step - loss: 0.2060 - accuracy: 0.9400 - balanced_acc: 0.9392 - val_loss: 0.6387 - val_accuracy: 0.7668 - val_balanced_acc: 0.4234 - lr: 0.0010\n",
            "Epoch 20/50\n",
            "143/156 [==========================>...] - ETA: 0s - loss: 0.2034 - accuracy: 0.9412 - balanced_acc: 0.9396\n",
            "Epoch 20: val_balanced_acc did not improve from 0.46312\n",
            "156/156 [==============================] - 1s 3ms/step - loss: 0.2032 - accuracy: 0.9409 - balanced_acc: 0.9390 - val_loss: 0.6606 - val_accuracy: 0.7565 - val_balanced_acc: 0.4151 - lr: 0.0010\n",
            "Epoch 21/50\n",
            "144/156 [==========================>...] - ETA: 0s - loss: 0.1987 - accuracy: 0.9410 - balanced_acc: 0.9373\n",
            "Epoch 21: val_balanced_acc did not improve from 0.46312\n",
            "156/156 [==============================] - 1s 3ms/step - loss: 0.1991 - accuracy: 0.9415 - balanced_acc: 0.9379 - val_loss: 0.7158 - val_accuracy: 0.7513 - val_balanced_acc: 0.4173 - lr: 0.0010\n",
            "Epoch 22/50\n",
            "146/156 [===========================>..] - ETA: 0s - loss: 0.1941 - accuracy: 0.9443 - balanced_acc: 0.9418\n",
            "Epoch 22: val_balanced_acc did not improve from 0.46312\n",
            "156/156 [==============================] - 1s 3ms/step - loss: 0.1933 - accuracy: 0.9444 - balanced_acc: 0.9421 - val_loss: 0.7183 - val_accuracy: 0.7409 - val_balanced_acc: 0.4561 - lr: 0.0010\n",
            "Epoch 23/50\n",
            "142/156 [==========================>...] - ETA: 0s - loss: 0.1896 - accuracy: 0.9484 - balanced_acc: 0.9475\n",
            "Epoch 23: val_balanced_acc did not improve from 0.46312\n",
            "156/156 [==============================] - 1s 3ms/step - loss: 0.1873 - accuracy: 0.9498 - balanced_acc: 0.9489 - val_loss: 0.6852 - val_accuracy: 0.7513 - val_balanced_acc: 0.4239 - lr: 0.0010\n",
            "Epoch 24/50\n",
            "143/156 [==========================>...] - ETA: 0s - loss: 0.1883 - accuracy: 0.9474 - balanced_acc: 0.9451\n",
            "Epoch 24: val_balanced_acc did not improve from 0.46312\n",
            "156/156 [==============================] - 1s 3ms/step - loss: 0.1875 - accuracy: 0.9482 - balanced_acc: 0.9459 - val_loss: 0.6669 - val_accuracy: 0.7617 - val_balanced_acc: 0.4225 - lr: 0.0010\n",
            "Epoch 25/50\n",
            "145/156 [==========================>...] - ETA: 0s - loss: 0.1822 - accuracy: 0.9491 - balanced_acc: 0.9462\n",
            "Epoch 25: val_balanced_acc did not improve from 0.46312\n",
            "156/156 [==============================] - 1s 3ms/step - loss: 0.1808 - accuracy: 0.9495 - balanced_acc: 0.9464 - val_loss: 0.6831 - val_accuracy: 0.7565 - val_balanced_acc: 0.4214 - lr: 0.0010\n",
            "Epoch 26/50\n",
            "141/156 [==========================>...] - ETA: 0s - loss: 0.1805 - accuracy: 0.9500 - balanced_acc: 0.9476\n",
            "Epoch 26: val_balanced_acc did not improve from 0.46312\n",
            "156/156 [==============================] - 1s 3ms/step - loss: 0.1815 - accuracy: 0.9497 - balanced_acc: 0.9475 - val_loss: 0.6915 - val_accuracy: 0.7461 - val_balanced_acc: 0.3955 - lr: 0.0010\n",
            "Epoch 27/50\n",
            "145/156 [==========================>...] - ETA: 0s - loss: 0.1762 - accuracy: 0.9516 - balanced_acc: 0.9482\n",
            "Epoch 27: val_balanced_acc did not improve from 0.46312\n",
            "156/156 [==============================] - 1s 3ms/step - loss: 0.1756 - accuracy: 0.9519 - balanced_acc: 0.9491 - val_loss: 0.6899 - val_accuracy: 0.7565 - val_balanced_acc: 0.4205 - lr: 0.0010\n",
            "Epoch 28/50\n",
            "144/156 [==========================>...] - ETA: 0s - loss: 0.1723 - accuracy: 0.9520 - balanced_acc: 0.9467\n",
            "Epoch 28: val_balanced_acc did not improve from 0.46312\n",
            "156/156 [==============================] - 1s 3ms/step - loss: 0.1720 - accuracy: 0.9524 - balanced_acc: 0.9477 - val_loss: 0.6772 - val_accuracy: 0.7668 - val_balanced_acc: 0.4315 - lr: 0.0010\n",
            "Epoch 29/50\n",
            "154/156 [============================>.] - ETA: 0s - loss: 0.1681 - accuracy: 0.9533 - balanced_acc: 0.9501\n",
            "Epoch 29: val_balanced_acc did not improve from 0.46312\n",
            "156/156 [==============================] - 1s 4ms/step - loss: 0.1691 - accuracy: 0.9530 - balanced_acc: 0.9498 - val_loss: 0.6537 - val_accuracy: 0.7565 - val_balanced_acc: 0.4154 - lr: 0.0010\n",
            "Epoch 30/50\n",
            "144/156 [==========================>...] - ETA: 0s - loss: 0.1652 - accuracy: 0.9552 - balanced_acc: 0.9526\n",
            "Epoch 30: val_balanced_acc did not improve from 0.46312\n",
            "156/156 [==============================] - 1s 3ms/step - loss: 0.1673 - accuracy: 0.9541 - balanced_acc: 0.9520 - val_loss: 0.6963 - val_accuracy: 0.7617 - val_balanced_acc: 0.4271 - lr: 0.0010\n",
            "Epoch 31/50\n",
            "145/156 [==========================>...] - ETA: 0s - loss: 0.1615 - accuracy: 0.9567 - balanced_acc: 0.9526\n",
            "Epoch 31: val_balanced_acc did not improve from 0.46312\n",
            "156/156 [==============================] - 1s 3ms/step - loss: 0.1616 - accuracy: 0.9566 - balanced_acc: 0.9528 - val_loss: 0.6431 - val_accuracy: 0.7668 - val_balanced_acc: 0.4197 - lr: 0.0010\n",
            "Epoch 32/50\n",
            "142/156 [==========================>...] - ETA: 0s - loss: 0.1595 - accuracy: 0.9564 - balanced_acc: 0.9530\n",
            "Epoch 32: val_balanced_acc did not improve from 0.46312\n",
            "156/156 [==============================] - 1s 3ms/step - loss: 0.1601 - accuracy: 0.9563 - balanced_acc: 0.9531 - val_loss: 0.6407 - val_accuracy: 0.7565 - val_balanced_acc: 0.4211 - lr: 0.0010\n",
            "Epoch 33/50\n",
            "143/156 [==========================>...] - ETA: 0s - loss: 0.1588 - accuracy: 0.9580 - balanced_acc: 0.9543\n",
            "Epoch 33: val_balanced_acc did not improve from 0.46312\n",
            "156/156 [==============================] - 1s 3ms/step - loss: 0.1600 - accuracy: 0.9578 - balanced_acc: 0.9544 - val_loss: 0.6802 - val_accuracy: 0.7565 - val_balanced_acc: 0.4199 - lr: 0.0010\n",
            "Epoch 34/50\n",
            "143/156 [==========================>...] - ETA: 0s - loss: 0.1540 - accuracy: 0.9602 - balanced_acc: 0.9573\n",
            "Epoch 34: val_balanced_acc did not improve from 0.46312\n",
            "156/156 [==============================] - 1s 3ms/step - loss: 0.1527 - accuracy: 0.9606 - balanced_acc: 0.9577 - val_loss: 0.7330 - val_accuracy: 0.7461 - val_balanced_acc: 0.4260 - lr: 0.0010\n",
            "Epoch 35/50\n",
            "142/156 [==========================>...] - ETA: 0s - loss: 0.1524 - accuracy: 0.9599 - balanced_acc: 0.9568\n",
            "Epoch 35: val_balanced_acc did not improve from 0.46312\n",
            "156/156 [==============================] - 1s 3ms/step - loss: 0.1535 - accuracy: 0.9593 - balanced_acc: 0.9565 - val_loss: 0.6659 - val_accuracy: 0.7617 - val_balanced_acc: 0.4193 - lr: 0.0010\n",
            "Epoch 36/50\n",
            "141/156 [==========================>...] - ETA: 0s - loss: 0.1563 - accuracy: 0.9592 - balanced_acc: 0.9549\n",
            "Epoch 36: val_balanced_acc did not improve from 0.46312\n",
            "156/156 [==============================] - 1s 3ms/step - loss: 0.1552 - accuracy: 0.9599 - balanced_acc: 0.9559 - val_loss: 0.6999 - val_accuracy: 0.7513 - val_balanced_acc: 0.4184 - lr: 0.0010\n",
            "Epoch 37/50\n",
            "144/156 [==========================>...] - ETA: 0s - loss: 0.1438 - accuracy: 0.9634 - balanced_acc: 0.9574\n",
            "Epoch 37: val_balanced_acc did not improve from 0.46312\n",
            "156/156 [==============================] - 1s 3ms/step - loss: 0.1435 - accuracy: 0.9633 - balanced_acc: 0.9578 - val_loss: 0.6781 - val_accuracy: 0.7617 - val_balanced_acc: 0.4318 - lr: 0.0010\n",
            "Epoch 38/50\n",
            "144/156 [==========================>...] - ETA: 0s - loss: 0.1485 - accuracy: 0.9625 - balanced_acc: 0.9597\n",
            "Epoch 38: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "\n",
            "Epoch 38: val_balanced_acc did not improve from 0.46312\n",
            "156/156 [==============================] - 1s 3ms/step - loss: 0.1475 - accuracy: 0.9626 - balanced_acc: 0.9601 - val_loss: 0.6438 - val_accuracy: 0.7668 - val_balanced_acc: 0.4279 - lr: 0.0010\n",
            "Epoch 39/50\n",
            "142/156 [==========================>...] - ETA: 0s - loss: 0.1377 - accuracy: 0.9659 - balanced_acc: 0.9649\n",
            "Epoch 39: val_balanced_acc did not improve from 0.46312\n",
            "156/156 [==============================] - 1s 3ms/step - loss: 0.1372 - accuracy: 0.9660 - balanced_acc: 0.9652 - val_loss: 0.6817 - val_accuracy: 0.7617 - val_balanced_acc: 0.4318 - lr: 5.0000e-04\n",
            "Epoch 40/50\n",
            "143/156 [==========================>...] - ETA: 0s - loss: 0.1378 - accuracy: 0.9672 - balanced_acc: 0.9644\n",
            "Epoch 40: val_balanced_acc did not improve from 0.46312\n",
            "156/156 [==============================] - 1s 3ms/step - loss: 0.1380 - accuracy: 0.9665 - balanced_acc: 0.9640 - val_loss: 0.7267 - val_accuracy: 0.7513 - val_balanced_acc: 0.4269 - lr: 5.0000e-04\n",
            "Epoch 41/50\n",
            "141/156 [==========================>...] - ETA: 0s - loss: 0.1341 - accuracy: 0.9698 - balanced_acc: 0.9659\n",
            "Epoch 41: val_balanced_acc did not improve from 0.46312\n",
            "156/156 [==============================] - 1s 4ms/step - loss: 0.1364 - accuracy: 0.9685 - balanced_acc: 0.9651 - val_loss: 0.7219 - val_accuracy: 0.7565 - val_balanced_acc: 0.4340 - lr: 5.0000e-04\n",
            "Epoch 42/50\n",
            "151/156 [============================>.] - ETA: 0s - loss: 0.1360 - accuracy: 0.9672 - balanced_acc: 0.9633\n",
            "Epoch 42: val_balanced_acc did not improve from 0.46312\n",
            "156/156 [==============================] - 1s 4ms/step - loss: 0.1355 - accuracy: 0.9676 - balanced_acc: 0.9637 - val_loss: 0.7055 - val_accuracy: 0.7565 - val_balanced_acc: 0.4307 - lr: 5.0000e-04\n",
            "Epoch 43/50\n",
            "142/156 [==========================>...] - ETA: 0s - loss: 0.1388 - accuracy: 0.9671 - balanced_acc: 0.9639\n",
            "Epoch 43: val_balanced_acc did not improve from 0.46312\n",
            "156/156 [==============================] - 1s 3ms/step - loss: 0.1370 - accuracy: 0.9679 - balanced_acc: 0.9651 - val_loss: 0.6786 - val_accuracy: 0.7668 - val_balanced_acc: 0.4279 - lr: 5.0000e-04\n",
            "Epoch 44/50\n",
            "143/156 [==========================>...] - ETA: 0s - loss: 0.1312 - accuracy: 0.9698 - balanced_acc: 0.9651\n",
            "Epoch 44: val_balanced_acc did not improve from 0.46312\n",
            "156/156 [==============================] - 1s 3ms/step - loss: 0.1307 - accuracy: 0.9699 - balanced_acc: 0.9659 - val_loss: 0.6860 - val_accuracy: 0.7668 - val_balanced_acc: 0.4360 - lr: 5.0000e-04\n",
            "Epoch 45/50\n",
            "154/156 [============================>.] - ETA: 0s - loss: 0.1339 - accuracy: 0.9676 - balanced_acc: 0.9647\n",
            "Epoch 45: val_balanced_acc did not improve from 0.46312\n",
            "156/156 [==============================] - 1s 4ms/step - loss: 0.1346 - accuracy: 0.9677 - balanced_acc: 0.9648 - val_loss: 0.6957 - val_accuracy: 0.7565 - val_balanced_acc: 0.4277 - lr: 5.0000e-04\n",
            "Epoch 46/50\n",
            "143/156 [==========================>...] - ETA: 0s - loss: 0.1300 - accuracy: 0.9692 - balanced_acc: 0.9671\n",
            "Epoch 46: val_balanced_acc did not improve from 0.46312\n",
            "156/156 [==============================] - 1s 3ms/step - loss: 0.1316 - accuracy: 0.9689 - balanced_acc: 0.9666 - val_loss: 0.6940 - val_accuracy: 0.7668 - val_balanced_acc: 0.4360 - lr: 5.0000e-04\n",
            "Epoch 47/50\n",
            "145/156 [==========================>...] - ETA: 0s - loss: 0.1289 - accuracy: 0.9720 - balanced_acc: 0.9673\n",
            "Epoch 47: val_balanced_acc did not improve from 0.46312\n",
            "156/156 [==============================] - 1s 3ms/step - loss: 0.1296 - accuracy: 0.9713 - balanced_acc: 0.9663 - val_loss: 0.6926 - val_accuracy: 0.7617 - val_balanced_acc: 0.4271 - lr: 5.0000e-04\n",
            "Epoch 48/50\n",
            "144/156 [==========================>...] - ETA: 0s - loss: 0.1280 - accuracy: 0.9719 - balanced_acc: 0.9697\n",
            "Epoch 48: val_balanced_acc did not improve from 0.46312\n",
            "156/156 [==============================] - 1s 3ms/step - loss: 0.1306 - accuracy: 0.9709 - balanced_acc: 0.9693 - val_loss: 0.7107 - val_accuracy: 0.7513 - val_balanced_acc: 0.4251 - lr: 5.0000e-04\n",
            "Epoch 49/50\n",
            "143/156 [==========================>...] - ETA: 0s - loss: 0.1296 - accuracy: 0.9705 - balanced_acc: 0.9673\n",
            "Epoch 49: val_balanced_acc did not improve from 0.46312\n",
            "156/156 [==============================] - 1s 3ms/step - loss: 0.1295 - accuracy: 0.9707 - balanced_acc: 0.9677 - val_loss: 0.7301 - val_accuracy: 0.7409 - val_balanced_acc: 0.4171 - lr: 5.0000e-04\n",
            "Epoch 50/50\n",
            "142/156 [==========================>...] - ETA: 0s - loss: 0.1249 - accuracy: 0.9724 - balanced_acc: 0.9694\n",
            "Epoch 50: val_balanced_acc did not improve from 0.46312\n",
            "156/156 [==============================] - 1s 3ms/step - loss: 0.1254 - accuracy: 0.9724 - balanced_acc: 0.9696 - val_loss: 0.6951 - val_accuracy: 0.7668 - val_balanced_acc: 0.4360 - lr: 5.0000e-04\n"
          ]
        }
      ],
      "source": [
        "best_model_fpath = '/content/drive/MyDrive/PHD/Model/best_model_'+exp_name+'_'+dataset_name+'.h5'\n",
        "print(\"best_model_fpath:\"+best_model_fpath)\n",
        "last_model_fpath = '/content/drive/MyDrive/PHD/Model/last_model_'+exp_name+'_'+dataset_name+'.h5'\n",
        "print(\"last_model_fpath:\"+last_model_fpath)\n",
        "mc1 = ModelCheckpoint(best_model_fpath, monitor='val_balanced_acc', mode='max', verbose=1, save_best_only=True)\n",
        "learning_rate_reduction = ReduceLROnPlateau(monitor='val_balanced_acc', patience=20, verbose=1, factor=0.5, min_lr=0.00001)\n",
        "early_stopping_monitor = EarlyStopping(patience=40,monitor='val_balanced_acc')\n",
        "model2.compile(optimizer = opt_SGD , loss = \"categorical_crossentropy\", metrics=['accuracy', balanced_acc])\n",
        "hst = model2.fit(X_train_fm_ov, y_train_ov, epochs=EPOCHS, batch_size=BATCH_SIZE, validation_data=(X_val_fm, y_val), verbose=1,\n",
        "                    steps_per_epoch=X_train_fm_ov.shape[0] // BATCH_SIZE, \n",
        "                    #callbacks=[learning_rate_reduction,early_stopping_monitor, mc1])\n",
        "                    callbacks=[learning_rate_reduction,mc1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "8XhlbWn--8Or",
        "outputId": "69127b4a-c638-4449-a068-fd80494a4008"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "# summarize history for accuracy\n",
        "plt.plot(hst.history['accuracy'])\n",
        "plt.plot(hst.history['balanced_acc'])\n",
        "plt.plot(hst.history['val_accuracy'])\n",
        "plt.plot(hst.history['val_balanced_acc'])\n",
        "plt.title('Model accuracy')\n",
        "plt.ylabel('Performance')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train accuracy', 'train balanced acc.', 'val. accuracy', 'val. balanced acc.'], loc='lower right')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "u-x0SENPGmm9"
      },
      "outputs": [],
      "source": [
        "#save last model\n",
        "model2.save(last_model_fpath)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U-e3ZaeeG1Bf",
        "outputId": "43185207-f891-4f63-85ec-9a590e61815f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 0s 1ms/step\n",
            "7/7 [==============================] - 0s 2ms/step\n",
            "accuracy on training 0.9733653749874838\n",
            "balanced accuracy on training 0.9736294240111035\n",
            "accuracy on validation 0.7668393782383419\n",
            "balanced accuracy on validation 0.5717909558501892\n",
            "Score on val data:  (0.5185897435897436, 0.5717909558501892, 0.5377159543062507, None)\n"
          ]
        }
      ],
      "source": [
        "last_model = load_model(last_model_fpath, custom_objects={'balanced_acc' : balanced_acc})\n",
        "y_train_pred = last_model.predict(X_train_fm_ov)\n",
        "y_val_pred = last_model.predict(X_val_fm)\n",
        "\n",
        "#print('accuracy on training',accuracy_score(np.argmax(y_train, axis=1), np.argmax(y_train_pred, axis=1)))\n",
        "print('accuracy on training',accuracy_score(np.argmax(y_train_ov, axis=1), np.argmax(y_train_pred, axis=1)))\n",
        "print('balanced accuracy on training',balanced_accuracy_score(np.argmax(y_train_ov, axis=1), np.argmax(y_train_pred, axis=1)))\n",
        "print('accuracy on validation',accuracy_score(np.argmax(y_val, axis=1), np.argmax(y_val_pred, axis=1)))\n",
        "print('balanced accuracy on validation',balanced_accuracy_score(np.argmax(y_val, axis=1), np.argmax(y_val_pred, axis=1)))\n",
        "print('Score on val data: ',precision_recall_fscore_support(np.argmax(y_val, axis=1), np.argmax(y_val_pred, axis=1), average='macro'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EQ3baQLsHLat",
        "outputId": "71206047-eb2f-4c68-fc42-a6301a8a48c7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 0s 1ms/step\n",
            "7/7 [==============================] - 0s 2ms/step\n",
            "accuracy on training 0.9419245018524082\n",
            "balanced accuracy on training 0.9424854622354494\n",
            "accuracy on validation 0.7616580310880829\n",
            "balanced accuracy on validation 0.6986307826900162\n",
            "Score on val data:  (0.5416475972540045, 0.6986307826900162, 0.5756277857054772, None)\n"
          ]
        }
      ],
      "source": [
        "best_model = load_model(best_model_fpath, custom_objects={'balanced_acc' : balanced_acc})\n",
        "y_train_pred = best_model.predict(X_train_fm_ov)\n",
        "y_val_pred = best_model.predict(X_val_fm)\n",
        "\n",
        "print('accuracy on training',accuracy_score(np.argmax(y_train_ov, axis=1), np.argmax(y_train_pred, axis=1)))\n",
        "print('balanced accuracy on training',balanced_accuracy_score(np.argmax(y_train_ov, axis=1), np.argmax(y_train_pred, axis=1)))\n",
        "print('accuracy on validation',accuracy_score(np.argmax(y_val, axis=1), np.argmax(y_val_pred, axis=1)))\n",
        "print('balanced accuracy on validation',balanced_accuracy_score(np.argmax(y_val, axis=1), np.argmax(y_val_pred, axis=1)))\n",
        "print('Score on val data: ',precision_recall_fscore_support(np.argmax(y_val, axis=1), np.argmax(y_val_pred, axis=1), average='macro'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RcRGeofw-8tK"
      },
      "source": [
        "#Load ISIC 2018 Challange Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "l3P7IjyLuZGY"
      },
      "outputs": [],
      "source": [
        "X_train, y_train, X_val, y_val = load_isic2018_dataset(train_under_frac = train_under_frac)\n",
        "print(X_train.shape)\n",
        "print(y_train.shape)\n",
        "print(X_val.shape)\n",
        "print(y_val.shape)\n",
        "print('Counter train data: ', Counter(np.argmax(y_train, axis=1)))\n",
        "print('Counter val data: ', Counter(np.argmax(y_val, axis=1)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "XT95XFaHQD6d"
      },
      "outputs": [],
      "source": [
        "X_train = preprocess_image_input(X_train, the_arch)\n",
        "X_val = preprocess_image_input(X_val, the_arch)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path = '/content/drive/MyDrive/PHD/Datasets/isic2018/'\n",
        "df1 = pd.DataFrame(X_train.reshape(X_train.shape[0],-1))\n",
        "df1['y_train'] = np.argmax(y_train, axis=1).tolist()\n",
        "df2 = pd.DataFrame(X_val.reshape(X_val.shape[0],-1))\n",
        "df2['y_val'] = np.argmax(y_val, axis=1).tolist()\n",
        "df1.to_pickle(path+\"isic2018_train_\"+dataset_name+\".pkl\")\n",
        "df2.to_pickle(path+\"isic2018_val_\"+dataset_name+\".pkl\")"
      ],
      "metadata": {
        "id": "APHFdj25vatJ"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"dataset saved:\", dataset_name)"
      ],
      "metadata": {
        "id": "NMEfVJy052YF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c9642a12-986c-40c8-cd08-7a3d23ae1736"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dataset saved: under80_128px\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2IncA-_o_n5w"
      },
      "outputs": [],
      "source": [
        "# ordered count of rows per unique label\n",
        "labels_count = y_train.value_counts(ascending=True)\n",
        "\n",
        "f = plt.figure(figsize=(15, 6))\n",
        "s = sns.barplot(x=labels_count.index,y=labels_count.values)\n",
        "s.set_xticklabels(s.get_xticklabels(), rotation = 30)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AnKMKSb4Bkym"
      },
      "source": [
        "Plot 3 images per label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jdnVuqbFBW3K"
      },
      "outputs": [],
      "source": [
        "def plot_images_per_label(df, label, cols: int, size: tuple):\n",
        "    fig, axs = plt.subplots(nrows=1, ncols=cols, figsize=size)\n",
        "\n",
        "    cntMax = cols\n",
        "    cntCur = 0\n",
        "    for index, row in df.iterrows():\n",
        "        if(y_train == label and cntCur < cntMax):\n",
        "            axs[cntCur].imshow(plt.imread(df.FilePaths[index]))\n",
        "            axs[cntCur].set_title(df.Labels[index])\n",
        "\n",
        "            cntCur += 1\n",
        "        else:\n",
        "            if(cntCur >= cntMax):\n",
        "                break\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "# unique labels\n",
        "labels = sorted(df1['y_train'].unique())\n",
        "for label in range(7):\n",
        "    plot_images_per_label(df1, label, 3, (12,9))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "asV1O58Lrq-R"
      },
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "img = Image.fromarray(X_train[0], 'RGB')\n",
        "display(img)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qRKKrNacAZtl"
      },
      "source": [
        "Drop duplicate images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ERwfyPDHP-zC"
      },
      "outputs": [],
      "source": [
        "#df_group = pd.read_csv('/content/drive/MyDrive/PHD/Datasets/isic2018/ISIC2018_Task3_Training_LesionGroupings.csv') \n",
        "#df_train = df_train.set_index('image').join(df_group.set_index('image'))\n",
        "#df_train = df_train.drop_duplicates(subset=['lesion_id'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cNBXx28B9yGu"
      },
      "source": [
        "#DeepSMOTE Oversampling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YmX_Uqbmj-tN"
      },
      "outputs": [],
      "source": [
        "from numpy import moveaxis\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "max_el = np.inf\n",
        "\n",
        "args = {}\n",
        "args['dim_h'] = 64         # factor controlling size of hidden layers\n",
        "args['n_channel'] = 3#1    # number of channels in the input data \n",
        "args['n_z'] = 600 #300     # number of dimensions in latent space. \n",
        "args['sigma'] = 1.0        # variance in n_z\n",
        "args['lambda'] = 0.01      # hyper param for weight of discriminator loss\n",
        "args['lr'] = 0.0002        # learning rate for Adam optimizer .000\n",
        "args['epochs'] = 300       # how many epochs to run for\n",
        "args['batch_size'] = 100   # batch size for SGD\n",
        "args['save'] = True        # save weights at each epoch of training if True\n",
        "args['train'] = True       # train networks if True, else load networks from\n",
        "args['patience'] = 20"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NydOdPMajEfT"
      },
      "outputs": [],
      "source": [
        "class Encoder(nn.Module):\n",
        "    def __init__(self, args):\n",
        "        super(Encoder, self).__init__()\n",
        "\n",
        "        self.n_channel = args['n_channel']\n",
        "        self.dim_h = args['dim_h']\n",
        "        self.n_z = args['n_z']\n",
        "        \n",
        "        # convolutional filters, work excellent with image data\n",
        "        # [(WK+2P)/S]+1\n",
        "        self.conv = nn.Sequential(\n",
        "            nn.AvgPool2d(7, stride=7),\n",
        "            nn.Conv2d(self.n_channel, self.dim_h, 4, 2, 1, bias=False),# 16\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Conv2d(self.dim_h, self.dim_h * 2, 4, 2, 1, bias=False), # 8\n",
        "            nn.BatchNorm2d(self.dim_h * 2),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Conv2d(self.dim_h * 2, self.dim_h * 4, 4, 2, 1, bias=False),# 4\n",
        "            nn.BatchNorm2d(self.dim_h * 4),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Conv2d(self.dim_h * 4, self.dim_h * 8, 4, 2, 0, bias=False),#14\n",
        "            nn.BatchNorm2d(self.dim_h * 8),\n",
        "            nn.LeakyReLU(0.2, inplace=True))\n",
        "        self.fc = nn.Linear(self.dim_h * (2 ** 3), self.n_z)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv(x)\n",
        "        \n",
        "        x = x.squeeze()\n",
        "        x = self.fc(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self, args):\n",
        "        super(Decoder, self).__init__()\n",
        "\n",
        "        self.n_channel = args['n_channel']\n",
        "        self.dim_h = args['dim_h']\n",
        "        self.n_z = args['n_z']\n",
        "\n",
        "        # first layer is fully connected\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(self.n_z, self.dim_h * 2**3 * 7 * 7),\n",
        "            nn.ReLU())\n",
        "\n",
        "        # deconvolutional filters, essentially inverse of convolutional filters\n",
        "        # H_out = (H_in1)*stride[0]  2padding[0] + dilation[0](kernel_size[0]1) + output_padding[0] + 1\n",
        "        self.deconv = nn.Sequential(\n",
        "            nn.ConvTranspose2d(self.dim_h * 8, self.dim_h * 4, 4), #10\n",
        "            nn.BatchNorm2d(self.dim_h * 4),\n",
        "            nn.ReLU(True),\n",
        "            nn.ConvTranspose2d(self.dim_h * 4, self.dim_h * 2, 4), #13\n",
        "            nn.BatchNorm2d(self.dim_h * 2),\n",
        "            nn.ReLU(True),\n",
        "            nn.ConvTranspose2d(self.dim_h * 2, self.dim_h, 4),# 16\n",
        "            nn.BatchNorm2d(self.dim_h),\n",
        "            nn.ReLU(True),\n",
        "            nn.ConvTranspose2d(self.dim_h, 3, 4, 2, 1),# 32\n",
        "            nn.UpsamplingBilinear2d(scale_factor=7),\n",
        "            nn.Tanh())\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.fc(x)\n",
        "        x = x.view(-1, self.dim_h * 2**3, 7, 7)\n",
        "        x = self.deconv(x)\n",
        "        return x\n",
        "\n",
        "##############################################################################\n",
        "\"\"\"set models, loss functions\"\"\"\n",
        "# control which parameters are frozen / free for optimization\n",
        "def free_params(module: nn.Module):\n",
        "    for p in module.parameters():\n",
        "        p.requires_grad = True\n",
        "\n",
        "def frozen_params(module: nn.Module):\n",
        "    for p in module.parameters():\n",
        "        p.requires_grad = False\n",
        "\n",
        "def biased_get_class(X, y, c):\n",
        "    \n",
        "    xbeg = X[y == c]\n",
        "    ybeg = y[y == c]\n",
        "    \n",
        "    return xbeg, ybeg\n",
        "    #return xclass, yclass\n",
        "\n",
        "def G_SM(X, y,n_to_sample,cl):\n",
        "    n_neigh = 5\n",
        "    nn = NearestNeighbors(n_neighbors=n_neigh, n_jobs=1)\n",
        "    nn.fit(X)\n",
        "    dist, ind = nn.kneighbors(X)\n",
        "\n",
        "    # generating samples\n",
        "    base_indices = np.random.choice(list(range(len(X))),n_to_sample)\n",
        "    neighbor_indices = np.random.choice(list(range(1, n_neigh)),n_to_sample)\n",
        "\n",
        "    X_base = X[base_indices]\n",
        "    X_neighbor = X[ind[base_indices, neighbor_indices]]\n",
        "\n",
        "    samples = X_base + np.multiply(np.random.rand(n_to_sample,1),\n",
        "            X_neighbor - X_base)\n",
        "\n",
        "    #use 10 as label because 0 to 9 real classes and 1 fake/smoted = 10\n",
        "    return samples, [cl]*n_to_sample\n",
        "\n",
        "def DeepSMOTE_train(X_train, y_train, one_hot = False):\n",
        "  from torch.utils.data import TensorDataset\n",
        "  import os\n",
        "\n",
        "  max_el = np.max(X_train)\n",
        "  X_train = X_train / max_el\n",
        "  X_train = moveaxis(X_train, 3, 1)\n",
        "  if one_hot:\n",
        "    y_train = np.argmax(y_train, axis=1)\n",
        "  #X_train = X_train.astype('float32') / 255.\n",
        "  \n",
        "  batch_size = args['batch_size']\n",
        "  patience = args['patience']\n",
        "  encoder = Encoder(args)\n",
        "  decoder = Decoder(args)\n",
        "\n",
        "  device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "  print(device)\n",
        "  decoder = decoder.to(device)\n",
        "  encoder = encoder.to(device)\n",
        "\n",
        "  train_on_gpu = torch.cuda.is_available()\n",
        "\n",
        "  #decoder loss function\n",
        "  criterion = nn.MSELoss()\n",
        "  criterion = criterion.to(device)\n",
        "\n",
        "  num_workers = 0\n",
        "\n",
        "  #torch.Tensor returns float so if want long then use torch.tensor\n",
        "  tensor_x = torch.from_numpy(X_train.copy())#torch.Tensor(X_train)\n",
        "  tensor_y = torch.tensor(y_train,dtype=torch.long)\n",
        "  mnist_bal = TensorDataset(tensor_x,tensor_y) \n",
        "  train_loader = torch.utils.data.DataLoader(mnist_bal, \n",
        "      batch_size=batch_size,shuffle=True,num_workers=num_workers)\n",
        "\n",
        "  best_loss = np.inf\n",
        "\n",
        "  enc_optim = torch.optim.Adam(encoder.parameters(), lr = args['lr'])\n",
        "  dec_optim = torch.optim.Adam(decoder.parameters(), lr = args['lr'])\n",
        "\n",
        "  for epoch in range(args['epochs']):\n",
        "      train_loss = 0.0\n",
        "      tmse_loss = 0.0\n",
        "      tdiscr_loss = 0.0\n",
        "      # train for one epoch -- set nets to train mode\n",
        "      encoder.train()\n",
        "      decoder.train()\n",
        "  \n",
        "      for images,labs in train_loader:\n",
        "      \n",
        "          # zero gradients for each batch\n",
        "          encoder.zero_grad()\n",
        "          decoder.zero_grad()\n",
        "          images, labs = images.to(device), labs.to(device)\n",
        "          labsn = labs.detach().cpu().numpy()\n",
        "#            print('images shape', images.shape)\n",
        "          # run images\n",
        "          z_hat = encoder(images)\n",
        "#            print('images shape after encoding', z_hat.shape)\n",
        "      \n",
        "          x_hat = decoder(z_hat) #decoder outputs tanh\n",
        "#            print('images shape after decoding', x_hat.shape)\n",
        "          mse = criterion(x_hat,images)\n",
        "                  \n",
        "          resx = []\n",
        "          resy = []\n",
        "      \n",
        "          tc = np.random.choice(num_classes,1)\n",
        "          #tc = 9\n",
        "          xbeg = X_train[y_train == tc]\n",
        "          ybeg = y_train[y_train == tc] \n",
        "          xlen = len(xbeg)\n",
        "          nsamp = min(xlen, 100)\n",
        "          ind = np.random.choice(list(range(len(xbeg))),nsamp,replace=False)\n",
        "          xclass = xbeg[ind]\n",
        "          yclass = ybeg[ind]\n",
        "      \n",
        "          xclen = len(xclass)\n",
        "          xcminus = np.arange(1,xclen)\n",
        "          \n",
        "          xcplus = np.append(xcminus,0)\n",
        "          xcnew = (xclass[[xcplus],:])\n",
        "          xcnew = xcnew.reshape(xcnew.shape[1],xcnew.shape[2],xcnew.shape[3],xcnew.shape[4])\n",
        "      \n",
        "          xcnew = torch.Tensor(xcnew)\n",
        "          xcnew = xcnew.to(device)\n",
        "      \n",
        "          #encode xclass to feature space\n",
        "          xclass = torch.Tensor(xclass)\n",
        "          xclass = xclass.to(device)\n",
        "          xclass = encoder(xclass)\n",
        "      \n",
        "          xclass = xclass.detach().cpu().numpy()\n",
        "      \n",
        "          xc_enc = (xclass[[xcplus],:])\n",
        "          xc_enc = np.squeeze(xc_enc)\n",
        "      \n",
        "          xc_enc = torch.Tensor(xc_enc)\n",
        "          xc_enc = xc_enc.to(device)\n",
        "          \n",
        "          ximg = decoder(xc_enc)\n",
        "          \n",
        "          mse2 = criterion(ximg,xcnew)\n",
        "      \n",
        "          comb_loss = mse2 + mse\n",
        "          comb_loss.backward()\n",
        "      \n",
        "          enc_optim.step()\n",
        "          dec_optim.step()\n",
        "      \n",
        "          train_loss += comb_loss.item()*images.size(0)\n",
        "          tmse_loss += mse.item()*images.size(0)\n",
        "          tdiscr_loss += mse2.item()*images.size(0)\n",
        "\n",
        "      train_loss = train_loss/len(train_loader)\n",
        "      tmse_loss = tmse_loss/len(train_loader)\n",
        "      tdiscr_loss = tdiscr_loss/len(train_loader)\n",
        "      print('Epoch: {} \\tTrain Loss: {:.6f} \\tmse loss: {:.6f} \\tmse2 loss: {:.6f}'.format(epoch,\n",
        "              train_loss,tmse_loss,tdiscr_loss))\n",
        "      \n",
        "  \n",
        "  \n",
        "      #store the best encoder and decoder models\n",
        "      #here, /crs5 is a reference to 5 way cross validation, but is not\n",
        "      #necessary for illustration purposes\n",
        "      if train_loss < best_loss:\n",
        "          print('Saving..')\n",
        "          patience = args['patience']\n",
        "          path_enc = '/content/drive/MyDrive/PHD/Model/DeepSMOTE/32/bst_enc.pth'\n",
        "          path_dec = '/content/drive/MyDrive/PHD/Model/DeepSMOTE/32/bst_dec.pth'\n",
        "        \n",
        "          torch.save(encoder.state_dict(), path_enc)\n",
        "          torch.save(decoder.state_dict(), path_dec)\n",
        "  \n",
        "          best_loss = train_loss\n",
        "      else:\n",
        "          patience = patience - 1\n",
        "\n",
        "      if patience == 0:\n",
        "          print('Out of patience. \\n')\n",
        "          break\n",
        "\n",
        "def DeepSMOTE_Data(X_train, y_train, one_hot = False):\n",
        "  batch_size = args['batch_size']\n",
        "  max_el = np.max(X_train)\n",
        "  X_train = X_train / max_el\n",
        "  X_train = moveaxis(X_train, 3, 1)\n",
        "  if one_hot:\n",
        "    y_train = np.argmax(y_train, axis=1)\n",
        "  #Generate artificial images\n",
        "  import torch\n",
        "  np.printoptions(precision=5,suppress=True)\n",
        "\n",
        "  #path on the computer where the models are stored\n",
        "  modpth = '/content/drive/MyDrive/PHD/Model/DeepSMOTE/32/'\n",
        "\n",
        "  path_enc = modpth + '/bst_enc.pth'\n",
        "  path_dec = modpth + '/bst_dec.pth'\n",
        "  \n",
        "  train_on_gpu = torch.cuda.is_available()\n",
        "  device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "  encoder = Encoder(args)\n",
        "  encoder.load_state_dict(torch.load(path_enc), strict=False)\n",
        "  encoder = encoder.to(device)\n",
        "\n",
        "  decoder = Decoder(args)\n",
        "  decoder.load_state_dict(torch.load(path_dec), strict=False)\n",
        "  decoder = decoder.to(device)\n",
        "\n",
        "  encoder.eval()\n",
        "  decoder.eval()\n",
        "\n",
        "  resx = []\n",
        "  resy = []\n",
        "  \n",
        "  counter = Counter(y_train)\n",
        "  counter = sorted(counter.items())\n",
        "  counter = [value for _, value in counter]\n",
        "\n",
        "  for i in range(num_classes):\n",
        "      torch.cuda.empty_cache()\n",
        "\n",
        "      xclass, yclass = biased_get_class(X_train, y_train, i)\n",
        "      #encode xclass to feature space\n",
        "      xclass = torch.Tensor(xclass)\n",
        "      xclass = xclass.to(device)\n",
        "      xclass = encoder(xclass)\n",
        "          \n",
        "      xclass = xclass.detach().cpu().numpy()\n",
        "      n = np.max(counter) - counter[i]\n",
        "      if n == 0:\n",
        "        continue\n",
        "#        resx2 = []\n",
        "#        resy2 = []\n",
        "#        for j in range(batch_size, n+batch_size+1, batch_size):\n",
        "#          if j <= n:\n",
        "#            batch_size_max = batch_size\n",
        "#          elif n % batch_size != 0:\n",
        "#            batch_size_max = n%batch_size\n",
        "#          else:\n",
        "#            break\n",
        "#          xsamp, ysamp = G_SM(xclass,yclass,batch_size_max,i)\n",
        "      xsamp, ysamp = G_SM(xclass,yclass,n,i)\n",
        "      ysamp = np.array(ysamp)\n",
        "  \n",
        "      \"\"\"to generate samples for resnet\"\"\"   \n",
        "      xsamp = torch.Tensor(xsamp)\n",
        "      xsamp = xsamp.to(device)\n",
        "      ximg = decoder(xsamp)\n",
        "\n",
        "      ximn = ximg.detach().cpu().numpy()\n",
        "#        resx2.append(ximn)\n",
        "#        resy2.append(ysamp)\n",
        "#        \n",
        "#        resx2 = np.vstack(resx2)\n",
        "#        resy2 = np.hstack(resy2)\n",
        "      resx.append(ximn)\n",
        "      resy.append(ysamp)\n",
        "  \n",
        "  resx1 = np.vstack(resx)\n",
        "  resy1 = np.hstack(resy)\n",
        "  resx1 = resx1.reshape(resx1.shape[0],-1)\n",
        "  X_train = X_train.reshape(X_train.shape[0],-1)\n",
        "  X_train = np.vstack((resx1,X_train))\n",
        "  y_train = np.hstack((resy1,y_train))\n",
        "  y_train = to_categorical(y_train)\n",
        "  X_train = X_train.reshape(-1, 3, IMAGE_W, IMAGE_H)\n",
        "  X_train = moveaxis(X_train, 1, 3)\n",
        "  X_train = X_train * max_el\n",
        "  return X_train, y_train"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0jrJ33lUDkCM"
      },
      "source": [
        "#Split dataset to train and val"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e6qneWL_Bs2U"
      },
      "outputs": [],
      "source": [
        "# stratified train and rem (20%) datasets\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, stratify=y_train, random_state=1)\n",
        "\n",
        "print('Train Data: ', X_train.shape)\n",
        "print('Remaining Data: ', X_val.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8Kef4r_zxjgk"
      },
      "outputs": [],
      "source": [
        "#Data Augmentation\n",
        "dataaugment = ImageDataGenerator(\n",
        "        rotation_range=90,  # randomly rotate images in the range (degrees, 0 to 180)\n",
        "        zoom_range = 0.1, # Randomly zoom image \n",
        "        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
        "        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
        "        horizontal_flip=True,  # randomly flip images\n",
        "        vertical_flip=True,  # randomly flip images\n",
        "        shear_range = 10) \n",
        "\n",
        "dataaugment.fit(X_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B2PgksTFkOAq"
      },
      "source": [
        "#Fine Tune"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nr1jnSM7yzJc"
      },
      "outputs": [],
      "source": [
        "limit = 171\n",
        "for layer in model.layers[:limit]:\n",
        "   layer.trainable = False\n",
        "for layer in model.layers[limit:]:\n",
        "   layer.trainable = True\n",
        "\n",
        "optimizer_SGD = SGD(learning_rate=0.0001, momentum=0.9)\n",
        "model.compile(optimizer = optimizer_SGD , loss = \"categorical_crossentropy\", metrics=['accuracy', balanced_acc])\n",
        "hst2 = model.fit(train_data_batches,\n",
        "                    epochs = EPOCHS, validation_data = valid_data_batches,\n",
        "                    callbacks=[learning_rate_reduction,early_stopping_monitor, mc])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vO1aAQBmiy0K"
      },
      "outputs": [],
      "source": [
        "# summarize history for accuracy\n",
        "plt.plot(hst2.history['balanced_acc'])\n",
        "plt.plot(hst2.history['val_balanced_acc'])\n",
        "plt.title('model balance_acc after tunning')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'val'], loc='upper left')\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "E_x4c0_DTkaa",
        "BE9FCWBe8deT",
        "iDRWiTnO0MGh",
        "eaK4zbtoaAaC",
        "3K908bbiYwbS",
        "UswA0co2y1wl",
        "LfcFpsBwM0d4",
        "cNBXx28B9yGu",
        "0jrJ33lUDkCM",
        "B2PgksTFkOAq"
      ],
      "machine_shape": "hm",
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}