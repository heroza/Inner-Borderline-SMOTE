{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/heroza/Inner-Borderline-SMOTE/blob/main/Skin_Cancer_Diagnosis_using_Borderline_Self.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Eus_4tUgfEk9",
        "outputId": "38265674-4669-4ab8-c563-7fa327dbe244"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E_x4c0_DTkaa"
      },
      "source": [
        "#Library, atribut, and function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "nR2MJBYq-oiB"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import os\n",
        "from collections import Counter\n",
        "from pathlib import Path\n",
        "from PIL import Image\n",
        "from sklearn import preprocessing\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "from sklearn.metrics import precision_recall_fscore_support, balanced_accuracy_score, confusion_matrix, accuracy_score\n",
        "from keras.callbacks import ReduceLROnPlateau, EarlyStopping, ModelCheckpoint\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D, UpSampling2D\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.optimizers import Adam, SGD\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input, decode_predictions\n",
        "from tensorflow.keras.applications.inception_v3 import InceptionV3, preprocess_input\n",
        "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Input, Dropout, Flatten\n",
        "from tensorflow.keras.models import Model, load_model\n",
        "from keras.utils.np_utils import to_categorical\n",
        "import imblearn\n",
        "from imblearn.over_sampling import SMOTE, BorderlineSMOTE, SVMSMOTE, ADASYN, KMeansSMOTE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "9-c7Xghg4SB4"
      },
      "outputs": [],
      "source": [
        "# input image size\n",
        "IMAGE_W = 224\n",
        "IMAGE_H = 224\n",
        "IMG_SIZE = (IMAGE_W,IMAGE_H)\n",
        "num_classes = 7\n",
        "EPOCHS = 100\n",
        "BATCH_SIZE = 64\n",
        "opt_adam = Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
        "opt_SGD = SGD(learning_rate=0.001)\n",
        "the_arch = 'resnet50'\n",
        "\n",
        "#Callbacks\n",
        "best_model_fpath = '/content/drive/MyDrive/PHD/Model/best_model_attention.h5'\n",
        "last_model_fpath = '/content/drive/MyDrive/PHD/Model/last_model_attention.h5'\n",
        "mc = ModelCheckpoint(best_model_fpath, monitor='val_balanced_acc', mode='max', verbose=1, save_best_only=True)\n",
        "learning_rate_reduction = ReduceLROnPlateau(monitor='val_balanced_acc', patience=20, verbose=1, factor=0.5, min_lr=0.00001)\n",
        "early_stopping_monitor = EarlyStopping(patience=30,monitor='val_balanced_acc')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "JffFid9sOXeo"
      },
      "outputs": [],
      "source": [
        "# load train and test dataset\n",
        "def preprocess_image_input(input_images, arch = the_arch):\n",
        "  input_images = input_images.astype('float32')\n",
        "  if arch == 'inception_v3':\n",
        "    output_ims = tf.keras.applications.inception_v3.preprocess_input(input_images)\n",
        "  else:\n",
        "    output_ims = tf.keras.applications.resnet50.preprocess_input(input_images)\n",
        "  return output_ims\n",
        "\n",
        "def load_cifar10_dataset():\n",
        "  from keras.datasets import cifar10\n",
        "    # load dataset\n",
        "  (X_train, y_train), (X_val, y_val) = cifar10.load_data()\n",
        "    # one hot encode target values\n",
        "  y_train = to_categorical(y_train)\n",
        "  y_val = to_categorical(y_val)\n",
        "\n",
        "  return X_train, y_train, X_val, y_val\n",
        "\n",
        "def balanced_acc(y_true, y_pred):\n",
        "    from keras import backend as K\n",
        "\n",
        "    tensor1 = tf.math.argmax(y_true, axis=1)\n",
        "    tensor2 = tf.math.argmax(y_pred, axis=1)\n",
        "\n",
        "    cm = tf.math.confusion_matrix(tensor1, tensor2)\n",
        "    \n",
        "    diag = tf.linalg.tensor_diag_part (cm)\n",
        "    tpfn = tf.cast(K.sum(cm, axis = 1), tf.float32) + K.epsilon()\n",
        "    recall = tf.divide(tf.cast(diag, tf.float32),tpfn)\n",
        "    balanced_acc = K.mean(recall)\n",
        "    return balanced_acc\n",
        "\n",
        "def define_base_model(arch = the_arch, start_trainable_layer = 9999, attention=False):\n",
        "  #x = data_augmentation(input_tensor)\n",
        "  #x = layers.Rescaling(1.0 / 255)(input_tensor)  # Rescale inputs\n",
        "  if arch != 'dense':\n",
        "    input_tensor = Input(shape=(IMAGE_H, IMAGE_W, 3))\n",
        "    #if IMAGE_H == 32:\n",
        "      #x = UpSampling2D(size=(7,7))(input_tensor)\n",
        "    if arch == 'resnet50':\n",
        "      base_model = ResNet50(input_tensor=input_tensor, weights='imagenet', include_top=False)\n",
        "    elif arch == 'inception_v3':\n",
        "      base_model = InceptionV3(input_tensor=input_tensor, weights='imagenet', include_top=False)\n",
        "    elif arch == 'ResNet':\n",
        "      base_model = ResNet(classes ,image_shape)(input_tensor)\n",
        "    x = base_model.output\n",
        "    if attention:\n",
        "      x = Attention(1024,1024,7,8)(x)\n",
        "    x = GlobalAveragePooling2D()(x)\n",
        "    for layer in base_model.layers:\n",
        "      layer.trainable = False\n",
        "    if start_trainable_layer != 9999:\n",
        "      for layer in base_model.layers[start_trainable_layer:]:\n",
        "        layer.trainable = True\n",
        "  else:\n",
        "    input_tensor = Input(shape=(2048))\n",
        "    x = input_tensor\n",
        "  #x = Flatten()(x)\n",
        "  x = Dense(1024, activation='relu')(x)\n",
        "  #x = Dropout(0.2)(x)\n",
        "  x = Dense(512, activation='relu')(x)\n",
        "  predictions = Dense(num_classes, activation='softmax')(x)\n",
        "  model = Model(inputs=input_tensor, outputs=predictions)\n",
        "  model.compile(optimizer = opt_SGD , loss = \"categorical_crossentropy\", metrics=['accuracy', balanced_acc])\n",
        "  return model\n",
        "\n",
        "# plot diagnostic learning curves\n",
        "def summarize_diagnostics(history):\n",
        "    # plot loss\n",
        "    plt.subplot(211)\n",
        "    plt.title('Cross Entropy Loss')\n",
        "    plt.plot(history.history['loss'], color='blue', label='train')\n",
        "    plt.plot(history.history['val_loss'], color='orange', label='test')\n",
        "    # plot accuracy\n",
        "    plt.subplot(212)\n",
        "    plt.title('Classification Accuracy')\n",
        "    plt.plot(history.history['accuracy'], color='blue', label='train')\n",
        "    plt.plot(history.history['val_accuracy'], color='orange', label='test')\n",
        " \n",
        "# scale pixels\n",
        "def norm_pixels(train, test):\n",
        "    # convert from integers to floats\n",
        "    train_norm = train.astype('float32')\n",
        "    test_norm = test.astype('float32')\n",
        "    # normalize to range 0-1\n",
        "    train_norm = train_norm / 255.0\n",
        "    test_norm = test_norm / 255.0\n",
        "    # return normalized images\n",
        "    return train_norm, test_norm\n",
        "\n",
        "def load_isic2018_dataset(train_under_frac = 0):\n",
        "  df_train = pd.read_csv('/content/drive/MyDrive/PHD/Datasets/isic2018/ISIC2018_Task3_Training_GroundTruth/ISIC2018_Task3_Training_GroundTruth.csv') \n",
        "  df_val = pd.read_csv('/content/drive/MyDrive/PHD/Datasets/isic2018/ISIC2018_Task3_Validation_GroundTruth/ISIC2018_Task3_Validation_GroundTruth.csv') \n",
        "\n",
        "  #decode one hot label\n",
        "  df_train[\"Labels\"] = (df_train.iloc[:, 1:]).idxmax(axis=1)\n",
        "  df_val[\"Labels\"] = (df_val.iloc[:, 1:]).idxmax(axis=1)\n",
        "\n",
        "  #random undersampling for training dataset\n",
        "  if train_under_frac !=0:\n",
        "    df_train = df_train.drop(df_train[df_train['Labels'] == 'NV'].sample(frac=train_under_frac).index)\n",
        "\n",
        "  #drop one-hot column\n",
        "  df_train = df_train.drop(columns=['MEL', 'NV', 'BCC', 'AKIEC', 'BKL', 'DF', 'VASC'])\n",
        "  df_val = df_val.drop(columns=['MEL', 'NV', 'BCC', 'AKIEC', 'BKL', 'DF', 'VASC'])\n",
        "\n",
        "  #make filepaths of the image\n",
        "  dir_train = '/content/drive/MyDrive/PHD/Datasets/isic2018/ISIC2018_Task3_Training_Input/'\n",
        "  dir_val = '/content/drive/MyDrive/PHD/Datasets/isic2018/ISIC2018_Task3_Validation_Input/'\n",
        "  df_train['FilePaths'] = dir_train + df_train['image'] + '.jpg'\n",
        "  df_val['FilePaths'] = dir_val + df_val['image'] + '.jpg'\n",
        "  \n",
        "  #load image pixels to dataframe\n",
        "  df_train['image_px'] = df_train['FilePaths'].map(lambda x: np.asarray(Image.open(x).resize(IMG_SIZE)))\n",
        "  df_val['image_px'] = df_val['FilePaths'].map(lambda x: np.asarray(Image.open(x).resize(IMG_SIZE)))\n",
        "\n",
        "  X_train = np.asarray(df_train['image_px'].tolist())\n",
        "  X_val = np.asarray(df_val['image_px'].tolist())\n",
        "  y_train = np.array(df_train['Labels'].values)\n",
        "  y_val = np.array(df_val['Labels'].values)\n",
        "\n",
        "  label_encoder = preprocessing.LabelEncoder()\n",
        "  y_train = label_encoder.fit_transform(y_train)\n",
        "  y_val = label_encoder.fit_transform(y_val)\n",
        "  \n",
        "  y_train = to_categorical(y_train, num_classes = num_classes)\n",
        "  y_val = to_categorical(y_val, num_classes = num_classes)\n",
        "\n",
        "  return X_train, y_train, X_val, y_val\n",
        "\n",
        "def reset_dataset(df_train, df_val):\n",
        "  X_train = np.asarray(df_train['image_px'].tolist())\n",
        "  X_val = np.asarray(df_val['image_px'].tolist())\n",
        "  y_train = np.array(df_train['Labels'].values)\n",
        "  y_val = np.array(df_val['Labels'].values)\n",
        "\n",
        "  X_train = preprocess_image_input(X_train, the_arch)\n",
        "  X_val = preprocess_image_input(X_val, the_arch)\n",
        "\n",
        "  label_encoder = preprocessing.LabelEncoder()\n",
        "  y_train = label_encoder.fit_transform(y_train)\n",
        "  y_val = label_encoder.fit_transform(y_val)\n",
        "  \n",
        "  y_train = to_categorical(y_train, num_classes = num_classes)\n",
        "  y_val = to_categorical(y_val, num_classes = num_classes)\n",
        "  return X_train, y_train, X_val, y_val\n",
        "\n",
        "def SMOTE_Data(X, y, one_hot = False, k = 5, width = IMAGE_W, height = IMAGE_H, c = 3, type = 'smote'):\n",
        "  if one_hot:\n",
        "    y = np.argmax(y, axis=1)\n",
        "  if type == 'borderline':\n",
        "    sm = BorderlineSMOTE(random_state=42, k_neighbors=k)\n",
        "  elif type == 'svm':\n",
        "    sm = SVMSMOTE()\n",
        "  elif type == 'adasyn':\n",
        "    sm = ADASYN(random_state=42, n_neighbors=k)\n",
        "  elif type == 'kmeans':\n",
        "    sm = KMeansSMOTE(k_neighbors=k, kmeans_estimator=10)\n",
        "  else:\n",
        "    sm = SMOTE(random_state=42, k_neighbors=k)\n",
        "  X_resampled, y_resampled = sm.fit_resample(X.reshape((-1, width * height * c)), y)\n",
        "  X_resampled = X_resampled.reshape(-1, width, height, c)\n",
        "  if one_hot:\n",
        "    y_resampled = to_categorical(y_resampled, num_classes = num_classes)\n",
        "  else:\n",
        "    y_resampled = y_resampled.reshape(-1,1)\n",
        "  return X_resampled, y_resampled\n",
        "\n",
        "def SMOTE_Data2(X, y, one_hot = False, k = 5):\n",
        "  if one_hot:\n",
        "    y = np.argmax(y, axis=1)\n",
        "  sm = BorderlineSMOTE(random_state=42, k_neighbors=k)\n",
        "  X_resampled, y_resampled = sm.fit_resample(X, y)\n",
        "  if one_hot:\n",
        "    y_resampled = to_categorical(y_resampled, num_classes = num_classes)\n",
        "  else:\n",
        "    y_resampled = y_resampled.reshape(-1,1)\n",
        "  return X_resampled, y_resampled"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Inner-Borderline SMOTE"
      ],
      "metadata": {
        "id": "BE9FCWBe8deT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_class(X, y, c):\n",
        "    xbeg = X[y == c]\n",
        "    ybeg = y[y == c]\n",
        "    \n",
        "    return xbeg, ybeg\n",
        "def find_border(xclass, yclass, X, y, cli, n_neigh=5):\n",
        "    nn = NearestNeighbors(n_neighbors=n_neigh, n_jobs=1)\n",
        "    nn.fit(X)\n",
        "    dist, ind = nn.kneighbors(xclass)\n",
        "    ret = []\n",
        "    for i in range(len(ind)):\n",
        "      ret.append(sum(y[ind[i,j]] != cli for j in range(1,len(ind[i]))))\n",
        "    ret = np.array(ret)\n",
        "    xclass = xclass[np.logical_and(ret < (n_neigh-1),ret > ((n_neigh-1)/2))]\n",
        "    yclass = yclass[np.logical_and(ret < (n_neigh-1),ret > ((n_neigh-1)/2))]\n",
        "\n",
        "    return xclass, yclass\n",
        "def find_inner_border(xclass, yclass, X, y, cli, n_neigh=5):\n",
        "    nn = NearestNeighbors(n_neighbors=n_neigh, n_jobs=1)\n",
        "    nn.fit(X)\n",
        "    dist, ind = nn.kneighbors(xclass)\n",
        "    ret = []\n",
        "    for i in range(len(ind)):\n",
        "      ret.append(sum(y[ind[i,j]] != cli for j in range(1,len(ind[i]))))\n",
        "    ret = np.array(ret)\n",
        "    xclass = xclass[np.logical_and(ret < (n_neigh-1),ret > ((n_neigh-1)/2))]\n",
        "    yclass = yclass[np.logical_and(ret < (n_neigh-1),ret > ((n_neigh-1)/2))]\n",
        "\n",
        "    return xclass, yclass\n",
        "\n",
        "def G_SM(xclass,n_to_sample,cl, n_neigh = 6):\n",
        "    \n",
        "    nn = NearestNeighbors(n_neighbors=n_neigh, n_jobs=1)\n",
        "    nn.fit(xclass)\n",
        "    dist, ind = nn.kneighbors(xclass)\n",
        "\n",
        "    # generating samples\n",
        "    base_indices = np.random.choice(list(range(len(xclass))),n_to_sample)\n",
        "    neighbor_indices = np.random.choice(list(range(1, n_neigh)),n_to_sample)\n",
        "\n",
        "    X_base = xclass[base_indices]\n",
        "    X_neighbor = xclass[ind[base_indices, neighbor_indices]]\n",
        "\n",
        "    samples = X_base + np.multiply(np.random.rand(n_to_sample,1),\n",
        "            X_neighbor - X_base)\n",
        "\n",
        "    #use 10 as label because 0 to 9 real classes and 1 fake/smoted = 10\n",
        "    return samples, [cl]*n_to_sample\n",
        "\n",
        "def Borderline_SMOTE(X_train, y_train, random_state=42, k_neighbors=5, start=0, n=4):\n",
        "  #reshape X_train\n",
        "  X_train = X_train.reshape(-1, IMAGE_W * IMAGE_H * 3)\n",
        "  #decode y_train from one-hot encoding\n",
        "  y_train = np.argmax(y_train, axis=1) \n",
        "\n",
        "  counter = Counter(y_train)\n",
        "  key_max = max(counter, key=counter.get)\n",
        "  class_max = counter[key_max]\n",
        "  resx=[]\n",
        "  resy=[]\n",
        "\n",
        "  for i in range(start,n):\n",
        "      xclass, yclass = get_class(X_train, y_train, i)\n",
        "      if xclass.shape[0] == class_max:\n",
        "        continue\n",
        "      xclass_bdr, yclass_bdr = find_border(xclass, yclass, X_train, y_train, i, n_neigh=k_neighbors)\n",
        "      n = class_max - xclass.shape[0]\n",
        "      xsamp, ysamp = G_SM(xclass_bdr,n,i, n_neigh=k_neighbors)\n",
        "      ysamp = np.array(ysamp)\n",
        "      resx.append(xsamp)\n",
        "      resy.append(ysamp)\n",
        "  \n",
        "  resx = np.vstack(resx)\n",
        "  resy = np.hstack(resy)\n",
        "  X_train = np.vstack((resx,X_train))\n",
        "  y_train = np.hstack((resy,y_train))\n",
        "  y_train = to_categorical(y_train)\n",
        "  X_train = X_train.reshape(-1, IMAGE_W, IMAGE_H, 3)\n",
        "  return X_train, y_train"
      ],
      "metadata": {
        "id": "s3UnuaKz8kzJ"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_ov, y_train_ov = Borderline_SMOTE(X_train, y_train, random_state=42, k_neighbors=4, start=0, n=7)"
      ],
      "metadata": {
        "id": "m9YF522I-HXe"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_train_ov.shape)\n",
        "print(y_train_ov.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lj-gWlzMa2CM",
        "outputId": "b3a89b73-046c-44e1-f8fd-9686f50ef2a9"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(5460, 150528)\n",
            "(5460, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_train_ov.shape)\n",
        "print(y_train_ov.shape)\n",
        "print(X_val.shape)\n",
        "print(y_val.shape)\n",
        "print('Counter train data: ', Counter(np.argmax(y_train_ov, axis=1)))\n",
        "print('Counter val data: ', Counter(np.argmax(y_val, axis=1)))"
      ],
      "metadata": {
        "id": "zF-01XxCTW32",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d5c27d55-449d-47d9-c480-08aae556304e"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(7980, 224, 224, 3)\n",
            "(7980, 7)\n",
            "(193, 224, 224, 3)\n",
            "(193, 7)\n",
            "Counter train data:  Counter({0: 1140, 1: 1140, 2: 1140, 3: 1140, 4: 1140, 6: 1140, 5: 1140})\n",
            "Counter val data:  Counter({5: 123, 2: 22, 4: 21, 1: 15, 0: 8, 6: 3, 3: 1})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5v7sLC2svMuJ"
      },
      "source": [
        "# Main"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qge6cnxQPnH6",
        "outputId": "c147c81b-75fa-4bc6-811e-667771a72057"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(7980, 224, 224, 3)\n",
            "(7980, 7)\n",
            "(193, 224, 224, 3)\n",
            "(193, 7)\n",
            "Counter train data:  Counter({0: 1140, 1: 1140, 2: 1140, 3: 1140, 4: 1140, 6: 1140, 5: 1140})\n",
            "Counter val data:  Counter({5: 123, 2: 22, 4: 21, 1: 15, 0: 8, 6: 3, 3: 1})\n"
          ]
        }
      ],
      "source": [
        "path = '/content/drive/MyDrive/PHD/Datasets/isic2018/'\n",
        "df1 = pd.read_pickle(path+\"isic2018_train_bov.pkl\")\n",
        "X_train = df1.loc[:, df1.columns != 'y_train'].to_numpy()\n",
        "X_train = X_train.reshape(-1,224,224,3)\n",
        "y_train = df1.loc[:, df1.columns == 'y_train'].to_numpy()\n",
        "y_train = to_categorical(y_train)\n",
        "\n",
        "df1 = pd.read_pickle(path+\"isic2018_val.pkl\")\n",
        "X_val = df1.loc[:, df1.columns != 'y_val'].to_numpy()\n",
        "X_val = X_val.reshape(-1,224,224,3)\n",
        "y_val = df1.loc[:, df1.columns == 'y_val'].to_numpy()\n",
        "y_val = to_categorical(y_val)\n",
        "\n",
        "print(X_train.shape)\n",
        "print(y_train.shape)\n",
        "print(X_val.shape)\n",
        "print(y_val.shape)\n",
        "print('Counter train data: ', Counter(np.argmax(y_train, axis=1)))\n",
        "print('Counter val data: ', Counter(np.argmax(y_val, axis=1)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xArGWuciBt_-",
        "outputId": "a2a8c7f4-f5a1-4af5-9a64-b272685ea624"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(14077, 32, 32, 3)\n",
            "(14077, 7)\n",
            "(193, 32, 32, 3)\n",
            "(193, 7)\n",
            "Counter train data:  Counter({5: 2011, 4: 2011, 2: 2011, 3: 2011, 0: 2011, 1: 2011, 6: 2011})\n",
            "Counter val data:  Counter({5: 123, 2: 22, 4: 21, 1: 15, 0: 8, 6: 3, 3: 1})\n"
          ]
        }
      ],
      "source": [
        "#X_train, y_train = SMOTE_Data(X_train, y_train, True)\n",
        "X_train, y_train = Borderline_SMOTE(X_train, y_train)\n",
        "print(X_train.shape)\n",
        "print(y_train.shape)\n",
        "print(X_val.shape)\n",
        "print(y_val.shape)\n",
        "print('Counter train data: ', Counter(np.argmax(y_train, axis=1)))\n",
        "print('Counter val data: ', Counter(np.argmax(y_val, axis=1)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "V7Z_nccu6QjB"
      },
      "outputs": [],
      "source": [
        "#path = '/content/drive/MyDrive/PHD/Datasets/isic2018/'\n",
        "#df1 = pd.DataFrame(X_train_ov.reshape(X_train_ov.shape[0],-1))\n",
        "#df1['y_train'] = np.argmax(y_train_ov, axis=1).tolist()\n",
        "#df2 = pd.DataFrame(X_val.reshape(X_val.shape[0],-1))\n",
        "#df2['y_val'] = np.argmax(y_val, axis=1).tolist()\n",
        "#df1.to_pickle(path+\"isic2018_train_bov.pkl\")\n",
        "#df2.to_pickle(path+\"isic2018_val.pkl\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nAMBgWqIsAAB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aae3bd98-457d-41fb-a6d5-4cd90f9c5bbc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(5321, 32, 32, 3)\n",
            "(5321, 7)\n",
            "(193, 32, 32, 3)\n",
            "(193, 7)\n",
            "Counter train data:  Counter({5: 2011, 4: 1113, 2: 1099, 1: 514, 0: 327, 6: 142, 3: 115})\n",
            "Counter val data:  Counter({5: 123, 2: 22, 4: 21, 1: 15, 0: 8, 6: 3, 3: 1})\n"
          ]
        }
      ],
      "source": [
        "print(X_train.shape)\n",
        "print(y_train.shape)\n",
        "print(X_val.shape)\n",
        "print(y_val.shape)\n",
        "print('Counter train data: ', Counter(np.argmax(y_train, axis=1)))\n",
        "print('Counter val data: ', Counter(np.argmax(y_val, axis=1)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "vIygrW81Ln4z",
        "outputId": "10da357c-d314-4c6e-a1c3-fec56e16b694"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "124/124 [==============================] - ETA: 0s - loss: 1.6403 - accuracy: 0.3412 - balanced_acc: 0.3432\n",
            "Epoch 1: val_balanced_acc improved from -inf to 0.16644, saving model to /content/drive/MyDrive/PHD/Model/best_model_attention.h5\n",
            "124/124 [==============================] - 36s 202ms/step - loss: 1.6403 - accuracy: 0.3412 - balanced_acc: 0.3432 - val_loss: 1.3643 - val_accuracy: 0.5855 - val_balanced_acc: 0.1664 - lr: 0.0010\n",
            "Epoch 2/100\n",
            "124/124 [==============================] - ETA: 0s - loss: 1.4270 - accuracy: 0.4587 - balanced_acc: 0.4579\n",
            "Epoch 2: val_balanced_acc did not improve from 0.16644\n",
            "124/124 [==============================] - 23s 182ms/step - loss: 1.4270 - accuracy: 0.4587 - balanced_acc: 0.4579 - val_loss: 1.3009 - val_accuracy: 0.5855 - val_balanced_acc: 0.1488 - lr: 0.0010\n",
            "Epoch 3/100\n",
            "124/124 [==============================] - ETA: 0s - loss: 1.3306 - accuracy: 0.4986 - balanced_acc: 0.4995\n",
            "Epoch 3: val_balanced_acc improved from 0.16644 to 0.16848, saving model to /content/drive/MyDrive/PHD/Model/best_model_attention.h5\n",
            "124/124 [==============================] - 24s 194ms/step - loss: 1.3306 - accuracy: 0.4986 - balanced_acc: 0.4995 - val_loss: 1.2368 - val_accuracy: 0.6166 - val_balanced_acc: 0.1685 - lr: 0.0010\n",
            "Epoch 4/100\n",
            "124/124 [==============================] - ETA: 0s - loss: 1.2648 - accuracy: 0.5251 - balanced_acc: 0.5267\n",
            "Epoch 4: val_balanced_acc improved from 0.16848 to 0.18998, saving model to /content/drive/MyDrive/PHD/Model/best_model_attention.h5\n",
            "124/124 [==============================] - 25s 199ms/step - loss: 1.2648 - accuracy: 0.5251 - balanced_acc: 0.5267 - val_loss: 1.2376 - val_accuracy: 0.6062 - val_balanced_acc: 0.1900 - lr: 0.0010\n",
            "Epoch 5/100\n",
            "124/124 [==============================] - ETA: 0s - loss: 1.2143 - accuracy: 0.5421 - balanced_acc: 0.5437\n",
            "Epoch 5: val_balanced_acc improved from 0.18998 to 0.20903, saving model to /content/drive/MyDrive/PHD/Model/best_model_attention.h5\n",
            "124/124 [==============================] - 25s 203ms/step - loss: 1.2143 - accuracy: 0.5421 - balanced_acc: 0.5437 - val_loss: 1.2222 - val_accuracy: 0.6269 - val_balanced_acc: 0.2090 - lr: 0.0010\n",
            "Epoch 6/100\n",
            "124/124 [==============================] - ETA: 0s - loss: 1.1750 - accuracy: 0.5600 - balanced_acc: 0.5595\n",
            "Epoch 6: val_balanced_acc improved from 0.20903 to 0.21078, saving model to /content/drive/MyDrive/PHD/Model/best_model_attention.h5\n",
            "124/124 [==============================] - 25s 200ms/step - loss: 1.1750 - accuracy: 0.5600 - balanced_acc: 0.5595 - val_loss: 1.1944 - val_accuracy: 0.6321 - val_balanced_acc: 0.2108 - lr: 0.0010\n",
            "Epoch 7/100\n",
            "124/124 [==============================] - ETA: 0s - loss: 1.1450 - accuracy: 0.5672 - balanced_acc: 0.5687\n",
            "Epoch 7: val_balanced_acc improved from 0.21078 to 0.22149, saving model to /content/drive/MyDrive/PHD/Model/best_model_attention.h5\n",
            "124/124 [==============================] - 25s 198ms/step - loss: 1.1450 - accuracy: 0.5672 - balanced_acc: 0.5687 - val_loss: 1.1641 - val_accuracy: 0.6269 - val_balanced_acc: 0.2215 - lr: 0.0010\n",
            "Epoch 8/100\n",
            "124/124 [==============================] - ETA: 0s - loss: 1.1134 - accuracy: 0.5800 - balanced_acc: 0.5775\n",
            "Epoch 8: val_balanced_acc improved from 0.22149 to 0.23671, saving model to /content/drive/MyDrive/PHD/Model/best_model_attention.h5\n",
            "124/124 [==============================] - 25s 201ms/step - loss: 1.1134 - accuracy: 0.5800 - balanced_acc: 0.5775 - val_loss: 1.2002 - val_accuracy: 0.6373 - val_balanced_acc: 0.2367 - lr: 0.0010\n",
            "Epoch 9/100\n",
            "124/124 [==============================] - ETA: 0s - loss: 1.0926 - accuracy: 0.5940 - balanced_acc: 0.5902\n",
            "Epoch 9: val_balanced_acc did not improve from 0.23671\n",
            "124/124 [==============================] - 23s 189ms/step - loss: 1.0926 - accuracy: 0.5940 - balanced_acc: 0.5902 - val_loss: 1.1853 - val_accuracy: 0.6269 - val_balanced_acc: 0.2200 - lr: 0.0010\n",
            "Epoch 10/100\n",
            "124/124 [==============================] - ETA: 0s - loss: 1.0746 - accuracy: 0.5970 - balanced_acc: 0.5990\n",
            "Epoch 10: val_balanced_acc did not improve from 0.23671\n",
            "124/124 [==============================] - 23s 189ms/step - loss: 1.0746 - accuracy: 0.5970 - balanced_acc: 0.5990 - val_loss: 1.1818 - val_accuracy: 0.6269 - val_balanced_acc: 0.2288 - lr: 0.0010\n",
            "Epoch 11/100\n",
            "124/124 [==============================] - ETA: 0s - loss: 1.0548 - accuracy: 0.6100 - balanced_acc: 0.6121\n",
            "Epoch 11: val_balanced_acc did not improve from 0.23671\n",
            "124/124 [==============================] - 23s 188ms/step - loss: 1.0548 - accuracy: 0.6100 - balanced_acc: 0.6121 - val_loss: 1.2066 - val_accuracy: 0.6114 - val_balanced_acc: 0.2227 - lr: 0.0010\n",
            "Epoch 12/100\n",
            "124/124 [==============================] - ETA: 0s - loss: 1.0315 - accuracy: 0.6103 - balanced_acc: 0.6096\n",
            "Epoch 12: val_balanced_acc improved from 0.23671 to 0.24042, saving model to /content/drive/MyDrive/PHD/Model/best_model_attention.h5\n",
            "124/124 [==============================] - 25s 199ms/step - loss: 1.0315 - accuracy: 0.6103 - balanced_acc: 0.6096 - val_loss: 1.2014 - val_accuracy: 0.6269 - val_balanced_acc: 0.2404 - lr: 0.0010\n",
            "Epoch 13/100\n",
            "124/124 [==============================] - ETA: 0s - loss: 1.0211 - accuracy: 0.6217 - balanced_acc: 0.6250\n",
            "Epoch 13: val_balanced_acc did not improve from 0.24042\n",
            "124/124 [==============================] - 23s 188ms/step - loss: 1.0211 - accuracy: 0.6217 - balanced_acc: 0.6250 - val_loss: 1.2487 - val_accuracy: 0.6114 - val_balanced_acc: 0.2296 - lr: 0.0010\n",
            "Epoch 14/100\n",
            "124/124 [==============================] - ETA: 0s - loss: 1.0072 - accuracy: 0.6291 - balanced_acc: 0.6275\n",
            "Epoch 14: val_balanced_acc improved from 0.24042 to 0.24663, saving model to /content/drive/MyDrive/PHD/Model/best_model_attention.h5\n",
            "124/124 [==============================] - 25s 200ms/step - loss: 1.0072 - accuracy: 0.6291 - balanced_acc: 0.6275 - val_loss: 1.2101 - val_accuracy: 0.6321 - val_balanced_acc: 0.2466 - lr: 0.0010\n",
            "Epoch 15/100\n",
            "124/124 [==============================] - ETA: 0s - loss: 0.9821 - accuracy: 0.6364 - balanced_acc: 0.6391\n",
            "Epoch 15: val_balanced_acc did not improve from 0.24663\n",
            "124/124 [==============================] - 23s 189ms/step - loss: 0.9821 - accuracy: 0.6364 - balanced_acc: 0.6391 - val_loss: 1.1860 - val_accuracy: 0.6321 - val_balanced_acc: 0.2466 - lr: 0.0010\n",
            "Epoch 16/100\n",
            "124/124 [==============================] - ETA: 0s - loss: 0.9819 - accuracy: 0.6339 - balanced_acc: 0.6336\n",
            "Epoch 16: val_balanced_acc improved from 0.24663 to 0.24937, saving model to /content/drive/MyDrive/PHD/Model/best_model_attention.h5\n",
            "124/124 [==============================] - 25s 200ms/step - loss: 0.9819 - accuracy: 0.6339 - balanced_acc: 0.6336 - val_loss: 1.2156 - val_accuracy: 0.6321 - val_balanced_acc: 0.2494 - lr: 0.0010\n",
            "Epoch 17/100\n",
            "124/124 [==============================] - ETA: 0s - loss: 0.9588 - accuracy: 0.6482 - balanced_acc: 0.6466\n",
            "Epoch 17: val_balanced_acc did not improve from 0.24937\n",
            "124/124 [==============================] - 23s 189ms/step - loss: 0.9588 - accuracy: 0.6482 - balanced_acc: 0.6466 - val_loss: 1.2574 - val_accuracy: 0.6010 - val_balanced_acc: 0.2404 - lr: 0.0010\n",
            "Epoch 18/100\n",
            "124/124 [==============================] - ETA: 0s - loss: 0.9505 - accuracy: 0.6472 - balanced_acc: 0.6443\n",
            "Epoch 18: val_balanced_acc did not improve from 0.24937\n",
            "124/124 [==============================] - 23s 189ms/step - loss: 0.9505 - accuracy: 0.6472 - balanced_acc: 0.6443 - val_loss: 1.2899 - val_accuracy: 0.5959 - val_balanced_acc: 0.2396 - lr: 0.0010\n",
            "Epoch 19/100\n",
            "124/124 [==============================] - ETA: 0s - loss: 0.9340 - accuracy: 0.6563 - balanced_acc: 0.6591\n",
            "Epoch 19: val_balanced_acc improved from 0.24937 to 0.25023, saving model to /content/drive/MyDrive/PHD/Model/best_model_attention.h5\n",
            "124/124 [==============================] - 25s 199ms/step - loss: 0.9340 - accuracy: 0.6563 - balanced_acc: 0.6591 - val_loss: 1.2433 - val_accuracy: 0.6218 - val_balanced_acc: 0.2502 - lr: 0.0010\n",
            "Epoch 20/100\n",
            "124/124 [==============================] - ETA: 0s - loss: 0.9339 - accuracy: 0.6564 - balanced_acc: 0.6573\n",
            "Epoch 20: val_balanced_acc improved from 0.25023 to 0.25186, saving model to /content/drive/MyDrive/PHD/Model/best_model_attention.h5\n",
            "124/124 [==============================] - 25s 198ms/step - loss: 0.9339 - accuracy: 0.6564 - balanced_acc: 0.6573 - val_loss: 1.2750 - val_accuracy: 0.6062 - val_balanced_acc: 0.2519 - lr: 0.0010\n",
            "Epoch 21/100\n",
            "124/124 [==============================] - ETA: 0s - loss: 0.9192 - accuracy: 0.6641 - balanced_acc: 0.6654\n",
            "Epoch 21: val_balanced_acc did not improve from 0.25186\n",
            "124/124 [==============================] - 23s 189ms/step - loss: 0.9192 - accuracy: 0.6641 - balanced_acc: 0.6654 - val_loss: 1.2702 - val_accuracy: 0.5959 - val_balanced_acc: 0.2438 - lr: 0.0010\n",
            "Epoch 22/100\n",
            "124/124 [==============================] - ETA: 0s - loss: 0.9042 - accuracy: 0.6698 - balanced_acc: 0.6710\n",
            "Epoch 22: val_balanced_acc did not improve from 0.25186\n",
            "124/124 [==============================] - 24s 190ms/step - loss: 0.9042 - accuracy: 0.6698 - balanced_acc: 0.6710 - val_loss: 1.3161 - val_accuracy: 0.5855 - val_balanced_acc: 0.2422 - lr: 0.0010\n",
            "Epoch 23/100\n",
            "124/124 [==============================] - ETA: 0s - loss: 0.9030 - accuracy: 0.6700 - balanced_acc: 0.6683\n",
            "Epoch 23: val_balanced_acc did not improve from 0.25186\n",
            "124/124 [==============================] - 23s 189ms/step - loss: 0.9030 - accuracy: 0.6700 - balanced_acc: 0.6683 - val_loss: 1.3445 - val_accuracy: 0.5803 - val_balanced_acc: 0.2413 - lr: 0.0010\n",
            "Epoch 24/100\n",
            "124/124 [==============================] - ETA: 0s - loss: 0.8835 - accuracy: 0.6852 - balanced_acc: 0.6836\n",
            "Epoch 24: val_balanced_acc did not improve from 0.25186\n",
            "124/124 [==============================] - 23s 189ms/step - loss: 0.8835 - accuracy: 0.6852 - balanced_acc: 0.6836 - val_loss: 1.3576 - val_accuracy: 0.5803 - val_balanced_acc: 0.2413 - lr: 0.0010\n",
            "Epoch 25/100\n",
            "124/124 [==============================] - ETA: 0s - loss: 0.8834 - accuracy: 0.6862 - balanced_acc: 0.6836\n",
            "Epoch 25: val_balanced_acc did not improve from 0.25186\n",
            "124/124 [==============================] - 23s 189ms/step - loss: 0.8834 - accuracy: 0.6862 - balanced_acc: 0.6836 - val_loss: 1.3425 - val_accuracy: 0.5855 - val_balanced_acc: 0.2458 - lr: 0.0010\n",
            "Epoch 26/100\n",
            "124/124 [==============================] - ETA: 0s - loss: 0.8695 - accuracy: 0.6868 - balanced_acc: 0.6869\n",
            "Epoch 26: val_balanced_acc did not improve from 0.25186\n",
            "124/124 [==============================] - 23s 188ms/step - loss: 0.8695 - accuracy: 0.6868 - balanced_acc: 0.6869 - val_loss: 1.3724 - val_accuracy: 0.5855 - val_balanced_acc: 0.2449 - lr: 0.0010\n",
            "Epoch 27/100\n",
            "124/124 [==============================] - ETA: 0s - loss: 0.8617 - accuracy: 0.6851 - balanced_acc: 0.6842\n",
            "Epoch 27: val_balanced_acc improved from 0.25186 to 0.25567, saving model to /content/drive/MyDrive/PHD/Model/best_model_attention.h5\n",
            "124/124 [==============================] - 26s 208ms/step - loss: 0.8617 - accuracy: 0.6851 - balanced_acc: 0.6842 - val_loss: 1.3417 - val_accuracy: 0.6166 - val_balanced_acc: 0.2557 - lr: 0.0010\n",
            "Epoch 28/100\n",
            "124/124 [==============================] - ETA: 0s - loss: 0.8466 - accuracy: 0.6891 - balanced_acc: 0.6901\n",
            "Epoch 28: val_balanced_acc improved from 0.25567 to 0.25853, saving model to /content/drive/MyDrive/PHD/Model/best_model_attention.h5\n",
            "124/124 [==============================] - 25s 204ms/step - loss: 0.8466 - accuracy: 0.6891 - balanced_acc: 0.6901 - val_loss: 1.3980 - val_accuracy: 0.5855 - val_balanced_acc: 0.2585 - lr: 0.0010\n",
            "Epoch 29/100\n",
            "124/124 [==============================] - ETA: 0s - loss: 0.8605 - accuracy: 0.6899 - balanced_acc: 0.6929\n",
            "Epoch 29: val_balanced_acc did not improve from 0.25853\n",
            "124/124 [==============================] - 23s 189ms/step - loss: 0.8605 - accuracy: 0.6899 - balanced_acc: 0.6929 - val_loss: 1.4192 - val_accuracy: 0.5699 - val_balanced_acc: 0.2517 - lr: 0.0010\n",
            "Epoch 30/100\n",
            "124/124 [==============================] - ETA: 0s - loss: 0.8365 - accuracy: 0.7022 - balanced_acc: 0.7021\n",
            "Epoch 30: val_balanced_acc did not improve from 0.25853\n",
            "124/124 [==============================] - 23s 189ms/step - loss: 0.8365 - accuracy: 0.7022 - balanced_acc: 0.7021 - val_loss: 1.4614 - val_accuracy: 0.5544 - val_balanced_acc: 0.2507 - lr: 0.0010\n",
            "Epoch 31/100\n",
            "124/124 [==============================] - ETA: 0s - loss: 0.8325 - accuracy: 0.7024 - balanced_acc: 0.6977\n",
            "Epoch 31: val_balanced_acc did not improve from 0.25853\n",
            "124/124 [==============================] - 23s 189ms/step - loss: 0.8325 - accuracy: 0.7024 - balanced_acc: 0.6977 - val_loss: 1.3708 - val_accuracy: 0.6062 - val_balanced_acc: 0.2449 - lr: 0.0010\n",
            "Epoch 32/100\n",
            "124/124 [==============================] - ETA: 0s - loss: 0.8206 - accuracy: 0.7033 - balanced_acc: 0.7026\n",
            "Epoch 32: val_balanced_acc did not improve from 0.25853\n",
            "124/124 [==============================] - 23s 189ms/step - loss: 0.8206 - accuracy: 0.7033 - balanced_acc: 0.7026 - val_loss: 1.3710 - val_accuracy: 0.6166 - val_balanced_acc: 0.2529 - lr: 0.0010\n",
            "Epoch 33/100\n",
            "124/124 [==============================] - ETA: 0s - loss: 0.8142 - accuracy: 0.7082 - balanced_acc: 0.7073\n",
            "Epoch 33: val_balanced_acc did not improve from 0.25853\n",
            "124/124 [==============================] - 23s 189ms/step - loss: 0.8142 - accuracy: 0.7082 - balanced_acc: 0.7073 - val_loss: 1.4389 - val_accuracy: 0.5648 - val_balanced_acc: 0.2339 - lr: 0.0010\n",
            "Epoch 34/100\n",
            "124/124 [==============================] - ETA: 0s - loss: 0.8012 - accuracy: 0.7141 - balanced_acc: 0.7105\n",
            "Epoch 34: val_balanced_acc did not improve from 0.25853\n",
            "124/124 [==============================] - 23s 189ms/step - loss: 0.8012 - accuracy: 0.7141 - balanced_acc: 0.7105 - val_loss: 1.4550 - val_accuracy: 0.5699 - val_balanced_acc: 0.2490 - lr: 0.0010\n",
            "Epoch 35/100\n",
            "124/124 [==============================] - ETA: 0s - loss: 0.8075 - accuracy: 0.7160 - balanced_acc: 0.7152\n",
            "Epoch 35: val_balanced_acc did not improve from 0.25853\n",
            "124/124 [==============================] - 23s 189ms/step - loss: 0.8075 - accuracy: 0.7160 - balanced_acc: 0.7152 - val_loss: 1.4928 - val_accuracy: 0.5389 - val_balanced_acc: 0.2444 - lr: 0.0010\n",
            "Epoch 36/100\n",
            "124/124 [==============================] - ETA: 0s - loss: 0.8009 - accuracy: 0.7172 - balanced_acc: 0.7204\n",
            "Epoch 36: val_balanced_acc did not improve from 0.25853\n",
            "124/124 [==============================] - 23s 189ms/step - loss: 0.8009 - accuracy: 0.7172 - balanced_acc: 0.7204 - val_loss: 1.4606 - val_accuracy: 0.5751 - val_balanced_acc: 0.2356 - lr: 0.0010\n",
            "Epoch 37/100\n",
            "124/124 [==============================] - ETA: 0s - loss: 0.7911 - accuracy: 0.7161 - balanced_acc: 0.7185\n",
            "Epoch 37: val_balanced_acc did not improve from 0.25853\n",
            "124/124 [==============================] - 23s 189ms/step - loss: 0.7911 - accuracy: 0.7161 - balanced_acc: 0.7185 - val_loss: 1.4678 - val_accuracy: 0.5751 - val_balanced_acc: 0.2356 - lr: 0.0010\n",
            "Epoch 38/100\n",
            "124/124 [==============================] - ETA: 0s - loss: 0.7821 - accuracy: 0.7231 - balanced_acc: 0.7227\n",
            "Epoch 38: val_balanced_acc did not improve from 0.25853\n",
            "124/124 [==============================] - 23s 189ms/step - loss: 0.7821 - accuracy: 0.7231 - balanced_acc: 0.7227 - val_loss: 1.5058 - val_accuracy: 0.5492 - val_balanced_acc: 0.2312 - lr: 0.0010\n",
            "Epoch 39/100\n",
            "124/124 [==============================] - ETA: 0s - loss: 0.7756 - accuracy: 0.7254 - balanced_acc: 0.7262\n",
            "Epoch 39: val_balanced_acc did not improve from 0.25853\n",
            "124/124 [==============================] - 23s 189ms/step - loss: 0.7756 - accuracy: 0.7254 - balanced_acc: 0.7262 - val_loss: 1.5340 - val_accuracy: 0.5233 - val_balanced_acc: 0.2187 - lr: 0.0010\n",
            "Epoch 40/100\n",
            "124/124 [==============================] - ETA: 0s - loss: 0.7679 - accuracy: 0.7308 - balanced_acc: 0.7316\n",
            "Epoch 40: val_balanced_acc did not improve from 0.25853\n",
            "124/124 [==============================] - 23s 189ms/step - loss: 0.7679 - accuracy: 0.7308 - balanced_acc: 0.7316 - val_loss: 1.5550 - val_accuracy: 0.5233 - val_balanced_acc: 0.2213 - lr: 0.0010\n",
            "Epoch 41/100\n",
            "124/124 [==============================] - ETA: 0s - loss: 0.7692 - accuracy: 0.7276 - balanced_acc: 0.7285\n",
            "Epoch 41: val_balanced_acc did not improve from 0.25853\n",
            "124/124 [==============================] - 23s 189ms/step - loss: 0.7692 - accuracy: 0.7276 - balanced_acc: 0.7285 - val_loss: 1.5356 - val_accuracy: 0.5285 - val_balanced_acc: 0.2195 - lr: 0.0010\n",
            "Epoch 42/100\n",
            "124/124 [==============================] - ETA: 0s - loss: 0.7652 - accuracy: 0.7311 - balanced_acc: 0.7303\n",
            "Epoch 42: val_balanced_acc did not improve from 0.25853\n",
            "124/124 [==============================] - 24s 190ms/step - loss: 0.7652 - accuracy: 0.7311 - balanced_acc: 0.7303 - val_loss: 1.5554 - val_accuracy: 0.5285 - val_balanced_acc: 0.2195 - lr: 0.0010\n",
            "Epoch 43/100\n",
            "124/124 [==============================] - ETA: 0s - loss: 0.7517 - accuracy: 0.7371 - balanced_acc: 0.7349\n",
            "Epoch 43: val_balanced_acc did not improve from 0.25853\n",
            "124/124 [==============================] - 23s 190ms/step - loss: 0.7517 - accuracy: 0.7371 - balanced_acc: 0.7349 - val_loss: 1.6000 - val_accuracy: 0.5233 - val_balanced_acc: 0.2186 - lr: 0.0010\n",
            "Epoch 44/100\n",
            "124/124 [==============================] - ETA: 0s - loss: 0.7377 - accuracy: 0.7472 - balanced_acc: 0.7503\n",
            "Epoch 44: val_balanced_acc did not improve from 0.25853\n",
            "124/124 [==============================] - 23s 189ms/step - loss: 0.7377 - accuracy: 0.7472 - balanced_acc: 0.7503 - val_loss: 1.6002 - val_accuracy: 0.5181 - val_balanced_acc: 0.2123 - lr: 0.0010\n",
            "Epoch 45/100\n",
            "124/124 [==============================] - ETA: 0s - loss: 0.7506 - accuracy: 0.7336 - balanced_acc: 0.7335\n",
            "Epoch 45: val_balanced_acc did not improve from 0.25853\n",
            "124/124 [==============================] - 23s 189ms/step - loss: 0.7506 - accuracy: 0.7336 - balanced_acc: 0.7335 - val_loss: 1.5590 - val_accuracy: 0.5337 - val_balanced_acc: 0.2176 - lr: 0.0010\n",
            "Epoch 46/100\n",
            "124/124 [==============================] - ETA: 0s - loss: 0.7395 - accuracy: 0.7438 - balanced_acc: 0.7453\n",
            "Epoch 46: val_balanced_acc did not improve from 0.25853\n",
            "124/124 [==============================] - 23s 189ms/step - loss: 0.7395 - accuracy: 0.7438 - balanced_acc: 0.7453 - val_loss: 1.5573 - val_accuracy: 0.5337 - val_balanced_acc: 0.2115 - lr: 0.0010\n",
            "Epoch 47/100\n",
            "124/124 [==============================] - ETA: 0s - loss: 0.7340 - accuracy: 0.7391 - balanced_acc: 0.7382\n",
            "Epoch 47: val_balanced_acc did not improve from 0.25853\n",
            "124/124 [==============================] - 23s 189ms/step - loss: 0.7340 - accuracy: 0.7391 - balanced_acc: 0.7382 - val_loss: 1.6084 - val_accuracy: 0.5285 - val_balanced_acc: 0.2167 - lr: 0.0010\n",
            "Epoch 48/100\n",
            "124/124 [==============================] - ETA: 0s - loss: 0.7227 - accuracy: 0.7486 - balanced_acc: 0.7514\n",
            "Epoch 48: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "\n",
            "Epoch 48: val_balanced_acc did not improve from 0.25853\n",
            "124/124 [==============================] - 23s 189ms/step - loss: 0.7227 - accuracy: 0.7486 - balanced_acc: 0.7514 - val_loss: 1.7079 - val_accuracy: 0.4922 - val_balanced_acc: 0.2106 - lr: 0.0010\n",
            "Epoch 49/100\n",
            "124/124 [==============================] - ETA: 0s - loss: 0.7179 - accuracy: 0.7527 - balanced_acc: 0.7543\n",
            "Epoch 49: val_balanced_acc did not improve from 0.25853\n",
            "124/124 [==============================] - 23s 189ms/step - loss: 0.7179 - accuracy: 0.7527 - balanced_acc: 0.7543 - val_loss: 1.6566 - val_accuracy: 0.5130 - val_balanced_acc: 0.2168 - lr: 5.0000e-04\n",
            "Epoch 50/100\n",
            "124/124 [==============================] - ETA: 0s - loss: 0.7135 - accuracy: 0.7523 - balanced_acc: 0.7485\n",
            "Epoch 50: val_balanced_acc did not improve from 0.25853\n",
            "124/124 [==============================] - 23s 189ms/step - loss: 0.7135 - accuracy: 0.7523 - balanced_acc: 0.7485 - val_loss: 1.6860 - val_accuracy: 0.4922 - val_balanced_acc: 0.2134 - lr: 5.0000e-04\n",
            "Epoch 51/100\n",
            "124/124 [==============================] - ETA: 0s - loss: 0.7088 - accuracy: 0.7562 - balanced_acc: 0.7547\n",
            "Epoch 51: val_balanced_acc did not improve from 0.25853\n",
            "124/124 [==============================] - 24s 190ms/step - loss: 0.7088 - accuracy: 0.7562 - balanced_acc: 0.7547 - val_loss: 1.6887 - val_accuracy: 0.5026 - val_balanced_acc: 0.2159 - lr: 5.0000e-04\n",
            "Epoch 52/100\n",
            "124/124 [==============================] - ETA: 0s - loss: 0.7095 - accuracy: 0.7593 - balanced_acc: 0.7630\n",
            "Epoch 52: val_balanced_acc did not improve from 0.25853\n",
            "124/124 [==============================] - 23s 189ms/step - loss: 0.7095 - accuracy: 0.7593 - balanced_acc: 0.7630 - val_loss: 1.6789 - val_accuracy: 0.5078 - val_balanced_acc: 0.2159 - lr: 5.0000e-04\n",
            "Epoch 53/100\n",
            "124/124 [==============================] - ETA: 0s - loss: 0.6989 - accuracy: 0.7612 - balanced_acc: 0.7629\n",
            "Epoch 53: val_balanced_acc did not improve from 0.25853\n",
            "124/124 [==============================] - 23s 189ms/step - loss: 0.6989 - accuracy: 0.7612 - balanced_acc: 0.7629 - val_loss: 1.6801 - val_accuracy: 0.5078 - val_balanced_acc: 0.2132 - lr: 5.0000e-04\n",
            "Epoch 54/100\n",
            "124/124 [==============================] - ETA: 0s - loss: 0.7104 - accuracy: 0.7514 - balanced_acc: 0.7547\n",
            "Epoch 54: val_balanced_acc did not improve from 0.25853\n",
            "124/124 [==============================] - 23s 189ms/step - loss: 0.7104 - accuracy: 0.7514 - balanced_acc: 0.7547 - val_loss: 1.6320 - val_accuracy: 0.5389 - val_balanced_acc: 0.2257 - lr: 5.0000e-04\n",
            "Epoch 55/100\n",
            "124/124 [==============================] - ETA: 0s - loss: 0.6925 - accuracy: 0.7638 - balanced_acc: 0.7608\n",
            "Epoch 55: val_balanced_acc did not improve from 0.25853\n",
            "124/124 [==============================] - 23s 189ms/step - loss: 0.6925 - accuracy: 0.7638 - balanced_acc: 0.7608 - val_loss: 1.7134 - val_accuracy: 0.4974 - val_balanced_acc: 0.2142 - lr: 5.0000e-04\n",
            "Epoch 56/100\n",
            "124/124 [==============================] - ETA: 0s - loss: 0.6999 - accuracy: 0.7633 - balanced_acc: 0.7643\n",
            "Epoch 56: val_balanced_acc did not improve from 0.25853\n",
            "124/124 [==============================] - 23s 189ms/step - loss: 0.6999 - accuracy: 0.7633 - balanced_acc: 0.7643 - val_loss: 1.7316 - val_accuracy: 0.4922 - val_balanced_acc: 0.2143 - lr: 5.0000e-04\n",
            "Epoch 57/100\n",
            "124/124 [==============================] - ETA: 0s - loss: 0.6928 - accuracy: 0.7668 - balanced_acc: 0.7683\n",
            "Epoch 57: val_balanced_acc did not improve from 0.25853\n",
            "124/124 [==============================] - 24s 190ms/step - loss: 0.6928 - accuracy: 0.7668 - balanced_acc: 0.7683 - val_loss: 1.6916 - val_accuracy: 0.5130 - val_balanced_acc: 0.2176 - lr: 5.0000e-04\n",
            "Epoch 58/100\n",
            "124/124 [==============================] - ETA: 0s - loss: 0.7004 - accuracy: 0.7592 - balanced_acc: 0.7607\n",
            "Epoch 58: val_balanced_acc did not improve from 0.25853\n",
            "124/124 [==============================] - 23s 189ms/step - loss: 0.7004 - accuracy: 0.7592 - balanced_acc: 0.7607 - val_loss: 1.7102 - val_accuracy: 0.5078 - val_balanced_acc: 0.2168 - lr: 5.0000e-04\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "# define model\n",
        "model = define_base_model('resnet50')\n",
        "#model.summary()\n",
        "hst = model.fit(X_train, y_train, epochs=EPOCHS, batch_size=BATCH_SIZE, validation_data=(X_val, y_val), verbose=1,\n",
        "                    steps_per_epoch=X_train.shape[0] // BATCH_SIZE, \n",
        "                    callbacks=[learning_rate_reduction,early_stopping_monitor, mc])\n",
        "# learning curves\n",
        "summarize_diagnostics(hst)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "vXnW3lmCgln3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "9a9d4664-2644-4c88-804b-a9bb06435f2e"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "# summarize history for accuracy\n",
        "plt.plot(hst.history['accuracy'])\n",
        "plt.plot(hst.history['balanced_acc'])\n",
        "plt.plot(hst.history['val_accuracy'])\n",
        "plt.plot(hst.history['val_balanced_acc'])\n",
        "plt.title('Model accuracy')\n",
        "plt.ylabel('Performance')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train accuracy', 'train balanced acc.', 'val. accuracy', 'val. balanced acc.'], loc='lower right')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rwwLiXUSG0IZ"
      },
      "outputs": [],
      "source": [
        "#Training\n",
        "#hst = model.fit(train_data_batches,\n",
        "#                    epochs = EPOCHS, validation_data = valid_data_batches,      \n",
        "                    #steps_per_epoch=X_train.shape[0] // BATCH_SIZE, \n",
        "#                    callbacks=[learning_rate_reduction,early_stopping_monitor, mc])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "icgjmi-4UIT-"
      },
      "source": [
        "#Evaluate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "SPz8NH1Oylv9"
      },
      "outputs": [],
      "source": [
        "#save last model\n",
        "model.save(last_model_fpath)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lS3ewyxO_anU",
        "outputId": "1b0e1e21-f001-49ae-c3b5-b41a27933226"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy on training 0.7631578947368421\n",
            "balanced accuracy on training 0.7631578947368419\n",
            "accuracy on validation 0.5077720207253886\n",
            "balanced accuracy on validation 0.309900900493235\n",
            "Score on val data:  (0.270430369097924, 0.309900900493235, 0.23279044290983722, None)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ],
      "source": [
        "last_model = load_model(last_model_fpath, custom_objects={'balanced_acc' : balanced_acc})\n",
        "y_train_pred = last_model.predict(X_train)\n",
        "y_val_pred = last_model.predict(X_val)\n",
        "\n",
        "#print('accuracy on training',accuracy_score(np.argmax(y_train, axis=1), np.argmax(y_train_pred, axis=1)))\n",
        "print('accuracy on training',accuracy_score(np.argmax(y_train, axis=1), np.argmax(y_train_pred, axis=1)))\n",
        "print('balanced accuracy on training',balanced_accuracy_score(np.argmax(y_train, axis=1), np.argmax(y_train_pred, axis=1)))\n",
        "print('accuracy on validation',accuracy_score(np.argmax(y_val, axis=1), np.argmax(y_val_pred, axis=1)))\n",
        "print('balanced accuracy on validation',balanced_accuracy_score(np.argmax(y_val, axis=1), np.argmax(y_val_pred, axis=1)))\n",
        "print('Score on val data: ',precision_recall_fscore_support(np.argmax(y_val, axis=1), np.argmax(y_val_pred, axis=1), average='macro'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "W3IyWjdGG4Xq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7e6386d8-05b3-497b-de93-729dbc7cef17"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy on training 0.6902255639097744\n",
            "balanced accuracy on training 0.6902255639097746\n",
            "accuracy on validation 0.5854922279792746\n",
            "balanced accuracy on validation 0.38537188711404735\n",
            "Score on val data:  (0.25398450080780455, 0.38537188711404735, 0.25890004763874386, None)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ],
      "source": [
        "best_model = load_model(best_model_fpath, custom_objects={'balanced_acc' : balanced_acc})\n",
        "y_train_pred = best_model.predict(X_train)\n",
        "y_val_pred = best_model.predict(X_val)\n",
        "\n",
        "print('accuracy on training',accuracy_score(np.argmax(y_train, axis=1), np.argmax(y_train_pred, axis=1)))\n",
        "print('balanced accuracy on training',balanced_accuracy_score(np.argmax(y_train, axis=1), np.argmax(y_train_pred, axis=1)))\n",
        "print('accuracy on validation',accuracy_score(np.argmax(y_val, axis=1), np.argmax(y_val_pred, axis=1)))\n",
        "print('balanced accuracy on validation',balanced_accuracy_score(np.argmax(y_val, axis=1), np.argmax(y_val_pred, axis=1)))\n",
        "print('Score on val data: ',precision_recall_fscore_support(np.argmax(y_val, axis=1), np.argmax(y_val_pred, axis=1), average='macro'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iDRWiTnO0MGh"
      },
      "source": [
        "#Cut-off"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tGnCoIdLyDHS"
      },
      "outputs": [],
      "source": [
        "df_val_pred = pd.DataFrame(y_val_pred, columns = ['AKIEC', 'BCC', 'BKL', 'DF', 'MEL', 'NV', 'VASC'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QdyCbloQyWTC"
      },
      "outputs": [],
      "source": [
        "numbers = [float(x)/40 for x in range(11)]\n",
        "for i in numbers:\n",
        "    df_val_pred[i]= df_val_pred.MEL.map(lambda x: 1 if x > i else 0)\n",
        "df_val_pred.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G4SQsRx73kgk"
      },
      "outputs": [],
      "source": [
        "y_val_true= [1 if x == 4 else 0 for x in np.argmax(y_val, axis=1)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QcUISWFi0J05"
      },
      "outputs": [],
      "source": [
        "#num = [0.0,0.05,0.1,0.15,0.2,0.25,0.3,0.35,0.4,0.45,0.5]\n",
        "cutoff_df = pd.DataFrame( columns = ['Probability','Accuracy','Sensitivity','Specificity'])\n",
        "for i in numbers:\n",
        "    cm1 = confusion_matrix(y_val_true, df_val_pred[i])\n",
        "    total1=sum(sum(cm1))\n",
        "    Accuracy = (cm1[0,0]+cm1[1,1])/total1\n",
        "    Specificity = cm1[0,0]/(cm1[0,0]+cm1[0,1])\n",
        "    Sensitivity = cm1[1,1]/(cm1[1,0]+cm1[1,1])\n",
        "    cutoff_df.loc[i] =[ i ,Accuracy,Sensitivity,Specificity]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W31LSzov1tCt"
      },
      "outputs": [],
      "source": [
        "cutoff_df[['Accuracy','Sensitivity','Specificity']].plot()\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P6CIKT94Jqye"
      },
      "outputs": [],
      "source": [
        "i = 0.025\n",
        "cm1 = confusion_matrix(y_val_true, df_val_pred[i])\n",
        "total1=sum(sum(cm1))\n",
        "Accuracy = (cm1[0,0]+cm1[1,1])/total1\n",
        "Specificity = cm1[0,0]/(cm1[0,0]+cm1[0,1])\n",
        "Sensitivity = cm1[1,1]/(cm1[1,0]+cm1[1,1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3U2tkFebL_VC"
      },
      "outputs": [],
      "source": [
        "print('Accuracy: ', Accuracy)\n",
        "print('Sensitivity: ', Sensitivity)\n",
        "print('Specificity: ', Specificity)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eaK4zbtoaAaC"
      },
      "source": [
        "#Confusion Metric on Validation Set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YkPOFLehOmFg"
      },
      "outputs": [],
      "source": [
        "#change melanoma flag back to 4\n",
        "df_val_pred[df_val_pred[i] == 1] = 4\n",
        "#decode one-hot y_val_pred while use cut-off melanoma data\n",
        "condition = df_val_pred[i] == 4\n",
        "y_val_pred2 = np.where(condition, df_val_pred[i], np.argmax(y_val_pred, axis=1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LOVl6dWlTDLo"
      },
      "outputs": [],
      "source": [
        "print('Accuracy: ',accuracy_score(np.argmax(y_val, axis=1), y_val_pred2))\n",
        "print('Balanced accuracy: ',balanced_accuracy_score(np.argmax(y_val, axis=1), y_val_pred2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mqvYutTKRhR_"
      },
      "outputs": [],
      "source": [
        "#Get the confusion matrix\n",
        "cf_matrix = confusion_matrix(np.argmax(y_val, axis=1), y_val_pred2)\n",
        "print(cf_matrix)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gVtvW3YeaLlC"
      },
      "outputs": [],
      "source": [
        "ax = sns.heatmap(cf_matrix / cf_matrix.sum(axis=1, keepdims=True), annot=True, \n",
        "            cmap='Blues')\n",
        "\n",
        "ax.set_title('Confusion Matrix \\n');\n",
        "ax.set_xlabel('\\nPredicted')\n",
        "ax.set_ylabel('Actual ');\n",
        "\n",
        "## Ticket labels - List must be in alphabetical order\n",
        "ax.xaxis.set_ticklabels(['AKIEC', 'BCC', 'BKL', 'DF', 'MEL', 'NV', 'VASC'])\n",
        "ax.yaxis.set_ticklabels(['AKIEC', 'BCC', 'BKL', 'DF', 'MEL', 'NV', 'VASC'])\n",
        "\n",
        "plt.rcParams[\"figure.figsize\"] = (15,3)\n",
        "\n",
        "## Display the visualization of the Confusion Matrix.\n",
        "plt.xticks(rotation=45, ha='right')\n",
        "plt.yticks(rotation=0, ha='right')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ey-1yjWGeKs7"
      },
      "outputs": [],
      "source": [
        "# ordered count of rows per unique label\n",
        "#labels_count = df_val['Labels'].value_counts().sort_index()\n",
        "\n",
        "#f = plt.figure(figsize=(15, 6))\n",
        "#s = sns.barplot(x=labels_count.index,y=labels_count.values)\n",
        "#s.set_xticklabels(s.get_xticklabels(), rotation = 30)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3K908bbiYwbS"
      },
      "source": [
        "#Testing"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_test = pd.read_pickle(path+\"isic2018_test.pkl\")\n",
        "X_train = df_test.loc[:, df_test.columns != 'y_train'].to_numpy()\n",
        "X_train = X_train.reshape(-1,224,224,3)"
      ],
      "metadata": {
        "id": "cN98sOWPyT3P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NeMY2yvMYxsC"
      },
      "outputs": [],
      "source": [
        "#dir_test = '/content/drive/MyDrive/PHD/Datasets/isic2018/ISIC2018_Task3_Test_Input/'\n",
        "#filepaths = sorted( filter( lambda x: (os.path.isfile(os.path.join(dir_test, x))) and (x.endswith('.jpg')),\n",
        "#                        os.listdir(dir_test) ) )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6ic95mefkpG3"
      },
      "outputs": [],
      "source": [
        "#df_test = pd.DataFrame(filepaths, columns =['image'])\n",
        "#df_test['FilePaths'] = dir_test + df_test['image']\n",
        "#df_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NBa1TxPuY8ni"
      },
      "outputs": [],
      "source": [
        "#df_test['image_px'] = df_test['FilePaths'].map(lambda x: np.asarray(Image.open(x).resize(IMG_SIZE)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "60LYAT7VsNOZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "33bd32fe-fac9-4d07-87a9-2cce7336b6dd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1512, 224, 224, 3)\n"
          ]
        }
      ],
      "source": [
        "#X_test = np.asarray(df_test['image_px'].tolist())\n",
        "#print(np.array(X_test).shape)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#df3 = pd.DataFrame(X_test.reshape(X_test.shape[0],-1))\n",
        "#df3.to_pickle(path+\"isic2018_test.pkl\")"
      ],
      "metadata": {
        "id": "JC17MArBxhSW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cXnnIIwC4cHE"
      },
      "outputs": [],
      "source": [
        "#preprocess\n",
        "#X_test = preprocess_image_input(X_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FF7ml90JZ8FK"
      },
      "source": [
        "Calculate y_pred from training and testing for analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KeDTXdaMLmyU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a6ea64da-79f0-424f-f913-5b0bd6c66170"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1512, 2048)"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ],
      "source": [
        "X_test = model1.predict(X_test)\n",
        "X_test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dIX0AmEFNv3Y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3b58601a-b55c-4ef2-b817-f788416ed73c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Y_pred2 (1512, 7)\n"
          ]
        }
      ],
      "source": [
        "# predicting\n",
        "#CHANGE THE MODEL IF NECESSARY\n",
        "Y_test2 = model.predict(X_test)\n",
        "#Y_pred2 = model2.predict(X_test)\n",
        "print(\"Y_pred2\", Y_pred2.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7oeArO5CtxGb"
      },
      "outputs": [],
      "source": [
        "df_pred = pd.DataFrame(Y_pred2, columns = ['AKIEC', 'BCC', 'BKL', 'DF', 'MEL', 'NV', 'VASC'])\n",
        "df_pred['image'] = df_test['FilePaths'].map(lambda x: x.replace(dir_test, '').replace('.jpg', ''))\n",
        "df_pred = df_pred[['image', 'MEL', 'NV', 'BCC', 'AKIEC', 'BKL', 'DF', 'VASC']]\n",
        "df_pred.set_index(\"image\", inplace = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9ynyd8PjT589"
      },
      "outputs": [],
      "source": [
        "#update MEL data using cut-off value\n",
        "df_pred.MEL[df_pred.MEL > i] = 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fjRdONoQVMq0"
      },
      "outputs": [],
      "source": [
        "df_pred.loc[df_pred.MEL > i, ['NV', 'BCC', 'AKIEC', 'BKL', 'DF', 'VASC']] = 0"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_pred.head(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "id": "K4Iv_3s4z0R9",
        "outputId": "a7dca29b-4c36-4693-d619-9bd440e6a18f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                   MEL        NV       BCC     AKIEC       BKL        DF  \\\n",
              "image                                                                      \n",
              "ISIC_0034524  0.002193  0.930769  0.003427  0.000460  0.036592  0.004333   \n",
              "ISIC_0034525  0.122186  0.828252  0.002661  0.010148  0.009148  0.021819   \n",
              "ISIC_0034526  0.020197  0.003637  0.000938  0.028031  0.947131  0.000066   \n",
              "ISIC_0034527  0.131679  0.808747  0.000006  0.000279  0.059272  0.000017   \n",
              "ISIC_0034528  0.005777  0.840918  0.000002  0.000037  0.151937  0.001316   \n",
              "\n",
              "                      VASC  \n",
              "image                       \n",
              "ISIC_0034524  2.222793e-02  \n",
              "ISIC_0034525  5.786379e-03  \n",
              "ISIC_0034526  1.199605e-08  \n",
              "ISIC_0034527  6.856867e-08  \n",
              "ISIC_0034528  1.348875e-05  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5268f553-0d89-461e-9c87-fc1271d7e6d5\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>MEL</th>\n",
              "      <th>NV</th>\n",
              "      <th>BCC</th>\n",
              "      <th>AKIEC</th>\n",
              "      <th>BKL</th>\n",
              "      <th>DF</th>\n",
              "      <th>VASC</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>image</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>ISIC_0034524</th>\n",
              "      <td>0.002193</td>\n",
              "      <td>0.930769</td>\n",
              "      <td>0.003427</td>\n",
              "      <td>0.000460</td>\n",
              "      <td>0.036592</td>\n",
              "      <td>0.004333</td>\n",
              "      <td>2.222793e-02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ISIC_0034525</th>\n",
              "      <td>0.122186</td>\n",
              "      <td>0.828252</td>\n",
              "      <td>0.002661</td>\n",
              "      <td>0.010148</td>\n",
              "      <td>0.009148</td>\n",
              "      <td>0.021819</td>\n",
              "      <td>5.786379e-03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ISIC_0034526</th>\n",
              "      <td>0.020197</td>\n",
              "      <td>0.003637</td>\n",
              "      <td>0.000938</td>\n",
              "      <td>0.028031</td>\n",
              "      <td>0.947131</td>\n",
              "      <td>0.000066</td>\n",
              "      <td>1.199605e-08</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ISIC_0034527</th>\n",
              "      <td>0.131679</td>\n",
              "      <td>0.808747</td>\n",
              "      <td>0.000006</td>\n",
              "      <td>0.000279</td>\n",
              "      <td>0.059272</td>\n",
              "      <td>0.000017</td>\n",
              "      <td>6.856867e-08</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ISIC_0034528</th>\n",
              "      <td>0.005777</td>\n",
              "      <td>0.840918</td>\n",
              "      <td>0.000002</td>\n",
              "      <td>0.000037</td>\n",
              "      <td>0.151937</td>\n",
              "      <td>0.001316</td>\n",
              "      <td>1.348875e-05</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5268f553-0d89-461e-9c87-fc1271d7e6d5')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-5268f553-0d89-461e-9c87-fc1271d7e6d5 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-5268f553-0d89-461e-9c87-fc1271d7e6d5');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sOnjc3RJ0e4T"
      },
      "outputs": [],
      "source": [
        "df_pred.to_csv('/content/drive/MyDrive/PHD/Datasets/isic2018/response_Borderline-SMOTE.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P0MghVs0tsGw"
      },
      "source": [
        "result: 0.656"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UswA0co2y1wl"
      },
      "source": [
        "#Exp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dnqJYIONy34l"
      },
      "outputs": [],
      "source": [
        "input_tensor = Input(shape=(IMAGE_H, IMAGE_W, 3))\n",
        "base_model = ResNet50(input_shape=(224,224,3), weights='imagenet', include_top=False)\n",
        "x = base_model(input_tensor, training=False)\n",
        "x = Attention(2048,2048,7,8)(x)\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "res50 = Model(inputs=input_tensor, outputs=x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kcn8hQg3J8yP"
      },
      "outputs": [],
      "source": [
        "#Train i-last layer\n",
        "# summarize feature map shapes\n",
        "for i in range(len(model.layers)):\n",
        "    layer = model.layers[i]\n",
        "    # summarize output shape\n",
        "    print(i, layer.name, layer.output.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UA7Af2Y73FUv"
      },
      "outputs": [],
      "source": [
        "X_train = res50.predict(X_train)\n",
        "X_val = res50.predict(X_val)\n",
        "print(X_train.shape)\n",
        "print(y_train.shape)\n",
        "print(X_val.shape)\n",
        "print(y_val.shape)\n",
        "print('Counter train data: ', Counter(np.argmax(y_train, axis=1)))\n",
        "print('Counter val data: ', Counter(np.argmax(y_val, axis=1)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "krJiAb1m3QNf"
      },
      "outputs": [],
      "source": [
        "X_train, y_train = SMOTE_Data2(X_train, y_train, True)\n",
        "print(X_train.shape)\n",
        "print(y_train.shape)\n",
        "print(X_val.shape)\n",
        "print(y_val.shape)\n",
        "print('Counter train data: ', Counter(np.argmax(y_train, axis=1)))\n",
        "print('Counter val data: ', Counter(np.argmax(y_val, axis=1)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LfcFpsBwM0d4"
      },
      "source": [
        "#Attention"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C_s6OIGKM26a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 398
        },
        "outputId": "371bd24a-4bf9-491a-e0ec-78b7eb06e6d9"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-ff488085aaa5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mConv2D\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mMaxPooling2D\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mAveragePooling2D\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mBatchNormalization\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mAdd\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mZeroPadding2D\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mFlatten\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mInput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mLeakyReLU\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mSoftmax\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mReLU\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAdam\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    471\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_current_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"keras\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    472\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 473\u001b[0;31m     \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    474\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    475\u001b[0m     \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/lazy_loader.py\u001b[0m in \u001b[0;36m_load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;34m\"\"\"Load the module and insert it into the parent's globals.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0;31m# Import the target module and insert it into the parent's namespace\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m     \u001b[0mmodule\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimportlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimport_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_module_globals\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_local_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/importlib/__init__.py\u001b[0m in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m    125\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m             \u001b[0mlevel\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_bootstrap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gcd_import\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpackage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;31m# See b/110718070#comment18 for more details about this import.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_layer\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mInput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/models.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv2\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmetrics\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmetrics_module\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0moptimizer_v1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfunctional\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/metrics.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mwarnings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mactivations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbase_layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/activations.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0madvanced_activations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgeneric_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdeserialize_keras_object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgeneric_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mserialize_keras_object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/layers/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_spec\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mInputSpec\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_layer\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLayer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_preprocessing_layer\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPreprocessingLayer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;31m# Image preprocessing layers.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/base_preprocessing_layer.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mabc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdata_adapter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_layer\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLayer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mversion_utils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m   \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m  \u001b[0;31m# pylint: disable=g-import-not-at-top\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m   \u001b[0mpd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tester\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 179\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtesting\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    180\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/testing.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m from pandas._testing import (\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0massert_extension_array_equal\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0massert_frame_equal\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/_testing/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    946\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    947\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 948\u001b[0;31m \u001b[0mcython_table\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommon\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cython_table\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    949\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    950\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: module 'pandas' has no attribute 'core'"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow.keras as tk\n",
        "from tensorflow.keras.layers import Conv2D,MaxPooling2D,AveragePooling2D,BatchNormalization,Add,ZeroPadding2D,Flatten,Dense,Input,LeakyReLU,Softmax,ReLU\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.models import Model\n",
        "import numpy as np\n",
        "import pickle\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "\n",
        "class Attention(tk.layers.Layer):\n",
        "    \n",
        "    def __init__(self,input_channels,output_channel,kernel_size,groups):\n",
        "        super().__init__()\n",
        "        self.input_channels = input_channels\n",
        "        self.output_channel = output_channel    \n",
        "        self.kernel_size = kernel_size\n",
        "        self.stride = 1\n",
        "        self.groups = groups\n",
        "\n",
        "        assert output_channel % groups == 0\n",
        "        \n",
        "        self.rel_h = tk.backend.variable(lambda : tk.backend.truncated_normal((1,1,kernel_size,1,output_channel//2),stddev = 0.1)) \n",
        "        #output_channels//2 is the number of channels on which the relative position will be considered,1 denotes the number of those filters and the one after that too and (kernel_size,1) denotes the size of that filter\n",
        "        self.rel_w = tk.backend.variable(lambda : tk.backend.truncated_normal((1,1,1,kernel_size,output_channel//2),stddev = 0.1)) \n",
        "\n",
        "        self.key_weights = Conv2D(self.output_channel,kernel_size = 1,strides = self.stride)\n",
        "        self.query_weights = Conv2D(self.output_channel,kernel_size = 1,strides = self.stride)\n",
        "        self.value_weights = Conv2D(self.output_channel,kernel_size = 1,strides = self.stride)\n",
        "\n",
        "    def call(self,x):\n",
        "        \n",
        "        batch,height,width,channels = x.shape\n",
        "        x_padded = ZeroPadding2D(padding=(self.kernel_size//2,self.kernel_size//2))(x)\n",
        "        query = self.query_weights(x)\n",
        "        value = self.value_weights(x_padded)\n",
        "        key = self.key_weights(x_padded)\n",
        "        #key,query and value will have the shape of (batch,height,width,depth)\n",
        "        keys = tf.image.extract_patches(images = key,sizes = [1,self.kernel_size,self.kernel_size,1],strides = [1,self.stride,self.stride,1],rates = [1,1,1,1], padding = \"VALID\")\n",
        "        value = tf.image.extract_patches(images = value,sizes = [1,self.kernel_size,self.kernel_size,1],strides = [1,self.stride,self.stride,1],rates = [1,1,1,1], padding = \"VALID\")\n",
        "        no_of_kernels = key.shape[-2] - self.kernel_size + 1\n",
        "        keys = tf.reshape(keys,shape = (-1,no_of_kernels, no_of_kernels,self.kernel_size,self.kernel_size,self.output_channel))\n",
        "        key_split_h,key_split_w = tf.split(keys,num_or_size_splits = 2,axis = -1)\n",
        "        key_with_rel = tk.layers.concatenate([key_split_h + self.rel_h,key_split_w + self.rel_w],axis = -1) \n",
        "        \n",
        "        #reshaping the query and key\n",
        "        key_with_rel = tf.reshape(key_with_rel,(-1,self.groups,no_of_kernels,no_of_kernels,self.kernel_size*self.kernel_size,self.output_channel//self.groups))\n",
        "        query  = tf.reshape(query,(-1,self.groups,no_of_kernels,no_of_kernels,1,self.output_channel//self.groups))        \n",
        "        value = tf.reshape(value,(-1,self.groups,no_of_kernels,no_of_kernels,self.kernel_size*self.kernel_size,self.output_channel//self.groups))\n",
        "        \n",
        "        #multiplication  of key and query\n",
        "        #assert key_with_rel.shape == query.shape        \n",
        "        key_prod_query = query*key_with_rel\n",
        "        \n",
        "        # Now the function is passed through the softmax and is multiplied with the values\n",
        "        s = Softmax(axis = -2)(key_prod_query)\n",
        "        y = tf.einsum('bnchwk,bnchwk->bnchk',s,value)\n",
        "        y = tf.reshape(y,(-1,height,width,self.output_channel))\n",
        "        return y\n",
        "\n",
        "    def get_config(self):\n",
        "        config = super().get_config().copy()\n",
        "        config.update({\n",
        "            \"input_channels\": self.input_channels, \n",
        "            \"output_channel\": self.output_channel, \n",
        "            \"kernel_size\": self.kernel_size, \n",
        "            \"stride\": self.stride, \n",
        "            \"groups\": self.groups, \n",
        "            \"rel_h\": self.rel_h, \n",
        "            \"rel_w\": self.rel_w, \n",
        "            \"key_weights\": self.key_weights, \n",
        "            \"query_weights\": self.query_weights, \n",
        "            \"value_weights\": self.value_weights\n",
        "        })\n",
        "        return config\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kE8Ziq-BlEP4"
      },
      "source": [
        "#Oversampling on feature map level"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lm05Zet_B5am",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "81b00112-bfdc-41d4-aa2f-da035d40a9d8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 input_2 [(None, 224, 224, 3)] False\n",
            "1 conv1_pad (None, 230, 230, 3) False\n",
            "2 conv1_conv (None, 112, 112, 64) False\n",
            "3 conv1_bn (None, 112, 112, 64) False\n",
            "4 conv1_relu (None, 112, 112, 64) False\n",
            "5 pool1_pad (None, 114, 114, 64) False\n",
            "6 pool1_pool (None, 56, 56, 64) False\n",
            "7 conv2_block1_1_conv (None, 56, 56, 64) False\n",
            "8 conv2_block1_1_bn (None, 56, 56, 64) False\n",
            "9 conv2_block1_1_relu (None, 56, 56, 64) False\n",
            "10 conv2_block1_2_conv (None, 56, 56, 64) False\n",
            "11 conv2_block1_2_bn (None, 56, 56, 64) False\n",
            "12 conv2_block1_2_relu (None, 56, 56, 64) False\n",
            "13 conv2_block1_0_conv (None, 56, 56, 256) False\n",
            "14 conv2_block1_3_conv (None, 56, 56, 256) False\n",
            "15 conv2_block1_0_bn (None, 56, 56, 256) False\n",
            "16 conv2_block1_3_bn (None, 56, 56, 256) False\n",
            "17 conv2_block1_add (None, 56, 56, 256) False\n",
            "18 conv2_block1_out (None, 56, 56, 256) False\n",
            "19 conv2_block2_1_conv (None, 56, 56, 64) False\n",
            "20 conv2_block2_1_bn (None, 56, 56, 64) False\n",
            "21 conv2_block2_1_relu (None, 56, 56, 64) False\n",
            "22 conv2_block2_2_conv (None, 56, 56, 64) False\n",
            "23 conv2_block2_2_bn (None, 56, 56, 64) False\n",
            "24 conv2_block2_2_relu (None, 56, 56, 64) False\n",
            "25 conv2_block2_3_conv (None, 56, 56, 256) False\n",
            "26 conv2_block2_3_bn (None, 56, 56, 256) False\n",
            "27 conv2_block2_add (None, 56, 56, 256) False\n",
            "28 conv2_block2_out (None, 56, 56, 256) False\n",
            "29 conv2_block3_1_conv (None, 56, 56, 64) False\n",
            "30 conv2_block3_1_bn (None, 56, 56, 64) False\n",
            "31 conv2_block3_1_relu (None, 56, 56, 64) False\n",
            "32 conv2_block3_2_conv (None, 56, 56, 64) False\n",
            "33 conv2_block3_2_bn (None, 56, 56, 64) False\n",
            "34 conv2_block3_2_relu (None, 56, 56, 64) False\n",
            "35 conv2_block3_3_conv (None, 56, 56, 256) False\n",
            "36 conv2_block3_3_bn (None, 56, 56, 256) False\n",
            "37 conv2_block3_add (None, 56, 56, 256) False\n",
            "38 conv2_block3_out (None, 56, 56, 256) False\n",
            "39 conv3_block1_1_conv (None, 28, 28, 128) False\n",
            "40 conv3_block1_1_bn (None, 28, 28, 128) False\n",
            "41 conv3_block1_1_relu (None, 28, 28, 128) False\n",
            "42 conv3_block1_2_conv (None, 28, 28, 128) False\n",
            "43 conv3_block1_2_bn (None, 28, 28, 128) False\n",
            "44 conv3_block1_2_relu (None, 28, 28, 128) False\n",
            "45 conv3_block1_0_conv (None, 28, 28, 512) False\n",
            "46 conv3_block1_3_conv (None, 28, 28, 512) False\n",
            "47 conv3_block1_0_bn (None, 28, 28, 512) False\n",
            "48 conv3_block1_3_bn (None, 28, 28, 512) False\n",
            "49 conv3_block1_add (None, 28, 28, 512) False\n",
            "50 conv3_block1_out (None, 28, 28, 512) False\n",
            "51 conv3_block2_1_conv (None, 28, 28, 128) False\n",
            "52 conv3_block2_1_bn (None, 28, 28, 128) False\n",
            "53 conv3_block2_1_relu (None, 28, 28, 128) False\n",
            "54 conv3_block2_2_conv (None, 28, 28, 128) False\n",
            "55 conv3_block2_2_bn (None, 28, 28, 128) False\n",
            "56 conv3_block2_2_relu (None, 28, 28, 128) False\n",
            "57 conv3_block2_3_conv (None, 28, 28, 512) False\n",
            "58 conv3_block2_3_bn (None, 28, 28, 512) False\n",
            "59 conv3_block2_add (None, 28, 28, 512) False\n",
            "60 conv3_block2_out (None, 28, 28, 512) False\n",
            "61 conv3_block3_1_conv (None, 28, 28, 128) False\n",
            "62 conv3_block3_1_bn (None, 28, 28, 128) False\n",
            "63 conv3_block3_1_relu (None, 28, 28, 128) False\n",
            "64 conv3_block3_2_conv (None, 28, 28, 128) False\n",
            "65 conv3_block3_2_bn (None, 28, 28, 128) False\n",
            "66 conv3_block3_2_relu (None, 28, 28, 128) False\n",
            "67 conv3_block3_3_conv (None, 28, 28, 512) False\n",
            "68 conv3_block3_3_bn (None, 28, 28, 512) False\n",
            "69 conv3_block3_add (None, 28, 28, 512) False\n",
            "70 conv3_block3_out (None, 28, 28, 512) False\n",
            "71 conv3_block4_1_conv (None, 28, 28, 128) False\n",
            "72 conv3_block4_1_bn (None, 28, 28, 128) False\n",
            "73 conv3_block4_1_relu (None, 28, 28, 128) False\n",
            "74 conv3_block4_2_conv (None, 28, 28, 128) False\n",
            "75 conv3_block4_2_bn (None, 28, 28, 128) False\n",
            "76 conv3_block4_2_relu (None, 28, 28, 128) False\n",
            "77 conv3_block4_3_conv (None, 28, 28, 512) False\n",
            "78 conv3_block4_3_bn (None, 28, 28, 512) False\n",
            "79 conv3_block4_add (None, 28, 28, 512) False\n",
            "80 conv3_block4_out (None, 28, 28, 512) False\n",
            "81 conv4_block1_1_conv (None, 14, 14, 256) False\n",
            "82 conv4_block1_1_bn (None, 14, 14, 256) False\n",
            "83 conv4_block1_1_relu (None, 14, 14, 256) False\n",
            "84 conv4_block1_2_conv (None, 14, 14, 256) False\n",
            "85 conv4_block1_2_bn (None, 14, 14, 256) False\n",
            "86 conv4_block1_2_relu (None, 14, 14, 256) False\n",
            "87 conv4_block1_0_conv (None, 14, 14, 1024) False\n",
            "88 conv4_block1_3_conv (None, 14, 14, 1024) False\n",
            "89 conv4_block1_0_bn (None, 14, 14, 1024) False\n",
            "90 conv4_block1_3_bn (None, 14, 14, 1024) False\n",
            "91 conv4_block1_add (None, 14, 14, 1024) False\n",
            "92 conv4_block1_out (None, 14, 14, 1024) False\n",
            "93 conv4_block2_1_conv (None, 14, 14, 256) False\n",
            "94 conv4_block2_1_bn (None, 14, 14, 256) False\n",
            "95 conv4_block2_1_relu (None, 14, 14, 256) False\n",
            "96 conv4_block2_2_conv (None, 14, 14, 256) False\n",
            "97 conv4_block2_2_bn (None, 14, 14, 256) False\n",
            "98 conv4_block2_2_relu (None, 14, 14, 256) False\n",
            "99 conv4_block2_3_conv (None, 14, 14, 1024) False\n",
            "100 conv4_block2_3_bn (None, 14, 14, 1024) False\n",
            "101 conv4_block2_add (None, 14, 14, 1024) False\n",
            "102 conv4_block2_out (None, 14, 14, 1024) False\n",
            "103 conv4_block3_1_conv (None, 14, 14, 256) False\n",
            "104 conv4_block3_1_bn (None, 14, 14, 256) False\n",
            "105 conv4_block3_1_relu (None, 14, 14, 256) False\n",
            "106 conv4_block3_2_conv (None, 14, 14, 256) False\n",
            "107 conv4_block3_2_bn (None, 14, 14, 256) False\n",
            "108 conv4_block3_2_relu (None, 14, 14, 256) False\n",
            "109 conv4_block3_3_conv (None, 14, 14, 1024) False\n",
            "110 conv4_block3_3_bn (None, 14, 14, 1024) False\n",
            "111 conv4_block3_add (None, 14, 14, 1024) False\n",
            "112 conv4_block3_out (None, 14, 14, 1024) False\n",
            "113 conv4_block4_1_conv (None, 14, 14, 256) False\n",
            "114 conv4_block4_1_bn (None, 14, 14, 256) False\n",
            "115 conv4_block4_1_relu (None, 14, 14, 256) False\n",
            "116 conv4_block4_2_conv (None, 14, 14, 256) False\n",
            "117 conv4_block4_2_bn (None, 14, 14, 256) False\n",
            "118 conv4_block4_2_relu (None, 14, 14, 256) False\n",
            "119 conv4_block4_3_conv (None, 14, 14, 1024) False\n",
            "120 conv4_block4_3_bn (None, 14, 14, 1024) False\n",
            "121 conv4_block4_add (None, 14, 14, 1024) False\n",
            "122 conv4_block4_out (None, 14, 14, 1024) False\n",
            "123 conv4_block5_1_conv (None, 14, 14, 256) False\n",
            "124 conv4_block5_1_bn (None, 14, 14, 256) False\n",
            "125 conv4_block5_1_relu (None, 14, 14, 256) False\n",
            "126 conv4_block5_2_conv (None, 14, 14, 256) False\n",
            "127 conv4_block5_2_bn (None, 14, 14, 256) False\n",
            "128 conv4_block5_2_relu (None, 14, 14, 256) False\n",
            "129 conv4_block5_3_conv (None, 14, 14, 1024) False\n",
            "130 conv4_block5_3_bn (None, 14, 14, 1024) False\n",
            "131 conv4_block5_add (None, 14, 14, 1024) False\n",
            "132 conv4_block5_out (None, 14, 14, 1024) False\n",
            "133 conv4_block6_1_conv (None, 14, 14, 256) False\n",
            "134 conv4_block6_1_bn (None, 14, 14, 256) False\n",
            "135 conv4_block6_1_relu (None, 14, 14, 256) False\n",
            "136 conv4_block6_2_conv (None, 14, 14, 256) False\n",
            "137 conv4_block6_2_bn (None, 14, 14, 256) False\n",
            "138 conv4_block6_2_relu (None, 14, 14, 256) False\n",
            "139 conv4_block6_3_conv (None, 14, 14, 1024) False\n",
            "140 conv4_block6_3_bn (None, 14, 14, 1024) False\n",
            "141 conv4_block6_add (None, 14, 14, 1024) False\n",
            "142 conv4_block6_out (None, 14, 14, 1024) False\n",
            "143 conv5_block1_1_conv (None, 7, 7, 512) False\n",
            "144 conv5_block1_1_bn (None, 7, 7, 512) False\n",
            "145 conv5_block1_1_relu (None, 7, 7, 512) False\n",
            "146 conv5_block1_2_conv (None, 7, 7, 512) False\n",
            "147 conv5_block1_2_bn (None, 7, 7, 512) False\n",
            "148 conv5_block1_2_relu (None, 7, 7, 512) False\n",
            "149 conv5_block1_0_conv (None, 7, 7, 2048) False\n",
            "150 conv5_block1_3_conv (None, 7, 7, 2048) False\n",
            "151 conv5_block1_0_bn (None, 7, 7, 2048) False\n",
            "152 conv5_block1_3_bn (None, 7, 7, 2048) False\n",
            "153 conv5_block1_add (None, 7, 7, 2048) False\n",
            "154 conv5_block1_out (None, 7, 7, 2048) False\n",
            "155 conv5_block2_1_conv (None, 7, 7, 512) False\n",
            "156 conv5_block2_1_bn (None, 7, 7, 512) False\n",
            "157 conv5_block2_1_relu (None, 7, 7, 512) False\n",
            "158 conv5_block2_2_conv (None, 7, 7, 512) False\n",
            "159 conv5_block2_2_bn (None, 7, 7, 512) False\n",
            "160 conv5_block2_2_relu (None, 7, 7, 512) False\n",
            "161 conv5_block2_3_conv (None, 7, 7, 2048) False\n",
            "162 conv5_block2_3_bn (None, 7, 7, 2048) False\n",
            "163 conv5_block2_add (None, 7, 7, 2048) False\n",
            "164 conv5_block2_out (None, 7, 7, 2048) False\n",
            "165 conv5_block3_1_conv (None, 7, 7, 512) False\n",
            "166 conv5_block3_1_bn (None, 7, 7, 512) False\n",
            "167 conv5_block3_1_relu (None, 7, 7, 512) False\n",
            "168 conv5_block3_2_conv (None, 7, 7, 512) False\n",
            "169 conv5_block3_2_bn (None, 7, 7, 512) False\n",
            "170 conv5_block3_2_relu (None, 7, 7, 512) False\n",
            "171 conv5_block3_3_conv (None, 7, 7, 2048) False\n",
            "172 conv5_block3_3_bn (None, 7, 7, 2048) False\n",
            "173 conv5_block3_add (None, 7, 7, 2048) False\n",
            "174 conv5_block3_out (None, 7, 7, 2048) False\n",
            "175 global_average_pooling2d_1 (None, 2048) True\n",
            "176 dense_3 (None, 1024) True\n",
            "177 dense_4 (None, 512) True\n",
            "178 dense_5 (None, 7) True\n"
          ]
        }
      ],
      "source": [
        "for i in range(len(model.layers)):\n",
        "  layer = model.layers[i]\n",
        "  print(i, layer.name, layer.output_shape, layer.trainable)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KqeSic6NmLsR"
      },
      "outputs": [],
      "source": [
        "# redefine model to output right after the first hidden layer\n",
        "end = 175\n",
        "model1 = Model(inputs=model.inputs, outputs=model.layers[end].output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZVHYG9Rwm28i"
      },
      "outputs": [],
      "source": [
        "# get feature map for first hidden layer\n",
        "X_train_fm = model1.predict(X_train)\n",
        "X_val_fm = model1.predict(X_val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VNozN8-wDUNL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "54bb793f-cdc5-49df-d893-a4882d26670a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(193, 2048)\n"
          ]
        }
      ],
      "source": [
        "print(X_val_fm.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "19hK7aQNeAQo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "913b6cac-b79b-4e38-b094-7ac5b4ce6fb1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(14077, 2048)\n",
            "(14077, 7)\n",
            "(193, 224, 224, 3)\n",
            "(193, 7)\n",
            "Counter train data:  Counter({5: 2011, 4: 2011, 2: 2011, 3: 2011, 0: 2011, 1: 2011, 6: 2011})\n",
            "Counter val data:  Counter({5: 123, 2: 22, 4: 21, 1: 15, 0: 8, 6: 3, 3: 1})\n"
          ]
        }
      ],
      "source": [
        "X_train_fm_ov, y_train_ov = SMOTE_Data2(X_train_fm, y_train, True, 5)\n",
        "print(X_train_fm_ov.shape)\n",
        "print(y_train_ov.shape)\n",
        "print(X_val_fm.shape)\n",
        "print(y_val.shape)\n",
        "print('Counter train data: ', Counter(np.argmax(y_train_ov, axis=1)))\n",
        "print('Counter val data: ', Counter(np.argmax(y_val, axis=1)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5qP4iyYcnAYa"
      },
      "outputs": [],
      "source": [
        "model2 = Model(inputs=model.layers[end+1].input, outputs=model.layers[len(model.layers)-1].output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pzdjs0WbvDB0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b2dc9a2f-35cd-4c8b-9a69-0e3103876a5e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "217/219 [============================>.] - ETA: 0s - loss: 0.7611 - accuracy: 0.7544 - balanced_acc: 0.7542\n",
            "Epoch 1: val_balanced_acc did not improve from 0.44139\n",
            "219/219 [==============================] - 2s 4ms/step - loss: 0.7608 - accuracy: 0.7548 - balanced_acc: 0.7544 - val_loss: 0.7893 - val_accuracy: 0.7202 - val_balanced_acc: 0.3897 - lr: 5.0000e-04\n",
            "Epoch 2/100\n",
            "218/219 [============================>.] - ETA: 0s - loss: 0.7207 - accuracy: 0.7688 - balanced_acc: 0.7687\n",
            "Epoch 2: val_balanced_acc did not improve from 0.44139\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.7210 - accuracy: 0.7689 - balanced_acc: 0.7688 - val_loss: 0.8056 - val_accuracy: 0.7202 - val_balanced_acc: 0.4013 - lr: 5.0000e-04\n",
            "Epoch 3/100\n",
            "218/219 [============================>.] - ETA: 0s - loss: 0.6956 - accuracy: 0.7750 - balanced_acc: 0.7741\n",
            "Epoch 3: val_balanced_acc did not improve from 0.44139\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.6954 - accuracy: 0.7749 - balanced_acc: 0.7741 - val_loss: 0.8024 - val_accuracy: 0.7150 - val_balanced_acc: 0.3888 - lr: 5.0000e-04\n",
            "Epoch 4/100\n",
            "218/219 [============================>.] - ETA: 0s - loss: 0.6748 - accuracy: 0.7836 - balanced_acc: 0.7847\n",
            "Epoch 4: val_balanced_acc did not improve from 0.44139\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.6747 - accuracy: 0.7836 - balanced_acc: 0.7848 - val_loss: 0.7801 - val_accuracy: 0.7150 - val_balanced_acc: 0.3951 - lr: 5.0000e-04\n",
            "Epoch 5/100\n",
            "219/219 [==============================] - ETA: 0s - loss: 0.6547 - accuracy: 0.7923 - balanced_acc: 0.7924\n",
            "Epoch 5: val_balanced_acc did not improve from 0.44139\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.6547 - accuracy: 0.7923 - balanced_acc: 0.7924 - val_loss: 0.8027 - val_accuracy: 0.7047 - val_balanced_acc: 0.3892 - lr: 5.0000e-04\n",
            "Epoch 6/100\n",
            "218/219 [============================>.] - ETA: 0s - loss: 0.6403 - accuracy: 0.7975 - balanced_acc: 0.7968\n",
            "Epoch 6: val_balanced_acc did not improve from 0.44139\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.6402 - accuracy: 0.7973 - balanced_acc: 0.7967 - val_loss: 0.7869 - val_accuracy: 0.7098 - val_balanced_acc: 0.3838 - lr: 5.0000e-04\n",
            "Epoch 7/100\n",
            "210/219 [===========================>..] - ETA: 0s - loss: 0.6250 - accuracy: 0.8024 - balanced_acc: 0.8032\n",
            "Epoch 7: val_balanced_acc did not improve from 0.44139\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.6252 - accuracy: 0.8025 - balanced_acc: 0.8030 - val_loss: 0.8063 - val_accuracy: 0.7047 - val_balanced_acc: 0.3892 - lr: 5.0000e-04\n",
            "Epoch 8/100\n",
            "219/219 [==============================] - ETA: 0s - loss: 0.6120 - accuracy: 0.8075 - balanced_acc: 0.8076\n",
            "Epoch 8: val_balanced_acc did not improve from 0.44139\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.6120 - accuracy: 0.8075 - balanced_acc: 0.8076 - val_loss: 0.7607 - val_accuracy: 0.7254 - val_balanced_acc: 0.3927 - lr: 5.0000e-04\n",
            "Epoch 9/100\n",
            "218/219 [============================>.] - ETA: 0s - loss: 0.5990 - accuracy: 0.8125 - balanced_acc: 0.8114\n",
            "Epoch 9: val_balanced_acc did not improve from 0.44139\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.5989 - accuracy: 0.8125 - balanced_acc: 0.8114 - val_loss: 0.7482 - val_accuracy: 0.7358 - val_balanced_acc: 0.3908 - lr: 5.0000e-04\n",
            "Epoch 10/100\n",
            "210/219 [===========================>..] - ETA: 0s - loss: 0.5875 - accuracy: 0.8177 - balanced_acc: 0.8174\n",
            "Epoch 10: val_balanced_acc did not improve from 0.44139\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.5881 - accuracy: 0.8175 - balanced_acc: 0.8174 - val_loss: 0.7348 - val_accuracy: 0.7461 - val_balanced_acc: 0.3961 - lr: 5.0000e-04\n",
            "Epoch 11/100\n",
            "212/219 [============================>.] - ETA: 0s - loss: 0.5722 - accuracy: 0.8213 - balanced_acc: 0.8211\n",
            "Epoch 11: val_balanced_acc did not improve from 0.44139\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.5734 - accuracy: 0.8210 - balanced_acc: 0.8209 - val_loss: 0.7276 - val_accuracy: 0.7461 - val_balanced_acc: 0.3884 - lr: 5.0000e-04\n",
            "Epoch 12/100\n",
            "214/219 [============================>.] - ETA: 0s - loss: 0.5693 - accuracy: 0.8222 - balanced_acc: 0.8220\n",
            "Epoch 12: val_balanced_acc did not improve from 0.44139\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.5697 - accuracy: 0.8219 - balanced_acc: 0.8213 - val_loss: 0.7368 - val_accuracy: 0.7306 - val_balanced_acc: 0.3899 - lr: 5.0000e-04\n",
            "Epoch 13/100\n",
            "216/219 [============================>.] - ETA: 0s - loss: 0.5545 - accuracy: 0.8268 - balanced_acc: 0.8273\n",
            "Epoch 13: val_balanced_acc did not improve from 0.44139\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.5549 - accuracy: 0.8264 - balanced_acc: 0.8270 - val_loss: 0.7274 - val_accuracy: 0.7565 - val_balanced_acc: 0.3979 - lr: 5.0000e-04\n",
            "Epoch 14/100\n",
            "213/219 [============================>.] - ETA: 0s - loss: 0.5468 - accuracy: 0.8305 - balanced_acc: 0.8315\n",
            "Epoch 14: val_balanced_acc did not improve from 0.44139\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.5477 - accuracy: 0.8301 - balanced_acc: 0.8308 - val_loss: 0.7584 - val_accuracy: 0.7098 - val_balanced_acc: 0.4181 - lr: 5.0000e-04\n",
            "Epoch 15/100\n",
            "205/219 [===========================>..] - ETA: 0s - loss: 0.5403 - accuracy: 0.8311 - balanced_acc: 0.8291\n",
            "Epoch 15: val_balanced_acc did not improve from 0.44139\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.5383 - accuracy: 0.8319 - balanced_acc: 0.8301 - val_loss: 0.7276 - val_accuracy: 0.7306 - val_balanced_acc: 0.4190 - lr: 5.0000e-04\n",
            "Epoch 16/100\n",
            "216/219 [============================>.] - ETA: 0s - loss: 0.5278 - accuracy: 0.8380 - balanced_acc: 0.8376\n",
            "Epoch 16: val_balanced_acc did not improve from 0.44139\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.5277 - accuracy: 0.8377 - balanced_acc: 0.8371 - val_loss: 0.7613 - val_accuracy: 0.6995 - val_balanced_acc: 0.4111 - lr: 5.0000e-04\n",
            "Epoch 17/100\n",
            "218/219 [============================>.] - ETA: 0s - loss: 0.5253 - accuracy: 0.8367 - balanced_acc: 0.8374\n",
            "Epoch 17: val_balanced_acc did not improve from 0.44139\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.5258 - accuracy: 0.8362 - balanced_acc: 0.8369 - val_loss: 0.7530 - val_accuracy: 0.7150 - val_balanced_acc: 0.4221 - lr: 5.0000e-04\n",
            "Epoch 18/100\n",
            "218/219 [============================>.] - ETA: 0s - loss: 0.5143 - accuracy: 0.8408 - balanced_acc: 0.8417\n",
            "Epoch 18: val_balanced_acc did not improve from 0.44139\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.5138 - accuracy: 0.8410 - balanced_acc: 0.8419 - val_loss: 0.7256 - val_accuracy: 0.7513 - val_balanced_acc: 0.4242 - lr: 5.0000e-04\n",
            "Epoch 19/100\n",
            "219/219 [==============================] - ETA: 0s - loss: 0.5082 - accuracy: 0.8443 - balanced_acc: 0.8436\n",
            "Epoch 19: val_balanced_acc improved from 0.44139 to 0.45244, saving model to /content/drive/MyDrive/PHD/Model/best_model_attention.h5\n",
            "219/219 [==============================] - 2s 8ms/step - loss: 0.5082 - accuracy: 0.8443 - balanced_acc: 0.8436 - val_loss: 0.7413 - val_accuracy: 0.7202 - val_balanced_acc: 0.4524 - lr: 5.0000e-04\n",
            "Epoch 20/100\n",
            "216/219 [============================>.] - ETA: 0s - loss: 0.5010 - accuracy: 0.8469 - balanced_acc: 0.8487\n",
            "Epoch 20: val_balanced_acc did not improve from 0.45244\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.5011 - accuracy: 0.8470 - balanced_acc: 0.8489 - val_loss: 0.7558 - val_accuracy: 0.7202 - val_balanced_acc: 0.4519 - lr: 5.0000e-04\n",
            "Epoch 21/100\n",
            "217/219 [============================>.] - ETA: 0s - loss: 0.4910 - accuracy: 0.8516 - balanced_acc: 0.8528\n",
            "Epoch 21: val_balanced_acc did not improve from 0.45244\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.4908 - accuracy: 0.8518 - balanced_acc: 0.8530 - val_loss: 0.7313 - val_accuracy: 0.7461 - val_balanced_acc: 0.4275 - lr: 5.0000e-04\n",
            "Epoch 22/100\n",
            "213/219 [============================>.] - ETA: 0s - loss: 0.4873 - accuracy: 0.8519 - balanced_acc: 0.8511\n",
            "Epoch 22: val_balanced_acc did not improve from 0.45244\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.4878 - accuracy: 0.8516 - balanced_acc: 0.8510 - val_loss: 0.7409 - val_accuracy: 0.7150 - val_balanced_acc: 0.4516 - lr: 5.0000e-04\n",
            "Epoch 23/100\n",
            "216/219 [============================>.] - ETA: 0s - loss: 0.4786 - accuracy: 0.8562 - balanced_acc: 0.8562\n",
            "Epoch 23: val_balanced_acc did not improve from 0.45244\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.4781 - accuracy: 0.8562 - balanced_acc: 0.8563 - val_loss: 0.7368 - val_accuracy: 0.7202 - val_balanced_acc: 0.4504 - lr: 5.0000e-04\n",
            "Epoch 24/100\n",
            "215/219 [============================>.] - ETA: 0s - loss: 0.4743 - accuracy: 0.8579 - balanced_acc: 0.8546\n",
            "Epoch 24: val_balanced_acc improved from 0.45244 to 0.45973, saving model to /content/drive/MyDrive/PHD/Model/best_model_attention.h5\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.4753 - accuracy: 0.8575 - balanced_acc: 0.8545 - val_loss: 0.7293 - val_accuracy: 0.7358 - val_balanced_acc: 0.4597 - lr: 5.0000e-04\n",
            "Epoch 25/100\n",
            "214/219 [============================>.] - ETA: 0s - loss: 0.4721 - accuracy: 0.8580 - balanced_acc: 0.8571\n",
            "Epoch 25: val_balanced_acc did not improve from 0.45973\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.4713 - accuracy: 0.8581 - balanced_acc: 0.8570 - val_loss: 0.7299 - val_accuracy: 0.7461 - val_balanced_acc: 0.4551 - lr: 5.0000e-04\n",
            "Epoch 26/100\n",
            "214/219 [============================>.] - ETA: 0s - loss: 0.4622 - accuracy: 0.8627 - balanced_acc: 0.8626\n",
            "Epoch 26: val_balanced_acc did not improve from 0.45973\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.4615 - accuracy: 0.8630 - balanced_acc: 0.8627 - val_loss: 0.7382 - val_accuracy: 0.7254 - val_balanced_acc: 0.4557 - lr: 5.0000e-04\n",
            "Epoch 27/100\n",
            "217/219 [============================>.] - ETA: 0s - loss: 0.4552 - accuracy: 0.8666 - balanced_acc: 0.8666\n",
            "Epoch 27: val_balanced_acc did not improve from 0.45973\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.4560 - accuracy: 0.8663 - balanced_acc: 0.8661 - val_loss: 0.7232 - val_accuracy: 0.7409 - val_balanced_acc: 0.4518 - lr: 5.0000e-04\n",
            "Epoch 28/100\n",
            "210/219 [===========================>..] - ETA: 0s - loss: 0.4531 - accuracy: 0.8645 - balanced_acc: 0.8640\n",
            "Epoch 28: val_balanced_acc did not improve from 0.45973\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.4516 - accuracy: 0.8648 - balanced_acc: 0.8641 - val_loss: 0.7336 - val_accuracy: 0.7461 - val_balanced_acc: 0.4590 - lr: 5.0000e-04\n",
            "Epoch 29/100\n",
            "212/219 [============================>.] - ETA: 0s - loss: 0.4471 - accuracy: 0.8673 - balanced_acc: 0.8659\n",
            "Epoch 29: val_balanced_acc did not improve from 0.45973\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.4467 - accuracy: 0.8669 - balanced_acc: 0.8656 - val_loss: 0.7095 - val_accuracy: 0.7513 - val_balanced_acc: 0.4578 - lr: 5.0000e-04\n",
            "Epoch 30/100\n",
            "213/219 [============================>.] - ETA: 0s - loss: 0.4420 - accuracy: 0.8712 - balanced_acc: 0.8728\n",
            "Epoch 30: val_balanced_acc did not improve from 0.45973\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.4419 - accuracy: 0.8710 - balanced_acc: 0.8723 - val_loss: 0.7241 - val_accuracy: 0.7254 - val_balanced_acc: 0.4578 - lr: 5.0000e-04\n",
            "Epoch 31/100\n",
            "218/219 [============================>.] - ETA: 0s - loss: 0.4378 - accuracy: 0.8715 - balanced_acc: 0.8722\n",
            "Epoch 31: val_balanced_acc did not improve from 0.45973\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.4378 - accuracy: 0.8715 - balanced_acc: 0.8724 - val_loss: 0.7181 - val_accuracy: 0.7461 - val_balanced_acc: 0.4565 - lr: 5.0000e-04\n",
            "Epoch 32/100\n",
            "212/219 [============================>.] - ETA: 0s - loss: 0.4325 - accuracy: 0.8738 - balanced_acc: 0.8723\n",
            "Epoch 32: val_balanced_acc did not improve from 0.45973\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.4316 - accuracy: 0.8740 - balanced_acc: 0.8723 - val_loss: 0.7410 - val_accuracy: 0.7150 - val_balanced_acc: 0.4516 - lr: 5.0000e-04\n",
            "Epoch 33/100\n",
            "216/219 [============================>.] - ETA: 0s - loss: 0.4263 - accuracy: 0.8740 - balanced_acc: 0.8737\n",
            "Epoch 33: val_balanced_acc did not improve from 0.45973\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.4266 - accuracy: 0.8740 - balanced_acc: 0.8736 - val_loss: 0.7264 - val_accuracy: 0.7254 - val_balanced_acc: 0.4557 - lr: 5.0000e-04\n",
            "Epoch 34/100\n",
            "218/219 [============================>.] - ETA: 0s - loss: 0.4199 - accuracy: 0.8793 - balanced_acc: 0.8787\n",
            "Epoch 34: val_balanced_acc did not improve from 0.45973\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.4191 - accuracy: 0.8796 - balanced_acc: 0.8789 - val_loss: 0.7544 - val_accuracy: 0.7150 - val_balanced_acc: 0.4538 - lr: 5.0000e-04\n",
            "Epoch 35/100\n",
            "215/219 [============================>.] - ETA: 0s - loss: 0.4178 - accuracy: 0.8780 - balanced_acc: 0.8778\n",
            "Epoch 35: val_balanced_acc did not improve from 0.45973\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.4174 - accuracy: 0.8784 - balanced_acc: 0.8781 - val_loss: 0.7436 - val_accuracy: 0.7254 - val_balanced_acc: 0.4557 - lr: 5.0000e-04\n",
            "Epoch 36/100\n",
            "213/219 [============================>.] - ETA: 0s - loss: 0.4155 - accuracy: 0.8795 - balanced_acc: 0.8804\n",
            "Epoch 36: val_balanced_acc did not improve from 0.45973\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.4158 - accuracy: 0.8791 - balanced_acc: 0.8797 - val_loss: 0.7196 - val_accuracy: 0.7358 - val_balanced_acc: 0.4528 - lr: 5.0000e-04\n",
            "Epoch 37/100\n",
            "214/219 [============================>.] - ETA: 0s - loss: 0.4117 - accuracy: 0.8787 - balanced_acc: 0.8786\n",
            "Epoch 37: val_balanced_acc did not improve from 0.45973\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.4113 - accuracy: 0.8790 - balanced_acc: 0.8792 - val_loss: 0.7267 - val_accuracy: 0.7358 - val_balanced_acc: 0.4503 - lr: 5.0000e-04\n",
            "Epoch 38/100\n",
            "217/219 [============================>.] - ETA: 0s - loss: 0.4012 - accuracy: 0.8854 - balanced_acc: 0.8854\n",
            "Epoch 38: val_balanced_acc did not improve from 0.45973\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.4010 - accuracy: 0.8855 - balanced_acc: 0.8854 - val_loss: 0.7066 - val_accuracy: 0.7513 - val_balanced_acc: 0.4573 - lr: 5.0000e-04\n",
            "Epoch 39/100\n",
            "218/219 [============================>.] - ETA: 0s - loss: 0.3998 - accuracy: 0.8828 - balanced_acc: 0.8837\n",
            "Epoch 39: val_balanced_acc improved from 0.45973 to 0.46289, saving model to /content/drive/MyDrive/PHD/Model/best_model_attention.h5\n",
            "219/219 [==============================] - 2s 7ms/step - loss: 0.4006 - accuracy: 0.8824 - balanced_acc: 0.8834 - val_loss: 0.7339 - val_accuracy: 0.7306 - val_balanced_acc: 0.4629 - lr: 5.0000e-04\n",
            "Epoch 40/100\n",
            "214/219 [============================>.] - ETA: 0s - loss: 0.3946 - accuracy: 0.8869 - balanced_acc: 0.8871\n",
            "Epoch 40: val_balanced_acc improved from 0.46289 to 0.46484, saving model to /content/drive/MyDrive/PHD/Model/best_model_attention.h5\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.3944 - accuracy: 0.8869 - balanced_acc: 0.8868 - val_loss: 0.7275 - val_accuracy: 0.7409 - val_balanced_acc: 0.4648 - lr: 5.0000e-04\n",
            "Epoch 41/100\n",
            "207/219 [===========================>..] - ETA: 0s - loss: 0.3931 - accuracy: 0.8898 - balanced_acc: 0.8907\n",
            "Epoch 41: val_balanced_acc did not improve from 0.46484\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.3919 - accuracy: 0.8902 - balanced_acc: 0.8910 - val_loss: 0.7216 - val_accuracy: 0.7358 - val_balanced_acc: 0.4577 - lr: 5.0000e-04\n",
            "Epoch 42/100\n",
            "214/219 [============================>.] - ETA: 0s - loss: 0.3915 - accuracy: 0.8875 - balanced_acc: 0.8881\n",
            "Epoch 42: val_balanced_acc did not improve from 0.46484\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.3922 - accuracy: 0.8874 - balanced_acc: 0.8883 - val_loss: 0.7028 - val_accuracy: 0.7565 - val_balanced_acc: 0.4624 - lr: 5.0000e-04\n",
            "Epoch 43/100\n",
            "218/219 [============================>.] - ETA: 0s - loss: 0.3827 - accuracy: 0.8920 - balanced_acc: 0.8925\n",
            "Epoch 43: val_balanced_acc did not improve from 0.46484\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.3822 - accuracy: 0.8921 - balanced_acc: 0.8926 - val_loss: 0.7282 - val_accuracy: 0.7409 - val_balanced_acc: 0.4608 - lr: 5.0000e-04\n",
            "Epoch 44/100\n",
            "214/219 [============================>.] - ETA: 0s - loss: 0.3832 - accuracy: 0.8923 - balanced_acc: 0.8921\n",
            "Epoch 44: val_balanced_acc did not improve from 0.46484\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.3833 - accuracy: 0.8924 - balanced_acc: 0.8924 - val_loss: 0.7037 - val_accuracy: 0.7358 - val_balanced_acc: 0.4530 - lr: 5.0000e-04\n",
            "Epoch 45/100\n",
            "218/219 [============================>.] - ETA: 0s - loss: 0.3790 - accuracy: 0.8938 - balanced_acc: 0.8943\n",
            "Epoch 45: val_balanced_acc did not improve from 0.46484\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.3790 - accuracy: 0.8939 - balanced_acc: 0.8944 - val_loss: 0.7065 - val_accuracy: 0.7409 - val_balanced_acc: 0.4581 - lr: 5.0000e-04\n",
            "Epoch 46/100\n",
            "215/219 [============================>.] - ETA: 0s - loss: 0.3708 - accuracy: 0.8954 - balanced_acc: 0.8965\n",
            "Epoch 46: val_balanced_acc did not improve from 0.46484\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.3711 - accuracy: 0.8954 - balanced_acc: 0.8967 - val_loss: 0.7274 - val_accuracy: 0.7358 - val_balanced_acc: 0.4613 - lr: 5.0000e-04\n",
            "Epoch 47/100\n",
            "213/219 [============================>.] - ETA: 0s - loss: 0.3682 - accuracy: 0.8979 - balanced_acc: 0.8974\n",
            "Epoch 47: val_balanced_acc did not improve from 0.46484\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.3704 - accuracy: 0.8970 - balanced_acc: 0.8970 - val_loss: 0.7095 - val_accuracy: 0.7409 - val_balanced_acc: 0.4648 - lr: 5.0000e-04\n",
            "Epoch 48/100\n",
            "216/219 [============================>.] - ETA: 0s - loss: 0.3655 - accuracy: 0.8987 - balanced_acc: 0.8986\n",
            "Epoch 48: val_balanced_acc did not improve from 0.46484\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.3657 - accuracy: 0.8987 - balanced_acc: 0.8986 - val_loss: 0.7118 - val_accuracy: 0.7409 - val_balanced_acc: 0.4539 - lr: 5.0000e-04\n",
            "Epoch 49/100\n",
            "207/219 [===========================>..] - ETA: 0s - loss: 0.3675 - accuracy: 0.8988 - balanced_acc: 0.8971\n",
            "Epoch 49: val_balanced_acc did not improve from 0.46484\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.3675 - accuracy: 0.8988 - balanced_acc: 0.8977 - val_loss: 0.6959 - val_accuracy: 0.7461 - val_balanced_acc: 0.4590 - lr: 5.0000e-04\n",
            "Epoch 50/100\n",
            "211/219 [===========================>..] - ETA: 0s - loss: 0.3553 - accuracy: 0.9010 - balanced_acc: 0.9030\n",
            "Epoch 50: val_balanced_acc did not improve from 0.46484\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.3569 - accuracy: 0.9002 - balanced_acc: 0.9017 - val_loss: 0.7085 - val_accuracy: 0.7409 - val_balanced_acc: 0.4608 - lr: 5.0000e-04\n",
            "Epoch 51/100\n",
            "217/219 [============================>.] - ETA: 0s - loss: 0.3575 - accuracy: 0.9017 - balanced_acc: 0.9020\n",
            "Epoch 51: val_balanced_acc did not improve from 0.46484\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.3575 - accuracy: 0.9017 - balanced_acc: 0.9021 - val_loss: 0.7068 - val_accuracy: 0.7461 - val_balanced_acc: 0.4632 - lr: 5.0000e-04\n",
            "Epoch 52/100\n",
            "210/219 [===========================>..] - ETA: 0s - loss: 0.3531 - accuracy: 0.9025 - balanced_acc: 0.9024\n",
            "Epoch 52: val_balanced_acc improved from 0.46484 to 0.46491, saving model to /content/drive/MyDrive/PHD/Model/best_model_attention.h5\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.3545 - accuracy: 0.9014 - balanced_acc: 0.9012 - val_loss: 0.6835 - val_accuracy: 0.7565 - val_balanced_acc: 0.4649 - lr: 5.0000e-04\n",
            "Epoch 53/100\n",
            "210/219 [===========================>..] - ETA: 0s - loss: 0.3497 - accuracy: 0.9038 - balanced_acc: 0.9042\n",
            "Epoch 53: val_balanced_acc did not improve from 0.46491\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.3514 - accuracy: 0.9029 - balanced_acc: 0.9034 - val_loss: 0.6702 - val_accuracy: 0.7565 - val_balanced_acc: 0.4582 - lr: 5.0000e-04\n",
            "Epoch 54/100\n",
            "216/219 [============================>.] - ETA: 0s - loss: 0.3491 - accuracy: 0.9049 - balanced_acc: 0.9053\n",
            "Epoch 54: val_balanced_acc did not improve from 0.46491\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.3490 - accuracy: 0.9046 - balanced_acc: 0.9049 - val_loss: 0.7076 - val_accuracy: 0.7358 - val_balanced_acc: 0.4579 - lr: 5.0000e-04\n",
            "Epoch 55/100\n",
            "214/219 [============================>.] - ETA: 0s - loss: 0.3434 - accuracy: 0.9059 - balanced_acc: 0.9067\n",
            "Epoch 55: val_balanced_acc did not improve from 0.46491\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.3443 - accuracy: 0.9054 - balanced_acc: 0.9061 - val_loss: 0.7172 - val_accuracy: 0.7409 - val_balanced_acc: 0.4648 - lr: 5.0000e-04\n",
            "Epoch 56/100\n",
            "217/219 [============================>.] - ETA: 0s - loss: 0.3413 - accuracy: 0.9077 - balanced_acc: 0.9067\n",
            "Epoch 56: val_balanced_acc improved from 0.46491 to 0.46576, saving model to /content/drive/MyDrive/PHD/Model/best_model_attention.h5\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.3414 - accuracy: 0.9076 - balanced_acc: 0.9067 - val_loss: 0.6852 - val_accuracy: 0.7617 - val_balanced_acc: 0.4658 - lr: 5.0000e-04\n",
            "Epoch 57/100\n",
            "219/219 [==============================] - ETA: 0s - loss: 0.3398 - accuracy: 0.9069 - balanced_acc: 0.9059\n",
            "Epoch 57: val_balanced_acc did not improve from 0.46576\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.3398 - accuracy: 0.9069 - balanced_acc: 0.9059 - val_loss: 0.6840 - val_accuracy: 0.7617 - val_balanced_acc: 0.4658 - lr: 5.0000e-04\n",
            "Epoch 58/100\n",
            "218/219 [============================>.] - ETA: 0s - loss: 0.3344 - accuracy: 0.9096 - balanced_acc: 0.9091\n",
            "Epoch 58: val_balanced_acc did not improve from 0.46576\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.3343 - accuracy: 0.9097 - balanced_acc: 0.9091 - val_loss: 0.7152 - val_accuracy: 0.7461 - val_balanced_acc: 0.4632 - lr: 5.0000e-04\n",
            "Epoch 59/100\n",
            "204/219 [==========================>...] - ETA: 0s - loss: 0.3325 - accuracy: 0.9099 - balanced_acc: 0.9101\n",
            "Epoch 59: val_balanced_acc improved from 0.46576 to 0.46593, saving model to /content/drive/MyDrive/PHD/Model/best_model_attention.h5\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.3346 - accuracy: 0.9089 - balanced_acc: 0.9087 - val_loss: 0.7102 - val_accuracy: 0.7461 - val_balanced_acc: 0.4659 - lr: 5.0000e-04\n",
            "Epoch 60/100\n",
            "216/219 [============================>.] - ETA: 0s - loss: 0.3318 - accuracy: 0.9088 - balanced_acc: 0.9082\n",
            "Epoch 60: val_balanced_acc did not improve from 0.46593\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.3318 - accuracy: 0.9088 - balanced_acc: 0.9083 - val_loss: 0.7138 - val_accuracy: 0.7254 - val_balanced_acc: 0.4560 - lr: 5.0000e-04\n",
            "Epoch 61/100\n",
            "214/219 [============================>.] - ETA: 0s - loss: 0.3257 - accuracy: 0.9140 - balanced_acc: 0.9138\n",
            "Epoch 61: val_balanced_acc did not improve from 0.46593\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.3252 - accuracy: 0.9140 - balanced_acc: 0.9137 - val_loss: 0.7153 - val_accuracy: 0.7409 - val_balanced_acc: 0.4648 - lr: 5.0000e-04\n",
            "Epoch 62/100\n",
            "208/219 [===========================>..] - ETA: 0s - loss: 0.3248 - accuracy: 0.9107 - balanced_acc: 0.9101\n",
            "Epoch 62: val_balanced_acc did not improve from 0.46593\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.3254 - accuracy: 0.9095 - balanced_acc: 0.9089 - val_loss: 0.6975 - val_accuracy: 0.7461 - val_balanced_acc: 0.4590 - lr: 5.0000e-04\n",
            "Epoch 63/100\n",
            "210/219 [===========================>..] - ETA: 0s - loss: 0.3242 - accuracy: 0.9124 - balanced_acc: 0.9137\n",
            "Epoch 63: val_balanced_acc improved from 0.46593 to 0.47274, saving model to /content/drive/MyDrive/PHD/Model/best_model_attention.h5\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.3223 - accuracy: 0.9134 - balanced_acc: 0.9145 - val_loss: 0.6916 - val_accuracy: 0.7565 - val_balanced_acc: 0.4727 - lr: 5.0000e-04\n",
            "Epoch 64/100\n",
            "212/219 [============================>.] - ETA: 0s - loss: 0.3161 - accuracy: 0.9163 - balanced_acc: 0.9168\n",
            "Epoch 64: val_balanced_acc did not improve from 0.47274\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.3158 - accuracy: 0.9170 - balanced_acc: 0.9175 - val_loss: 0.7060 - val_accuracy: 0.7409 - val_balanced_acc: 0.4651 - lr: 5.0000e-04\n",
            "Epoch 65/100\n",
            "214/219 [============================>.] - ETA: 0s - loss: 0.3190 - accuracy: 0.9127 - balanced_acc: 0.9124\n",
            "Epoch 65: val_balanced_acc did not improve from 0.47274\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.3188 - accuracy: 0.9132 - balanced_acc: 0.9127 - val_loss: 0.7074 - val_accuracy: 0.7461 - val_balanced_acc: 0.4659 - lr: 5.0000e-04\n",
            "Epoch 66/100\n",
            "212/219 [============================>.] - ETA: 0s - loss: 0.3138 - accuracy: 0.9153 - balanced_acc: 0.9146\n",
            "Epoch 66: val_balanced_acc did not improve from 0.47274\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.3143 - accuracy: 0.9151 - balanced_acc: 0.9144 - val_loss: 0.7076 - val_accuracy: 0.7358 - val_balanced_acc: 0.4579 - lr: 5.0000e-04\n",
            "Epoch 67/100\n",
            "214/219 [============================>.] - ETA: 0s - loss: 0.3122 - accuracy: 0.9165 - balanced_acc: 0.9161\n",
            "Epoch 67: val_balanced_acc did not improve from 0.47274\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.3134 - accuracy: 0.9162 - balanced_acc: 0.9161 - val_loss: 0.7015 - val_accuracy: 0.7461 - val_balanced_acc: 0.4632 - lr: 5.0000e-04\n",
            "Epoch 68/100\n",
            "215/219 [============================>.] - ETA: 0s - loss: 0.3101 - accuracy: 0.9175 - balanced_acc: 0.9172\n",
            "Epoch 68: val_balanced_acc did not improve from 0.47274\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.3112 - accuracy: 0.9166 - balanced_acc: 0.9160 - val_loss: 0.6830 - val_accuracy: 0.7565 - val_balanced_acc: 0.4586 - lr: 5.0000e-04\n",
            "Epoch 69/100\n",
            "212/219 [============================>.] - ETA: 0s - loss: 0.3041 - accuracy: 0.9197 - balanced_acc: 0.9200\n",
            "Epoch 69: val_balanced_acc did not improve from 0.47274\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.3043 - accuracy: 0.9192 - balanced_acc: 0.9195 - val_loss: 0.6770 - val_accuracy: 0.7617 - val_balanced_acc: 0.4658 - lr: 5.0000e-04\n",
            "Epoch 70/100\n",
            "206/219 [===========================>..] - ETA: 0s - loss: 0.3030 - accuracy: 0.9198 - balanced_acc: 0.9213\n",
            "Epoch 70: val_balanced_acc did not improve from 0.47274\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.3021 - accuracy: 0.9200 - balanced_acc: 0.9212 - val_loss: 0.6834 - val_accuracy: 0.7565 - val_balanced_acc: 0.4622 - lr: 5.0000e-04\n",
            "Epoch 71/100\n",
            "214/219 [============================>.] - ETA: 0s - loss: 0.3005 - accuracy: 0.9202 - balanced_acc: 0.9202\n",
            "Epoch 71: val_balanced_acc did not improve from 0.47274\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.3009 - accuracy: 0.9199 - balanced_acc: 0.9200 - val_loss: 0.6959 - val_accuracy: 0.7617 - val_balanced_acc: 0.4700 - lr: 5.0000e-04\n",
            "Epoch 72/100\n",
            "216/219 [============================>.] - ETA: 0s - loss: 0.3049 - accuracy: 0.9175 - balanced_acc: 0.9175\n",
            "Epoch 72: val_balanced_acc did not improve from 0.47274\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.3044 - accuracy: 0.9178 - balanced_acc: 0.9178 - val_loss: 0.6702 - val_accuracy: 0.7617 - val_balanced_acc: 0.4646 - lr: 5.0000e-04\n",
            "Epoch 73/100\n",
            "215/219 [============================>.] - ETA: 0s - loss: 0.2950 - accuracy: 0.9224 - balanced_acc: 0.9219\n",
            "Epoch 73: val_balanced_acc did not improve from 0.47274\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.2954 - accuracy: 0.9220 - balanced_acc: 0.9217 - val_loss: 0.6965 - val_accuracy: 0.7409 - val_balanced_acc: 0.4624 - lr: 5.0000e-04\n",
            "Epoch 74/100\n",
            "213/219 [============================>.] - ETA: 0s - loss: 0.2940 - accuracy: 0.9233 - balanced_acc: 0.9224\n",
            "Epoch 74: val_balanced_acc did not improve from 0.47274\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.2941 - accuracy: 0.9234 - balanced_acc: 0.9225 - val_loss: 0.6882 - val_accuracy: 0.7461 - val_balanced_acc: 0.4605 - lr: 5.0000e-04\n",
            "Epoch 75/100\n",
            "214/219 [============================>.] - ETA: 0s - loss: 0.2929 - accuracy: 0.9210 - balanced_acc: 0.9199\n",
            "Epoch 75: val_balanced_acc did not improve from 0.47274\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.2924 - accuracy: 0.9211 - balanced_acc: 0.9201 - val_loss: 0.6878 - val_accuracy: 0.7565 - val_balanced_acc: 0.4649 - lr: 5.0000e-04\n",
            "Epoch 76/100\n",
            "212/219 [============================>.] - ETA: 0s - loss: 0.2904 - accuracy: 0.9243 - balanced_acc: 0.9258\n",
            "Epoch 76: val_balanced_acc did not improve from 0.47274\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.2902 - accuracy: 0.9239 - balanced_acc: 0.9253 - val_loss: 0.6962 - val_accuracy: 0.7409 - val_balanced_acc: 0.4588 - lr: 5.0000e-04\n",
            "Epoch 77/100\n",
            "209/219 [===========================>..] - ETA: 0s - loss: 0.2919 - accuracy: 0.9219 - balanced_acc: 0.9213\n",
            "Epoch 77: val_balanced_acc did not improve from 0.47274\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.2912 - accuracy: 0.9221 - balanced_acc: 0.9213 - val_loss: 0.6975 - val_accuracy: 0.7461 - val_balanced_acc: 0.4605 - lr: 5.0000e-04\n",
            "Epoch 78/100\n",
            "207/219 [===========================>..] - ETA: 0s - loss: 0.2791 - accuracy: 0.9274 - balanced_acc: 0.9280\n",
            "Epoch 78: val_balanced_acc did not improve from 0.47274\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.2793 - accuracy: 0.9272 - balanced_acc: 0.9277 - val_loss: 0.6786 - val_accuracy: 0.7513 - val_balanced_acc: 0.4605 - lr: 5.0000e-04\n",
            "Epoch 79/100\n",
            "206/219 [===========================>..] - ETA: 0s - loss: 0.2913 - accuracy: 0.9215 - balanced_acc: 0.9199\n",
            "Epoch 79: val_balanced_acc did not improve from 0.47274\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.2902 - accuracy: 0.9224 - balanced_acc: 0.9211 - val_loss: 0.6853 - val_accuracy: 0.7461 - val_balanced_acc: 0.4542 - lr: 5.0000e-04\n",
            "Epoch 80/100\n",
            "206/219 [===========================>..] - ETA: 0s - loss: 0.2793 - accuracy: 0.9257 - balanced_acc: 0.9252\n",
            "Epoch 80: val_balanced_acc did not improve from 0.47274\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.2810 - accuracy: 0.9250 - balanced_acc: 0.9249 - val_loss: 0.6997 - val_accuracy: 0.7358 - val_balanced_acc: 0.4579 - lr: 5.0000e-04\n",
            "Epoch 81/100\n",
            "206/219 [===========================>..] - ETA: 0s - loss: 0.2818 - accuracy: 0.9263 - balanced_acc: 0.9276\n",
            "Epoch 81: val_balanced_acc did not improve from 0.47274\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.2815 - accuracy: 0.9264 - balanced_acc: 0.9280 - val_loss: 0.6753 - val_accuracy: 0.7617 - val_balanced_acc: 0.4673 - lr: 5.0000e-04\n",
            "Epoch 82/100\n",
            "208/219 [===========================>..] - ETA: 0s - loss: 0.2754 - accuracy: 0.9261 - balanced_acc: 0.9251\n",
            "Epoch 82: val_balanced_acc did not improve from 0.47274\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.2750 - accuracy: 0.9264 - balanced_acc: 0.9253 - val_loss: 0.6990 - val_accuracy: 0.7461 - val_balanced_acc: 0.4639 - lr: 5.0000e-04\n",
            "Epoch 83/100\n",
            "210/219 [===========================>..] - ETA: 0s - loss: 0.2744 - accuracy: 0.9296 - balanced_acc: 0.9293\n",
            "Epoch 83: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "\n",
            "Epoch 83: val_balanced_acc did not improve from 0.47274\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.2737 - accuracy: 0.9298 - balanced_acc: 0.9294 - val_loss: 0.6966 - val_accuracy: 0.7461 - val_balanced_acc: 0.4632 - lr: 5.0000e-04\n",
            "Epoch 84/100\n",
            "207/219 [===========================>..] - ETA: 0s - loss: 0.2749 - accuracy: 0.9282 - balanced_acc: 0.9277\n",
            "Epoch 84: val_balanced_acc did not improve from 0.47274\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.2739 - accuracy: 0.9292 - balanced_acc: 0.9289 - val_loss: 0.6815 - val_accuracy: 0.7513 - val_balanced_acc: 0.4620 - lr: 2.5000e-04\n",
            "Epoch 85/100\n",
            "209/219 [===========================>..] - ETA: 0s - loss: 0.2742 - accuracy: 0.9276 - balanced_acc: 0.9272\n",
            "Epoch 85: val_balanced_acc did not improve from 0.47274\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.2739 - accuracy: 0.9277 - balanced_acc: 0.9269 - val_loss: 0.6936 - val_accuracy: 0.7461 - val_balanced_acc: 0.4596 - lr: 2.5000e-04\n",
            "Epoch 86/100\n",
            "207/219 [===========================>..] - ETA: 0s - loss: 0.2679 - accuracy: 0.9312 - balanced_acc: 0.9301\n",
            "Epoch 86: val_balanced_acc did not improve from 0.47274\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.2675 - accuracy: 0.9315 - balanced_acc: 0.9299 - val_loss: 0.6855 - val_accuracy: 0.7461 - val_balanced_acc: 0.4569 - lr: 2.5000e-04\n",
            "Epoch 87/100\n",
            "209/219 [===========================>..] - ETA: 0s - loss: 0.2659 - accuracy: 0.9314 - balanced_acc: 0.9318\n",
            "Epoch 87: val_balanced_acc did not improve from 0.47274\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.2678 - accuracy: 0.9306 - balanced_acc: 0.9310 - val_loss: 0.6833 - val_accuracy: 0.7513 - val_balanced_acc: 0.4613 - lr: 2.5000e-04\n",
            "Epoch 88/100\n",
            "209/219 [===========================>..] - ETA: 0s - loss: 0.2687 - accuracy: 0.9314 - balanced_acc: 0.9318\n",
            "Epoch 88: val_balanced_acc did not improve from 0.47274\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.2688 - accuracy: 0.9318 - balanced_acc: 0.9320 - val_loss: 0.6699 - val_accuracy: 0.7513 - val_balanced_acc: 0.4578 - lr: 2.5000e-04\n",
            "Epoch 89/100\n",
            "208/219 [===========================>..] - ETA: 0s - loss: 0.2678 - accuracy: 0.9303 - balanced_acc: 0.9322\n",
            "Epoch 89: val_balanced_acc did not improve from 0.47274\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.2689 - accuracy: 0.9301 - balanced_acc: 0.9318 - val_loss: 0.6909 - val_accuracy: 0.7461 - val_balanced_acc: 0.4569 - lr: 2.5000e-04\n",
            "Epoch 90/100\n",
            "216/219 [============================>.] - ETA: 0s - loss: 0.2715 - accuracy: 0.9303 - balanced_acc: 0.9301\n",
            "Epoch 90: val_balanced_acc did not improve from 0.47274\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.2719 - accuracy: 0.9302 - balanced_acc: 0.9298 - val_loss: 0.6821 - val_accuracy: 0.7461 - val_balanced_acc: 0.4542 - lr: 2.5000e-04\n",
            "Epoch 91/100\n",
            "210/219 [===========================>..] - ETA: 0s - loss: 0.2622 - accuracy: 0.9326 - balanced_acc: 0.9316\n",
            "Epoch 91: val_balanced_acc did not improve from 0.47274\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.2623 - accuracy: 0.9325 - balanced_acc: 0.9313 - val_loss: 0.6980 - val_accuracy: 0.7409 - val_balanced_acc: 0.4588 - lr: 2.5000e-04\n",
            "Epoch 92/100\n",
            "209/219 [===========================>..] - ETA: 0s - loss: 0.2637 - accuracy: 0.9331 - balanced_acc: 0.9339\n",
            "Epoch 92: val_balanced_acc did not improve from 0.47274\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.2629 - accuracy: 0.9333 - balanced_acc: 0.9335 - val_loss: 0.6957 - val_accuracy: 0.7409 - val_balanced_acc: 0.4588 - lr: 2.5000e-04\n",
            "Epoch 93/100\n",
            "214/219 [============================>.] - ETA: 0s - loss: 0.2676 - accuracy: 0.9314 - balanced_acc: 0.9311\n",
            "Epoch 93: val_balanced_acc did not improve from 0.47274\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.2675 - accuracy: 0.9316 - balanced_acc: 0.9314 - val_loss: 0.6966 - val_accuracy: 0.7409 - val_balanced_acc: 0.4630 - lr: 2.5000e-04\n"
          ]
        }
      ],
      "source": [
        "best_model_fpath = '/content/drive/MyDrive/PHD/Model/Feature-Map-Ov/best_model_no.h5'\n",
        "last_model_fpath = '/content/drive/MyDrive/PHD/Model/Feature-Map-Ov/last_model_no.h5'\n",
        "model2.compile(optimizer = opt_SGD , loss = \"categorical_crossentropy\", metrics=['accuracy', balanced_acc])\n",
        "hst = model2.fit(X_train_fm_ov, y_train_ov, epochs=EPOCHS, batch_size=BATCH_SIZE, validation_data=(X_val_fm, y_val), verbose=1,\n",
        "                    steps_per_epoch=X_train_fm_ov.shape[0] // BATCH_SIZE, \n",
        "                    callbacks=[learning_rate_reduction,early_stopping_monitor, mc])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8XhlbWn--8Or",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "cc2db38f-c4b1-46d1-cebb-1d292045017f"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "# summarize history for accuracy\n",
        "plt.plot(hst.history['accuracy'])\n",
        "plt.plot(hst.history['balanced_acc'])\n",
        "plt.plot(hst.history['val_accuracy'])\n",
        "plt.plot(hst.history['val_balanced_acc'])\n",
        "plt.title('Model accuracy')\n",
        "plt.ylabel('Performance')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train accuracy', 'train balanced acc.', 'val. accuracy', 'val. balanced acc.'], loc='lower right')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IW-_U6vFpIci"
      },
      "outputs": [],
      "source": [
        "# get feature map for first hidden layer\n",
        "y_train_pred = model2.predict(X_train_fm_ov)\n",
        "y_val_pred = model2.predict(X_val_fm)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OLop0YK-ZK40",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3733507c-9883-4a46-d215-8ba49e778389"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy on training 0.9326561057043404\n",
            "balanced accuracy on training 0.9326561057043404\n",
            "accuracy on validation 0.7409326424870466\n",
            "balanced accuracy on validation 0.7154754362942517\n",
            "Score on val data:  (0.5704461396208969, 0.7154754362942517, 0.6059867124026416, None)\n"
          ]
        }
      ],
      "source": [
        "print('accuracy on training',accuracy_score(np.argmax(y_train_ov, axis=1), np.argmax(y_train_pred, axis=1)))\n",
        "print('balanced accuracy on training',balanced_accuracy_score(np.argmax(y_train_ov, axis=1), np.argmax(y_train_pred, axis=1)))\n",
        "print('accuracy on validation',accuracy_score(np.argmax(y_val, axis=1), np.argmax(y_val_pred, axis=1)))\n",
        "print('balanced accuracy on validation',balanced_accuracy_score(np.argmax(y_val, axis=1), np.argmax(y_val_pred, axis=1)))\n",
        "print('Score on val data: ',precision_recall_fscore_support(np.argmax(y_val, axis=1), np.argmax(y_val_pred, axis=1), average='macro'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RcRGeofw-8tK"
      },
      "source": [
        "#Load ISIC 2018 Challange Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "l3P7IjyLuZGY"
      },
      "outputs": [],
      "source": [
        "X_train, y_train, X_val, y_val = load_isic2018_dataset(train_under_frac = 0.83)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2IncA-_o_n5w"
      },
      "outputs": [],
      "source": [
        "# ordered count of rows per unique label\n",
        "labels_count = y_train.value_counts(ascending=True)\n",
        "\n",
        "f = plt.figure(figsize=(15, 6))\n",
        "s = sns.barplot(x=labels_count.index,y=labels_count.values)\n",
        "s.set_xticklabels(s.get_xticklabels(), rotation = 30)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AnKMKSb4Bkym"
      },
      "source": [
        "Plot 3 images per label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jdnVuqbFBW3K"
      },
      "outputs": [],
      "source": [
        "def plot_images_per_label(df, label, cols: int, size: tuple):\n",
        "    fig, axs = plt.subplots(nrows=1, ncols=cols, figsize=size)\n",
        "\n",
        "    cntMax = cols\n",
        "    cntCur = 0\n",
        "    for index, row in df.iterrows():\n",
        "        if(y_train == label and cntCur < cntMax):\n",
        "            axs[cntCur].imshow(plt.imread(df.FilePaths[index]))\n",
        "            axs[cntCur].set_title(df.Labels[index])\n",
        "\n",
        "            cntCur += 1\n",
        "        else:\n",
        "            if(cntCur >= cntMax):\n",
        "                break\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "# unique labels\n",
        "labels = sorted(df1['y_train'].unique())\n",
        "for label in range(7):\n",
        "    plot_images_per_label(df1, label, 3, (12,9))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "asV1O58Lrq-R"
      },
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "img = Image.fromarray(X_train[0], 'RGB')\n",
        "display(img)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qRKKrNacAZtl"
      },
      "source": [
        "Drop duplicate images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ERwfyPDHP-zC"
      },
      "outputs": [],
      "source": [
        "#df_group = pd.read_csv('/content/drive/MyDrive/PHD/Datasets/isic2018/ISIC2018_Task3_Training_LesionGroupings.csv') \n",
        "#df_train = df_train.set_index('image').join(df_group.set_index('image'))\n",
        "#df_train = df_train.drop_duplicates(subset=['lesion_id'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cNBXx28B9yGu"
      },
      "source": [
        "#DeepSMOTE Oversampling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YmX_Uqbmj-tN"
      },
      "outputs": [],
      "source": [
        "from numpy import moveaxis\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "max_el = np.inf\n",
        "\n",
        "args = {}\n",
        "args['dim_h'] = 64         # factor controlling size of hidden layers\n",
        "args['n_channel'] = 3#1    # number of channels in the input data \n",
        "args['n_z'] = 600 #300     # number of dimensions in latent space. \n",
        "args['sigma'] = 1.0        # variance in n_z\n",
        "args['lambda'] = 0.01      # hyper param for weight of discriminator loss\n",
        "args['lr'] = 0.0002        # learning rate for Adam optimizer .000\n",
        "args['epochs'] = 300       # how many epochs to run for\n",
        "args['batch_size'] = 100   # batch size for SGD\n",
        "args['save'] = True        # save weights at each epoch of training if True\n",
        "args['train'] = True       # train networks if True, else load networks from\n",
        "args['patience'] = 20"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NydOdPMajEfT"
      },
      "outputs": [],
      "source": [
        "class Encoder(nn.Module):\n",
        "    def __init__(self, args):\n",
        "        super(Encoder, self).__init__()\n",
        "\n",
        "        self.n_channel = args['n_channel']\n",
        "        self.dim_h = args['dim_h']\n",
        "        self.n_z = args['n_z']\n",
        "        \n",
        "        # convolutional filters, work excellent with image data\n",
        "        # [(W−K+2P)/S]+1\n",
        "        self.conv = nn.Sequential(\n",
        "            nn.AvgPool2d(7, stride=7),\n",
        "            nn.Conv2d(self.n_channel, self.dim_h, 4, 2, 1, bias=False),# 16\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Conv2d(self.dim_h, self.dim_h * 2, 4, 2, 1, bias=False), # 8\n",
        "            nn.BatchNorm2d(self.dim_h * 2),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Conv2d(self.dim_h * 2, self.dim_h * 4, 4, 2, 1, bias=False),# 4\n",
        "            nn.BatchNorm2d(self.dim_h * 4),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Conv2d(self.dim_h * 4, self.dim_h * 8, 4, 2, 0, bias=False),#14\n",
        "            nn.BatchNorm2d(self.dim_h * 8),\n",
        "            nn.LeakyReLU(0.2, inplace=True))\n",
        "        self.fc = nn.Linear(self.dim_h * (2 ** 3), self.n_z)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv(x)\n",
        "        \n",
        "        x = x.squeeze()\n",
        "        x = self.fc(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self, args):\n",
        "        super(Decoder, self).__init__()\n",
        "\n",
        "        self.n_channel = args['n_channel']\n",
        "        self.dim_h = args['dim_h']\n",
        "        self.n_z = args['n_z']\n",
        "\n",
        "        # first layer is fully connected\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(self.n_z, self.dim_h * 2**3 * 7 * 7),\n",
        "            nn.ReLU())\n",
        "\n",
        "        # deconvolutional filters, essentially inverse of convolutional filters\n",
        "        # H_out ​= (H_in​−1)*stride[0] − 2×padding[0] + dilation[0]×(kernel_size[0]−1) + output_padding[0] + 1\n",
        "        self.deconv = nn.Sequential(\n",
        "            nn.ConvTranspose2d(self.dim_h * 8, self.dim_h * 4, 4), #10\n",
        "            nn.BatchNorm2d(self.dim_h * 4),\n",
        "            nn.ReLU(True),\n",
        "            nn.ConvTranspose2d(self.dim_h * 4, self.dim_h * 2, 4), #13\n",
        "            nn.BatchNorm2d(self.dim_h * 2),\n",
        "            nn.ReLU(True),\n",
        "            nn.ConvTranspose2d(self.dim_h * 2, self.dim_h, 4),# 16\n",
        "            nn.BatchNorm2d(self.dim_h),\n",
        "            nn.ReLU(True),\n",
        "            nn.ConvTranspose2d(self.dim_h, 3, 4, 2, 1),# 32\n",
        "            nn.UpsamplingBilinear2d(scale_factor=7),\n",
        "            nn.Tanh())\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.fc(x)\n",
        "        x = x.view(-1, self.dim_h * 2**3, 7, 7)\n",
        "        x = self.deconv(x)\n",
        "        return x\n",
        "\n",
        "##############################################################################\n",
        "\"\"\"set models, loss functions\"\"\"\n",
        "# control which parameters are frozen / free for optimization\n",
        "def free_params(module: nn.Module):\n",
        "    for p in module.parameters():\n",
        "        p.requires_grad = True\n",
        "\n",
        "def frozen_params(module: nn.Module):\n",
        "    for p in module.parameters():\n",
        "        p.requires_grad = False\n",
        "\n",
        "def biased_get_class(X, y, c):\n",
        "    \n",
        "    xbeg = X[y == c]\n",
        "    ybeg = y[y == c]\n",
        "    \n",
        "    return xbeg, ybeg\n",
        "    #return xclass, yclass\n",
        "\n",
        "def G_SM(X, y,n_to_sample,cl):\n",
        "    n_neigh = 5\n",
        "    nn = NearestNeighbors(n_neighbors=n_neigh, n_jobs=1)\n",
        "    nn.fit(X)\n",
        "    dist, ind = nn.kneighbors(X)\n",
        "\n",
        "    # generating samples\n",
        "    base_indices = np.random.choice(list(range(len(X))),n_to_sample)\n",
        "    neighbor_indices = np.random.choice(list(range(1, n_neigh)),n_to_sample)\n",
        "\n",
        "    X_base = X[base_indices]\n",
        "    X_neighbor = X[ind[base_indices, neighbor_indices]]\n",
        "\n",
        "    samples = X_base + np.multiply(np.random.rand(n_to_sample,1),\n",
        "            X_neighbor - X_base)\n",
        "\n",
        "    #use 10 as label because 0 to 9 real classes and 1 fake/smoted = 10\n",
        "    return samples, [cl]*n_to_sample\n",
        "\n",
        "def DeepSMOTE_train(X_train, y_train, one_hot = False):\n",
        "  from torch.utils.data import TensorDataset\n",
        "  import os\n",
        "\n",
        "  max_el = np.max(X_train)\n",
        "  X_train = X_train / max_el\n",
        "  X_train = moveaxis(X_train, 3, 1)\n",
        "  if one_hot:\n",
        "    y_train = np.argmax(y_train, axis=1)\n",
        "  #X_train = X_train.astype('float32') / 255.\n",
        "  \n",
        "  batch_size = args['batch_size']\n",
        "  patience = args['patience']\n",
        "  encoder = Encoder(args)\n",
        "  decoder = Decoder(args)\n",
        "\n",
        "  device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "  print(device)\n",
        "  decoder = decoder.to(device)\n",
        "  encoder = encoder.to(device)\n",
        "\n",
        "  train_on_gpu = torch.cuda.is_available()\n",
        "\n",
        "  #decoder loss function\n",
        "  criterion = nn.MSELoss()\n",
        "  criterion = criterion.to(device)\n",
        "\n",
        "  num_workers = 0\n",
        "\n",
        "  #torch.Tensor returns float so if want long then use torch.tensor\n",
        "  tensor_x = torch.from_numpy(X_train.copy())#torch.Tensor(X_train)\n",
        "  tensor_y = torch.tensor(y_train,dtype=torch.long)\n",
        "  mnist_bal = TensorDataset(tensor_x,tensor_y) \n",
        "  train_loader = torch.utils.data.DataLoader(mnist_bal, \n",
        "      batch_size=batch_size,shuffle=True,num_workers=num_workers)\n",
        "\n",
        "  best_loss = np.inf\n",
        "\n",
        "  enc_optim = torch.optim.Adam(encoder.parameters(), lr = args['lr'])\n",
        "  dec_optim = torch.optim.Adam(decoder.parameters(), lr = args['lr'])\n",
        "\n",
        "  for epoch in range(args['epochs']):\n",
        "      train_loss = 0.0\n",
        "      tmse_loss = 0.0\n",
        "      tdiscr_loss = 0.0\n",
        "      # train for one epoch -- set nets to train mode\n",
        "      encoder.train()\n",
        "      decoder.train()\n",
        "  \n",
        "      for images,labs in train_loader:\n",
        "      \n",
        "          # zero gradients for each batch\n",
        "          encoder.zero_grad()\n",
        "          decoder.zero_grad()\n",
        "          images, labs = images.to(device), labs.to(device)\n",
        "          labsn = labs.detach().cpu().numpy()\n",
        "#            print('images shape', images.shape)\n",
        "          # run images\n",
        "          z_hat = encoder(images)\n",
        "#            print('images shape after encoding', z_hat.shape)\n",
        "      \n",
        "          x_hat = decoder(z_hat) #decoder outputs tanh\n",
        "#            print('images shape after decoding', x_hat.shape)\n",
        "          mse = criterion(x_hat,images)\n",
        "                  \n",
        "          resx = []\n",
        "          resy = []\n",
        "      \n",
        "          tc = np.random.choice(num_classes,1)\n",
        "          #tc = 9\n",
        "          xbeg = X_train[y_train == tc]\n",
        "          ybeg = y_train[y_train == tc] \n",
        "          xlen = len(xbeg)\n",
        "          nsamp = min(xlen, 100)\n",
        "          ind = np.random.choice(list(range(len(xbeg))),nsamp,replace=False)\n",
        "          xclass = xbeg[ind]\n",
        "          yclass = ybeg[ind]\n",
        "      \n",
        "          xclen = len(xclass)\n",
        "          xcminus = np.arange(1,xclen)\n",
        "          \n",
        "          xcplus = np.append(xcminus,0)\n",
        "          xcnew = (xclass[[xcplus],:])\n",
        "          xcnew = xcnew.reshape(xcnew.shape[1],xcnew.shape[2],xcnew.shape[3],xcnew.shape[4])\n",
        "      \n",
        "          xcnew = torch.Tensor(xcnew)\n",
        "          xcnew = xcnew.to(device)\n",
        "      \n",
        "          #encode xclass to feature space\n",
        "          xclass = torch.Tensor(xclass)\n",
        "          xclass = xclass.to(device)\n",
        "          xclass = encoder(xclass)\n",
        "      \n",
        "          xclass = xclass.detach().cpu().numpy()\n",
        "      \n",
        "          xc_enc = (xclass[[xcplus],:])\n",
        "          xc_enc = np.squeeze(xc_enc)\n",
        "      \n",
        "          xc_enc = torch.Tensor(xc_enc)\n",
        "          xc_enc = xc_enc.to(device)\n",
        "          \n",
        "          ximg = decoder(xc_enc)\n",
        "          \n",
        "          mse2 = criterion(ximg,xcnew)\n",
        "      \n",
        "          comb_loss = mse2 + mse\n",
        "          comb_loss.backward()\n",
        "      \n",
        "          enc_optim.step()\n",
        "          dec_optim.step()\n",
        "      \n",
        "          train_loss += comb_loss.item()*images.size(0)\n",
        "          tmse_loss += mse.item()*images.size(0)\n",
        "          tdiscr_loss += mse2.item()*images.size(0)\n",
        "\n",
        "      train_loss = train_loss/len(train_loader)\n",
        "      tmse_loss = tmse_loss/len(train_loader)\n",
        "      tdiscr_loss = tdiscr_loss/len(train_loader)\n",
        "      print('Epoch: {} \\tTrain Loss: {:.6f} \\tmse loss: {:.6f} \\tmse2 loss: {:.6f}'.format(epoch,\n",
        "              train_loss,tmse_loss,tdiscr_loss))\n",
        "      \n",
        "  \n",
        "  \n",
        "      #store the best encoder and decoder models\n",
        "      #here, /crs5 is a reference to 5 way cross validation, but is not\n",
        "      #necessary for illustration purposes\n",
        "      if train_loss < best_loss:\n",
        "          print('Saving..')\n",
        "          patience = args['patience']\n",
        "          path_enc = '/content/drive/MyDrive/PHD/Model/DeepSMOTE/32/bst_enc.pth'\n",
        "          path_dec = '/content/drive/MyDrive/PHD/Model/DeepSMOTE/32/bst_dec.pth'\n",
        "        \n",
        "          torch.save(encoder.state_dict(), path_enc)\n",
        "          torch.save(decoder.state_dict(), path_dec)\n",
        "  \n",
        "          best_loss = train_loss\n",
        "      else:\n",
        "          patience = patience - 1\n",
        "\n",
        "      if patience == 0:\n",
        "          print('Out of patience. \\n')\n",
        "          break\n",
        "\n",
        "def DeepSMOTE_Data(X_train, y_train, one_hot = False):\n",
        "  batch_size = args['batch_size']\n",
        "  max_el = np.max(X_train)\n",
        "  X_train = X_train / max_el\n",
        "  X_train = moveaxis(X_train, 3, 1)\n",
        "  if one_hot:\n",
        "    y_train = np.argmax(y_train, axis=1)\n",
        "  #Generate artificial images\n",
        "  import torch\n",
        "  np.printoptions(precision=5,suppress=True)\n",
        "\n",
        "  #path on the computer where the models are stored\n",
        "  modpth = '/content/drive/MyDrive/PHD/Model/DeepSMOTE/32/'\n",
        "\n",
        "  path_enc = modpth + '/bst_enc.pth'\n",
        "  path_dec = modpth + '/bst_dec.pth'\n",
        "  \n",
        "  train_on_gpu = torch.cuda.is_available()\n",
        "  device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "  encoder = Encoder(args)\n",
        "  encoder.load_state_dict(torch.load(path_enc), strict=False)\n",
        "  encoder = encoder.to(device)\n",
        "\n",
        "  decoder = Decoder(args)\n",
        "  decoder.load_state_dict(torch.load(path_dec), strict=False)\n",
        "  decoder = decoder.to(device)\n",
        "\n",
        "  encoder.eval()\n",
        "  decoder.eval()\n",
        "\n",
        "  resx = []\n",
        "  resy = []\n",
        "  \n",
        "  counter = Counter(y_train)\n",
        "  counter = sorted(counter.items())\n",
        "  counter = [value for _, value in counter]\n",
        "\n",
        "  for i in range(num_classes):\n",
        "      torch.cuda.empty_cache()\n",
        "\n",
        "      xclass, yclass = biased_get_class(X_train, y_train, i)\n",
        "      #encode xclass to feature space\n",
        "      xclass = torch.Tensor(xclass)\n",
        "      xclass = xclass.to(device)\n",
        "      xclass = encoder(xclass)\n",
        "          \n",
        "      xclass = xclass.detach().cpu().numpy()\n",
        "      n = np.max(counter) - counter[i]\n",
        "      if n == 0:\n",
        "        continue\n",
        "#        resx2 = []\n",
        "#        resy2 = []\n",
        "#        for j in range(batch_size, n+batch_size+1, batch_size):\n",
        "#          if j <= n:\n",
        "#            batch_size_max = batch_size\n",
        "#          elif n % batch_size != 0:\n",
        "#            batch_size_max = n%batch_size\n",
        "#          else:\n",
        "#            break\n",
        "#          xsamp, ysamp = G_SM(xclass,yclass,batch_size_max,i)\n",
        "      xsamp, ysamp = G_SM(xclass,yclass,n,i)\n",
        "      ysamp = np.array(ysamp)\n",
        "  \n",
        "      \"\"\"to generate samples for resnet\"\"\"   \n",
        "      xsamp = torch.Tensor(xsamp)\n",
        "      xsamp = xsamp.to(device)\n",
        "      ximg = decoder(xsamp)\n",
        "\n",
        "      ximn = ximg.detach().cpu().numpy()\n",
        "#        resx2.append(ximn)\n",
        "#        resy2.append(ysamp)\n",
        "#        \n",
        "#        resx2 = np.vstack(resx2)\n",
        "#        resy2 = np.hstack(resy2)\n",
        "      resx.append(ximn)\n",
        "      resy.append(ysamp)\n",
        "  \n",
        "  resx1 = np.vstack(resx)\n",
        "  resy1 = np.hstack(resy)\n",
        "  resx1 = resx1.reshape(resx1.shape[0],-1)\n",
        "  X_train = X_train.reshape(X_train.shape[0],-1)\n",
        "  X_train = np.vstack((resx1,X_train))\n",
        "  y_train = np.hstack((resy1,y_train))\n",
        "  y_train = to_categorical(y_train)\n",
        "  X_train = X_train.reshape(-1, 3, IMAGE_W, IMAGE_H)\n",
        "  X_train = moveaxis(X_train, 1, 3)\n",
        "  X_train = X_train * max_el\n",
        "  return X_train, y_train"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0jrJ33lUDkCM"
      },
      "source": [
        "#Split dataset to train and val"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e6qneWL_Bs2U"
      },
      "outputs": [],
      "source": [
        "# stratified train and rem (20%) datasets\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, stratify=y_train, random_state=1)\n",
        "\n",
        "print('Train Data: ', X_train.shape)\n",
        "print('Remaining Data: ', X_val.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8Kef4r_zxjgk"
      },
      "outputs": [],
      "source": [
        "#Data Augmentation\n",
        "dataaugment = ImageDataGenerator(\n",
        "        rotation_range=90,  # randomly rotate images in the range (degrees, 0 to 180)\n",
        "        zoom_range = 0.1, # Randomly zoom image \n",
        "        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
        "        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
        "        horizontal_flip=True,  # randomly flip images\n",
        "        vertical_flip=True,  # randomly flip images\n",
        "        shear_range = 10) \n",
        "\n",
        "dataaugment.fit(X_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B2PgksTFkOAq"
      },
      "source": [
        "#Fine Tune"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nr1jnSM7yzJc"
      },
      "outputs": [],
      "source": [
        "limit = 171\n",
        "for layer in model.layers[:limit]:\n",
        "   layer.trainable = False\n",
        "for layer in model.layers[limit:]:\n",
        "   layer.trainable = True\n",
        "\n",
        "optimizer_SGD = SGD(learning_rate=0.0001, momentum=0.9)\n",
        "model.compile(optimizer = optimizer_SGD , loss = \"categorical_crossentropy\", metrics=['accuracy', balanced_acc])\n",
        "hst2 = model.fit(train_data_batches,\n",
        "                    epochs = EPOCHS, validation_data = valid_data_batches,\n",
        "                    callbacks=[learning_rate_reduction,early_stopping_monitor, mc])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vO1aAQBmiy0K"
      },
      "outputs": [],
      "source": [
        "# summarize history for accuracy\n",
        "plt.plot(hst2.history['balanced_acc'])\n",
        "plt.plot(hst2.history['val_balanced_acc'])\n",
        "plt.title('model balance_acc after tunning')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'val'], loc='upper left')\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "UswA0co2y1wl",
        "iDRWiTnO0MGh",
        "eaK4zbtoaAaC",
        "3K908bbiYwbS",
        "kE8Ziq-BlEP4",
        "RcRGeofw-8tK",
        "cNBXx28B9yGu",
        "0jrJ33lUDkCM",
        "B2PgksTFkOAq"
      ],
      "machine_shape": "hm",
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}