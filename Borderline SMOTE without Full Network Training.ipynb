{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/heroza/Inner-Borderline-SMOTE/blob/main/Borderline%20SMOTE%20without%20Full%20Network%20Training.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Eus_4tUgfEk9",
        "outputId": "1ccb5408-fb80-478b-94c0-50085ae2686e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E_x4c0_DTkaa"
      },
      "source": [
        "#Library, atribut, and function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "nR2MJBYq-oiB"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import os\n",
        "from collections import Counter\n",
        "from pathlib import Path\n",
        "from PIL import Image\n",
        "from sklearn import preprocessing\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "from sklearn.metrics import precision_recall_fscore_support, balanced_accuracy_score, confusion_matrix, accuracy_score\n",
        "from keras.callbacks import ReduceLROnPlateau, EarlyStopping, ModelCheckpoint\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D, UpSampling2D\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.optimizers import Adam, SGD\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input, decode_predictions\n",
        "from tensorflow.keras.applications.inception_v3 import InceptionV3, preprocess_input\n",
        "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Input, Dropout, Flatten\n",
        "from tensorflow.keras.models import Model, load_model\n",
        "from keras.utils.np_utils import to_categorical\n",
        "import imblearn\n",
        "from imblearn.over_sampling import SMOTE, BorderlineSMOTE, SVMSMOTE, ADASYN, KMeansSMOTE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "9-c7Xghg4SB4"
      },
      "outputs": [],
      "source": [
        "# input image size\n",
        "IMAGE_W = 224\n",
        "IMAGE_H = 224\n",
        "IMG_SIZE = (IMAGE_W,IMAGE_H)\n",
        "num_classes = 7\n",
        "EPOCHS = 100\n",
        "BATCH_SIZE = 64\n",
        "opt_adam = Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
        "opt_SGD = SGD(learning_rate=0.001)\n",
        "the_arch = 'resnet50'\n",
        "\n",
        "#Callbacks\n",
        "best_model_fpath = '/content/drive/MyDrive/PHD/Model/best_model_attention.h5'\n",
        "last_model_fpath = '/content/drive/MyDrive/PHD/Model/last_model_attention.h5'\n",
        "mc = ModelCheckpoint(best_model_fpath, monitor='val_balanced_acc', mode='max', verbose=1, save_best_only=True)\n",
        "learning_rate_reduction = ReduceLROnPlateau(monitor='val_balanced_acc', patience=20, verbose=1, factor=0.5, min_lr=0.00001)\n",
        "early_stopping_monitor = EarlyStopping(patience=30,monitor='val_balanced_acc')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "JffFid9sOXeo"
      },
      "outputs": [],
      "source": [
        "# load train and test dataset\n",
        "def preprocess_image_input(input_images, arch = the_arch):\n",
        "  input_images = input_images.astype('float32')\n",
        "  if arch == 'inception_v3':\n",
        "    output_ims = tf.keras.applications.inception_v3.preprocess_input(input_images)\n",
        "  else:\n",
        "    output_ims = tf.keras.applications.resnet50.preprocess_input(input_images)\n",
        "  return output_ims\n",
        "\n",
        "def load_cifar10_dataset():\n",
        "  from keras.datasets import cifar10\n",
        "    # load dataset\n",
        "  (X_train, y_train), (X_val, y_val) = cifar10.load_data()\n",
        "    # one hot encode target values\n",
        "  y_train = to_categorical(y_train)\n",
        "  y_val = to_categorical(y_val)\n",
        "\n",
        "  return X_train, y_train, X_val, y_val\n",
        "\n",
        "def balanced_acc(y_true, y_pred):\n",
        "    from keras import backend as K\n",
        "\n",
        "    tensor1 = tf.math.argmax(y_true, axis=1)\n",
        "    tensor2 = tf.math.argmax(y_pred, axis=1)\n",
        "\n",
        "    cm = tf.math.confusion_matrix(tensor1, tensor2)\n",
        "    \n",
        "    diag = tf.linalg.tensor_diag_part (cm)\n",
        "    tpfn = tf.cast(K.sum(cm, axis = 1), tf.float32) + K.epsilon()\n",
        "    recall = tf.divide(tf.cast(diag, tf.float32),tpfn)\n",
        "    balanced_acc = K.mean(recall)\n",
        "    return balanced_acc\n",
        "\n",
        "def define_base_model(arch = the_arch, start_trainable_layer = 9999, attention=False):\n",
        "  #x = data_augmentation(input_tensor)\n",
        "  #x = layers.Rescaling(1.0 / 255)(input_tensor)  # Rescale inputs\n",
        "  if arch != 'dense':\n",
        "    input_tensor = Input(shape=(IMAGE_H, IMAGE_W, 3))\n",
        "    #if IMAGE_H == 32:\n",
        "      #x = UpSampling2D(size=(7,7))(input_tensor)\n",
        "    if arch == 'resnet50':\n",
        "      base_model = ResNet50(input_tensor=input_tensor, weights='imagenet', include_top=False)\n",
        "    elif arch == 'inception_v3':\n",
        "      base_model = InceptionV3(input_tensor=input_tensor, weights='imagenet', include_top=False)\n",
        "    elif arch == 'ResNet':\n",
        "      base_model = ResNet(classes ,image_shape)(input_tensor)\n",
        "    x = base_model.output\n",
        "    if attention:\n",
        "      x = Attention(1024,1024,7,8)(x)\n",
        "    x = GlobalAveragePooling2D()(x)\n",
        "    for layer in base_model.layers:\n",
        "      layer.trainable = False\n",
        "    if start_trainable_layer != 9999:\n",
        "      for layer in base_model.layers[start_trainable_layer:]:\n",
        "        layer.trainable = True\n",
        "  else:\n",
        "    input_tensor = Input(shape=(2048))\n",
        "    x = input_tensor\n",
        "  #x = Flatten()(x)\n",
        "  x = Dense(1024, activation='relu')(x)\n",
        "  #x = Dropout(0.2)(x)\n",
        "  x = Dense(512, activation='relu')(x)\n",
        "  predictions = Dense(num_classes, activation='softmax')(x)\n",
        "  model = Model(inputs=input_tensor, outputs=predictions)\n",
        "  model.compile(optimizer = opt_SGD , loss = \"categorical_crossentropy\", metrics=['accuracy', balanced_acc])\n",
        "  return model\n",
        "\n",
        "# plot diagnostic learning curves\n",
        "def summarize_diagnostics(history):\n",
        "    # plot loss\n",
        "    plt.subplot(211)\n",
        "    plt.title('Cross Entropy Loss')\n",
        "    plt.plot(history.history['loss'], color='blue', label='train')\n",
        "    plt.plot(history.history['val_loss'], color='orange', label='test')\n",
        "    # plot accuracy\n",
        "    plt.subplot(212)\n",
        "    plt.title('Classification Accuracy')\n",
        "    plt.plot(history.history['accuracy'], color='blue', label='train')\n",
        "    plt.plot(history.history['val_accuracy'], color='orange', label='test')\n",
        " \n",
        "# scale pixels\n",
        "def norm_pixels(train, test):\n",
        "    # convert from integers to floats\n",
        "    train_norm = train.astype('float32')\n",
        "    test_norm = test.astype('float32')\n",
        "    # normalize to range 0-1\n",
        "    train_norm = train_norm / 255.0\n",
        "    test_norm = test_norm / 255.0\n",
        "    # return normalized images\n",
        "    return train_norm, test_norm\n",
        "\n",
        "def load_isic2018_dataset(train_under_frac = 0):\n",
        "  df_train = pd.read_csv('/content/drive/MyDrive/PHD/Datasets/isic2018/ISIC2018_Task3_Training_GroundTruth/ISIC2018_Task3_Training_GroundTruth.csv') \n",
        "  df_val = pd.read_csv('/content/drive/MyDrive/PHD/Datasets/isic2018/ISIC2018_Task3_Validation_GroundTruth/ISIC2018_Task3_Validation_GroundTruth.csv') \n",
        "\n",
        "  #decode one hot label\n",
        "  df_train[\"Labels\"] = (df_train.iloc[:, 1:]).idxmax(axis=1)\n",
        "  df_val[\"Labels\"] = (df_val.iloc[:, 1:]).idxmax(axis=1)\n",
        "\n",
        "  #random undersampling for training dataset\n",
        "  if train_under_frac !=0:\n",
        "    df_train = df_train.drop(df_train[df_train['Labels'] == 'NV'].sample(frac=train_under_frac).index)\n",
        "\n",
        "  #drop one-hot column\n",
        "  df_train = df_train.drop(columns=['MEL', 'NV', 'BCC', 'AKIEC', 'BKL', 'DF', 'VASC'])\n",
        "  df_val = df_val.drop(columns=['MEL', 'NV', 'BCC', 'AKIEC', 'BKL', 'DF', 'VASC'])\n",
        "\n",
        "  #make filepaths of the image\n",
        "  dir_train = '/content/drive/MyDrive/PHD/Datasets/isic2018/ISIC2018_Task3_Training_Input/'\n",
        "  dir_val = '/content/drive/MyDrive/PHD/Datasets/isic2018/ISIC2018_Task3_Validation_Input/'\n",
        "  df_train['FilePaths'] = dir_train + df_train['image'] + '.jpg'\n",
        "  df_val['FilePaths'] = dir_val + df_val['image'] + '.jpg'\n",
        "  \n",
        "  #load image pixels to dataframe\n",
        "  df_train['image_px'] = df_train['FilePaths'].map(lambda x: np.asarray(Image.open(x).resize(IMG_SIZE)))\n",
        "  df_val['image_px'] = df_val['FilePaths'].map(lambda x: np.asarray(Image.open(x).resize(IMG_SIZE)))\n",
        "\n",
        "  X_train = np.asarray(df_train['image_px'].tolist())\n",
        "  X_val = np.asarray(df_val['image_px'].tolist())\n",
        "  y_train = np.array(df_train['Labels'].values)\n",
        "  y_val = np.array(df_val['Labels'].values)\n",
        "\n",
        "  label_encoder = preprocessing.LabelEncoder()\n",
        "  y_train = label_encoder.fit_transform(y_train)\n",
        "  y_val = label_encoder.fit_transform(y_val)\n",
        "  \n",
        "  y_train = to_categorical(y_train, num_classes = num_classes)\n",
        "  y_val = to_categorical(y_val, num_classes = num_classes)\n",
        "\n",
        "  return X_train, y_train, X_val, y_val\n",
        "\n",
        "def reset_dataset(df_train, df_val):\n",
        "  X_train = np.asarray(df_train['image_px'].tolist())\n",
        "  X_val = np.asarray(df_val['image_px'].tolist())\n",
        "  y_train = np.array(df_train['Labels'].values)\n",
        "  y_val = np.array(df_val['Labels'].values)\n",
        "\n",
        "  X_train = preprocess_image_input(X_train, the_arch)\n",
        "  X_val = preprocess_image_input(X_val, the_arch)\n",
        "\n",
        "  label_encoder = preprocessing.LabelEncoder()\n",
        "  y_train = label_encoder.fit_transform(y_train)\n",
        "  y_val = label_encoder.fit_transform(y_val)\n",
        "  \n",
        "  y_train = to_categorical(y_train, num_classes = num_classes)\n",
        "  y_val = to_categorical(y_val, num_classes = num_classes)\n",
        "  return X_train, y_train, X_val, y_val\n",
        "\n",
        "def SMOTE_Data(X, y, one_hot = False, k = 5, width = IMAGE_W, height = IMAGE_H, c = 3, type = 'smote'):\n",
        "  if one_hot:\n",
        "    y = np.argmax(y, axis=1)\n",
        "  if type == 'borderline':\n",
        "    sm = BorderlineSMOTE(random_state=42, k_neighbors=k)\n",
        "  elif type == 'svm':\n",
        "    sm = SVMSMOTE()\n",
        "  elif type == 'adasyn':\n",
        "    sm = ADASYN(random_state=42, n_neighbors=k)\n",
        "  elif type == 'kmeans':\n",
        "    sm = KMeansSMOTE(k_neighbors=k, kmeans_estimator=10)\n",
        "  else:\n",
        "    sm = SMOTE(random_state=42, k_neighbors=k)\n",
        "  X_resampled, y_resampled = sm.fit_resample(X.reshape((-1, width * height * c)), y)\n",
        "  X_resampled = X_resampled.reshape(-1, width, height, c)\n",
        "  if one_hot:\n",
        "    y_resampled = to_categorical(y_resampled, num_classes = num_classes)\n",
        "  else:\n",
        "    y_resampled = y_resampled.reshape(-1,1)\n",
        "  return X_resampled, y_resampled\n",
        "\n",
        "def SMOTE_Data2(X, y, one_hot = False, k = 5):\n",
        "  if one_hot:\n",
        "    y = np.argmax(y, axis=1)\n",
        "  sm = BorderlineSMOTE(random_state=42, k_neighbors=k)\n",
        "  X_resampled, y_resampled = sm.fit_resample(X, y)\n",
        "  if one_hot:\n",
        "    y_resampled = to_categorical(y_resampled, num_classes = num_classes)\n",
        "  else:\n",
        "    y_resampled = y_resampled.reshape(-1,1)\n",
        "  return X_resampled, y_resampled"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Inner-Borderline SMOTE"
      ],
      "metadata": {
        "id": "BE9FCWBe8deT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_class(X, y, c):\n",
        "    xbeg = X[y == c]\n",
        "    ybeg = y[y == c]\n",
        "    \n",
        "    return xbeg, ybeg\n",
        "def find_border(xclass, yclass, X, y, cli, n_neigh=5):\n",
        "    nn = NearestNeighbors(n_neighbors=n_neigh, n_jobs=1)\n",
        "    nn.fit(X)\n",
        "    dist, ind = nn.kneighbors(xclass)\n",
        "    ret = []\n",
        "    for i in range(len(ind)):\n",
        "      ret.append(sum(y[ind[i,j]] != cli for j in range(1,len(ind[i]))))\n",
        "    ret = np.array(ret)\n",
        "    xclass = xclass[np.logical_and(ret < (n_neigh-1),ret > ((n_neigh-1)/2))]\n",
        "    yclass = yclass[np.logical_and(ret < (n_neigh-1),ret > ((n_neigh-1)/2))]\n",
        "\n",
        "    return xclass, yclass\n",
        "def find_inner_border(xclass, yclass, X, y, cli, n_neigh=5):\n",
        "    nn = NearestNeighbors(n_neighbors=n_neigh, n_jobs=1)\n",
        "    nn.fit(X)\n",
        "    dist, ind = nn.kneighbors(xclass)\n",
        "    ret = []\n",
        "    for i in range(len(ind)):\n",
        "      ret.append(sum(y[ind[i,j]] != cli for j in range(1,len(ind[i]))))\n",
        "    ret = np.array(ret)\n",
        "    is_border = np.logical_and(ret < (n_neigh-1),ret > ((n_neigh-1)/2))\n",
        "    is_inner_border = []\n",
        "    for i in range(len(ind)):\n",
        "      is_inner_border.append(np.logical_and(not(is_border[i]), ))\n",
        "\n",
        "    return xclass, yclass\n",
        "\n",
        "def G_SM(xclass,n_to_sample,cl, n_neigh = 6):\n",
        "    \n",
        "    nn = NearestNeighbors(n_neighbors=n_neigh, n_jobs=1)\n",
        "    nn.fit(xclass)\n",
        "    dist, ind = nn.kneighbors(xclass)\n",
        "\n",
        "    # generating samples\n",
        "    base_indices = np.random.choice(list(range(len(xclass))),n_to_sample)\n",
        "    neighbor_indices = np.random.choice(list(range(1, n_neigh)),n_to_sample)\n",
        "\n",
        "    X_base = xclass[base_indices]\n",
        "    X_neighbor = xclass[ind[base_indices, neighbor_indices]]\n",
        "\n",
        "    samples = X_base + np.multiply(np.random.rand(n_to_sample,1),\n",
        "            X_neighbor - X_base)\n",
        "\n",
        "    #use 10 as label because 0 to 9 real classes and 1 fake/smoted = 10\n",
        "    return samples, [cl]*n_to_sample\n",
        "\n",
        "def Borderline_SMOTE(X_train, y_train, random_state=42, k_neighbors=5, start=0, n=4):\n",
        "  #reshape X_train\n",
        "  X_train = X_train.reshape(-1, IMAGE_W * IMAGE_H * 3)\n",
        "  #decode y_train from one-hot encoding\n",
        "  y_train = np.argmax(y_train, axis=1) \n",
        "\n",
        "  counter = Counter(y_train)\n",
        "  key_max = max(counter, key=counter.get)\n",
        "  class_max = counter[key_max]\n",
        "  resx=[]\n",
        "  resy=[]\n",
        "\n",
        "  for i in range(start,n):\n",
        "      xclass, yclass = get_class(X_train, y_train, i)\n",
        "      if xclass.shape[0] == class_max:\n",
        "        continue\n",
        "      xclass_bdr, yclass_bdr = find_border(xclass, yclass, X_train, y_train, i, n_neigh=k_neighbors)\n",
        "      n = class_max - xclass.shape[0]\n",
        "      xsamp, ysamp = G_SM(xclass_bdr,n,i, n_neigh=k_neighbors)\n",
        "      ysamp = np.array(ysamp)\n",
        "      resx.append(xsamp)\n",
        "      resy.append(ysamp)\n",
        "  \n",
        "  resx = np.vstack(resx)\n",
        "  resy = np.hstack(resy)\n",
        "  X_train = np.vstack((resx,X_train))\n",
        "  y_train = np.hstack((resy,y_train))\n",
        "  y_train = to_categorical(y_train)\n",
        "  X_train = X_train.reshape(-1, IMAGE_W, IMAGE_H, 3)\n",
        "  return X_train, y_train"
      ],
      "metadata": {
        "id": "s3UnuaKz8kzJ"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_ov, y_train_ov = Borderline_SMOTE(X_train, y_train, random_state=42, k_neighbors=4, start=0, n=7)"
      ],
      "metadata": {
        "id": "m9YF522I-HXe"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_train_ov.shape)\n",
        "print(y_train_ov.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lj-gWlzMa2CM",
        "outputId": "b3a89b73-046c-44e1-f8fd-9686f50ef2a9"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(5460, 150528)\n",
            "(5460, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_train_ov.shape)\n",
        "print(y_train_ov.shape)\n",
        "print(X_val.shape)\n",
        "print(y_val.shape)\n",
        "print('Counter train data: ', Counter(np.argmax(y_train_ov, axis=1)))\n",
        "print('Counter val data: ', Counter(np.argmax(y_val, axis=1)))"
      ],
      "metadata": {
        "id": "zF-01XxCTW32",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d5c27d55-449d-47d9-c480-08aae556304e"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(7980, 224, 224, 3)\n",
            "(7980, 7)\n",
            "(193, 224, 224, 3)\n",
            "(193, 7)\n",
            "Counter train data:  Counter({0: 1140, 1: 1140, 2: 1140, 3: 1140, 4: 1140, 6: 1140, 5: 1140})\n",
            "Counter val data:  Counter({5: 123, 2: 22, 4: 21, 1: 15, 0: 8, 6: 3, 3: 1})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5v7sLC2svMuJ"
      },
      "source": [
        "# Main"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qge6cnxQPnH6",
        "outputId": "8f3eeb91-cebd-4c3e-9504-77b90d40641a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(5321, 224, 224, 3)\n",
            "(5321, 7)\n",
            "(193, 224, 224, 3)\n",
            "(193, 7)\n",
            "Counter train data:  Counter({5: 2011, 4: 1113, 2: 1099, 1: 514, 0: 327, 6: 142, 3: 115})\n",
            "Counter val data:  Counter({5: 123, 2: 22, 4: 21, 1: 15, 0: 8, 6: 3, 3: 1})\n"
          ]
        }
      ],
      "source": [
        "path = '/content/drive/MyDrive/PHD/Datasets/isic2018/'\n",
        "df1 = pd.read_pickle(path+\"isic2018_train.pkl\")\n",
        "X_train = df1.loc[:, df1.columns != 'y_train'].to_numpy()\n",
        "X_train = X_train.reshape(-1,224,224,3)\n",
        "y_train = df1.loc[:, df1.columns == 'y_train'].to_numpy()\n",
        "y_train = to_categorical(y_train)\n",
        "\n",
        "df1 = pd.read_pickle(path+\"isic2018_val.pkl\")\n",
        "X_val = df1.loc[:, df1.columns != 'y_val'].to_numpy()\n",
        "X_val = X_val.reshape(-1,224,224,3)\n",
        "y_val = df1.loc[:, df1.columns == 'y_val'].to_numpy()\n",
        "y_val = to_categorical(y_val)\n",
        "\n",
        "print(X_train.shape)\n",
        "print(y_train.shape)\n",
        "print(X_val.shape)\n",
        "print(y_val.shape)\n",
        "print('Counter train data: ', Counter(np.argmax(y_train, axis=1)))\n",
        "print('Counter val data: ', Counter(np.argmax(y_val, axis=1)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xArGWuciBt_-",
        "outputId": "a2a8c7f4-f5a1-4af5-9a64-b272685ea624"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(14077, 32, 32, 3)\n",
            "(14077, 7)\n",
            "(193, 32, 32, 3)\n",
            "(193, 7)\n",
            "Counter train data:  Counter({5: 2011, 4: 2011, 2: 2011, 3: 2011, 0: 2011, 1: 2011, 6: 2011})\n",
            "Counter val data:  Counter({5: 123, 2: 22, 4: 21, 1: 15, 0: 8, 6: 3, 3: 1})\n"
          ]
        }
      ],
      "source": [
        "#X_train, y_train = SMOTE_Data(X_train, y_train, True)\n",
        "X_train, y_train = Borderline_SMOTE(X_train, y_train)\n",
        "print(X_train.shape)\n",
        "print(y_train.shape)\n",
        "print(X_val.shape)\n",
        "print(y_val.shape)\n",
        "print('Counter train data: ', Counter(np.argmax(y_train, axis=1)))\n",
        "print('Counter val data: ', Counter(np.argmax(y_val, axis=1)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "V7Z_nccu6QjB"
      },
      "outputs": [],
      "source": [
        "#path = '/content/drive/MyDrive/PHD/Datasets/isic2018/'\n",
        "#df1 = pd.DataFrame(X_train_ov.reshape(X_train_ov.shape[0],-1))\n",
        "#df1['y_train'] = np.argmax(y_train_ov, axis=1).tolist()\n",
        "#df2 = pd.DataFrame(X_val.reshape(X_val.shape[0],-1))\n",
        "#df2['y_val'] = np.argmax(y_val, axis=1).tolist()\n",
        "#df1.to_pickle(path+\"isic2018_train_bov.pkl\")\n",
        "#df2.to_pickle(path+\"isic2018_val.pkl\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nAMBgWqIsAAB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aae3bd98-457d-41fb-a6d5-4cd90f9c5bbc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(5321, 32, 32, 3)\n",
            "(5321, 7)\n",
            "(193, 32, 32, 3)\n",
            "(193, 7)\n",
            "Counter train data:  Counter({5: 2011, 4: 1113, 2: 1099, 1: 514, 0: 327, 6: 142, 3: 115})\n",
            "Counter val data:  Counter({5: 123, 2: 22, 4: 21, 1: 15, 0: 8, 6: 3, 3: 1})\n"
          ]
        }
      ],
      "source": [
        "print(X_train.shape)\n",
        "print(y_train.shape)\n",
        "print(X_val.shape)\n",
        "print(y_val.shape)\n",
        "print('Counter train data: ', Counter(np.argmax(y_train, axis=1)))\n",
        "print('Counter val data: ', Counter(np.argmax(y_val, axis=1)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "vIygrW81Ln4z"
      },
      "outputs": [],
      "source": [
        "# define model\n",
        "model = define_base_model('resnet50')\n",
        "#model.summary()\n",
        "hst = model.fit(X_train, y_train, epochs=EPOCHS, batch_size=BATCH_SIZE, validation_data=(X_val, y_val), verbose=1,\n",
        "                    steps_per_epoch=X_train.shape[0] // BATCH_SIZE, \n",
        "                    callbacks=[learning_rate_reduction,early_stopping_monitor, mc])\n",
        "# learning curves\n",
        "summarize_diagnostics(hst)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "vXnW3lmCgln3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "d10e8da3-b765-4fea-9b44-e7c3934fb6ee"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "# summarize history for accuracy\n",
        "plt.plot(hst.history['accuracy'])\n",
        "plt.plot(hst.history['balanced_acc'])\n",
        "plt.plot(hst.history['val_accuracy'])\n",
        "plt.plot(hst.history['val_balanced_acc'])\n",
        "plt.title('Model accuracy')\n",
        "plt.ylabel('Performance')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train accuracy', 'train balanced acc.', 'val. accuracy', 'val. balanced acc.'], loc='lower right')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rwwLiXUSG0IZ"
      },
      "outputs": [],
      "source": [
        "#Training\n",
        "#hst = model.fit(train_data_batches,\n",
        "#                    epochs = EPOCHS, validation_data = valid_data_batches,      \n",
        "                    #steps_per_epoch=X_train.shape[0] // BATCH_SIZE, \n",
        "#                    callbacks=[learning_rate_reduction,early_stopping_monitor, mc])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "icgjmi-4UIT-"
      },
      "source": [
        "#Evaluate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "SPz8NH1Oylv9"
      },
      "outputs": [],
      "source": [
        "#save last model\n",
        "model.save(last_model_fpath)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lS3ewyxO_anU",
        "outputId": "75b9e86b-4f84-4bcd-8b91-eab50d79ec0b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy on training 0.7643300131554219\n",
            "balanced accuracy on training 0.6569254510841571\n",
            "accuracy on validation 0.7564766839378239\n",
            "balanced accuracy on validation 0.4787267900508319\n",
            "Score on val data:  (0.5671734160930739, 0.4787267900508319, 0.4899698450808895, None)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ],
      "source": [
        "last_model = load_model(last_model_fpath, custom_objects={'balanced_acc' : balanced_acc})\n",
        "y_train_pred = last_model.predict(X_train)\n",
        "y_val_pred = last_model.predict(X_val)\n",
        "\n",
        "#print('accuracy on training',accuracy_score(np.argmax(y_train, axis=1), np.argmax(y_train_pred, axis=1)))\n",
        "print('accuracy on training',accuracy_score(np.argmax(y_train, axis=1), np.argmax(y_train_pred, axis=1)))\n",
        "print('balanced accuracy on training',balanced_accuracy_score(np.argmax(y_train, axis=1), np.argmax(y_train_pred, axis=1)))\n",
        "print('accuracy on validation',accuracy_score(np.argmax(y_val, axis=1), np.argmax(y_val_pred, axis=1)))\n",
        "print('balanced accuracy on validation',balanced_accuracy_score(np.argmax(y_val, axis=1), np.argmax(y_val_pred, axis=1)))\n",
        "print('Score on val data: ',precision_recall_fscore_support(np.argmax(y_val, axis=1), np.argmax(y_val_pred, axis=1), average='macro'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "W3IyWjdGG4Xq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bddd36cc-6e55-4fa6-e027-250f0f5bcef4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy on training 0.6549520766773163\n",
            "balanced accuracy on training 0.44545830706731154\n",
            "accuracy on validation 0.7461139896373057\n",
            "balanced accuracy on validation 0.3804485874172285\n",
            "Score on val data:  (0.3465418762028932, 0.3804485874172285, 0.35695752421955895, None)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ],
      "source": [
        "best_model = load_model(best_model_fpath, custom_objects={'balanced_acc' : balanced_acc})\n",
        "y_train_pred = best_model.predict(X_train)\n",
        "y_val_pred = best_model.predict(X_val)\n",
        "\n",
        "print('accuracy on training',accuracy_score(np.argmax(y_train, axis=1), np.argmax(y_train_pred, axis=1)))\n",
        "print('balanced accuracy on training',balanced_accuracy_score(np.argmax(y_train, axis=1), np.argmax(y_train_pred, axis=1)))\n",
        "print('accuracy on validation',accuracy_score(np.argmax(y_val, axis=1), np.argmax(y_val_pred, axis=1)))\n",
        "print('balanced accuracy on validation',balanced_accuracy_score(np.argmax(y_val, axis=1), np.argmax(y_val_pred, axis=1)))\n",
        "print('Score on val data: ',precision_recall_fscore_support(np.argmax(y_val, axis=1), np.argmax(y_val_pred, axis=1), average='macro'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iDRWiTnO0MGh"
      },
      "source": [
        "#Cut-off"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tGnCoIdLyDHS"
      },
      "outputs": [],
      "source": [
        "df_val_pred = pd.DataFrame(y_val_pred, columns = ['AKIEC', 'BCC', 'BKL', 'DF', 'MEL', 'NV', 'VASC'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QdyCbloQyWTC"
      },
      "outputs": [],
      "source": [
        "numbers = [float(x)/40 for x in range(11)]\n",
        "for i in numbers:\n",
        "    df_val_pred[i]= df_val_pred.MEL.map(lambda x: 1 if x > i else 0)\n",
        "df_val_pred.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G4SQsRx73kgk"
      },
      "outputs": [],
      "source": [
        "y_val_true= [1 if x == 4 else 0 for x in np.argmax(y_val, axis=1)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QcUISWFi0J05"
      },
      "outputs": [],
      "source": [
        "#num = [0.0,0.05,0.1,0.15,0.2,0.25,0.3,0.35,0.4,0.45,0.5]\n",
        "cutoff_df = pd.DataFrame( columns = ['Probability','Accuracy','Sensitivity','Specificity'])\n",
        "for i in numbers:\n",
        "    cm1 = confusion_matrix(y_val_true, df_val_pred[i])\n",
        "    total1=sum(sum(cm1))\n",
        "    Accuracy = (cm1[0,0]+cm1[1,1])/total1\n",
        "    Specificity = cm1[0,0]/(cm1[0,0]+cm1[0,1])\n",
        "    Sensitivity = cm1[1,1]/(cm1[1,0]+cm1[1,1])\n",
        "    cutoff_df.loc[i] =[ i ,Accuracy,Sensitivity,Specificity]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W31LSzov1tCt"
      },
      "outputs": [],
      "source": [
        "cutoff_df[['Accuracy','Sensitivity','Specificity']].plot()\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P6CIKT94Jqye"
      },
      "outputs": [],
      "source": [
        "i = 0.025\n",
        "cm1 = confusion_matrix(y_val_true, df_val_pred[i])\n",
        "total1=sum(sum(cm1))\n",
        "Accuracy = (cm1[0,0]+cm1[1,1])/total1\n",
        "Specificity = cm1[0,0]/(cm1[0,0]+cm1[0,1])\n",
        "Sensitivity = cm1[1,1]/(cm1[1,0]+cm1[1,1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3U2tkFebL_VC"
      },
      "outputs": [],
      "source": [
        "print('Accuracy: ', Accuracy)\n",
        "print('Sensitivity: ', Sensitivity)\n",
        "print('Specificity: ', Specificity)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eaK4zbtoaAaC"
      },
      "source": [
        "#Confusion Metric on Validation Set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YkPOFLehOmFg"
      },
      "outputs": [],
      "source": [
        "#change melanoma flag back to 4\n",
        "df_val_pred[df_val_pred[i] == 1] = 4\n",
        "#decode one-hot y_val_pred while use cut-off melanoma data\n",
        "condition = df_val_pred[i] == 4\n",
        "y_val_pred2 = np.where(condition, df_val_pred[i], np.argmax(y_val_pred, axis=1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LOVl6dWlTDLo"
      },
      "outputs": [],
      "source": [
        "print('Accuracy: ',accuracy_score(np.argmax(y_val, axis=1), y_val_pred2))\n",
        "print('Balanced accuracy: ',balanced_accuracy_score(np.argmax(y_val, axis=1), y_val_pred2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mqvYutTKRhR_"
      },
      "outputs": [],
      "source": [
        "#Get the confusion matrix\n",
        "cf_matrix = confusion_matrix(np.argmax(y_val, axis=1), y_val_pred2)\n",
        "print(cf_matrix)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gVtvW3YeaLlC"
      },
      "outputs": [],
      "source": [
        "ax = sns.heatmap(cf_matrix / cf_matrix.sum(axis=1, keepdims=True), annot=True, \n",
        "            cmap='Blues')\n",
        "\n",
        "ax.set_title('Confusion Matrix \\n');\n",
        "ax.set_xlabel('\\nPredicted')\n",
        "ax.set_ylabel('Actual ');\n",
        "\n",
        "## Ticket labels - List must be in alphabetical order\n",
        "ax.xaxis.set_ticklabels(['AKIEC', 'BCC', 'BKL', 'DF', 'MEL', 'NV', 'VASC'])\n",
        "ax.yaxis.set_ticklabels(['AKIEC', 'BCC', 'BKL', 'DF', 'MEL', 'NV', 'VASC'])\n",
        "\n",
        "plt.rcParams[\"figure.figsize\"] = (15,3)\n",
        "\n",
        "## Display the visualization of the Confusion Matrix.\n",
        "plt.xticks(rotation=45, ha='right')\n",
        "plt.yticks(rotation=0, ha='right')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ey-1yjWGeKs7"
      },
      "outputs": [],
      "source": [
        "# ordered count of rows per unique label\n",
        "#labels_count = df_val['Labels'].value_counts().sort_index()\n",
        "\n",
        "#f = plt.figure(figsize=(15, 6))\n",
        "#s = sns.barplot(x=labels_count.index,y=labels_count.values)\n",
        "#s.set_xticklabels(s.get_xticklabels(), rotation = 30)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3K908bbiYwbS"
      },
      "source": [
        "#Testing"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_test = pd.read_pickle(path+\"isic2018_test.pkl\")\n",
        "X_train = df_test.loc[:, df_test.columns != 'y_train'].to_numpy()\n",
        "X_train = X_train.reshape(-1,224,224,3)"
      ],
      "metadata": {
        "id": "cN98sOWPyT3P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NeMY2yvMYxsC"
      },
      "outputs": [],
      "source": [
        "#dir_test = '/content/drive/MyDrive/PHD/Datasets/isic2018/ISIC2018_Task3_Test_Input/'\n",
        "#filepaths = sorted( filter( lambda x: (os.path.isfile(os.path.join(dir_test, x))) and (x.endswith('.jpg')),\n",
        "#                        os.listdir(dir_test) ) )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6ic95mefkpG3"
      },
      "outputs": [],
      "source": [
        "#df_test = pd.DataFrame(filepaths, columns =['image'])\n",
        "#df_test['FilePaths'] = dir_test + df_test['image']\n",
        "#df_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NBa1TxPuY8ni"
      },
      "outputs": [],
      "source": [
        "#df_test['image_px'] = df_test['FilePaths'].map(lambda x: np.asarray(Image.open(x).resize(IMG_SIZE)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "60LYAT7VsNOZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "33bd32fe-fac9-4d07-87a9-2cce7336b6dd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1512, 224, 224, 3)\n"
          ]
        }
      ],
      "source": [
        "#X_test = np.asarray(df_test['image_px'].tolist())\n",
        "#print(np.array(X_test).shape)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#df3 = pd.DataFrame(X_test.reshape(X_test.shape[0],-1))\n",
        "#df3.to_pickle(path+\"isic2018_test.pkl\")"
      ],
      "metadata": {
        "id": "JC17MArBxhSW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cXnnIIwC4cHE"
      },
      "outputs": [],
      "source": [
        "#preprocess\n",
        "#X_test = preprocess_image_input(X_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FF7ml90JZ8FK"
      },
      "source": [
        "Calculate y_pred from training and testing for analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KeDTXdaMLmyU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a6ea64da-79f0-424f-f913-5b0bd6c66170"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1512, 2048)"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ],
      "source": [
        "X_test = model1.predict(X_test)\n",
        "X_test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dIX0AmEFNv3Y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3b58601a-b55c-4ef2-b817-f788416ed73c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Y_pred2 (1512, 7)\n"
          ]
        }
      ],
      "source": [
        "# predicting\n",
        "#CHANGE THE MODEL IF NECESSARY\n",
        "Y_test2 = model.predict(X_test)\n",
        "#Y_pred2 = model2.predict(X_test)\n",
        "print(\"Y_pred2\", Y_pred2.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7oeArO5CtxGb"
      },
      "outputs": [],
      "source": [
        "df_pred = pd.DataFrame(Y_pred2, columns = ['AKIEC', 'BCC', 'BKL', 'DF', 'MEL', 'NV', 'VASC'])\n",
        "df_pred['image'] = df_test['FilePaths'].map(lambda x: x.replace(dir_test, '').replace('.jpg', ''))\n",
        "df_pred = df_pred[['image', 'MEL', 'NV', 'BCC', 'AKIEC', 'BKL', 'DF', 'VASC']]\n",
        "df_pred.set_index(\"image\", inplace = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9ynyd8PjT589"
      },
      "outputs": [],
      "source": [
        "#update MEL data using cut-off value\n",
        "df_pred.MEL[df_pred.MEL > i] = 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fjRdONoQVMq0"
      },
      "outputs": [],
      "source": [
        "df_pred.loc[df_pred.MEL > i, ['NV', 'BCC', 'AKIEC', 'BKL', 'DF', 'VASC']] = 0"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_pred.head(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "id": "K4Iv_3s4z0R9",
        "outputId": "a7dca29b-4c36-4693-d619-9bd440e6a18f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                   MEL        NV       BCC     AKIEC       BKL        DF  \\\n",
              "image                                                                      \n",
              "ISIC_0034524  0.002193  0.930769  0.003427  0.000460  0.036592  0.004333   \n",
              "ISIC_0034525  0.122186  0.828252  0.002661  0.010148  0.009148  0.021819   \n",
              "ISIC_0034526  0.020197  0.003637  0.000938  0.028031  0.947131  0.000066   \n",
              "ISIC_0034527  0.131679  0.808747  0.000006  0.000279  0.059272  0.000017   \n",
              "ISIC_0034528  0.005777  0.840918  0.000002  0.000037  0.151937  0.001316   \n",
              "\n",
              "                      VASC  \n",
              "image                       \n",
              "ISIC_0034524  2.222793e-02  \n",
              "ISIC_0034525  5.786379e-03  \n",
              "ISIC_0034526  1.199605e-08  \n",
              "ISIC_0034527  6.856867e-08  \n",
              "ISIC_0034528  1.348875e-05  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5268f553-0d89-461e-9c87-fc1271d7e6d5\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>MEL</th>\n",
              "      <th>NV</th>\n",
              "      <th>BCC</th>\n",
              "      <th>AKIEC</th>\n",
              "      <th>BKL</th>\n",
              "      <th>DF</th>\n",
              "      <th>VASC</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>image</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>ISIC_0034524</th>\n",
              "      <td>0.002193</td>\n",
              "      <td>0.930769</td>\n",
              "      <td>0.003427</td>\n",
              "      <td>0.000460</td>\n",
              "      <td>0.036592</td>\n",
              "      <td>0.004333</td>\n",
              "      <td>2.222793e-02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ISIC_0034525</th>\n",
              "      <td>0.122186</td>\n",
              "      <td>0.828252</td>\n",
              "      <td>0.002661</td>\n",
              "      <td>0.010148</td>\n",
              "      <td>0.009148</td>\n",
              "      <td>0.021819</td>\n",
              "      <td>5.786379e-03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ISIC_0034526</th>\n",
              "      <td>0.020197</td>\n",
              "      <td>0.003637</td>\n",
              "      <td>0.000938</td>\n",
              "      <td>0.028031</td>\n",
              "      <td>0.947131</td>\n",
              "      <td>0.000066</td>\n",
              "      <td>1.199605e-08</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ISIC_0034527</th>\n",
              "      <td>0.131679</td>\n",
              "      <td>0.808747</td>\n",
              "      <td>0.000006</td>\n",
              "      <td>0.000279</td>\n",
              "      <td>0.059272</td>\n",
              "      <td>0.000017</td>\n",
              "      <td>6.856867e-08</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ISIC_0034528</th>\n",
              "      <td>0.005777</td>\n",
              "      <td>0.840918</td>\n",
              "      <td>0.000002</td>\n",
              "      <td>0.000037</td>\n",
              "      <td>0.151937</td>\n",
              "      <td>0.001316</td>\n",
              "      <td>1.348875e-05</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5268f553-0d89-461e-9c87-fc1271d7e6d5')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-5268f553-0d89-461e-9c87-fc1271d7e6d5 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-5268f553-0d89-461e-9c87-fc1271d7e6d5');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sOnjc3RJ0e4T"
      },
      "outputs": [],
      "source": [
        "df_pred.to_csv('/content/drive/MyDrive/PHD/Datasets/isic2018/response_Borderline-SMOTE.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P0MghVs0tsGw"
      },
      "source": [
        "result: 0.656"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UswA0co2y1wl"
      },
      "source": [
        "#Exp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dnqJYIONy34l"
      },
      "outputs": [],
      "source": [
        "input_tensor = Input(shape=(IMAGE_H, IMAGE_W, 3))\n",
        "base_model = ResNet50(input_shape=(224,224,3), weights='imagenet', include_top=False)\n",
        "x = base_model(input_tensor, training=False)\n",
        "x = Attention(2048,2048,7,8)(x)\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "res50 = Model(inputs=input_tensor, outputs=x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kcn8hQg3J8yP"
      },
      "outputs": [],
      "source": [
        "#Train i-last layer\n",
        "# summarize feature map shapes\n",
        "for i in range(len(model.layers)):\n",
        "    layer = model.layers[i]\n",
        "    # summarize output shape\n",
        "    print(i, layer.name, layer.output.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UA7Af2Y73FUv"
      },
      "outputs": [],
      "source": [
        "X_train = res50.predict(X_train)\n",
        "X_val = res50.predict(X_val)\n",
        "print(X_train.shape)\n",
        "print(y_train.shape)\n",
        "print(X_val.shape)\n",
        "print(y_val.shape)\n",
        "print('Counter train data: ', Counter(np.argmax(y_train, axis=1)))\n",
        "print('Counter val data: ', Counter(np.argmax(y_val, axis=1)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "krJiAb1m3QNf"
      },
      "outputs": [],
      "source": [
        "X_train, y_train = SMOTE_Data2(X_train, y_train, True)\n",
        "print(X_train.shape)\n",
        "print(y_train.shape)\n",
        "print(X_val.shape)\n",
        "print(y_val.shape)\n",
        "print('Counter train data: ', Counter(np.argmax(y_train, axis=1)))\n",
        "print('Counter val data: ', Counter(np.argmax(y_val, axis=1)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LfcFpsBwM0d4"
      },
      "source": [
        "#Attention"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C_s6OIGKM26a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 398
        },
        "outputId": "371bd24a-4bf9-491a-e0ec-78b7eb06e6d9"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-ff488085aaa5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mConv2D\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mMaxPooling2D\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mAveragePooling2D\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mBatchNormalization\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mAdd\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mZeroPadding2D\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mFlatten\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mInput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mLeakyReLU\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mSoftmax\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mReLU\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAdam\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    471\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_current_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"keras\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    472\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 473\u001b[0;31m     \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    474\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    475\u001b[0m     \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/lazy_loader.py\u001b[0m in \u001b[0;36m_load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;34m\"\"\"Load the module and insert it into the parent's globals.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0;31m# Import the target module and insert it into the parent's namespace\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m     \u001b[0mmodule\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimportlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimport_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_module_globals\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_local_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/importlib/__init__.py\u001b[0m in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m    125\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m             \u001b[0mlevel\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_bootstrap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gcd_import\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpackage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;31m# See b/110718070#comment18 for more details about this import.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_layer\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mInput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/models.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv2\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmetrics\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmetrics_module\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0moptimizer_v1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfunctional\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/metrics.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mwarnings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mactivations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbase_layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/activations.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0madvanced_activations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgeneric_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdeserialize_keras_object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgeneric_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mserialize_keras_object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/layers/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_spec\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mInputSpec\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_layer\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLayer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_preprocessing_layer\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPreprocessingLayer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;31m# Image preprocessing layers.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/base_preprocessing_layer.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mabc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdata_adapter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_layer\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLayer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mversion_utils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m   \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m  \u001b[0;31m# pylint: disable=g-import-not-at-top\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m   \u001b[0mpd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tester\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 179\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtesting\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    180\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/testing.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m from pandas._testing import (\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0massert_extension_array_equal\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0massert_frame_equal\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/_testing/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    946\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    947\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 948\u001b[0;31m \u001b[0mcython_table\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommon\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cython_table\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    949\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    950\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: module 'pandas' has no attribute 'core'"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow.keras as tk\n",
        "from tensorflow.keras.layers import Conv2D,MaxPooling2D,AveragePooling2D,BatchNormalization,Add,ZeroPadding2D,Flatten,Dense,Input,LeakyReLU,Softmax,ReLU\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.models import Model\n",
        "import numpy as np\n",
        "import pickle\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "\n",
        "class Attention(tk.layers.Layer):\n",
        "    \n",
        "    def __init__(self,input_channels,output_channel,kernel_size,groups):\n",
        "        super().__init__()\n",
        "        self.input_channels = input_channels\n",
        "        self.output_channel = output_channel    \n",
        "        self.kernel_size = kernel_size\n",
        "        self.stride = 1\n",
        "        self.groups = groups\n",
        "\n",
        "        assert output_channel % groups == 0\n",
        "        \n",
        "        self.rel_h = tk.backend.variable(lambda : tk.backend.truncated_normal((1,1,kernel_size,1,output_channel//2),stddev = 0.1)) \n",
        "        #output_channels//2 is the number of channels on which the relative position will be considered,1 denotes the number of those filters and the one after that too and (kernel_size,1) denotes the size of that filter\n",
        "        self.rel_w = tk.backend.variable(lambda : tk.backend.truncated_normal((1,1,1,kernel_size,output_channel//2),stddev = 0.1)) \n",
        "\n",
        "        self.key_weights = Conv2D(self.output_channel,kernel_size = 1,strides = self.stride)\n",
        "        self.query_weights = Conv2D(self.output_channel,kernel_size = 1,strides = self.stride)\n",
        "        self.value_weights = Conv2D(self.output_channel,kernel_size = 1,strides = self.stride)\n",
        "\n",
        "    def call(self,x):\n",
        "        \n",
        "        batch,height,width,channels = x.shape\n",
        "        x_padded = ZeroPadding2D(padding=(self.kernel_size//2,self.kernel_size//2))(x)\n",
        "        query = self.query_weights(x)\n",
        "        value = self.value_weights(x_padded)\n",
        "        key = self.key_weights(x_padded)\n",
        "        #key,query and value will have the shape of (batch,height,width,depth)\n",
        "        keys = tf.image.extract_patches(images = key,sizes = [1,self.kernel_size,self.kernel_size,1],strides = [1,self.stride,self.stride,1],rates = [1,1,1,1], padding = \"VALID\")\n",
        "        value = tf.image.extract_patches(images = value,sizes = [1,self.kernel_size,self.kernel_size,1],strides = [1,self.stride,self.stride,1],rates = [1,1,1,1], padding = \"VALID\")\n",
        "        no_of_kernels = key.shape[-2] - self.kernel_size + 1\n",
        "        keys = tf.reshape(keys,shape = (-1,no_of_kernels, no_of_kernels,self.kernel_size,self.kernel_size,self.output_channel))\n",
        "        key_split_h,key_split_w = tf.split(keys,num_or_size_splits = 2,axis = -1)\n",
        "        key_with_rel = tk.layers.concatenate([key_split_h + self.rel_h,key_split_w + self.rel_w],axis = -1) \n",
        "        \n",
        "        #reshaping the query and key\n",
        "        key_with_rel = tf.reshape(key_with_rel,(-1,self.groups,no_of_kernels,no_of_kernels,self.kernel_size*self.kernel_size,self.output_channel//self.groups))\n",
        "        query  = tf.reshape(query,(-1,self.groups,no_of_kernels,no_of_kernels,1,self.output_channel//self.groups))        \n",
        "        value = tf.reshape(value,(-1,self.groups,no_of_kernels,no_of_kernels,self.kernel_size*self.kernel_size,self.output_channel//self.groups))\n",
        "        \n",
        "        #multiplication  of key and query\n",
        "        #assert key_with_rel.shape == query.shape        \n",
        "        key_prod_query = query*key_with_rel\n",
        "        \n",
        "        # Now the function is passed through the softmax and is multiplied with the values\n",
        "        s = Softmax(axis = -2)(key_prod_query)\n",
        "        y = tf.einsum('bnchwk,bnchwk->bnchk',s,value)\n",
        "        y = tf.reshape(y,(-1,height,width,self.output_channel))\n",
        "        return y\n",
        "\n",
        "    def get_config(self):\n",
        "        config = super().get_config().copy()\n",
        "        config.update({\n",
        "            \"input_channels\": self.input_channels, \n",
        "            \"output_channel\": self.output_channel, \n",
        "            \"kernel_size\": self.kernel_size, \n",
        "            \"stride\": self.stride, \n",
        "            \"groups\": self.groups, \n",
        "            \"rel_h\": self.rel_h, \n",
        "            \"rel_w\": self.rel_w, \n",
        "            \"key_weights\": self.key_weights, \n",
        "            \"query_weights\": self.query_weights, \n",
        "            \"value_weights\": self.value_weights\n",
        "        })\n",
        "        return config\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kE8Ziq-BlEP4"
      },
      "source": [
        "#Oversampling on feature map level"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "Lm05Zet_B5am",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "75eed14b-4b95-42ee-de5a-2d467d83cd14"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 input_1 [(None, 224, 224, 3)] False\n",
            "1 conv1_pad (None, 230, 230, 3) False\n",
            "2 conv1_conv (None, 112, 112, 64) False\n",
            "3 conv1_bn (None, 112, 112, 64) False\n",
            "4 conv1_relu (None, 112, 112, 64) False\n",
            "5 pool1_pad (None, 114, 114, 64) False\n",
            "6 pool1_pool (None, 56, 56, 64) False\n",
            "7 conv2_block1_1_conv (None, 56, 56, 64) False\n",
            "8 conv2_block1_1_bn (None, 56, 56, 64) False\n",
            "9 conv2_block1_1_relu (None, 56, 56, 64) False\n",
            "10 conv2_block1_2_conv (None, 56, 56, 64) False\n",
            "11 conv2_block1_2_bn (None, 56, 56, 64) False\n",
            "12 conv2_block1_2_relu (None, 56, 56, 64) False\n",
            "13 conv2_block1_0_conv (None, 56, 56, 256) False\n",
            "14 conv2_block1_3_conv (None, 56, 56, 256) False\n",
            "15 conv2_block1_0_bn (None, 56, 56, 256) False\n",
            "16 conv2_block1_3_bn (None, 56, 56, 256) False\n",
            "17 conv2_block1_add (None, 56, 56, 256) False\n",
            "18 conv2_block1_out (None, 56, 56, 256) False\n",
            "19 conv2_block2_1_conv (None, 56, 56, 64) False\n",
            "20 conv2_block2_1_bn (None, 56, 56, 64) False\n",
            "21 conv2_block2_1_relu (None, 56, 56, 64) False\n",
            "22 conv2_block2_2_conv (None, 56, 56, 64) False\n",
            "23 conv2_block2_2_bn (None, 56, 56, 64) False\n",
            "24 conv2_block2_2_relu (None, 56, 56, 64) False\n",
            "25 conv2_block2_3_conv (None, 56, 56, 256) False\n",
            "26 conv2_block2_3_bn (None, 56, 56, 256) False\n",
            "27 conv2_block2_add (None, 56, 56, 256) False\n",
            "28 conv2_block2_out (None, 56, 56, 256) False\n",
            "29 conv2_block3_1_conv (None, 56, 56, 64) False\n",
            "30 conv2_block3_1_bn (None, 56, 56, 64) False\n",
            "31 conv2_block3_1_relu (None, 56, 56, 64) False\n",
            "32 conv2_block3_2_conv (None, 56, 56, 64) False\n",
            "33 conv2_block3_2_bn (None, 56, 56, 64) False\n",
            "34 conv2_block3_2_relu (None, 56, 56, 64) False\n",
            "35 conv2_block3_3_conv (None, 56, 56, 256) False\n",
            "36 conv2_block3_3_bn (None, 56, 56, 256) False\n",
            "37 conv2_block3_add (None, 56, 56, 256) False\n",
            "38 conv2_block3_out (None, 56, 56, 256) False\n",
            "39 conv3_block1_1_conv (None, 28, 28, 128) False\n",
            "40 conv3_block1_1_bn (None, 28, 28, 128) False\n",
            "41 conv3_block1_1_relu (None, 28, 28, 128) False\n",
            "42 conv3_block1_2_conv (None, 28, 28, 128) False\n",
            "43 conv3_block1_2_bn (None, 28, 28, 128) False\n",
            "44 conv3_block1_2_relu (None, 28, 28, 128) False\n",
            "45 conv3_block1_0_conv (None, 28, 28, 512) False\n",
            "46 conv3_block1_3_conv (None, 28, 28, 512) False\n",
            "47 conv3_block1_0_bn (None, 28, 28, 512) False\n",
            "48 conv3_block1_3_bn (None, 28, 28, 512) False\n",
            "49 conv3_block1_add (None, 28, 28, 512) False\n",
            "50 conv3_block1_out (None, 28, 28, 512) False\n",
            "51 conv3_block2_1_conv (None, 28, 28, 128) False\n",
            "52 conv3_block2_1_bn (None, 28, 28, 128) False\n",
            "53 conv3_block2_1_relu (None, 28, 28, 128) False\n",
            "54 conv3_block2_2_conv (None, 28, 28, 128) False\n",
            "55 conv3_block2_2_bn (None, 28, 28, 128) False\n",
            "56 conv3_block2_2_relu (None, 28, 28, 128) False\n",
            "57 conv3_block2_3_conv (None, 28, 28, 512) False\n",
            "58 conv3_block2_3_bn (None, 28, 28, 512) False\n",
            "59 conv3_block2_add (None, 28, 28, 512) False\n",
            "60 conv3_block2_out (None, 28, 28, 512) False\n",
            "61 conv3_block3_1_conv (None, 28, 28, 128) False\n",
            "62 conv3_block3_1_bn (None, 28, 28, 128) False\n",
            "63 conv3_block3_1_relu (None, 28, 28, 128) False\n",
            "64 conv3_block3_2_conv (None, 28, 28, 128) False\n",
            "65 conv3_block3_2_bn (None, 28, 28, 128) False\n",
            "66 conv3_block3_2_relu (None, 28, 28, 128) False\n",
            "67 conv3_block3_3_conv (None, 28, 28, 512) False\n",
            "68 conv3_block3_3_bn (None, 28, 28, 512) False\n",
            "69 conv3_block3_add (None, 28, 28, 512) False\n",
            "70 conv3_block3_out (None, 28, 28, 512) False\n",
            "71 conv3_block4_1_conv (None, 28, 28, 128) False\n",
            "72 conv3_block4_1_bn (None, 28, 28, 128) False\n",
            "73 conv3_block4_1_relu (None, 28, 28, 128) False\n",
            "74 conv3_block4_2_conv (None, 28, 28, 128) False\n",
            "75 conv3_block4_2_bn (None, 28, 28, 128) False\n",
            "76 conv3_block4_2_relu (None, 28, 28, 128) False\n",
            "77 conv3_block4_3_conv (None, 28, 28, 512) False\n",
            "78 conv3_block4_3_bn (None, 28, 28, 512) False\n",
            "79 conv3_block4_add (None, 28, 28, 512) False\n",
            "80 conv3_block4_out (None, 28, 28, 512) False\n",
            "81 conv4_block1_1_conv (None, 14, 14, 256) False\n",
            "82 conv4_block1_1_bn (None, 14, 14, 256) False\n",
            "83 conv4_block1_1_relu (None, 14, 14, 256) False\n",
            "84 conv4_block1_2_conv (None, 14, 14, 256) False\n",
            "85 conv4_block1_2_bn (None, 14, 14, 256) False\n",
            "86 conv4_block1_2_relu (None, 14, 14, 256) False\n",
            "87 conv4_block1_0_conv (None, 14, 14, 1024) False\n",
            "88 conv4_block1_3_conv (None, 14, 14, 1024) False\n",
            "89 conv4_block1_0_bn (None, 14, 14, 1024) False\n",
            "90 conv4_block1_3_bn (None, 14, 14, 1024) False\n",
            "91 conv4_block1_add (None, 14, 14, 1024) False\n",
            "92 conv4_block1_out (None, 14, 14, 1024) False\n",
            "93 conv4_block2_1_conv (None, 14, 14, 256) False\n",
            "94 conv4_block2_1_bn (None, 14, 14, 256) False\n",
            "95 conv4_block2_1_relu (None, 14, 14, 256) False\n",
            "96 conv4_block2_2_conv (None, 14, 14, 256) False\n",
            "97 conv4_block2_2_bn (None, 14, 14, 256) False\n",
            "98 conv4_block2_2_relu (None, 14, 14, 256) False\n",
            "99 conv4_block2_3_conv (None, 14, 14, 1024) False\n",
            "100 conv4_block2_3_bn (None, 14, 14, 1024) False\n",
            "101 conv4_block2_add (None, 14, 14, 1024) False\n",
            "102 conv4_block2_out (None, 14, 14, 1024) False\n",
            "103 conv4_block3_1_conv (None, 14, 14, 256) False\n",
            "104 conv4_block3_1_bn (None, 14, 14, 256) False\n",
            "105 conv4_block3_1_relu (None, 14, 14, 256) False\n",
            "106 conv4_block3_2_conv (None, 14, 14, 256) False\n",
            "107 conv4_block3_2_bn (None, 14, 14, 256) False\n",
            "108 conv4_block3_2_relu (None, 14, 14, 256) False\n",
            "109 conv4_block3_3_conv (None, 14, 14, 1024) False\n",
            "110 conv4_block3_3_bn (None, 14, 14, 1024) False\n",
            "111 conv4_block3_add (None, 14, 14, 1024) False\n",
            "112 conv4_block3_out (None, 14, 14, 1024) False\n",
            "113 conv4_block4_1_conv (None, 14, 14, 256) False\n",
            "114 conv4_block4_1_bn (None, 14, 14, 256) False\n",
            "115 conv4_block4_1_relu (None, 14, 14, 256) False\n",
            "116 conv4_block4_2_conv (None, 14, 14, 256) False\n",
            "117 conv4_block4_2_bn (None, 14, 14, 256) False\n",
            "118 conv4_block4_2_relu (None, 14, 14, 256) False\n",
            "119 conv4_block4_3_conv (None, 14, 14, 1024) False\n",
            "120 conv4_block4_3_bn (None, 14, 14, 1024) False\n",
            "121 conv4_block4_add (None, 14, 14, 1024) False\n",
            "122 conv4_block4_out (None, 14, 14, 1024) False\n",
            "123 conv4_block5_1_conv (None, 14, 14, 256) False\n",
            "124 conv4_block5_1_bn (None, 14, 14, 256) False\n",
            "125 conv4_block5_1_relu (None, 14, 14, 256) False\n",
            "126 conv4_block5_2_conv (None, 14, 14, 256) False\n",
            "127 conv4_block5_2_bn (None, 14, 14, 256) False\n",
            "128 conv4_block5_2_relu (None, 14, 14, 256) False\n",
            "129 conv4_block5_3_conv (None, 14, 14, 1024) False\n",
            "130 conv4_block5_3_bn (None, 14, 14, 1024) False\n",
            "131 conv4_block5_add (None, 14, 14, 1024) False\n",
            "132 conv4_block5_out (None, 14, 14, 1024) False\n",
            "133 conv4_block6_1_conv (None, 14, 14, 256) False\n",
            "134 conv4_block6_1_bn (None, 14, 14, 256) False\n",
            "135 conv4_block6_1_relu (None, 14, 14, 256) False\n",
            "136 conv4_block6_2_conv (None, 14, 14, 256) False\n",
            "137 conv4_block6_2_bn (None, 14, 14, 256) False\n",
            "138 conv4_block6_2_relu (None, 14, 14, 256) False\n",
            "139 conv4_block6_3_conv (None, 14, 14, 1024) False\n",
            "140 conv4_block6_3_bn (None, 14, 14, 1024) False\n",
            "141 conv4_block6_add (None, 14, 14, 1024) False\n",
            "142 conv4_block6_out (None, 14, 14, 1024) False\n",
            "143 conv5_block1_1_conv (None, 7, 7, 512) False\n",
            "144 conv5_block1_1_bn (None, 7, 7, 512) False\n",
            "145 conv5_block1_1_relu (None, 7, 7, 512) False\n",
            "146 conv5_block1_2_conv (None, 7, 7, 512) False\n",
            "147 conv5_block1_2_bn (None, 7, 7, 512) False\n",
            "148 conv5_block1_2_relu (None, 7, 7, 512) False\n",
            "149 conv5_block1_0_conv (None, 7, 7, 2048) False\n",
            "150 conv5_block1_3_conv (None, 7, 7, 2048) False\n",
            "151 conv5_block1_0_bn (None, 7, 7, 2048) False\n",
            "152 conv5_block1_3_bn (None, 7, 7, 2048) False\n",
            "153 conv5_block1_add (None, 7, 7, 2048) False\n",
            "154 conv5_block1_out (None, 7, 7, 2048) False\n",
            "155 conv5_block2_1_conv (None, 7, 7, 512) False\n",
            "156 conv5_block2_1_bn (None, 7, 7, 512) False\n",
            "157 conv5_block2_1_relu (None, 7, 7, 512) False\n",
            "158 conv5_block2_2_conv (None, 7, 7, 512) False\n",
            "159 conv5_block2_2_bn (None, 7, 7, 512) False\n",
            "160 conv5_block2_2_relu (None, 7, 7, 512) False\n",
            "161 conv5_block2_3_conv (None, 7, 7, 2048) False\n",
            "162 conv5_block2_3_bn (None, 7, 7, 2048) False\n",
            "163 conv5_block2_add (None, 7, 7, 2048) False\n",
            "164 conv5_block2_out (None, 7, 7, 2048) False\n",
            "165 conv5_block3_1_conv (None, 7, 7, 512) False\n",
            "166 conv5_block3_1_bn (None, 7, 7, 512) False\n",
            "167 conv5_block3_1_relu (None, 7, 7, 512) False\n",
            "168 conv5_block3_2_conv (None, 7, 7, 512) False\n",
            "169 conv5_block3_2_bn (None, 7, 7, 512) False\n",
            "170 conv5_block3_2_relu (None, 7, 7, 512) False\n",
            "171 conv5_block3_3_conv (None, 7, 7, 2048) False\n",
            "172 conv5_block3_3_bn (None, 7, 7, 2048) False\n",
            "173 conv5_block3_add (None, 7, 7, 2048) False\n",
            "174 conv5_block3_out (None, 7, 7, 2048) False\n",
            "175 global_average_pooling2d (None, 2048) True\n",
            "176 dense (None, 1024) True\n",
            "177 dense_1 (None, 512) True\n",
            "178 dense_2 (None, 7) True\n"
          ]
        }
      ],
      "source": [
        "for i in range(len(model.layers)):\n",
        "  layer = model.layers[i]\n",
        "  print(i, layer.name, layer.output_shape, layer.trainable)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "KqeSic6NmLsR"
      },
      "outputs": [],
      "source": [
        "# redefine model to output right after the first hidden layer\n",
        "end = 175\n",
        "model1 = Model(inputs=model.inputs, outputs=model.layers[end].output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "ZVHYG9Rwm28i"
      },
      "outputs": [],
      "source": [
        "# get feature map for first hidden layer\n",
        "X_train_fm = model1.predict(X_train)\n",
        "X_val_fm = model1.predict(X_val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "19hK7aQNeAQo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7c904b63-58b6-480a-a7d9-d5c1746b8d64"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(14077, 2048)\n",
            "(14077, 7)\n",
            "(193, 2048)\n",
            "(193, 7)\n",
            "Counter train data:  Counter({5: 2011, 4: 2011, 2: 2011, 3: 2011, 0: 2011, 1: 2011, 6: 2011})\n",
            "Counter val data:  Counter({5: 123, 2: 22, 4: 21, 1: 15, 0: 8, 6: 3, 3: 1})\n"
          ]
        }
      ],
      "source": [
        "X_train_fm_ov, y_train_ov = SMOTE_Data2(X_train_fm, y_train, True, 5)\n",
        "print(X_train_fm_ov.shape)\n",
        "print(y_train_ov.shape)\n",
        "print(X_val_fm.shape)\n",
        "print(y_val.shape)\n",
        "print('Counter train data: ', Counter(np.argmax(y_train_ov, axis=1)))\n",
        "print('Counter val data: ', Counter(np.argmax(y_val, axis=1)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "5qP4iyYcnAYa"
      },
      "outputs": [],
      "source": [
        "model2 = Model(inputs=model.layers[end+1].input, outputs=model.layers[len(model.layers)-1].output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "Pzdjs0WbvDB0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a0e42ab8-f09e-4f08-e241-697e74058789"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "214/219 [============================>.] - ETA: 0s - loss: 1.5150 - accuracy: 0.4671 - balanced_acc: 0.4667\n",
            "Epoch 1: val_balanced_acc improved from -inf to 0.20193, saving model to /content/drive/MyDrive/PHD/Model/Feature-Map-Ov/best_model_no.h5\n",
            "219/219 [==============================] - 2s 5ms/step - loss: 1.5086 - accuracy: 0.4701 - balanced_acc: 0.4692 - val_loss: 1.2457 - val_accuracy: 0.5648 - val_balanced_acc: 0.2019 - lr: 0.0010\n",
            "Epoch 2/100\n",
            "215/219 [============================>.] - ETA: 0s - loss: 1.1266 - accuracy: 0.6264 - balanced_acc: 0.6302\n",
            "Epoch 2: val_balanced_acc improved from 0.20193 to 0.29290, saving model to /content/drive/MyDrive/PHD/Model/Feature-Map-Ov/best_model_no.h5\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 1.1252 - accuracy: 0.6266 - balanced_acc: 0.6307 - val_loss: 1.1130 - val_accuracy: 0.5959 - val_balanced_acc: 0.2929 - lr: 0.0010\n",
            "Epoch 3/100\n",
            "218/219 [============================>.] - ETA: 0s - loss: 0.9753 - accuracy: 0.6722 - balanced_acc: 0.6708\n",
            "Epoch 3: val_balanced_acc improved from 0.29290 to 0.33117, saving model to /content/drive/MyDrive/PHD/Model/Feature-Map-Ov/best_model_no.h5\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.9749 - accuracy: 0.6723 - balanced_acc: 0.6708 - val_loss: 0.9958 - val_accuracy: 0.6477 - val_balanced_acc: 0.3312 - lr: 0.0010\n",
            "Epoch 4/100\n",
            "213/219 [============================>.] - ETA: 0s - loss: 0.8849 - accuracy: 0.7025 - balanced_acc: 0.7037\n",
            "Epoch 4: val_balanced_acc improved from 0.33117 to 0.36331, saving model to /content/drive/MyDrive/PHD/Model/Feature-Map-Ov/best_model_no.h5\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.8829 - accuracy: 0.7034 - balanced_acc: 0.7049 - val_loss: 0.9884 - val_accuracy: 0.6580 - val_balanced_acc: 0.3633 - lr: 0.0010\n",
            "Epoch 5/100\n",
            "210/219 [===========================>..] - ETA: 0s - loss: 0.8198 - accuracy: 0.7182 - balanced_acc: 0.7217\n",
            "Epoch 5: val_balanced_acc improved from 0.36331 to 0.40003, saving model to /content/drive/MyDrive/PHD/Model/Feature-Map-Ov/best_model_no.h5\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.8189 - accuracy: 0.7185 - balanced_acc: 0.7220 - val_loss: 0.9592 - val_accuracy: 0.6684 - val_balanced_acc: 0.4000 - lr: 0.0010\n",
            "Epoch 6/100\n",
            "215/219 [============================>.] - ETA: 0s - loss: 0.7730 - accuracy: 0.7365 - balanced_acc: 0.7382\n",
            "Epoch 6: val_balanced_acc did not improve from 0.40003\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.7723 - accuracy: 0.7363 - balanced_acc: 0.7381 - val_loss: 0.8560 - val_accuracy: 0.6995 - val_balanced_acc: 0.3974 - lr: 0.0010\n",
            "Epoch 7/100\n",
            "212/219 [============================>.] - ETA: 0s - loss: 0.7319 - accuracy: 0.7506 - balanced_acc: 0.7497\n",
            "Epoch 7: val_balanced_acc improved from 0.40003 to 0.41540, saving model to /content/drive/MyDrive/PHD/Model/Feature-Map-Ov/best_model_no.h5\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.7304 - accuracy: 0.7509 - balanced_acc: 0.7502 - val_loss: 0.9071 - val_accuracy: 0.6995 - val_balanced_acc: 0.4154 - lr: 0.0010\n",
            "Epoch 8/100\n",
            "213/219 [============================>.] - ETA: 0s - loss: 0.6973 - accuracy: 0.7640 - balanced_acc: 0.7631\n",
            "Epoch 8: val_balanced_acc improved from 0.41540 to 0.44180, saving model to /content/drive/MyDrive/PHD/Model/Feature-Map-Ov/best_model_no.h5\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.6979 - accuracy: 0.7639 - balanced_acc: 0.7631 - val_loss: 0.8526 - val_accuracy: 0.7098 - val_balanced_acc: 0.4418 - lr: 0.0010\n",
            "Epoch 9/100\n",
            "212/219 [============================>.] - ETA: 0s - loss: 0.6670 - accuracy: 0.7770 - balanced_acc: 0.7755\n",
            "Epoch 9: val_balanced_acc improved from 0.44180 to 0.44783, saving model to /content/drive/MyDrive/PHD/Model/Feature-Map-Ov/best_model_no.h5\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.6678 - accuracy: 0.7769 - balanced_acc: 0.7758 - val_loss: 0.8521 - val_accuracy: 0.7098 - val_balanced_acc: 0.4478 - lr: 0.0010\n",
            "Epoch 10/100\n",
            "215/219 [============================>.] - ETA: 0s - loss: 0.6417 - accuracy: 0.7844 - balanced_acc: 0.7839\n",
            "Epoch 10: val_balanced_acc did not improve from 0.44783\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.6430 - accuracy: 0.7835 - balanced_acc: 0.7833 - val_loss: 0.8257 - val_accuracy: 0.7047 - val_balanced_acc: 0.4367 - lr: 0.0010\n",
            "Epoch 11/100\n",
            "207/219 [===========================>..] - ETA: 0s - loss: 0.6209 - accuracy: 0.7946 - balanced_acc: 0.7955\n",
            "Epoch 11: val_balanced_acc did not improve from 0.44783\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.6205 - accuracy: 0.7942 - balanced_acc: 0.7953 - val_loss: 0.8221 - val_accuracy: 0.7047 - val_balanced_acc: 0.4424 - lr: 0.0010\n",
            "Epoch 12/100\n",
            "217/219 [============================>.] - ETA: 0s - loss: 0.6005 - accuracy: 0.8034 - balanced_acc: 0.8022\n",
            "Epoch 12: val_balanced_acc did not improve from 0.44783\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.6006 - accuracy: 0.8033 - balanced_acc: 0.8020 - val_loss: 0.8114 - val_accuracy: 0.6995 - val_balanced_acc: 0.4134 - lr: 0.0010\n",
            "Epoch 13/100\n",
            "215/219 [============================>.] - ETA: 0s - loss: 0.5813 - accuracy: 0.8085 - balanced_acc: 0.8081\n",
            "Epoch 13: val_balanced_acc improved from 0.44783 to 0.45331, saving model to /content/drive/MyDrive/PHD/Model/Feature-Map-Ov/best_model_no.h5\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.5814 - accuracy: 0.8088 - balanced_acc: 0.8086 - val_loss: 0.8435 - val_accuracy: 0.6995 - val_balanced_acc: 0.4533 - lr: 0.0010\n",
            "Epoch 14/100\n",
            "219/219 [==============================] - ETA: 0s - loss: 0.5637 - accuracy: 0.8142 - balanced_acc: 0.8150\n",
            "Epoch 14: val_balanced_acc did not improve from 0.45331\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.5637 - accuracy: 0.8142 - balanced_acc: 0.8150 - val_loss: 0.8188 - val_accuracy: 0.7098 - val_balanced_acc: 0.4470 - lr: 0.0010\n",
            "Epoch 15/100\n",
            "214/219 [============================>.] - ETA: 0s - loss: 0.5485 - accuracy: 0.8228 - balanced_acc: 0.8227\n",
            "Epoch 15: val_balanced_acc did not improve from 0.45331\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.5491 - accuracy: 0.8221 - balanced_acc: 0.8216 - val_loss: 0.8329 - val_accuracy: 0.6943 - val_balanced_acc: 0.4485 - lr: 0.0010\n",
            "Epoch 16/100\n",
            "214/219 [============================>.] - ETA: 0s - loss: 0.5320 - accuracy: 0.8288 - balanced_acc: 0.8272\n",
            "Epoch 16: val_balanced_acc did not improve from 0.45331\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.5326 - accuracy: 0.8284 - balanced_acc: 0.8269 - val_loss: 0.7685 - val_accuracy: 0.7098 - val_balanced_acc: 0.4425 - lr: 0.0010\n",
            "Epoch 17/100\n",
            "212/219 [============================>.] - ETA: 0s - loss: 0.5251 - accuracy: 0.8327 - balanced_acc: 0.8333\n",
            "Epoch 17: val_balanced_acc did not improve from 0.45331\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.5231 - accuracy: 0.8339 - balanced_acc: 0.8344 - val_loss: 0.7949 - val_accuracy: 0.7047 - val_balanced_acc: 0.4515 - lr: 0.0010\n",
            "Epoch 18/100\n",
            "208/219 [===========================>..] - ETA: 0s - loss: 0.5050 - accuracy: 0.8398 - balanced_acc: 0.8378\n",
            "Epoch 18: val_balanced_acc did not improve from 0.45331\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.5059 - accuracy: 0.8391 - balanced_acc: 0.8375 - val_loss: 0.8086 - val_accuracy: 0.6995 - val_balanced_acc: 0.4455 - lr: 0.0010\n",
            "Epoch 19/100\n",
            "206/219 [===========================>..] - ETA: 0s - loss: 0.4922 - accuracy: 0.8455 - balanced_acc: 0.8451\n",
            "Epoch 19: val_balanced_acc did not improve from 0.45331\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.4918 - accuracy: 0.8452 - balanced_acc: 0.8450 - val_loss: 0.7965 - val_accuracy: 0.7047 - val_balanced_acc: 0.4467 - lr: 0.0010\n",
            "Epoch 20/100\n",
            "219/219 [==============================] - ETA: 0s - loss: 0.4867 - accuracy: 0.8458 - balanced_acc: 0.8430\n",
            "Epoch 20: val_balanced_acc improved from 0.45331 to 0.45400, saving model to /content/drive/MyDrive/PHD/Model/Feature-Map-Ov/best_model_no.h5\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.4867 - accuracy: 0.8458 - balanced_acc: 0.8430 - val_loss: 0.7540 - val_accuracy: 0.7254 - val_balanced_acc: 0.4540 - lr: 0.0010\n",
            "Epoch 21/100\n",
            "219/219 [==============================] - ETA: 0s - loss: 0.4730 - accuracy: 0.8515 - balanced_acc: 0.8510\n",
            "Epoch 21: val_balanced_acc did not improve from 0.45400\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.4730 - accuracy: 0.8515 - balanced_acc: 0.8510 - val_loss: 0.7506 - val_accuracy: 0.7202 - val_balanced_acc: 0.4495 - lr: 0.0010\n",
            "Epoch 22/100\n",
            "206/219 [===========================>..] - ETA: 0s - loss: 0.4618 - accuracy: 0.8570 - balanced_acc: 0.8586\n",
            "Epoch 22: val_balanced_acc did not improve from 0.45400\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.4600 - accuracy: 0.8575 - balanced_acc: 0.8592 - val_loss: 0.7997 - val_accuracy: 0.6995 - val_balanced_acc: 0.4536 - lr: 0.0010\n",
            "Epoch 23/100\n",
            "218/219 [============================>.] - ETA: 0s - loss: 0.4557 - accuracy: 0.8576 - balanced_acc: 0.8577\n",
            "Epoch 23: val_balanced_acc did not improve from 0.45400\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.4559 - accuracy: 0.8577 - balanced_acc: 0.8578 - val_loss: 0.7854 - val_accuracy: 0.6891 - val_balanced_acc: 0.4435 - lr: 0.0010\n",
            "Epoch 24/100\n",
            "215/219 [============================>.] - ETA: 0s - loss: 0.4408 - accuracy: 0.8649 - balanced_acc: 0.8645\n",
            "Epoch 24: val_balanced_acc did not improve from 0.45400\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.4402 - accuracy: 0.8654 - balanced_acc: 0.8650 - val_loss: 0.8151 - val_accuracy: 0.6995 - val_balanced_acc: 0.4522 - lr: 0.0010\n",
            "Epoch 25/100\n",
            "207/219 [===========================>..] - ETA: 0s - loss: 0.4410 - accuracy: 0.8652 - balanced_acc: 0.8666\n",
            "Epoch 25: val_balanced_acc did not improve from 0.45400\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.4400 - accuracy: 0.8646 - balanced_acc: 0.8662 - val_loss: 0.7629 - val_accuracy: 0.7098 - val_balanced_acc: 0.4481 - lr: 0.0010\n",
            "Epoch 26/100\n",
            "207/219 [===========================>..] - ETA: 0s - loss: 0.4224 - accuracy: 0.8704 - balanced_acc: 0.8685\n",
            "Epoch 26: val_balanced_acc did not improve from 0.45400\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.4225 - accuracy: 0.8704 - balanced_acc: 0.8688 - val_loss: 0.7739 - val_accuracy: 0.7047 - val_balanced_acc: 0.4452 - lr: 0.0010\n",
            "Epoch 27/100\n",
            "217/219 [============================>.] - ETA: 0s - loss: 0.4166 - accuracy: 0.8756 - balanced_acc: 0.8744\n",
            "Epoch 27: val_balanced_acc improved from 0.45400 to 0.45790, saving model to /content/drive/MyDrive/PHD/Model/Feature-Map-Ov/best_model_no.h5\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.4167 - accuracy: 0.8756 - balanced_acc: 0.8746 - val_loss: 0.7795 - val_accuracy: 0.7254 - val_balanced_acc: 0.4579 - lr: 0.0010\n",
            "Epoch 28/100\n",
            "218/219 [============================>.] - ETA: 0s - loss: 0.4064 - accuracy: 0.8793 - balanced_acc: 0.8773\n",
            "Epoch 28: val_balanced_acc did not improve from 0.45790\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.4064 - accuracy: 0.8793 - balanced_acc: 0.8772 - val_loss: 0.7792 - val_accuracy: 0.6943 - val_balanced_acc: 0.4433 - lr: 0.0010\n",
            "Epoch 29/100\n",
            "218/219 [============================>.] - ETA: 0s - loss: 0.4059 - accuracy: 0.8794 - balanced_acc: 0.8802\n",
            "Epoch 29: val_balanced_acc did not improve from 0.45790\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.4056 - accuracy: 0.8795 - balanced_acc: 0.8802 - val_loss: 0.7536 - val_accuracy: 0.7202 - val_balanced_acc: 0.4471 - lr: 0.0010\n",
            "Epoch 30/100\n",
            "208/219 [===========================>..] - ETA: 0s - loss: 0.3944 - accuracy: 0.8810 - balanced_acc: 0.8821\n",
            "Epoch 30: val_balanced_acc did not improve from 0.45790\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.3932 - accuracy: 0.8814 - balanced_acc: 0.8826 - val_loss: 0.7717 - val_accuracy: 0.6943 - val_balanced_acc: 0.4424 - lr: 0.0010\n",
            "Epoch 31/100\n",
            "208/219 [===========================>..] - ETA: 0s - loss: 0.3904 - accuracy: 0.8866 - balanced_acc: 0.8860\n",
            "Epoch 31: val_balanced_acc did not improve from 0.45790\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.3906 - accuracy: 0.8861 - balanced_acc: 0.8855 - val_loss: 0.7363 - val_accuracy: 0.7202 - val_balanced_acc: 0.4465 - lr: 0.0010\n",
            "Epoch 32/100\n",
            "207/219 [===========================>..] - ETA: 0s - loss: 0.3739 - accuracy: 0.8895 - balanced_acc: 0.8896\n",
            "Epoch 32: val_balanced_acc did not improve from 0.45790\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.3734 - accuracy: 0.8904 - balanced_acc: 0.8908 - val_loss: 0.7300 - val_accuracy: 0.7254 - val_balanced_acc: 0.4554 - lr: 0.0010\n",
            "Epoch 33/100\n",
            "206/219 [===========================>..] - ETA: 0s - loss: 0.3776 - accuracy: 0.8908 - balanced_acc: 0.8907\n",
            "Epoch 33: val_balanced_acc did not improve from 0.45790\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.3781 - accuracy: 0.8899 - balanced_acc: 0.8895 - val_loss: 0.7092 - val_accuracy: 0.7358 - val_balanced_acc: 0.4535 - lr: 0.0010\n",
            "Epoch 34/100\n",
            "206/219 [===========================>..] - ETA: 0s - loss: 0.3674 - accuracy: 0.8919 - balanced_acc: 0.8919\n",
            "Epoch 34: val_balanced_acc did not improve from 0.45790\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.3685 - accuracy: 0.8910 - balanced_acc: 0.8914 - val_loss: 0.7448 - val_accuracy: 0.7254 - val_balanced_acc: 0.4557 - lr: 0.0010\n",
            "Epoch 35/100\n",
            "209/219 [===========================>..] - ETA: 0s - loss: 0.3598 - accuracy: 0.8944 - balanced_acc: 0.8943\n",
            "Epoch 35: val_balanced_acc did not improve from 0.45790\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 0.3602 - accuracy: 0.8938 - balanced_acc: 0.8938 - val_loss: 0.7462 - val_accuracy: 0.7202 - val_balanced_acc: 0.4468 - lr: 0.0010\n",
            "Epoch 36/100\n",
            "211/219 [===========================>..] - ETA: 0s - loss: 0.3573 - accuracy: 0.8977 - balanced_acc: 0.8974\n",
            "Epoch 36: val_balanced_acc did not improve from 0.45790\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 0.3566 - accuracy: 0.8985 - balanced_acc: 0.8980 - val_loss: 0.7425 - val_accuracy: 0.7306 - val_balanced_acc: 0.4527 - lr: 0.0010\n",
            "Epoch 37/100\n",
            "215/219 [============================>.] - ETA: 0s - loss: 0.3524 - accuracy: 0.8996 - balanced_acc: 0.9014\n",
            "Epoch 37: val_balanced_acc did not improve from 0.45790\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 0.3528 - accuracy: 0.8995 - balanced_acc: 0.9012 - val_loss: 0.7691 - val_accuracy: 0.7098 - val_balanced_acc: 0.4488 - lr: 0.0010\n",
            "Epoch 38/100\n",
            "219/219 [==============================] - ETA: 0s - loss: 0.3390 - accuracy: 0.9036 - balanced_acc: 0.9043\n",
            "Epoch 38: val_balanced_acc did not improve from 0.45790\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.3390 - accuracy: 0.9036 - balanced_acc: 0.9043 - val_loss: 0.7057 - val_accuracy: 0.7306 - val_balanced_acc: 0.4491 - lr: 0.0010\n",
            "Epoch 39/100\n",
            "206/219 [===========================>..] - ETA: 0s - loss: 0.3395 - accuracy: 0.9029 - balanced_acc: 0.9024\n",
            "Epoch 39: val_balanced_acc did not improve from 0.45790\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.3403 - accuracy: 0.9032 - balanced_acc: 0.9025 - val_loss: 0.7560 - val_accuracy: 0.7202 - val_balanced_acc: 0.4508 - lr: 0.0010\n",
            "Epoch 40/100\n",
            "205/219 [===========================>..] - ETA: 0s - loss: 0.3299 - accuracy: 0.9103 - balanced_acc: 0.9099\n",
            "Epoch 40: val_balanced_acc did not improve from 0.45790\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.3289 - accuracy: 0.9102 - balanced_acc: 0.9096 - val_loss: 0.6909 - val_accuracy: 0.7358 - val_balanced_acc: 0.4574 - lr: 0.0010\n",
            "Epoch 41/100\n",
            "219/219 [==============================] - ETA: 0s - loss: 0.3300 - accuracy: 0.9071 - balanced_acc: 0.9075\n",
            "Epoch 41: val_balanced_acc did not improve from 0.45790\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.3300 - accuracy: 0.9071 - balanced_acc: 0.9075 - val_loss: 0.7524 - val_accuracy: 0.7202 - val_balanced_acc: 0.4468 - lr: 0.0010\n",
            "Epoch 42/100\n",
            "211/219 [===========================>..] - ETA: 0s - loss: 0.3228 - accuracy: 0.9115 - balanced_acc: 0.9114\n",
            "Epoch 42: val_balanced_acc did not improve from 0.45790\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.3233 - accuracy: 0.9112 - balanced_acc: 0.9108 - val_loss: 0.7582 - val_accuracy: 0.7202 - val_balanced_acc: 0.4548 - lr: 0.0010\n",
            "Epoch 43/100\n",
            "208/219 [===========================>..] - ETA: 0s - loss: 0.3195 - accuracy: 0.9107 - balanced_acc: 0.9102\n",
            "Epoch 43: val_balanced_acc did not improve from 0.45790\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.3196 - accuracy: 0.9104 - balanced_acc: 0.9098 - val_loss: 0.7058 - val_accuracy: 0.7358 - val_balanced_acc: 0.4574 - lr: 0.0010\n",
            "Epoch 44/100\n",
            "208/219 [===========================>..] - ETA: 0s - loss: 0.3134 - accuracy: 0.9135 - balanced_acc: 0.9131\n",
            "Epoch 44: val_balanced_acc did not improve from 0.45790\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.3136 - accuracy: 0.9134 - balanced_acc: 0.9128 - val_loss: 0.6938 - val_accuracy: 0.7358 - val_balanced_acc: 0.4417 - lr: 0.0010\n",
            "Epoch 45/100\n",
            "209/219 [===========================>..] - ETA: 0s - loss: 0.3050 - accuracy: 0.9153 - balanced_acc: 0.9147\n",
            "Epoch 45: val_balanced_acc did not improve from 0.45790\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.3040 - accuracy: 0.9158 - balanced_acc: 0.9154 - val_loss: 0.7001 - val_accuracy: 0.7254 - val_balanced_acc: 0.4425 - lr: 0.0010\n",
            "Epoch 46/100\n",
            "205/219 [===========================>..] - ETA: 0s - loss: 0.3063 - accuracy: 0.9170 - balanced_acc: 0.9167\n",
            "Epoch 46: val_balanced_acc did not improve from 0.45790\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.3043 - accuracy: 0.9175 - balanced_acc: 0.9170 - val_loss: 0.7172 - val_accuracy: 0.7306 - val_balanced_acc: 0.4527 - lr: 0.0010\n",
            "Epoch 47/100\n",
            "218/219 [============================>.] - ETA: 0s - loss: 0.2983 - accuracy: 0.9183 - balanced_acc: 0.9164\n",
            "Epoch 47: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "\n",
            "Epoch 47: val_balanced_acc did not improve from 0.45790\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.2982 - accuracy: 0.9186 - balanced_acc: 0.9166 - val_loss: 0.7417 - val_accuracy: 0.7047 - val_balanced_acc: 0.4401 - lr: 0.0010\n",
            "Epoch 48/100\n",
            "217/219 [============================>.] - ETA: 0s - loss: 0.2938 - accuracy: 0.9222 - balanced_acc: 0.9218\n",
            "Epoch 48: val_balanced_acc improved from 0.45790 to 0.45819, saving model to /content/drive/MyDrive/PHD/Model/Feature-Map-Ov/best_model_no.h5\n",
            "219/219 [==============================] - 2s 8ms/step - loss: 0.2936 - accuracy: 0.9224 - balanced_acc: 0.9221 - val_loss: 0.6998 - val_accuracy: 0.7409 - val_balanced_acc: 0.4582 - lr: 5.0000e-04\n",
            "Epoch 49/100\n",
            "208/219 [===========================>..] - ETA: 0s - loss: 0.2930 - accuracy: 0.9202 - balanced_acc: 0.9195\n",
            "Epoch 49: val_balanced_acc did not improve from 0.45819\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.2932 - accuracy: 0.9201 - balanced_acc: 0.9197 - val_loss: 0.7139 - val_accuracy: 0.7306 - val_balanced_acc: 0.4565 - lr: 5.0000e-04\n",
            "Epoch 50/100\n",
            "207/219 [===========================>..] - ETA: 0s - loss: 0.2931 - accuracy: 0.9228 - balanced_acc: 0.9234\n",
            "Epoch 50: val_balanced_acc did not improve from 0.45819\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.2923 - accuracy: 0.9226 - balanced_acc: 0.9228 - val_loss: 0.7305 - val_accuracy: 0.7306 - val_balanced_acc: 0.4565 - lr: 5.0000e-04\n",
            "Epoch 51/100\n",
            "217/219 [============================>.] - ETA: 0s - loss: 0.2848 - accuracy: 0.9236 - balanced_acc: 0.9240\n",
            "Epoch 51: val_balanced_acc did not improve from 0.45819\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.2854 - accuracy: 0.9231 - balanced_acc: 0.9232 - val_loss: 0.7422 - val_accuracy: 0.7306 - val_balanced_acc: 0.4565 - lr: 5.0000e-04\n",
            "Epoch 52/100\n",
            "207/219 [===========================>..] - ETA: 0s - loss: 0.2820 - accuracy: 0.9240 - balanced_acc: 0.9250\n",
            "Epoch 52: val_balanced_acc did not improve from 0.45819\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.2829 - accuracy: 0.9236 - balanced_acc: 0.9249 - val_loss: 0.7053 - val_accuracy: 0.7358 - val_balanced_acc: 0.4573 - lr: 5.0000e-04\n",
            "Epoch 53/100\n",
            "218/219 [============================>.] - ETA: 0s - loss: 0.2865 - accuracy: 0.9234 - balanced_acc: 0.9233\n",
            "Epoch 53: val_balanced_acc did not improve from 0.45819\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.2863 - accuracy: 0.9235 - balanced_acc: 0.9234 - val_loss: 0.7298 - val_accuracy: 0.7306 - val_balanced_acc: 0.4565 - lr: 5.0000e-04\n",
            "Epoch 54/100\n",
            "205/219 [===========================>..] - ETA: 0s - loss: 0.2759 - accuracy: 0.9266 - balanced_acc: 0.9254\n",
            "Epoch 54: val_balanced_acc did not improve from 0.45819\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.2763 - accuracy: 0.9264 - balanced_acc: 0.9256 - val_loss: 0.7212 - val_accuracy: 0.7306 - val_balanced_acc: 0.4565 - lr: 5.0000e-04\n",
            "Epoch 55/100\n",
            "218/219 [============================>.] - ETA: 0s - loss: 0.2774 - accuracy: 0.9259 - balanced_acc: 0.9247\n",
            "Epoch 55: val_balanced_acc did not improve from 0.45819\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.2774 - accuracy: 0.9259 - balanced_acc: 0.9247 - val_loss: 0.7225 - val_accuracy: 0.7358 - val_balanced_acc: 0.4574 - lr: 5.0000e-04\n",
            "Epoch 56/100\n",
            "214/219 [============================>.] - ETA: 0s - loss: 0.2786 - accuracy: 0.9256 - balanced_acc: 0.9278\n",
            "Epoch 56: val_balanced_acc did not improve from 0.45819\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.2780 - accuracy: 0.9256 - balanced_acc: 0.9279 - val_loss: 0.7079 - val_accuracy: 0.7306 - val_balanced_acc: 0.4565 - lr: 5.0000e-04\n",
            "Epoch 57/100\n",
            "216/219 [============================>.] - ETA: 0s - loss: 0.2752 - accuracy: 0.9251 - balanced_acc: 0.9254\n",
            "Epoch 57: val_balanced_acc did not improve from 0.45819\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.2748 - accuracy: 0.9251 - balanced_acc: 0.9254 - val_loss: 0.7292 - val_accuracy: 0.7306 - val_balanced_acc: 0.4565 - lr: 5.0000e-04\n",
            "Epoch 58/100\n",
            "206/219 [===========================>..] - ETA: 0s - loss: 0.2727 - accuracy: 0.9274 - balanced_acc: 0.9278\n",
            "Epoch 58: val_balanced_acc did not improve from 0.45819\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.2731 - accuracy: 0.9278 - balanced_acc: 0.9278 - val_loss: 0.7014 - val_accuracy: 0.7254 - val_balanced_acc: 0.4476 - lr: 5.0000e-04\n",
            "Epoch 59/100\n",
            "213/219 [============================>.] - ETA: 0s - loss: 0.2662 - accuracy: 0.9281 - balanced_acc: 0.9278\n",
            "Epoch 59: val_balanced_acc did not improve from 0.45819\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.2678 - accuracy: 0.9275 - balanced_acc: 0.9273 - val_loss: 0.7047 - val_accuracy: 0.7306 - val_balanced_acc: 0.4565 - lr: 5.0000e-04\n",
            "Epoch 60/100\n",
            "216/219 [============================>.] - ETA: 0s - loss: 0.2759 - accuracy: 0.9282 - balanced_acc: 0.9292\n",
            "Epoch 60: val_balanced_acc did not improve from 0.45819\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.2758 - accuracy: 0.9285 - balanced_acc: 0.9296 - val_loss: 0.7078 - val_accuracy: 0.7409 - val_balanced_acc: 0.4582 - lr: 5.0000e-04\n",
            "Epoch 61/100\n",
            "218/219 [============================>.] - ETA: 0s - loss: 0.2615 - accuracy: 0.9310 - balanced_acc: 0.9307\n",
            "Epoch 61: val_balanced_acc did not improve from 0.45819\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.2615 - accuracy: 0.9310 - balanced_acc: 0.9307 - val_loss: 0.7478 - val_accuracy: 0.7150 - val_balanced_acc: 0.4499 - lr: 5.0000e-04\n",
            "Epoch 62/100\n",
            "207/219 [===========================>..] - ETA: 0s - loss: 0.2669 - accuracy: 0.9303 - balanced_acc: 0.9307\n",
            "Epoch 62: val_balanced_acc did not improve from 0.45819\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.2656 - accuracy: 0.9309 - balanced_acc: 0.9315 - val_loss: 0.7036 - val_accuracy: 0.7358 - val_balanced_acc: 0.4573 - lr: 5.0000e-04\n",
            "Epoch 63/100\n",
            "216/219 [============================>.] - ETA: 0s - loss: 0.2660 - accuracy: 0.9286 - balanced_acc: 0.9292\n",
            "Epoch 63: val_balanced_acc did not improve from 0.45819\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.2675 - accuracy: 0.9287 - balanced_acc: 0.9294 - val_loss: 0.7401 - val_accuracy: 0.7254 - val_balanced_acc: 0.4557 - lr: 5.0000e-04\n",
            "Epoch 64/100\n",
            "206/219 [===========================>..] - ETA: 0s - loss: 0.2585 - accuracy: 0.9319 - balanced_acc: 0.9317\n",
            "Epoch 64: val_balanced_acc did not improve from 0.45819\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.2577 - accuracy: 0.9324 - balanced_acc: 0.9324 - val_loss: 0.6788 - val_accuracy: 0.7409 - val_balanced_acc: 0.4493 - lr: 5.0000e-04\n",
            "Epoch 65/100\n",
            "208/219 [===========================>..] - ETA: 0s - loss: 0.2613 - accuracy: 0.9303 - balanced_acc: 0.9295\n",
            "Epoch 65: val_balanced_acc did not improve from 0.45819\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.2627 - accuracy: 0.9299 - balanced_acc: 0.9288 - val_loss: 0.7102 - val_accuracy: 0.7358 - val_balanced_acc: 0.4573 - lr: 5.0000e-04\n",
            "Epoch 66/100\n",
            "218/219 [============================>.] - ETA: 0s - loss: 0.2547 - accuracy: 0.9343 - balanced_acc: 0.9338\n",
            "Epoch 66: val_balanced_acc did not improve from 0.45819\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.2541 - accuracy: 0.9346 - balanced_acc: 0.9341 - val_loss: 0.7282 - val_accuracy: 0.7306 - val_balanced_acc: 0.4565 - lr: 5.0000e-04\n",
            "Epoch 67/100\n",
            "206/219 [===========================>..] - ETA: 0s - loss: 0.2575 - accuracy: 0.9325 - balanced_acc: 0.9310\n",
            "Epoch 67: val_balanced_acc did not improve from 0.45819\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.2580 - accuracy: 0.9326 - balanced_acc: 0.9312 - val_loss: 0.7213 - val_accuracy: 0.7306 - val_balanced_acc: 0.4565 - lr: 5.0000e-04\n",
            "Epoch 68/100\n",
            "219/219 [==============================] - ETA: 0s - loss: 0.2528 - accuracy: 0.9340 - balanced_acc: 0.9333\n",
            "Epoch 68: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "\n",
            "Epoch 68: val_balanced_acc did not improve from 0.45819\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.2528 - accuracy: 0.9340 - balanced_acc: 0.9333 - val_loss: 0.7142 - val_accuracy: 0.7358 - val_balanced_acc: 0.4573 - lr: 5.0000e-04\n",
            "Epoch 69/100\n",
            "217/219 [============================>.] - ETA: 0s - loss: 0.2573 - accuracy: 0.9321 - balanced_acc: 0.9326\n",
            "Epoch 69: val_balanced_acc did not improve from 0.45819\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.2571 - accuracy: 0.9323 - balanced_acc: 0.9328 - val_loss: 0.7109 - val_accuracy: 0.7409 - val_balanced_acc: 0.4582 - lr: 2.5000e-04\n",
            "Epoch 70/100\n",
            "209/219 [===========================>..] - ETA: 0s - loss: 0.2505 - accuracy: 0.9353 - balanced_acc: 0.9363\n",
            "Epoch 70: val_balanced_acc did not improve from 0.45819\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.2504 - accuracy: 0.9349 - balanced_acc: 0.9357 - val_loss: 0.7262 - val_accuracy: 0.7306 - val_balanced_acc: 0.4565 - lr: 2.5000e-04\n",
            "Epoch 71/100\n",
            "219/219 [==============================] - ETA: 0s - loss: 0.2495 - accuracy: 0.9355 - balanced_acc: 0.9360\n",
            "Epoch 71: val_balanced_acc did not improve from 0.45819\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.2495 - accuracy: 0.9355 - balanced_acc: 0.9360 - val_loss: 0.7086 - val_accuracy: 0.7358 - val_balanced_acc: 0.4573 - lr: 2.5000e-04\n",
            "Epoch 72/100\n",
            "218/219 [============================>.] - ETA: 0s - loss: 0.2509 - accuracy: 0.9350 - balanced_acc: 0.9336\n",
            "Epoch 72: val_balanced_acc did not improve from 0.45819\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.2510 - accuracy: 0.9348 - balanced_acc: 0.9333 - val_loss: 0.7010 - val_accuracy: 0.7409 - val_balanced_acc: 0.4582 - lr: 2.5000e-04\n",
            "Epoch 73/100\n",
            "218/219 [============================>.] - ETA: 0s - loss: 0.2478 - accuracy: 0.9359 - balanced_acc: 0.9360\n",
            "Epoch 73: val_balanced_acc did not improve from 0.45819\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.2475 - accuracy: 0.9360 - balanced_acc: 0.9361 - val_loss: 0.7048 - val_accuracy: 0.7358 - val_balanced_acc: 0.4573 - lr: 2.5000e-04\n",
            "Epoch 74/100\n",
            "218/219 [============================>.] - ETA: 0s - loss: 0.2472 - accuracy: 0.9365 - balanced_acc: 0.9352\n",
            "Epoch 74: val_balanced_acc did not improve from 0.45819\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.2469 - accuracy: 0.9366 - balanced_acc: 0.9354 - val_loss: 0.7115 - val_accuracy: 0.7306 - val_balanced_acc: 0.4565 - lr: 2.5000e-04\n",
            "Epoch 75/100\n",
            "205/219 [===========================>..] - ETA: 0s - loss: 0.2502 - accuracy: 0.9350 - balanced_acc: 0.9352\n",
            "Epoch 75: val_balanced_acc did not improve from 0.45819\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.2492 - accuracy: 0.9354 - balanced_acc: 0.9359 - val_loss: 0.7154 - val_accuracy: 0.7306 - val_balanced_acc: 0.4565 - lr: 2.5000e-04\n",
            "Epoch 76/100\n",
            "219/219 [==============================] - ETA: 0s - loss: 0.2415 - accuracy: 0.9394 - balanced_acc: 0.9403\n",
            "Epoch 76: val_balanced_acc did not improve from 0.45819\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.2415 - accuracy: 0.9394 - balanced_acc: 0.9403 - val_loss: 0.7103 - val_accuracy: 0.7358 - val_balanced_acc: 0.4573 - lr: 2.5000e-04\n",
            "Epoch 77/100\n",
            "218/219 [============================>.] - ETA: 0s - loss: 0.2453 - accuracy: 0.9372 - balanced_acc: 0.9382\n",
            "Epoch 77: val_balanced_acc did not improve from 0.45819\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.2455 - accuracy: 0.9369 - balanced_acc: 0.9378 - val_loss: 0.7120 - val_accuracy: 0.7306 - val_balanced_acc: 0.4565 - lr: 2.5000e-04\n",
            "Epoch 78/100\n",
            "207/219 [===========================>..] - ETA: 0s - loss: 0.2450 - accuracy: 0.9380 - balanced_acc: 0.9381\n",
            "Epoch 78: val_balanced_acc did not improve from 0.45819\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.2446 - accuracy: 0.9380 - balanced_acc: 0.9380 - val_loss: 0.7342 - val_accuracy: 0.7254 - val_balanced_acc: 0.4557 - lr: 2.5000e-04\n"
          ]
        }
      ],
      "source": [
        "best_model_fpath = '/content/drive/MyDrive/PHD/Model/Feature-Map-Ov/best_model_no.h5'\n",
        "last_model_fpath = '/content/drive/MyDrive/PHD/Model/Feature-Map-Ov/last_model_no.h5'\n",
        "mc1 = ModelCheckpoint(best_model_fpath, monitor='val_balanced_acc', mode='max', verbose=1, save_best_only=True)\n",
        "model2.compile(optimizer = opt_SGD , loss = \"categorical_crossentropy\", metrics=['accuracy', balanced_acc])\n",
        "hst = model2.fit(X_train_fm_ov, y_train_ov, epochs=100, batch_size=BATCH_SIZE, validation_data=(X_val_fm, y_val), verbose=1,\n",
        "                    steps_per_epoch=X_train_fm_ov.shape[0] // BATCH_SIZE, \n",
        "                    callbacks=[learning_rate_reduction,early_stopping_monitor, mc1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "8XhlbWn--8Or",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "c7ee41dc-5a19-4a56-d98d-0a2be86ff7ba"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYQAAAEWCAYAAABmE+CbAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOzdd3gVVfrA8e97W9pNJyGBkEITkCpIkaIL0oKKbW1rwbq61nXVVdFdV9f6U1dXURcRxbYqKixqEFQsoKAUkRJ6QiCN9HJTbj2/P+4lJiHABXNJAufzPPOYO3Nm5r3jZd6Zc86cEaUUmqZpmmZo6wA0TdO09kEnBE3TNA3QCUHTNE3z0QlB0zRNA3RC0DRN03x0QtA0TdMAnRC0E4SIpIqIEhGTH2VniMiKYxGXprUnOiFo7Y6I7BYRh4h0ajb/Z99JPbVtItO045tOCFp7lQ1cuv+DiAwAQtsunPbBnzscTTtaOiFo7dVbwJWNPl8FvNm4gIhEisibIlIsIjki8oCIGHzLjCLytIiUiEgWMK2FdV8TkQIRyRORf4qI0Z/ARGS+iBSKSKWIfCciJzdaFiIiz/jiqRSRFSIS4ls2RkR+EJEKEdkrIjN8878RkesabaNJlZXvruhmEdkB7PDNe963jSoRWSsiYxuVN4rI/SKyS0Sqfcu7icgsEXmm2XdZJCJ/9ud7a8c/nRC09moVECEifX0n6kuAt5uVeQGIBLoDp+NNIFf7ll0PnAUMAYYBFzZb9w3ABfT0lZkEXId/FgO9gHhgHfBOo2VPA0OB04AY4B7AIyIpvvVeAOKAwcB6P/cHcC4wAujn+7zat40Y4F1gvogE+5bdiffuKh2IAK4BaoF5wKWNkmYn4Ezf+poGSik96aldTcBuvCeqB4DHgSnAF4AJUEAqYAQcQL9G6/0R+Mb39zLgxkbLJvnWNQGdATsQ0mj5pcDXvr9nACv8jDXKt91IvBdYdcCgFsrdByw4yDa+Aa5r9LnJ/n3bH3+YOMr37xfYBkw/SLktwETf37cAGW39/1tP7WfS9ZFae/YW8B2QRrPqIqATYAZyGs3LAbr6/u4C7G22bL8U37oFIrJ/nqFZ+Rb57lYeBX6P90rf0yieICAY2NXCqt0OMt9fTWITkbuAa/F+T4X3TmB/I/yh9jUPuBxvgr0ceP43xKQdZ3SVkdZuKaVy8DYupwMfN1tcAjjxntz3SwbyfH8X4D0xNl623168dwidlFJRvilCKXUyh3cZMB3vHUwk3rsVAPHFVA/0aGG9vQeZD1BD0wbzhBbKNAxL7GsvuAe4CIhWSkUBlb4YDrevt4HpIjII6AssPEg57QSkE4LW3l2Lt7qkpvFMpZQb+AB4VETCfXX0d/JrO8MHwG0ikiQi0cC9jdYtAJYCz4hIhIgYRKSHiJzuRzzheJNJKd6T+GONtusB5gLPikgXX+PuKBEJwtvOcKaIXCQiJhGJFZHBvlXXA+eLSKiI9PR958PF4AKKAZOI/A3vHcJ+c4BHRKSXeA0UkVhfjLl42x/eAj5SStX58Z21E4ROCFq7ppTapZRac5DFt+K9us4CVuBtHJ3rW/YqsAT4BW/Db/M7jCsBC5CJt/79QyDRj5DexFv9lOdbd1Wz5XcBG/GedMuAJwGDUmoP3judv/jmrwcG+db5F972kH14q3Te4dCWAJ8D232x1NO0SulZvAlxKVAFvAaENFo+DxiANyloWgNRSr8gR9NOJCIyDu+dVIrSJwCtEX2HoGknEBExA7cDc3Qy0JrTCUHTThAi0heowFs19lwbh6O1Q7rKSNM0TQP0HYKmaZrm0+EeTOvUqZNKTU1t6zA0TdM6lLVr15YopeIOVabDJYTU1FTWrDlYL0RN0zStJSKSc7gyuspI0zRNA3RC0DRN03x0QtA0TdMAnRA0TdM0H50QNE3TNEAnBE3TNM1HJwRN0zQN6IDPIWiaph1XlMJZsImiX5ZgDrESkzoIU0I/CI485qHohKBpmnY4LgfOws3UlubidNhxOOw4HXY8wTFIwsmExCQRGmTC4fJQZrNj27cLT8EmHPU11KggbCoImyeIYBNEm91Emd1EGOpw715JXME3xLqLGt79ul+FsRMOgwXxuBGPC1Fusofcw7DpNwfsa+qEoGlau+Vye1BKYXDVInYb4nEgEV3AaG5SzllbSdbGlVQW52LtPpLUnn0ItXhPb9lFlWz+/hNCt35MnD2HfEsaZeF9qO90MmLthJTvJqgqh/CaPYR4bJiDQrAEhxIcasXiKMdatpmE+izMuDjYNXuZsrLBk4JZXPSRPfQS/15EV6OCWGcaRHHS1UT0n4LT6cC2dyMUb8VanYVZuTGazZhMZoxmMxFxab/lcB5WhxvtdNiwYUoPXaFp7ZDHAxU5EBINIVEHLHY77ezbswM3gsESiikoDIPRSH3RLpz7tiGl2zGUZeO2FWGoK8firMDqqcZKPQb59TzlxkCZKZ7q0G64LRGEVWwnwZnbpEye6sRm08nUGqyc5vieeKnAJmEUhfYiri6bcE/lAfHVSzDVhkiMHjtmj51gHNQQzDZDD0qsfXDED8TSKRWzJRhLUBBmcxCW+mKCSjMJLdtKRNU2lMFEbXRf3PEnY0wcSEh4FKE4CFJ1WDx1OD1CtdtEudNEhcNIXEofUjrHBub/RzMislYpNexQZfQdgqad6NwuqC7AU7EXV3kuHoMJCU+A8AQkPIG8wgL27thIRe5WPKW78HgUdlM4TpMVtymURHceafVbSK7bSojHBkC1OY7ysDQqQ5Oheh/RNdkkuPPpIp6DhuFRQj6xVKhI7JYosKZgssbgNIXjMIbiMIZi9xigYg8htj3EVOYRqfaw25LKli6TiUg7lbiEJGqzVmHKXcnI8rWEOG3kxY+lZPhldBp8NlZzMCgFVfmogl9w15Zjiu0OMd0JtsYTLAKAUoryWicCjAizHOYAnuX3obYAsb6pPdJ3CJp2HCi12fl58xbc6/9LUF0RrpheBCX2IzplAHhcVOxcieStJbJ8E+HOEkzKgVk5sSgH4dgw4t95wIkJAUy4Gua5MbBLUtgkvdhCGiFuG6lqL93JJU0KKZcoioPTsEf1xNy5F0aDAXHVIc468LhwR3RDdeqFOb4XURGRJEWHYDYevgOkx6OodbqxBh3kulYpcDvBdLgT+olB3yFo2nHA7VEUV9ZQXLiHyn27sVWWU+kwUO4wUu4wIMWZnFa9lPGGTRhEUUswoRX1kAV8/+t2nMrIblMqxUEpuA1BKKMFj8GCwxJJbUgi9aGJOMK6YBI3wXXFhNqLCbEXERweQ6eUfiSm9ccckwxiAFc91FeCvRpjRBd6W8Lo3ULcTreHVLOR1AAcF4NBDp4MAER0MjhCOiFoWjvhcnvYmV9M/ra12PM3YS7JJLZmJ4muPOIoJ0EOfhVfFZrIvr630mn0DEI7dae+bC+l2Ruo2rMJRIjsOZLOvU+lV1Bo6wRrDvFO4QkHLWI0CEaDsXX2px0TOiFoWisqKK1g049fEZvQjd59+mMN9Z6AnY56tq//gcLM76BkJ26zFVdQJCo4CuXxEFy8gS61W+nFXvqIG4A6gikISqM4ZhRFEUkERXclNC6ZyKhOWE1uDG4HuOogLI6IbiOJMPxazRIcm0zX2GS6DvO/flvTApoQRGQK8DxgBOYopZ5otjwFmAvEAWXA5Uqp3EDGpGmBkFNQzMZFzzEs/x0mSjkArv8ZyDPGU2+Koqt9FyeLk5OBagkjWNkxN6qHt4mVfRF9yUqYRESPU+nUYyghsWl0N+jBBLRjJ2AJQUSMwCxgIpALrBaRRUqpzEbFngbeVErNE5HxwOPAFYGKSdOOSn0l5P9M+Y5VVO36keDyHdQYI6iwJFIVlECd082I8k84S2xkhw8h77QnqKqqpCpvG5TuwmIvpSDuPMJ6nEaPU8YT0TnF2+DprIW6cpTHhTUqBauvh4umtZVA3iEMB3YqpbIAROQ9YDrQOCH0A+70/f01sDCA8WjaYdU7XGxevwr2/kR4yXpiKzYQXbcbA4pooMLTmS2mNCI9NXS2b2Rg1deYcLMz+jSYcj9pfcYCHPDU6QFEwBIGljB0GtDai0AmhK7A3kafc4ERzcr8ApyPt1rpPCBcRGKVUqWNC4nIDcANAMnJyQELWDsxVZUWsXXlIlzbltKr6keGSgUApSqc9Z6ebDVehL3zELr0O42RJ/fkjE5hv67scYPDRs82GHdG01pbWzcq3wW8KCIzgO+APMDdvJBSajYwG7zPIRzLALUORikqczZQX1eDMSIOS0RnLMFh1NXWUlW0G3vJbhwlu3Ht24K5bDtxdVnEq1KGA1WEsTtqBKV9JhJ+0umEde7JGSEWJhgOcQ1vMLbJIGSaFgiBTAh5QLdGn5N88xoopfLx3iEgIlbgAqVURQBj0o5Dbo9iy9bNlP/4Dim5n5Ls3tNkzJkaFUQkDqIbddusV2b2GpPItg5hZ2wfYk/+Hb2GnM5Ak/nAHWjaCSKQCWE10EtE0vAmgkuAyxoXEJFOQJlSygPch7fHkaYdmtuJszCTXRu+p3znaqylGzlZ7cQgii3mfnyTdi+m6CSMdSWY6kow15ehLOGoqGQMMSkEdUohKaU3vUKD2/qbaFq7ErCEoJRyicgtwBK83U7nKqU2i8jDwBql1CLgDOBxEVF4q4wCN66r1mGU2uwUVNbj8XgwVe0huGg9UpSJlGwnrHoX0fW5mHHTB6hRwRSE9mZbys10GXsVfbv2pm9bfwFN66D0WEZam6usdfLDjnyytvxMZc4Goqp30F+yGWDIJlq8g6W5lIEc1ZlsSaIkOBVPXF/SBo5myOChBFt0NY+mHY4ey0hrt+qdbpZtyiH/hw/ov+9/nCnbMPue0HWbTdRE9KQ6dir7YgZiix2AKaEf3eKimBBmQXR/fU0LCJ0QtGNGeTxs2LaDn1Z9R9juL5jGciKllrKQrpT2vp5OPYdiSuiPMbYnESYLEW0dsKadYHRC0Frd1m1b2ffLUiI8FYS7KwhzVaAq9hBasY1BqopBgNNgoSJlCu6x1xGTNhb0EA2a1uZ0QtBaze6dm9m76DFGVC5uGKDNrkyUEUGRiqY4dCSx3U+h7+CRhCSfQpzuv69p7YpOCNqRcdZj+/YFHFsysJsjqbV0ojYojvqiLIZULKULBrYknkvSpFtxWrtS7QnG5nATEWJmcJy1raPXNO0QdELQ/OJxe9i+7A3ifnyCWNc+fvF0x0Ix8bKGHlJNvTKzLuFCep07k0GJqQ3rHXy0fE3T2hudELRDKqqu54evPqH3hqfo59nOVlL5vM+LDBxzDiHBJmoNgl05iQgyMNwa3tbhapr2G+iEoAFQ63Bhs7uod3ioc7rZXVrDyh++ZdzelznX8DOlhk6sG/Io/abcQJ8g/VpCTTse6YRwAnO5Paxcuxb1zVOcWvMNDiLY6+nMHhWPVer4m/FHHGYrpcNnEjv+VmLNIW0dsqZpAaQTwgkor6KOpSvXErX6ec5yf4VHDGyPn4LV5KZPfR7DajdgctWiht9K8Lg7CQ6JbuuQNU07BnRCOEGU7ckk86cvqd71E4k1m7lcchAR8nteTJezZjIgOqnpCkp5X+KiadoJQyeE45jD5WHt90sIX/V/9K9byxiglhDKovtR2zOdyDE3kByd0vLKOhlo2glHJ4Tj0M4iG19/tZi+22Yxhp8pJ4Kvu/2JlFEX0L3PEEINxrYOUdO0dkgnhOOE26P4ft0G8pa/yeDypVxv2IPNEMGuAXeRMuV2fheiRwbSNO3QdELo4NxuNz8ueRfLmtmMcW/EIIrCyAHYTn0c64grsAbpZwM0TfOPTggdlHLUsm3pHMLWvcJpnjyKDHHs7HczaeOvJiGuZ1uHp2laB6QTQgdTW7KHnCUv0HXne/RRVWw19GTNqU9zyuQZxOv3AWua9hvohNABuD2KDSuXola9zICq7zgJD9+bTqXmlBsZP+lcLGbdSKxp2m8X0IQgIlOA5/G+U3mOUuqJZsuTgXlAlK/MvUqpjEDG1JFk7atg45fv0H3nGwxR26kijJXxFxE17ibG9B+o3xymaVqrClhCEBEjMAuYCOQCq0VkkVIqs1GxB4APlFIvi0g/IANIDVRMHcWWnHx+/Oh5xld8xHRDMftMXdjc/0F6TrqBcaG6t5CmaYERyDuE4cBOpVQWgIi8B0wHGicEBQ1vSowE8gMYT7tXU7KH9fOfon/hR8yQWgqjBlFx+lN0HjKdzvrZAU3TAiyQCaErsLfR51xgRLMyDwFLReRWIAw4s6UNicgNwA0AycnJrR5om3PUsue9O0jM+oiRyk1m1OmknX0vCT1HtXVkmqadQNq6UflS4A2l1DMiMgp4S0T6K6U8jQsppWYDswGGDRum2iDOgKkr3k3ZaxeSVLeTjOB00s7+KwP6D2rrsDRNOwEFMiHkAd0afU7yzWvsWmAKgFJqpYgEA52AogDG1W5krVlK9GfXEe5xsLDvM5z9+6sxG/XL5jVNaxuBPPusBnqJSJqIWIBLgEXNyuwBJgCISF8gGCgOYEztQnVNLcvfeoSkTy6hSoWxa/oizr/kWp0MNE1rUwG7Q1BKuUTkFmAJ3i6lc5VSm0XkYWCNUmoR8BfgVRH5M94G5hlKqeOqSqix3NJq1n46myFZ/2Gs7GNj2Ai6XfsOKbFxbR2apmka0tHOv8OGDVNr1qxp6zCOiN3l5r23ZzM6+9/0lHxyg3riHHcfaaddoIeZ1jTtmBCRtUqpYYcq09aNyse9yloHn7/0F66yvUlRSBplE+aQNPQCMOjqIU3T2hedEAIov7SSTa/M4GLnMvYmnU23Ga+BKaitw9I0TWuRTggBsn13DtXzLmOS2sSegbeTfN4/dPWQpmntmk4IAbD655/ptPAyBkgR+eOfJ3ncjLYOSdM07bB0QmhlX321mEHf3UCQwUPVBfPp0n98W4ekaZrmF92y2UqUUix6fw6jvrsKjykEue4LOulkoGlaB6LvEFqBx+3h09ceYlrev8kLOYmEG/+HJSqhrcPSNE07Ijoh/EZup53Vs67hnIpP2Rkzjh43/hcJsrZ1WJqmaUdMVxn9Bu7qInKencDIik/5Kelqet76P50MtDbl9Dhxup1tHcZRq3XWHvW6Sikq7ZWtFovD7cDp8f9Y1jprsbvtrbb/tqATwlFy5/9C1fOjSazdxuKTHmX4dc/ph820Njdz+UzO/PBMvt7zdVuHckRqnbU89MNDjPrvKL7d++0Rr+9RHv6x8h+MeW8MV2RcwX+3/pfSutIj3o7L4+L7vO+ZuWIm494fx4QPJrBsz7KDlq931bN091Lu+PoOxrw3hnHvjeO+5fexPHf5ESWT9kIPXXEUVNEWav8ziUqXieVD/83F55zdpvFoB1dcW8zz655nYNxAft/79wF/7ei2sm28vvl1bh1yK12tXQ9bflXBKuZunItLuRrmxYXE8eehfyYh7MjaoQprCpn80WSCjEHUueq4sPeF3D3sbkLNoYdd1+F2sCJvBV/kfIHVbGVa92kMiht00ONV46xh2Z5lfL33a7qFdyM9LZ2TYk46onj321C8gfuW38fe6r1EBkUSYYlg4fSFmI3mJuV2lu9k9obZXDvg2ib7Ukrx1OqneHvL20xMmUh2ZTY7K3ZiFCMju4xkWto0xiePJ8wc1uL+lVL8UvwLGdkZLNm9hLL6MsLN4ZyZciZby7aypWwLF/S6gHtOvYdQcyguj4ufCn7is+zP+GrPV9Q4a4gNjmVK2hRvgshZSrWjmuigaCalTmo4lgZp+YKx1lnLsr3L+HrP1ySFJ5Gelk7v6N6t/lv1Z+gKnRCOVMVebC9PoLbezifDXufas3VPovbqy5wv+cfKf1Bpr0ShGNt1LA+PfphOIZ0Ouo5HeVhduJpBcYMINgUfdPng+MEEGZs+dZ5dmc2Mz2dQVl9GkjWJeVPnER8af9B9rSlcw41f3kh0cHST5JFZmonJYOLBkQ8yNW1qk3V2lO/A6XHSL7bfAdt78ecXmb1hNovOXcSCnQt4fdPrJEckc03/azAbzAeUB1Ao1u1b13ASiwqKos5Vh91tp6u1K1PTptI9sntDeZfHxQ/5P/DN3m+od9fTKaQT5fXluJWbnlE9mZo2lcSwxIbyBjEwtPPQFpNbpb2Sd7a8w+wNs4kPjefRMY9S76rnT1/9ibuG3cVVJ1/VULbOVccln15CVmUWZoOZ20+5nSv6XYFBDLzw8wvM3jCby/tezj2n3oOIsL18OxlZGSzOXkx+TT5BxiDO6HYGo7uMxmT4tek0uzKbjOwM8mx5WAwWTu92OtPSpjE2aSwWowWn28ms9bOYu2ku3cK7MarLKL7I+YKy+jKsZisTkicwrfs0hicMx+h7q+H+5JqRncE3e7/B7rbTJawLU9Om0iOqR5NjuTJ/JV/v/brFY5mels7UtKkkhScd9Dd0JHRCaG01pdS8MgF31T5eTH2e+2YE/opTO3I1zhqe/OlJFuxcQL/Yfjw+5nFWFazi2bXPEmoK5aHTHmJ88oGJvKi2iAdWPMDKgpVM6z6NJ8Y+cUCZ1ze9zrNrn6VnVE+eGPtEw5Vqni2PqxZfhdPj5O5T7+aRlY+QGJbI61NeJzo4+oDtbCrZxHVLryM+NJ7XJ79ObEhsw7K9VXu5d8W9bCjeQHpaOtcOuJbvcr8jIzuDHeU7sBgs/O/c/zU5UTg9TiZ/OJk+MX146cyXAFhduJqZK2ZSUFNwyOMVagplQvIE0runMyJxBA63g2V7lvFZ9mesyl+FW7mblG9+5Vthr2Dp7qVkZGfwc9HPLe7jlPhTmNZ9GuOSxrG+eD0ZWRksz1uOy+NiWvdp3D/ifiIs3rfp3vjljWwo2sCn539KTHAMAI+uepT3tr3Hk2OfZMnuJSzbu4zhCcMZFDeIVze+yvm9zuehUQ8d8O/Rozzeq/8s79V/ub28yXKjGBmZOJL07umM7zYeq6XlNsA1hWuYuWImJXUlDUljTNKYAy4Kmtt/J5WRncHK/JUHHMuooCgmp04mPS2dwfGDqbBX8MXuL8jIzmBd0ToABsYNJD0tncmpkw95MXM4OiG0JruN+tfSYV8mf498hIduuYEQy/H5nuOvcr7inz/+k1GJo0jvns7IxJFNrqpak1KKR398lAp7BU+f/vRv2k5maSafZX9GRlYG5fZyru1/LTcNuqmh6mFXxS7uXX4vW8u2MrTzUNLT0pmUMomo4CiW7l7Kw6sexuF2MDxhON/mfsvjYx/nrO5nNewjszSTP2T8gUFxg8ipyqHSXsltQ25jStoUrv78aiodlbw++XVOijmJ1YWruenLm+ge2Z3XJr9GuCW8YTvby7dz9edXE24JZ96UeXQO63zA93F5XMzZOIdXfnml4SQyOG4wE5InMGv9LMYljeOZM55pKP9lzpf8+Zs/88L4Fzij2xkN8x1uB4U1hYc8dvGh8S3eDYH3Kr5xQ60gJFgTDnrHUVpXSo2zpuFznauOb/Z+Q0Z2BlmVWQ3z40LimJo2lfTu6Zwce3KTbeyq2MUFiy7gwt4X8sDIB/h277fcsuwWrux3JXefejdKKRbsXMATPz1BnauOqalTeXzs4w1X6Afj9DgptBWi+PWcFxkUSWRQ5CHX28/lceH0OAkxhfhVvrnmxxIg0Zp40GOZb8vn892fk5GVwbbybRjEwMwRM7nopIuOav86IbQWtxPHW7/HsPtb7jHew9233UFi5NH9KNq7wppCzl90PuHmcKqd1VQ7qokJjuHs7mdz+9DbD/rjPVoLdy7kwe8fBOCNKW8wtPPQA8p8l/sdwcZghicOb3EbH23/iNc3v05OVQ5mg5kxXcdwdf+rGRI/5ICyTreTt7a8xYIdC9hdtRuTmOgd05vM0kz6x/bn8bGPkxSexDVLrmFH+Q4+POdDulq7Uuus5eJPL6bWVcvH53zc0Ij51Z6vCDIGYRQjr056lYFxA5vEffvXt9MzqieD4n59LeqXOV9iFCPzps47bHXA5tLNbCjewLikcQ3VSi+vf5mXfnmJeVPmcUrnUwC4YekNZFdl8/n5nx/2xNgWlFJsL9/O9/nf0z+2P0M7Dz1knI/9+Bjvb3uf2RNnc8939xAXEse7097FYrQ0lNlbtZflecv5/Um/b/XfZXuzs3wnGdkZTE6dfNRtNTohtAalcP7vdszr5zHTfQMXXn8/Q5IPrAI4Hrg9bq5beh2ZpZnMP3s+CWEJrMhbwadZn/JFzhf8ceAfuWXILa22vz1Ve7jwkwvpG9OX3VW76Rfbj5fPfLlJmXxbPmcvOBuL0cKn533apGoFYEvpFi7+9GL6d+rPhb0vZELyBL+u+JRSbC3byuLsxXyf/z2/6/Y7/jjojw0nljxbHhcuupBe0b2YO3kuj/34GB9u/5A5k+Y0JCalFAt3LuTNzDe5f8T9nJpw6gH7+TLnS55a/VST7ogxwTE8c/ozdI/qfkB5f9S56jh7wdnEhsTy32n/Jbc6l2kLpnHz4Ju5cdCNR7XN9qaivoL0BenUOmsxGUy8f9b7TerftSPnT0JAKdWhpqFDh6pjyf7NM0r9PULNeuAKtXhjwTHd97H26oZXVf83+qsFOxYcsOz+5fergfMGqrWFa1tlXw63Q1366aVq1LujVIGtQM3+Zbbq/0Z/lVmS2aTcXd/cpYa+NVQNnjdY/eOHfzRZ5vF41IzFM9TY/45VlfbKVomrsU92faL6v9Ff3fTFTar/G/3VM2ueafV9HK39sS3csVA9vfppNWjeILWvZl9bh9Wq3s58W/V/o796d8u7bR3KcQHvmyoPeX4N6JPKIjIFeB7vKzTnKKWeaLb8X8DvfB9DgXilVFQgYzoSjvUfYvn6H3ziHkXKhY8zpb9/3QAr7ZU8s+YZMkszm8zvHtmd9O7pjO4y+oAudUdiW9k2nl/3PBeddFGT+uL99lTt4ZFVj9A3pi/p3dM5KfqkwzZ+byrZxKyfZzEpZRLTe0w/YPn9I+5n3b513Lf8PuafM7+hAfBwnG4nczbOYXPpZsYnj2+4gn/ll1fYWLKRp09/moSwBC7uczFzN81lzsY5DXXjPxf9zOe7P+fGQTdic9h4d+u7XNLnEnpH9wbgqz1fsWbfGh4c+eRjdlAAACAASURBVKDf8RyJs7qfxfLc5WRkZ9A3pi+3Dr611fdxtNLT0vnvlv/y/LrncXqcjE8ef8geTR3RZX0uY2TiyCa9nLTACliVkYgYge3ARCAXWA1cqpTKPEj5W4EhSqlrDrXdY1VlZN+9CnnjLDZ40iiY/j5nD/XvR7mqYBUzV8ykrK6M07qehlG89aTK19e53F5OhCWCiSkT6RXdq8m6fWP6Mjh+8EH7K3uUhzc3v8m/f/43To8Ts8HMi+Nf5LSupzWUKawp5MrFV1Jhr8DpduJSLm8iSksnPS2dbhHdDthuTlUON391M/Wuej4656ODVrlsKN7AlYuvZHLqZJ4c9+Rhj0VWZRb3Lb+PzNJM4kPiKaorwmQwMSJxBCvzV3JOj3N4ZPQjDeWfW/scczfNZdG5i0iOSOayzy6juLaYT877BKfHybQF0+gT04dXJ76K0+PknIXnEGIKYf7Z8wPW6F3tqOblX17m0pMubfHYtaVfin/h8ozLAZg9cTajuoxq44i09qytX6E5HNiplMryBfMeMB1oMSEAlwJ/D2A8R2TfB3diVJEUTp3bYjJQSlHvrm/47PK4eOWXV3gz801SI1L597R/H9B7wulxsip/FRnZGWRkZ1C3o+6A7SaGJXp7X6SlkxyR3DC/pK6Ev//wd1YXrmZ8t/H8Zdhf+Mu3f+H2r2/nlYmvMLTzUErqSrh+6fVUO6p5Y8obJIYl8kWOtwvbi+tf5MX1LzKw00Cmpk1lROIIVhWsIiMrg02lmzAZTMyeOPuQ9e8D4wZy06CbeHH9i4xNGtukB07zY/P+tvd5Zs0zBJuCee6M5xifPL6hF9CS7CWkRKRw7/B7m6x3eb/LeXvL28zdNJdTE05lc+lmHhvzWMODVX8a9Cce/+lxvs39lqzKLPJsefxn4n8ClgwAwi3h3HPqPQHb/m8xKG4Q5/U8j8zSTEYkjmjrcLTjQCDvEC4EpiilrvN9vgIYoZQ6oFVSRFKAVUCSUs066jZzLO4QSrZ9T6f/pvNp1zs46/p/tFjmvuX38WnWpwfMv/iki/nLsL8ctmuaw+1oMm6LS7lYVbCKz7I+a7G/Mnj7i987/F7O7XkuIkJpXSlXL7maotoinj39WZ5e+zS51bn8Z+J/DuhhU1hTyOLsxWRkZ7C1bGvD/L4xfZnWfRqTUyf79WSs2+PmmiXXsKVsCw+OfJCzup/VpDqqpK6Ev33/N5bnLWd0l9E8MvoR4kLjmmzDozx4lKfFE/ljPz7G/O3zibREkhiWyDvT3mm4Y3J6nFy46EIcbgfl9nJO7XwqL0x44bAxH888ygNw0LtKTduvTXsZHWFC+CveZNBiJa2I3ADcAJCcnDw0JycnIDHvt+HfF5FW+h2VN20gKeHAetmsiiym/286E5InNOlm2D+2/0G7Rh6Jsvoyvt7zNZWOX/ssG8XI+OTxdAtvWm2xr2YfV31+FXm2PMwGM7MmzDps1cGuil2s3beWYQnDjqp+tqi2iLu/vZt1ReuYnDqZB0c+SGRQJMv2LOOhHx6i1lXLnUPv5NI+lx7xg3v5tnymfTwNl3Lx1tS3GBw/uMnyFXkruOnLmzCJiQXTF5AamXrE8WvaiaitE8Io4CGl1GTf5/sAlFKPt1D2Z+BmpdQPh9tuoO8QyvftIeylwayKOY9xt7/WYpmZK2byRc4XLLlgSYtPoR5rudW5PLTyIa7oewWndzv9mOzT7XHz+ubXmfXzLGJCYhgaP5TFuxfTN6YvT4x94qi7VIK3n32du447h97Z4vInf3qSpPAk/tD3D0e9D0070bR1QjDhbVSeAOThbVS+TCm1uVm5PsDnQJryI5hAJ4RVc+5k+N657PnDclJ7Dzhg+f4r2Ev6XMJfh/81YHF0FJmlmdy7/F52V+7mmv7XcPPgm39TDypN0wKjTRuVlVIuEbkFWIK32+lcpdRmEXkYb3/YRb6ilwDv+ZMMAs1WY6N37nw2ho1kUAvJAOCNzW+A0GTgrRNZv9h+zD97PkW1RQdUZ2ma1rEE9DkEpVQGkNFs3t+afX4okDEciTWfvsoZVFF2estP45bUlfDxjo85u/vZRzw08fEsyBikk4GmHQd01wSfeoeLhC3z2GtKpefwaS2WeWfLOzjcDq7pf8hHJTRN0zokvxKCiISKyIMi8qrvcy8RabkTege1/KtP6EM29qHXQws9Y6od1by39T0mpU7SPVs0TTsu+XuH8DpgB/b3Z8wD/hmQiNpI8C/zqBIrPSZcfcAyt8fNiz+/iM1p49r+17ZBdJqmaYHnb0LooZR6CnACKKVqgePmzTDFJcUMq/uerM5TEEvT1+zl2/K5bul1vLv1XS7odQF9Y/u2UZSapmmB5W+jskNEQsD7ZgkR6YH3juG4sPPbdxklDqJGXdkwTynFZ9mf8eiqR/EoD/8c/U/O6XFOG0apaZoWWP4mhL/jfVagm4i8A4wGZgQqqGMtcvtH7JEupAwYC3hHK3101aMs3r2YIfFDeHTMo7oXjaZpxz2/EoJS6gsRWQeMxFtVdLtSqiSgkR0jlQW76Gf/hW+TbiTZYODHgh+ZuWImpXWl3DL4Fq4dcG1AB0/TNE1rL/w604nIecAypdRnvs9RInKuUmphQKM7BvZ+8waRQNTIS3h69dPMy5xHakQqb6e/zcmdTj7s+pqmaccLfxuV/66UahhpTSlVQTsaqvqoKUWnrI9ZK/1ZVv8N8zLncfFJF/P+We/rZKBp2gnH34TQUrkOX49Sm/0jCc5ccpPPYdneZZzW5TQeGPlAw/j7mqZpJxJ/E8IaEXlWRHr4pmeBtYEM7FjYt/wN6pQF8ylnsLtqN2O7jm3rkDRN09qMvwnhVsABvO+b7MDNgQrqmHDZicv5jG8MI6iwZAEwpuuYNg5K0zSt7fjby6gGuPewBTsQx5bPsXqqKEw7l7X535NkTSIlIqWtw9I0TWsz/o5l1FtEZovIUhFZtn8KdHCBlL/xG+zKTMrwifxU+BNjuo454rd7aZqmHU/8bRieD7wCzAEO+c7jjqK6rAATkZjDc6lz1TE2SbcfaJp2YvM3IbiUUi8HNJJjzFJXTKUhhpUF32MxWDg14dS2DknTNK1N+duo/ImI/ElEEkUkZv8U0MgCLMRRhs0cw4q8FQxLGEaIKaStQ9I0TWtT/t4h7H9f5N2N5ing6N+k3sbCXWWsjehBduU2ft/7920djqZpWpvz6w5BKZXWwnTYZCAiU0Rkm4jsFJEWeymJyEUikikim0Xk3SP9AkfF4yZCVbHR6n2Ns+5uqmmadgRPG4tIf6AfELx/nlLqzUOUNwKzgIlALrBaRBYppTIblekF3AeMVkqVi0j8kX+FI+eqLsaEhy0WG12tXUmNSD0Wu9U0TWvX/O12+nfgBd/0O+Ap4HAvBxgO7FRKZSmlHMB7wPRmZa4HZimlygGUUkVHEPtRqyzJwwFsp1h3N9U0TfPxt1H5QmACUKiUuhoYBEQeZp2uwN5Gn3N98xrrDfQWke9FZJWITGlpQyJyg4isEZE1xcXFfoZ8cNUl+awNDsKBU1cXaZqm+fibEOqUUh7AJSIRQBHQGm+MMQG9gDOAS4FXRSSqeSGl1Gyl1DCl1LC4uLjfvNPasnw+t4ZhFjPDE4b/5u1pmqYdD/xtQ1jjO1G/indQOxuw8jDr5NE0aST55jWWC/yolHIC2SKyHW+CWO1nXEelsCKLRdYwpnZL1yObapqm+fjby+hPSqkKpdQreBuJr/JVHR3KaqCXiKSJiAW4BFjUrMxCvHcHiEgnvFVIWUcQ/1HJqPsFBVw/+IZA70rTNK3DOJJeRgOB1P3riEhPpdTHByuvlHKJyC3AEsAIzFVKbRaRh4E1SqlFvmWTRCQT75AYdyulSo/62/ihvL6cbwz5nGHzkBadHMhdaZqmdSj+vkJzLjAQ2Ax4fLMVcNCEAKCUygAyms37W6O/FXCnbzom3tnyDg4U6VW6qkjTNK0xf+8QRiql+gU0kmPA5rDx7tZ3GVkH0YZObR2Opmlau+JvL6OVItLhE8L87fOpdlQzo9yGPUgnBE3TtMb8TQhv4k0K20Rkg4hsFJENgQystdndduZtnsfIhBGMtJfjCf3t3Vc1TdOOJ/5WGb0GXAFs5Nc2hA5l4Y6FlNaX8nDq3RhWzofwzm0dkqZpWrvib0Io9vUK6rD6xfbjqn5X0cMTC4A5QicETdO0xvxNCD/7RiL9BLDvn3mobqftzYC4AQyIG8C2FQsACIlObOOINE3T2hd/E0II3kQwqdG8w3Y7bY/qKwoAsMZ2aeNINE3T2pfDJgTfMNalSqm7jkE8AeeqLAQgKr75OHuapmkntsP2MlJKuYHRxyCWY0LZiqhRQcREdeg3gGqaprU6f6uM1ovIImA+ULN/ZkdqQ9jPWFtMuUQRZtDvQNA0TWvM34QQDJQC4xvN65BtCEH2UqpN0W0dhqZpWrvjV0LwY2TTDiPMWUqJpTVe5aBpmnZ88fcVmkkiskBEinzTRyKSFOjgAiHSXY4jRA9boWma1py/Q1e8jvddBl180ye+eR2Kx+kgimo8ofFtHYqmaVq7429CiFNKva6UcvmmN4AONxhQZUk+AAarTgiapmnN+ZsQSkXkchEx+qbL8TYydygVJd43eFqiEto4Ek3TtPbH34RwDXARUAgUABcCHa6huabU+5RySIx+SlnTNK25Q/YyEpEnlVJ/BYYrpc45RjEFjN03bEWEHrZC0zTtAIe7Q0gXEQHuO5qNi8gU3zsUdorIvS0snyEixSKy3jdddzT78Zezah8A0XrYCk3TtAMc7jmEz4FywCoiVYDgfSBN8L4SOeJgK/rGQJoFTARygdUiskgpldms6PtKqVuO9gscCbHto0YFExYeeSx2p2ma1qEc8g5BKXW3UioK+EwpFaGUCm/838NseziwUymVpZRyAO8B01sp7qNiqiuh3BDVliFomqa1W4dtVPZd6R/u5N+SrsDeRp9zffOau8D3Ws4PRaTFR4hF5AYRWSMia4qLi48iFK9gewk2kx7UTtM0rSX+jnbqEZFA1LN8AqQqpQYCXwDzDhLDbKXUMKXUsLi4o3/8weoqp84Se9Tra5qmHc/8HdzOBmwUkS9oOtrpbYdYJw9ofMWf5JvXQCnV+FmGOcBTfsZzVCI95ewLOTWQu9A0Teuw/E0IH3PkI5uuBnqJSBreRHAJcFnjAiKSqJQq8H08B9hyhPvwW319HVHYUGEd7gFrTdO0Y8Lf0U7niUgIkKyU2ubnOi4RuQVYAhiBuUqpzSLyMLBGKbUIuE1EzgFcQBkw42i+hD/Ki/JIBIzhetgKTdO0lviVEETkbOBpwAKkichg4OHDPaymlMoAMprN+1ujv+/jKJ9xOFKVJd6EYIlKPBa70zRN63D8HbriIbzdSCsAlFLrge4Biikgasu8NVNhetgKTdO0FvmbEJxKqcpm8zytHUwg2SsKAYiI008pa5qmtcTfRuXNInIZYBSRXsBtwA+BC6v1hThKAIjSCUHTNK1F/t4h3AqcDNiBd4FK4I5ABRUIgy+8H25dhzk4rK1D0TRNa5cON9ppMHAj0BPYCIxSSrmORWCtzhIKsT3aOgqtBY7cXDy1tQT37t3Wofxmyu3GVVyMOeHw79xQSuEuKUF5FObOrdP7zZ6dTe2aNZg7d8aUkIC5SxeMVuuh43A4cNtseHwTRiOGMCvGcCuGsDDE9OtpQimFstvx2Gy4q6vx2GoQiwWjNQxDeLi3vNHod7zK7cZVUoKroABnYSHu6moiJk3CGHngc7DK7ca+axfGqChMnTohhkNfz3ocDhw7dyIhIRjDwzFYrUhQEN7xOn3bdLnw1NTgrrbhqbHhqa5u+F4eWzUYjJgTE7zHMjERQ3Bwk2PlLfvr32IwYLBaMVitDfs0WMO9x8dqPfBYOhx4fNtw22oQs9l73K3WIz6WreFwVUbzACewHJgK9KWD3RkcLzy1tUhw8GH/EbTKvmpqqNu0meCTT8ZoPfCOyvsPqNqvk97h2JavIO+OO1BOJ0mzZmEdO+Y3bc9VUkLJf2bjsdkwJ3XF3LUr5i5d8FRX49idgyMnB2d+PtZx44i+7NIm/0B/C09tLRUfL6DszTdx7tlDxNlnk/D3vx1wMq7fsoWKjz7Gvn079u3bcVdUgMFA13/9i4jJk35TDI69e8m55FLclc2a+0S8U0uU8k6H0vg3d4TlxWQi8txzifvzHZiioxvmexwOyl57jZJX56Bqa5usXvz0M3S6+U9EX3IJYrGgPB6qFi+m5KWXceza5S1kNmOOj8eSmkrUBecTPnEiYjZ7Q/R4qPosg+LnnsOZ1+RZ2AOPhecYN4Ue4bE0hIZ6E224FWOYlZjrriVi4sSAhSfqEAGJyEal1ADf3ybgJ6XUKQGLxg/Dhg1Ta9asacsQjjl3VRU7z5yIMSqK6MsuJer88zFG+D+8lH3nTio++pjQoadgPeOMg54E3TYb5W+/Q9kbb+CuqEDMZkJHjMA6/ncE9+lD7eo11KxYQe369eB0EnPVlcT9+c8YgoObbKPkpZep37CBkFOHYR07lpCBA1vcZ/n7H1D48MME9ewJIjiyskh68QWs48Yd8TFSbjfl771H8XPP46mvxxQdjauo6IByxuhojNHROLKyCOrTh4S//Y3QU4Z4j9OOHZS//wHVS5di7tqVsFEjCRs1ipBBgxCL5dd9uVy4iotxFhTiLMinPjOTig8/wlNZSfCggYQMGEj5u+9i7tKFrk//HyGDB+PMy6P43/+mctEnSHAwwSedRFCvXgT16kXV4sXUbdpEt5deOmRCdJWXs++Rf2LPzibpX89iSU1tdNxryLn0UpxFRST/5xWUR+EqLMBZUIjbVn3IY2cICsJgDcdgDcNotaLcHt9VbzXuahvK3bRSwBAc4j1B+e4IlMPZUNZjs6E87l9jLiqicuH/MIaHE/eXO4m64AJqvv+Bwn8+gjNnD+ETzyRs9OiGK3DlcFD8r39R88NKLCkpRF30eyoWLMCxcxdBvXoSffkVKJcTV2EhzoJC6n75BefevZg6dyb6sssIOqk3JS+8SP3mzQT160vsjBkg4r2Sr7bhqa9r8l3EaPJdkYf7ruqtvjsd79/K5cJZUNhwLJXD3rRsszsAlGp6t2Gzefdb472DUK6DHEvfHYFyurzHcv96Nhtumy92WzXRV1xB+O9+d8j/nwcjImuVUsMOWeYwCWFd4wTQ/HNb6IgJwZ6VReXC/2FJSyPy3OlNbln9Uf7e+xQ+9BBB/fpiz9yChIQQedZZGCMjcBYV4Soqxl1eTtjIEURdfDFB3b09gj01NZS8/DKlb8wD3w/RFB9P1IUXEDl9uvcfSlkZrrJy6jdtouydd/BUVhJ2+jiizjuPul82YFu2DEdOTkMsQX36YB0zGne1jYr338fSvTtdnnyC4JNPpnLh/yh69lncpaUE9e6NfccO8HgwhIcTOnw4wSf3I7hfP4L79qPszXmUvTaXsHFj6frsv1BOB3uuvRbHjp3epHD66QA48/Ko+fEnJMiC9fTTD7jiVi4XtatXU/R/T1OfmUnoqJEkPPggQd2747Hbcebn48zPxxgejiUlBWNkJEopqr/4gn2PP4GroICIadNwFhRQt24dYjYTdvo4XEXF1G/aBB4PYjZ7r1RdLpTb3XAsGxgMhJ95JjEzZjQkl9p168i/626c+/YRPmECtm++ASDmqiuJvf76JgndXVVFzlUzcGRnk/zaHEKHDj3gN2D77jvyZ87EXVGJISQEESFp1ouEDhuG8njIve02bMu+pturs7GOHn1Ev69Aq9+2ncJHHqZuzVpMXRJx5RdgSUmh8wMPtJgAlVLUfPcd+576Pxy7dmHp0YO4m/9E+JQpB9whK48H27ffUv7WW9T8sBIAU5dE4u+4g4izzjomd9QdRWskBDe/jl0kQAhQix/vQwiUjpIQlMNB9VdfUf7e+9T++GPD/Ij0qSQ8/PABJzbnviKM0VEYGl2J7rf7kkvx1NhIW7QI+5YtlL39DlWffgpKYYqPxxQfjyEkmJrVa8DpJHT4cKzjxlL29ju4CguJvOB84u+4g7oNGyh//31qlq9o8VbVOn48nW66iZAB/ZvMt2dlY9+5g9AhQzA1Glyw5ocfyL9/Jq7iYixpqTh27iJk0CA6PzCTkAEDcFdWUrNyFbYVy6lbuw7H7t1N9ht16SUkzJzZcPfgrqhgzzXXYt+xg4j0qdT+vB7nnj0N5cVsJuy00wifNBHlclOzYgU1q1bhqa7GFB9P53v/SvjUqX4nXE9trTdhvv4Glq5dibroIiLPOxdTjHdEXHdVFbU//UTtzz+Dyw0mI2IyI2Yzprg4zIneq1pTYpcWq9bc1dUUPvQPqjIyiJw+nbjbbsXcpeXnYFylpeRcfgWu4mKS57yKOSnJWzVns1Exfz4V771PUK9edHnqSQxhYez94404cnPp8s9HcOTsoeSll+h8373EXHWVX9/9WFNKUfXJJ5S+OoeI9KnEXHtti7/1Juu4XNh37SKoZ0+/6tLtO3ZQv3074WeeiSEoqLVCP2785oTQHnWEhKA8HvZceZW3ca9LF6Iuvpio88+jYuFCip97HktSEl2f+xeWlBSqli6l8sOPqF2zhshzz6XLE4832ZZj9252TZlK/F1/Ifa6X18op5xOMJmanPxcJSVUfLyAig8+wJmbe0CVSMM2c/OwffcthpBQTDHRGGNiMMV3PqqGTXdVFfsef4LaH3+k0223EnnOOQe9KnPbarBv20r95s2Y4uK8V3zNTt7uykr2/ulm7Nu2EXrqqYSNGknoiJF4amxUL/2C6qVLcebnA2BKTMQ6ZjRho8dgHTsGQ9jR9SDz2O2IxXLEd27+cttsh23YBXAWFLD7D3/AlV/QdIEIMddcTdzttzecRN2VleTednvDxUbkueeS+PhjAfsOWsenE0Ibqfz0M/Lvuov4v/6VmCuvaHJ1U7t2LXl3/gV3eTliNuOpqcGckow5IZHa1avp/skignr82huq6PnnKf3PbHp+/bXfJ2zl8eDIzsaSktJqjabHmvJ4WkwsSins27cjJhOW7t2PuxOgs6CAqs+XIEGWhnplS0qKt52lGeVwsO+JJ3EWFtL1X8/qq2LtkHRCaAOe+np2padjjIoi7cMPWzypucrKKPq/p0GEqPPPI2ToUNwVFeyacCbWM06n67PPAt6T4s4zzySoew+S57x6rL+KpmnHEX8SQse8fGzHyt58C1d+AV0ee/ygVSemmBi6PP5Y03nR0URfcQWls2cT+8cbCT6pN7Wr1+DKLyD+z3cei9A1TTvB6Sb4VuQqLaX0P//B+rvfETZyxBGvH3v1DAxhYZS8+CIAlQsXYggLI/zMCa0dqqZp2gF0QmhFxS++iKe+nvi77zqq9Y1RUcRcdRXVX3xB7dq1VC9ZQvjUKRhCQlo5Uk3TtAPphNBK7Lt2UfHBfKIbPQdwNGKuuhJDRAS5t9yKp7aWqHPPbcUoNU3TDk63IbQC5XJR+I+HMYSE0OmWm3/TtowREcReczXFzz2POSmJkFPa9DlArYNwOp3k5uZSX1/f1qFobSw4OJikpCTMvqE8joROCK1g35NPUfvTTyQ+9ljDQ02/RfTlV1D+/gdEX3aZftJS80tubi7h4eGkpqYed11xNf8ppSgtLSU3N5e0tLQjXj+gZxsRmSIi20Rkp4jce4hyF4iIEpFDdolqj8rnz6f8rbeIuepKos4/r1W2abSG0XPZV8Rec3WrbE87/tXX1xMbG6uTwQlORIiNjT3qO8WAJQQRMQKz8I6S2g+4VET6tVAuHLgd+LH5svauds0aCh9+hLDRo4m/++5W3bb+h60dKf2b0eC3/Q4CWWU0HNiplMoCEJH3gOlAZrNyjwBPAq17Rm1lZW++ScXChQT16ElQ715YuiVT+PDDWLp2peuzz3TYJ4I1TdP2C2SVUVdgb6PPub55DUTkFKCbUuqzQ21IRG4QkTUisqa4uLj1Iz0Mj91OyayXcJeVU/vTTxQ/8+yvY/i/9FKLL/PQtBNJRUXF/7d372FR1vn/x59vEEE8IGoaeUhNV1MDDc/4K8tIzc08xmrp2qZlJWl9+25uW6Zp38tcO1lmUpbHEjXNI7pqsF67rQUaeUBCUdZDaKTIQeX8+f0xN+yIgEAOM8j7cV1ezn3PPfe8mBl4z316f/joo48q9diHHnqIixcv3uBEqjKc9rVWRNyAd4AJ11vWGBMGhIGtdYVjk10rY8cO8tPSaPXeu9Tt04f8ixfJPnoUjxYt8PDzq+o4SrmcwoLw7LPPXnNfXl4etcrYgt62bZsjo1WaMQZjDG416MQORxaEM0BLu+kW1rxC9YEuQJS1z+tWYJOIDDXGuFSzotTwNXjc3grvXrarj90bNsS7Rw8np1KqZLM2Hybu5/Qbus5OtzXg9Yc7l3r/9OnTSUxMpGvXrgQHBzNkyBBee+01fH19iY+PJyEhgWHDhnHq1CmysrKYOnUqTz31FACtW7cmJiaGzMxMBg8eTL9+/fj2229p3rw5GzdupE6xCzM3b97MnDlzyMnJoXHjxqxatYpmzZqRmZlJaGgoMTExiAivv/46I0eOZPv27bzyyivk5+fTpEkTdu/ezcyZM6lXrx4vvWS7iLRLly5s2bIFgIEDB9KrVy/27dvHtm3bmDt3LtHR0Vy5coVRo0Yxa9YsAKKjo5k6dSqXLl3C09OT3bt3M2TIEBYsWEDXrl0B6NevHwsXLiQgIOCGvh+O4siCEA20F5E22ArBH4CxhXcaY9KAJoXTIhIFvORqxSD72DGu7NtH0/99SU8BVaoUc+fO5dChQ8TGxgIQFRXF/v37OXToUNHpj5999hmNGjXiypUr9OjRg5EjR9K4ceOr1nP06FG+/PJLPvnkEx599FG++uorHn/88auW6devH3v37kVE+PTTT5k3bx5vv/02s2fPxsfHh4MHhUHCTAAAGbZJREFUDwKQmppKSkoKkyZNYs+ePbRp04YLFy5c92c5evQoy5Yto3fv3gC8+eabNGrUiPz8fAYMGMCBAwfo2LEjISEhhIeH06NHD9LT06lTpw5PPvkkS5cu5b333iMhIYGsrKxqUwzAgQXBGJMnIlOAHYA78Jkx5rCIvAHEGGM2Oeq5b6TUNWvAwwOf4TfmlFKlHK2sb/JVqWfPnledC79gwQI2bNgAwKlTpzh69Og1BaFNmzZF364DAwNJSkq6Zr2nT58mJCSE5ORkcnJyip5j165drF69umg5X19fNm/ezD333FO0TKNyXCd0++23FxUDgDVr1hAWFkZeXh7JycnExcUhIvj5+dHD2lPQwBoBb/To0cyePZu//e1vfPbZZ0yYMOG6z+dKHHoMwRizDdhWbN6MUpbt78gslVGQlUXa1xtpEPzADbngTKmapK7dgEVRUVHs2rWLf//733h7e9O/f/8Sz5X3tBvTwd3dnStXrlyzTGhoKC+++CJDhw4lKiqKmTNnVjhbrVq1KCgoKJq2z2Kf+8SJE8yfP5/o6Gh8fX2ZMGFCmef4e3t7ExwczMaNG1mzZg379u2rcDZn0n0gZUjfvp2C9HQaPhri7ChKubT69euTkZFR6v1paWn4+vri7e1NfHw8e/furfRzpaWl0by57YTFZcuWFc0PDg5m4cKFRdOpqan07t2bPXv2cOLECYCiXUatW7dm//79AOzfv7/o/uLS09OpW7cuPj4+nDt3joiICAA6dOhAcnIy0dHRAGRkZJBnjbU9ceJEnn/+eXr06IGvr2+lf05n0IJQhovha6jdujXevXo6O4pSLq1x48YEBQXRpUsX/reEizQHDRpEXl4ed955J9OnT79ql0xFzZw5k9GjRxMYGEiTJkWHIXn11VdJTU2lS5cuBAQEEBkZyS233EJYWBgjRowgICCAkBDbl7uRI0dy4cIFOnfuzIcffsjvfve7Ep8rICCAbt260bFjR8aOHUtQUBAAtWvXJjw8nNDQUAICAggODi7acggMDKRBgwY88UT16zSgI6aVIishgRNDH6Hpn/+sLSSUyzty5Ah33nmns2Mo4Oeff6Z///7Ex8c77ZTVkj4P5RkxTbcQSpH65ZeIhwc+w7X9tFKqfJYvX06vXr148803q+X1C9pvoQR5qamkbfiaBg8/TK1qtg9QKeU848ePZ/z48c6OUWnVr4RVgdRVX2Cysmj85J+cHUUppaqMFoRiCq5cIXXlSurddx+ed9zh7DhKKVVltCAUc3H9evIvXtStA6VUjaMFwY7Jy+PC0mXUCQigTmCgs+MopVSV0oJgJ2PnTnJPnaLRxCd1sBGlKqAq219PmDCBdevWlXv5pKQkunTpUplov1lFszqbFgSLMYbzny6h9u23U//++50dR6lqpayCUHgFb2m2bdtGw4YNHRFLVZCedmq5/N33ZB0+zK2zZiHu7s6Oo1TlRUyHswdv7DpvvQsGzy317qpsfw22RnZz584lPT2dd955h9///vckJSUxbtw4Ll26BMCHH35I3759r3pcacsU9kRq0qQJhw4dIjAwkJUrVyIiJba59vb2Zvr06URFRZGdnc1zzz3H008/jTGG0NBQdu7cScuWLaldu3aJr9cnn3xCWFgYOTk5tGvXjhUrVuDt7c25c+eYPHkyx48fB2DRokX07duX5cuXM3/+fEQEf39/VqxYUfH3sBy0IFhSV63E3dcXn2GPODuKUtVOVba/Btsf9u+//57ExETuu+8+jh07RtOmTdm5cydeXl4cPXqUMWPGULyrQVnL/PDDDxw+fJjbbruNoKAg/vWvf9GzZ88S21wvWbIEHx8foqOjyc7OJigoiAcffJAffviBn376ibi4OM6dO0enTp3405+uPUFlxIgRTJo0CbC13FiyZAmhoaE8//zz3HvvvWzYsIH8/HwyMzM5fPgwc+bM4dtvv6VJkyblauFdWVoQgLzz58mIjKLRuHG42XVbVKpaKuObfFVyVPtrgEcffRQ3Nzfat29P27ZtiY+Pp02bNkyZMoXY2Fjc3d1JSEi45nG5ubmlLtOzZ09atGgBQNeuXUlKSsLHx6fENtd///vfOXDgQNHxgbS0NI4ePcqePXsYM2YM7u7u3Hbbbdxfyu7nQ4cO8eqrr3Lx4kUyMzMZOHAgAN988w3Lly8HbN1efXx8WL58OaNHjy7q21SeFt6VpQUBSNu4CfLyaDhqpLOjKHXTcFT7a+Cakz5EhHfffZdmzZrx448/UlBQgJeX1zWPK2uZ4s9d1rEPYwwffPBB0R/yQuUdDnTChAl8/fXXBAQEsHTpUqKiosr1OEer8QeVjTFc/Oor6nTtqheiKVVJVdn+GmDt2rUUFBSQmJjI8ePH6dChA2lpafj5+eHm5saKFSvIz88vMcf1lrFXWpvrgQMHsmjRInJzcwFISEjg0qVL3HPPPYSHh5Ofn09ycjKRkZElrjcjIwM/Pz9yc3NZtWpV0fwBAwawaNEiAPLz80lLS+P+++9n7dq1nD9/HsChu4xqfEG4EhtLTmIiPiNHODuKUtVWVba/BmjVqhU9e/Zk8ODBfPzxx3h5efHss8+ybNkyAgICiI+Pv2oLpVB5lrFXWpvriRMn0qlTJ+6++266dOnC008/TV5eHsOHD6d9+/Z06tSJ8ePH06dPnxLXO3v2bHr16kVQUBAdO3Ysmv/+++8TGRnJXXfdRWBgIHFxcXTu3Jm//vWv3HvvvQQEBPDiiy8CsGnTJmbMKHG8sUqr8e2vk197jbSt22i/Zw/u9cr+cCjlqrT9tbLnku2vRWSQiPwkIsdEZHoJ908WkYMiEisi/xSRTo7MU1zBpUukb91Gg0GDtBgopWo8hxUEEXEHFgKDgU7AmBL+4H9hjLnLGNMVmAe846g8JUnfvoOCy5f1YLJSSuHYLYSewDFjzHFjTA6wGrjqJH9jTLrdZF2gSvdfXfzqK2q3aUOdbt2q8mmVUsolObIgNAdO2U2ftuZdRUSeE5FEbFsIz5e0IhF5SkRiRCQmJSXlhoTLPn6cK/v303DkCO1bpJRSuMBZRsaYhcaYO4CXgVdLWSbMGNPdGNP9lltuuSHPmx4RAW5u+DyiVyYrpRQ4tiCcAVraTbew5pVmNVBlAxhn/5RA7ZYtqXWDCoxSSlV3jiwI0UB7EWkjIrWBPwCb7BcQkfZ2k0OAow7Mc5Xs44nU1gvRlHKaevXqOTuCKsZhrSuMMXkiMgXYAbgDnxljDovIG0CMMWYTMEVEHgBygVTgj47Kc1W23Fxykv5D/fu0zbVSytaiu1Yt7eTj0FfAGLMN2FZs3gy721Md+fylyTl1CvLy8GynWwjq5vPW928RfyH+hq6zY6OOvNzz5VLvnz59Oi1btuS5554DYObMmdSrV4/JkyfzyCOPkJqaSm5uLnPmzOGRChy3e+ONN9i8eTNXrlyhb9++LF68GBHh2LFjTJ48mZSUFNzd3Vm7di133HEHb731FitXrsTNzY3Bgwczd+5c+vfvz/z58+nevTu//vor3bt3JykpiaVLl7J+/XoyMzPJz89n69atpWYt3n76o48+wt/fn4SEBDw8PEhPTycgIKBourqqkSUx+9gxAGq31YKg1I0QEhLCtGnTigrCmjVr2LFjB15eXmzYsIEGDRrw66+/0rt3b4YOHVruM/umTJlS1J5h3LhxbNmyhYcffpjHHnuM6dOnM3z4cLKysigoKCAiIoKNGzfy3Xff4e3tXa6eP/v37+fAgQM0atSIvLy8ErPGxcVd0366fv369O/fn61btzJs2DBWr17NiBEjqnUxgBpaEHKswSc827a5zpJKVT9lfZN3lG7duvHLL7/w888/k5KSgq+vLy1btiQ3N5dXXnmFPXv24ObmxpkzZzh37hy33nprudYbGRnJvHnzuHz5MhcuXKBz587079+fM2fOMHz4cICijqW7du3iiSeewNvbGyhfm+jg4OCi5YwxJWb95ptvSmw/PXHiRObNm8ewYcP4/PPP+eSTTyr2ormgGlkQso8lUus2P9yu09hKKVV+o0ePZt26dZw9e5aQkBAAVq1aRUpKCvv27cPDw4PWrVuX2Pa6JFlZWTz77LPExMTQsmVLZs6cWe7H2qtVqxYFBQVF67Rn39yuolmDgoJISkoiKiqK/Px8p43bfCM5/ToEZ8g+nojnHe2cHUOpm0pISAirV69m3bp1jB49GrC1m27atCkeHh5ERkbyn//8p9zrK/xj3KRJEzIzM4sGo6lfvz4tWrTg66+/BiA7O5vLly8THBzM559/zuXLl4H/tolu3bo1+/btAyhzwPvSspbVfnr8+PGMHTuWJ554otw/lyurcQXBFBSQc/wEnm3bOjuKUjeVzp07k5GRQfPmzfHz8wPgscceIyYmhrvuuovly5df1erZXuEoafYaNmzIpEmT6NKlCwMHDiwatQxgxYoVLFiwAH9/f/r27cvZs2cZNGgQQ4cOpXv37nTt2pX58+cD8NJLL7Fo0SK6devGr7/+Wmr+0rKW1n668DGpqamMGTOm4i+YC6px7a9zTp8m8YFgbp39Br7Wtxilqjttf+0c69atY+PGjQ4b9L6yKtv+usYdQyg8w0hHR1NK/RahoaFERESUe9jM6qDGFYScxMIzjHSXkVKq8j744ANnR7jhatwxhOzERNybNMG9YUNnR1FKKZdS4wpCTmKi7i5SSqkS1KiCYIwhOzERzzt0d5FSShVXowpC3i8pFGRmapdTpZQqQY0qCDmJeoaRUq6iPO2vW7duXea1A8UtXbqUKVOm/JZYlVbRrK6oRhWE7GOJgBYEpZQqSY067TT7eCJuPj64W02qlLoZnf2//yP7yI1tf+15Z0dufeWVUu93VPtrgHnz5hEREUGdOnX44osvaNeuHZs3b2bOnDnk5OTQuHFjVq1aRbNmza56XGnLzJw5k5MnT3L8+HFOnjzJtGnTeP5523Duxdtcr1ixgpSUFCZPnszJkycBeO+99wgKCuL8+fOMGTOGM2fO0KdPH0q7yPeZZ54hOjqaK1euMGrUKGbNmgVAdHQ0U6dO5dKlS3h6erJ79268vb15+eWX2b59O25ubkyaNInQ0NAKvV6/RY0qCDnHEvFs27bcrXeVUuXjqPbXAD4+Phw8eJDly5czbdo0tmzZQr9+/di7dy8iwqeffsq8efN4++23r3pcWcvEx8cTGRlJRkYGHTp04JlnniEhIeGaNtcAU6dO5YUXXqBfv36cPHmSgQMHcuTIEWbNmkW/fv2YMWMGW7duZcmSJSXmf/PNN2nUqBH5+fkMGDCAAwcO0LFjR0JCQggPD6dHjx6kp6dTp04dwsLCSEpKIjY2llq1apWrhfeNVKMKQvbx49QfoKOkqZtbWd/kHcVR7a+Boj5BY8aM4YUXXgDg9OnThISEkJycTE5ODm3aXNvKvqxlhgwZgqenJ56enjRt2rTMNte7du0iLi6u6LHp6elkZmayZ88e1q9fX7Q+X1/fEvOvWbOGsLAw8vLySE5OJi4uDhHBz8+vqD9TgwYNip5r8uTJRaO3laeF943k0GMIIjJIRH4SkWMiMr2E+18UkTgROSAiu0XkdkdlyUtNJf/CBR0URykHKWx/HR4eXmL769jYWJo1a1bhFtb2WxOFt0NDQ5kyZQoHDx5k8eLFJa6zrGU8PT2Lbru7u5OXl1fq8xcUFLB3715iY2OJjY3lzJkz5R4P+sSJE8yfP5/du3dz4MABhgwZUqkW3lXFYQVBRNyBhcBgoBMwRkQ6FVvsB6C7McYfWAfMc1SenETrgLIOm6mUQ9zo9teFwsPDi/7v06dP0XqbN28OwLJly0p8XHmWsVdam+sHH3zwqjYVsbGxANxzzz188cUXAERERJCamnrNOtPT06lbty4+Pj6cO3eOiIgIADp06EBycjLR0dEAZGRkkJeXR3BwMIsXLy4qUFW9y8iRWwg9gWPGmOPGmBxgNXDV0SRjTKQx5rI1uRdo4agwRWcYaQ8jpRziRre/LpSamoq/vz/vv/8+7777LmA7aD169GgCAwOLdvEUV55liucvqc31ggULiImJwd/fn06dOvHxxx8D8Prrr7Nnzx46d+7M+vXradWq1TXrDAgIoFu3bnTs2JGxY8cSFBQEQO3atQkPDyc0NJSAgACCg4PJyspi4sSJtGrVCn9/fwICAooKzowZM9i0adN1f4bfymHtr0VkFDDIGDPRmh4H9DLGlHiSsIh8CJw1xswp4b6ngKcAWrVqFViZbxkZu3dzcf0GWnywAHGrUWfbqhpA218re9W6/bWIPA50B+4t6X5jTBgQBrbxECrzHPUHDKD+gAGVzqiUUjc7RxaEM0BLu+kW1ryriMgDwF+Be40x2Q7Mo5RSqgyO3HcSDbQXkTYiUhv4A3DVTjAR6QYsBoYaY35xYBalbnrVbfRD5Ri/5XPgsIJgjMkDpgA7gCPAGmPMYRF5Q0SGWov9DagHrBWRWBFx/FETpW5CXl5enD9/XotCDWeM4fz583h5eVXq8TVuTGWlbka5ubmcPn3apc9xV1XDy8uLFi1a4OHhcdX8anNQWSn123h4eJR4ta5SFaHnXyqllAK0ICillLJoQVBKKQVUw4PKIpICVPxSZZsmgCsPaeTK+Vw5G7h2PlfOBq6dz5WzQfXKd7sx5payFq52BeG3EJGY6x1ldyZXzufK2cC187lyNnDtfK6cDW6+fLrLSCmlFKAFQSmllKWmFYQwZwe4DlfO58rZwLXzuXI2cO18rpwNbrJ8NeoYglJKqdLVtC0EpZRSpdCCoJRSCqhBBUFEBonITyJyTESmu0Cez0TkFxE5ZDevkYjsFJGj1v++TsrWUkQiRSRORA6LyFRXySciXiLyvYj8aGWbZc1vIyLfWe9vuNVy3WlExF1EfhCRLa6UT0SSROSg1V04xprn9PfVLl9DEVknIvEickRE+rhCPhHpYL1mhf/SRWSaK2Szy/iC9TtxSES+tH5XKvS5qxEFQUTcgYXAYKATMEZEOjk3FUuBQcXmTQd2G2PaA7utaWfIA/7HGNMJ6A08Z71erpAvG7jfGBMAdAUGiUhv4C3gXWNMOyAVeNIJ2exNxdb2vZAr5bvPGNPV7vx0V3hfC70PbDfGdAQCsL2GTs9njPnJes26AoHAZWCDK2QDEJHmwPNAd2NMF8Ad2xg0FfvcGWNu+n9AH2CH3fRfgL+4QK7WwCG76Z8AP+u2H/CTszNaWTYCwa6WD/AG9gO9sF2NWauk99sJuVpg++NwP7AFEFfJByQBTYrNc4n3FfABTmCd7OJq+ezyPAj8y5WyAc2BU0AjbF2stwADK/q5qxFbCPz3xSp02prnapoZY5Kt22eBZs4MAyAirYFuwHe4SD5rd0ws8AuwE0gELhrboEzg/Pf3PeDPQIE13RjXyWeAv4vIPhF5yprnEu8r0AZIAT63drd9KiJ1XShfoT8AX1q3XSKbMeYMMB84CSQDacA+Kvi5qykFodoxtpLu1HOCRaQe8BUwzRiTbn+fM/MZY/KNbdO9BdAT6OiMHCURkd8Dvxhj9jk7Syn6GWPuxrb79DkRucf+Tid/7moBdwOLjDHdgEsU2wXj7N8Lax/8UGBt8fucmc06dvEItqJ6G1CXa3dJX1dNKQhngJZ20y2sea7mnIj4AVj/O22caRHxwFYMVhlj1rtaPgBjzEUgEtumcEMRKRzwyZnvbxAwVESSgNXYdhu9j4vks75JYmxjmG/AVlBd5X09DZw2xnxnTa/DViBcJR/YCul+Y8w5a9pVsj0AnDDGpBhjcoH12D6LFfrc1ZSCEA20t46418a2yeeK4zdvAv5o3f4jtn33VU5EBFgCHDHGvGN3l9PzicgtItLQul0H27GNI9gKwyhnZgMwxvzFGNPCGNMa2+fsG2PMY66QT0Tqikj9wtvY9oUfwgXeVwBjzFnglIh0sGYNAOJwkXyWMfx3dxG4TraTQG8R8bZ+fwtfu4p97px5cKaKD7o8BCRg29/8VxfI8yW2fX252L4ZPYltX/Nu4CiwC2jkpGz9sG36HgBirX8PuUI+wB/4wcp2CJhhzW8LfA8cw7Y57+kC73F/YIur5LMy/Gj9O1z4e+AK76tdxq5AjPX+fg34uko+bLthzgM+dvNcIpuVZRYQb/1erAA8K/q509YVSimlgJqzy0gppdR1aEFQSikFaEFQSill0YKglFIK0IKglFLKogVBqSokIv0LO6Aq5Wq0ICillAK0IChVIhF53Bp3IVZEFlsN9TJF5F2r5/xuEbnFWrariOwVkQMisqGwJ76ItBORXdbYDftF5A5r9fXsev6vsq4sVcrptCAoVYyI3AmEAEHG1kQvH3gM25WqMcaYzsA/gNethywHXjbG+AMH7eavAhYa29gNfbFdmQ627rHTsI3N0RZbzxmlnK7W9RdRqsYZgG0QlGjry3sdbE3LCoBwa5mVwHoR8QEaGmP+Yc1fBqy1egY1N8ZsADDGZAFY6/veGHPamo7FNi7GPx3/YylVNi0ISl1LgGXGmL9cNVPktWLLVbbvS7bd7Xz091C5CN1lpNS1dgOjRKQpFI05fDu235fCzpFjgX8aY9KAVBH5f9b8ccA/jDEZwGkRGWatw1NEvKv0p1CqgvSbiVLFGGPiRORVbCOLuWHrSPsctgFbelr3/YLtOAPY2gp/bP3BPw48Yc0fBywWkTesdYyuwh9DqQrTbqdKlZOIZBpj6jk7h1KOoruMlFJKAbqFoJRSyqJbCEoppQAtCEoppSxaEJRSSgFaEJRSSlm0ICillALg/wPE8FdiB7HfHwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "# summarize history for accuracy\n",
        "plt.plot(hst.history['accuracy'])\n",
        "plt.plot(hst.history['balanced_acc'])\n",
        "plt.plot(hst.history['val_accuracy'])\n",
        "plt.plot(hst.history['val_balanced_acc'])\n",
        "plt.title('Model accuracy')\n",
        "plt.ylabel('Performance')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train accuracy', 'train balanced acc.', 'val. accuracy', 'val. balanced acc.'], loc='lower right')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#save last model\n",
        "model2.save(last_model_fpath)"
      ],
      "metadata": {
        "id": "u-x0SENPGmm9"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "last_model = load_model(last_model_fpath, custom_objects={'balanced_acc' : balanced_acc})\n",
        "y_train_pred = last_model.predict(X_train_fm_ov)\n",
        "y_val_pred = last_model.predict(X_val_fm)\n",
        "\n",
        "#print('accuracy on training',accuracy_score(np.argmax(y_train, axis=1), np.argmax(y_train_pred, axis=1)))\n",
        "print('accuracy on training',accuracy_score(np.argmax(y_train_ov, axis=1), np.argmax(y_train_pred, axis=1)))\n",
        "print('balanced accuracy on training',balanced_accuracy_score(np.argmax(y_train_ov, axis=1), np.argmax(y_train_pred, axis=1)))\n",
        "print('accuracy on validation',accuracy_score(np.argmax(y_val, axis=1), np.argmax(y_val_pred, axis=1)))\n",
        "print('balanced accuracy on validation',balanced_accuracy_score(np.argmax(y_val, axis=1), np.argmax(y_val_pred, axis=1)))\n",
        "print('Score on val data: ',precision_recall_fscore_support(np.argmax(y_val, axis=1), np.argmax(y_val_pred, axis=1), average='macro'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U-e3ZaeeG1Bf",
        "outputId": "f5ffbe8e-3bdf-4d42-9312-656a91fee324"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy on training 0.9391205512538183\n",
            "balanced accuracy on training 0.9391205512538183\n",
            "accuracy on validation 0.7253886010362695\n",
            "balanced accuracy on validation 0.6956046276603768\n",
            "Score on val data:  (0.5661189588346589, 0.6956046276603768, 0.5918149077812943, None)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_model = load_model(best_model_fpath, custom_objects={'balanced_acc' : balanced_acc})\n",
        "y_train_pred = best_model.predict(X_train_fm_ov)\n",
        "y_val_pred = best_model.predict(X_val_fm)\n",
        "\n",
        "print('accuracy on training',accuracy_score(np.argmax(y_train_ov, axis=1), np.argmax(y_train_pred, axis=1)))\n",
        "print('balanced accuracy on training',balanced_accuracy_score(np.argmax(y_train_ov, axis=1), np.argmax(y_train_pred, axis=1)))\n",
        "print('accuracy on validation',accuracy_score(np.argmax(y_val, axis=1), np.argmax(y_val_pred, axis=1)))\n",
        "print('balanced accuracy on validation',balanced_accuracy_score(np.argmax(y_val, axis=1), np.argmax(y_val_pred, axis=1)))\n",
        "print('Score on val data: ',precision_recall_fscore_support(np.argmax(y_val, axis=1), np.argmax(y_val_pred, axis=1), average='macro'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EQ3baQLsHLat",
        "outputId": "70f0420b-4e4f-44d6-d961-61bcf7f72f4a"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy on training 0.922852880585352\n",
            "balanced accuracy on training 0.922852880585352\n",
            "accuracy on validation 0.7409326424870466\n",
            "balanced accuracy on validation 0.6990889482178682\n",
            "Score on val data:  (0.5733872859488623, 0.6990889482178682, 0.5991301783871444, None)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RcRGeofw-8tK"
      },
      "source": [
        "#Load ISIC 2018 Challange Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "l3P7IjyLuZGY"
      },
      "outputs": [],
      "source": [
        "X_train, y_train, X_val, y_val = load_isic2018_dataset(train_under_frac = 0.83)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2IncA-_o_n5w"
      },
      "outputs": [],
      "source": [
        "# ordered count of rows per unique label\n",
        "labels_count = y_train.value_counts(ascending=True)\n",
        "\n",
        "f = plt.figure(figsize=(15, 6))\n",
        "s = sns.barplot(x=labels_count.index,y=labels_count.values)\n",
        "s.set_xticklabels(s.get_xticklabels(), rotation = 30)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AnKMKSb4Bkym"
      },
      "source": [
        "Plot 3 images per label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jdnVuqbFBW3K"
      },
      "outputs": [],
      "source": [
        "def plot_images_per_label(df, label, cols: int, size: tuple):\n",
        "    fig, axs = plt.subplots(nrows=1, ncols=cols, figsize=size)\n",
        "\n",
        "    cntMax = cols\n",
        "    cntCur = 0\n",
        "    for index, row in df.iterrows():\n",
        "        if(y_train == label and cntCur < cntMax):\n",
        "            axs[cntCur].imshow(plt.imread(df.FilePaths[index]))\n",
        "            axs[cntCur].set_title(df.Labels[index])\n",
        "\n",
        "            cntCur += 1\n",
        "        else:\n",
        "            if(cntCur >= cntMax):\n",
        "                break\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "# unique labels\n",
        "labels = sorted(df1['y_train'].unique())\n",
        "for label in range(7):\n",
        "    plot_images_per_label(df1, label, 3, (12,9))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "asV1O58Lrq-R"
      },
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "img = Image.fromarray(X_train[0], 'RGB')\n",
        "display(img)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qRKKrNacAZtl"
      },
      "source": [
        "Drop duplicate images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ERwfyPDHP-zC"
      },
      "outputs": [],
      "source": [
        "#df_group = pd.read_csv('/content/drive/MyDrive/PHD/Datasets/isic2018/ISIC2018_Task3_Training_LesionGroupings.csv') \n",
        "#df_train = df_train.set_index('image').join(df_group.set_index('image'))\n",
        "#df_train = df_train.drop_duplicates(subset=['lesion_id'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cNBXx28B9yGu"
      },
      "source": [
        "#DeepSMOTE Oversampling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YmX_Uqbmj-tN"
      },
      "outputs": [],
      "source": [
        "from numpy import moveaxis\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "max_el = np.inf\n",
        "\n",
        "args = {}\n",
        "args['dim_h'] = 64         # factor controlling size of hidden layers\n",
        "args['n_channel'] = 3#1    # number of channels in the input data \n",
        "args['n_z'] = 600 #300     # number of dimensions in latent space. \n",
        "args['sigma'] = 1.0        # variance in n_z\n",
        "args['lambda'] = 0.01      # hyper param for weight of discriminator loss\n",
        "args['lr'] = 0.0002        # learning rate for Adam optimizer .000\n",
        "args['epochs'] = 300       # how many epochs to run for\n",
        "args['batch_size'] = 100   # batch size for SGD\n",
        "args['save'] = True        # save weights at each epoch of training if True\n",
        "args['train'] = True       # train networks if True, else load networks from\n",
        "args['patience'] = 20"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NydOdPMajEfT"
      },
      "outputs": [],
      "source": [
        "class Encoder(nn.Module):\n",
        "    def __init__(self, args):\n",
        "        super(Encoder, self).__init__()\n",
        "\n",
        "        self.n_channel = args['n_channel']\n",
        "        self.dim_h = args['dim_h']\n",
        "        self.n_z = args['n_z']\n",
        "        \n",
        "        # convolutional filters, work excellent with image data\n",
        "        # [(WK+2P)/S]+1\n",
        "        self.conv = nn.Sequential(\n",
        "            nn.AvgPool2d(7, stride=7),\n",
        "            nn.Conv2d(self.n_channel, self.dim_h, 4, 2, 1, bias=False),# 16\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Conv2d(self.dim_h, self.dim_h * 2, 4, 2, 1, bias=False), # 8\n",
        "            nn.BatchNorm2d(self.dim_h * 2),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Conv2d(self.dim_h * 2, self.dim_h * 4, 4, 2, 1, bias=False),# 4\n",
        "            nn.BatchNorm2d(self.dim_h * 4),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Conv2d(self.dim_h * 4, self.dim_h * 8, 4, 2, 0, bias=False),#14\n",
        "            nn.BatchNorm2d(self.dim_h * 8),\n",
        "            nn.LeakyReLU(0.2, inplace=True))\n",
        "        self.fc = nn.Linear(self.dim_h * (2 ** 3), self.n_z)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv(x)\n",
        "        \n",
        "        x = x.squeeze()\n",
        "        x = self.fc(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self, args):\n",
        "        super(Decoder, self).__init__()\n",
        "\n",
        "        self.n_channel = args['n_channel']\n",
        "        self.dim_h = args['dim_h']\n",
        "        self.n_z = args['n_z']\n",
        "\n",
        "        # first layer is fully connected\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(self.n_z, self.dim_h * 2**3 * 7 * 7),\n",
        "            nn.ReLU())\n",
        "\n",
        "        # deconvolutional filters, essentially inverse of convolutional filters\n",
        "        # H_out = (H_in1)*stride[0]  2padding[0] + dilation[0](kernel_size[0]1) + output_padding[0] + 1\n",
        "        self.deconv = nn.Sequential(\n",
        "            nn.ConvTranspose2d(self.dim_h * 8, self.dim_h * 4, 4), #10\n",
        "            nn.BatchNorm2d(self.dim_h * 4),\n",
        "            nn.ReLU(True),\n",
        "            nn.ConvTranspose2d(self.dim_h * 4, self.dim_h * 2, 4), #13\n",
        "            nn.BatchNorm2d(self.dim_h * 2),\n",
        "            nn.ReLU(True),\n",
        "            nn.ConvTranspose2d(self.dim_h * 2, self.dim_h, 4),# 16\n",
        "            nn.BatchNorm2d(self.dim_h),\n",
        "            nn.ReLU(True),\n",
        "            nn.ConvTranspose2d(self.dim_h, 3, 4, 2, 1),# 32\n",
        "            nn.UpsamplingBilinear2d(scale_factor=7),\n",
        "            nn.Tanh())\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.fc(x)\n",
        "        x = x.view(-1, self.dim_h * 2**3, 7, 7)\n",
        "        x = self.deconv(x)\n",
        "        return x\n",
        "\n",
        "##############################################################################\n",
        "\"\"\"set models, loss functions\"\"\"\n",
        "# control which parameters are frozen / free for optimization\n",
        "def free_params(module: nn.Module):\n",
        "    for p in module.parameters():\n",
        "        p.requires_grad = True\n",
        "\n",
        "def frozen_params(module: nn.Module):\n",
        "    for p in module.parameters():\n",
        "        p.requires_grad = False\n",
        "\n",
        "def biased_get_class(X, y, c):\n",
        "    \n",
        "    xbeg = X[y == c]\n",
        "    ybeg = y[y == c]\n",
        "    \n",
        "    return xbeg, ybeg\n",
        "    #return xclass, yclass\n",
        "\n",
        "def G_SM(X, y,n_to_sample,cl):\n",
        "    n_neigh = 5\n",
        "    nn = NearestNeighbors(n_neighbors=n_neigh, n_jobs=1)\n",
        "    nn.fit(X)\n",
        "    dist, ind = nn.kneighbors(X)\n",
        "\n",
        "    # generating samples\n",
        "    base_indices = np.random.choice(list(range(len(X))),n_to_sample)\n",
        "    neighbor_indices = np.random.choice(list(range(1, n_neigh)),n_to_sample)\n",
        "\n",
        "    X_base = X[base_indices]\n",
        "    X_neighbor = X[ind[base_indices, neighbor_indices]]\n",
        "\n",
        "    samples = X_base + np.multiply(np.random.rand(n_to_sample,1),\n",
        "            X_neighbor - X_base)\n",
        "\n",
        "    #use 10 as label because 0 to 9 real classes and 1 fake/smoted = 10\n",
        "    return samples, [cl]*n_to_sample\n",
        "\n",
        "def DeepSMOTE_train(X_train, y_train, one_hot = False):\n",
        "  from torch.utils.data import TensorDataset\n",
        "  import os\n",
        "\n",
        "  max_el = np.max(X_train)\n",
        "  X_train = X_train / max_el\n",
        "  X_train = moveaxis(X_train, 3, 1)\n",
        "  if one_hot:\n",
        "    y_train = np.argmax(y_train, axis=1)\n",
        "  #X_train = X_train.astype('float32') / 255.\n",
        "  \n",
        "  batch_size = args['batch_size']\n",
        "  patience = args['patience']\n",
        "  encoder = Encoder(args)\n",
        "  decoder = Decoder(args)\n",
        "\n",
        "  device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "  print(device)\n",
        "  decoder = decoder.to(device)\n",
        "  encoder = encoder.to(device)\n",
        "\n",
        "  train_on_gpu = torch.cuda.is_available()\n",
        "\n",
        "  #decoder loss function\n",
        "  criterion = nn.MSELoss()\n",
        "  criterion = criterion.to(device)\n",
        "\n",
        "  num_workers = 0\n",
        "\n",
        "  #torch.Tensor returns float so if want long then use torch.tensor\n",
        "  tensor_x = torch.from_numpy(X_train.copy())#torch.Tensor(X_train)\n",
        "  tensor_y = torch.tensor(y_train,dtype=torch.long)\n",
        "  mnist_bal = TensorDataset(tensor_x,tensor_y) \n",
        "  train_loader = torch.utils.data.DataLoader(mnist_bal, \n",
        "      batch_size=batch_size,shuffle=True,num_workers=num_workers)\n",
        "\n",
        "  best_loss = np.inf\n",
        "\n",
        "  enc_optim = torch.optim.Adam(encoder.parameters(), lr = args['lr'])\n",
        "  dec_optim = torch.optim.Adam(decoder.parameters(), lr = args['lr'])\n",
        "\n",
        "  for epoch in range(args['epochs']):\n",
        "      train_loss = 0.0\n",
        "      tmse_loss = 0.0\n",
        "      tdiscr_loss = 0.0\n",
        "      # train for one epoch -- set nets to train mode\n",
        "      encoder.train()\n",
        "      decoder.train()\n",
        "  \n",
        "      for images,labs in train_loader:\n",
        "      \n",
        "          # zero gradients for each batch\n",
        "          encoder.zero_grad()\n",
        "          decoder.zero_grad()\n",
        "          images, labs = images.to(device), labs.to(device)\n",
        "          labsn = labs.detach().cpu().numpy()\n",
        "#            print('images shape', images.shape)\n",
        "          # run images\n",
        "          z_hat = encoder(images)\n",
        "#            print('images shape after encoding', z_hat.shape)\n",
        "      \n",
        "          x_hat = decoder(z_hat) #decoder outputs tanh\n",
        "#            print('images shape after decoding', x_hat.shape)\n",
        "          mse = criterion(x_hat,images)\n",
        "                  \n",
        "          resx = []\n",
        "          resy = []\n",
        "      \n",
        "          tc = np.random.choice(num_classes,1)\n",
        "          #tc = 9\n",
        "          xbeg = X_train[y_train == tc]\n",
        "          ybeg = y_train[y_train == tc] \n",
        "          xlen = len(xbeg)\n",
        "          nsamp = min(xlen, 100)\n",
        "          ind = np.random.choice(list(range(len(xbeg))),nsamp,replace=False)\n",
        "          xclass = xbeg[ind]\n",
        "          yclass = ybeg[ind]\n",
        "      \n",
        "          xclen = len(xclass)\n",
        "          xcminus = np.arange(1,xclen)\n",
        "          \n",
        "          xcplus = np.append(xcminus,0)\n",
        "          xcnew = (xclass[[xcplus],:])\n",
        "          xcnew = xcnew.reshape(xcnew.shape[1],xcnew.shape[2],xcnew.shape[3],xcnew.shape[4])\n",
        "      \n",
        "          xcnew = torch.Tensor(xcnew)\n",
        "          xcnew = xcnew.to(device)\n",
        "      \n",
        "          #encode xclass to feature space\n",
        "          xclass = torch.Tensor(xclass)\n",
        "          xclass = xclass.to(device)\n",
        "          xclass = encoder(xclass)\n",
        "      \n",
        "          xclass = xclass.detach().cpu().numpy()\n",
        "      \n",
        "          xc_enc = (xclass[[xcplus],:])\n",
        "          xc_enc = np.squeeze(xc_enc)\n",
        "      \n",
        "          xc_enc = torch.Tensor(xc_enc)\n",
        "          xc_enc = xc_enc.to(device)\n",
        "          \n",
        "          ximg = decoder(xc_enc)\n",
        "          \n",
        "          mse2 = criterion(ximg,xcnew)\n",
        "      \n",
        "          comb_loss = mse2 + mse\n",
        "          comb_loss.backward()\n",
        "      \n",
        "          enc_optim.step()\n",
        "          dec_optim.step()\n",
        "      \n",
        "          train_loss += comb_loss.item()*images.size(0)\n",
        "          tmse_loss += mse.item()*images.size(0)\n",
        "          tdiscr_loss += mse2.item()*images.size(0)\n",
        "\n",
        "      train_loss = train_loss/len(train_loader)\n",
        "      tmse_loss = tmse_loss/len(train_loader)\n",
        "      tdiscr_loss = tdiscr_loss/len(train_loader)\n",
        "      print('Epoch: {} \\tTrain Loss: {:.6f} \\tmse loss: {:.6f} \\tmse2 loss: {:.6f}'.format(epoch,\n",
        "              train_loss,tmse_loss,tdiscr_loss))\n",
        "      \n",
        "  \n",
        "  \n",
        "      #store the best encoder and decoder models\n",
        "      #here, /crs5 is a reference to 5 way cross validation, but is not\n",
        "      #necessary for illustration purposes\n",
        "      if train_loss < best_loss:\n",
        "          print('Saving..')\n",
        "          patience = args['patience']\n",
        "          path_enc = '/content/drive/MyDrive/PHD/Model/DeepSMOTE/32/bst_enc.pth'\n",
        "          path_dec = '/content/drive/MyDrive/PHD/Model/DeepSMOTE/32/bst_dec.pth'\n",
        "        \n",
        "          torch.save(encoder.state_dict(), path_enc)\n",
        "          torch.save(decoder.state_dict(), path_dec)\n",
        "  \n",
        "          best_loss = train_loss\n",
        "      else:\n",
        "          patience = patience - 1\n",
        "\n",
        "      if patience == 0:\n",
        "          print('Out of patience. \\n')\n",
        "          break\n",
        "\n",
        "def DeepSMOTE_Data(X_train, y_train, one_hot = False):\n",
        "  batch_size = args['batch_size']\n",
        "  max_el = np.max(X_train)\n",
        "  X_train = X_train / max_el\n",
        "  X_train = moveaxis(X_train, 3, 1)\n",
        "  if one_hot:\n",
        "    y_train = np.argmax(y_train, axis=1)\n",
        "  #Generate artificial images\n",
        "  import torch\n",
        "  np.printoptions(precision=5,suppress=True)\n",
        "\n",
        "  #path on the computer where the models are stored\n",
        "  modpth = '/content/drive/MyDrive/PHD/Model/DeepSMOTE/32/'\n",
        "\n",
        "  path_enc = modpth + '/bst_enc.pth'\n",
        "  path_dec = modpth + '/bst_dec.pth'\n",
        "  \n",
        "  train_on_gpu = torch.cuda.is_available()\n",
        "  device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "  encoder = Encoder(args)\n",
        "  encoder.load_state_dict(torch.load(path_enc), strict=False)\n",
        "  encoder = encoder.to(device)\n",
        "\n",
        "  decoder = Decoder(args)\n",
        "  decoder.load_state_dict(torch.load(path_dec), strict=False)\n",
        "  decoder = decoder.to(device)\n",
        "\n",
        "  encoder.eval()\n",
        "  decoder.eval()\n",
        "\n",
        "  resx = []\n",
        "  resy = []\n",
        "  \n",
        "  counter = Counter(y_train)\n",
        "  counter = sorted(counter.items())\n",
        "  counter = [value for _, value in counter]\n",
        "\n",
        "  for i in range(num_classes):\n",
        "      torch.cuda.empty_cache()\n",
        "\n",
        "      xclass, yclass = biased_get_class(X_train, y_train, i)\n",
        "      #encode xclass to feature space\n",
        "      xclass = torch.Tensor(xclass)\n",
        "      xclass = xclass.to(device)\n",
        "      xclass = encoder(xclass)\n",
        "          \n",
        "      xclass = xclass.detach().cpu().numpy()\n",
        "      n = np.max(counter) - counter[i]\n",
        "      if n == 0:\n",
        "        continue\n",
        "#        resx2 = []\n",
        "#        resy2 = []\n",
        "#        for j in range(batch_size, n+batch_size+1, batch_size):\n",
        "#          if j <= n:\n",
        "#            batch_size_max = batch_size\n",
        "#          elif n % batch_size != 0:\n",
        "#            batch_size_max = n%batch_size\n",
        "#          else:\n",
        "#            break\n",
        "#          xsamp, ysamp = G_SM(xclass,yclass,batch_size_max,i)\n",
        "      xsamp, ysamp = G_SM(xclass,yclass,n,i)\n",
        "      ysamp = np.array(ysamp)\n",
        "  \n",
        "      \"\"\"to generate samples for resnet\"\"\"   \n",
        "      xsamp = torch.Tensor(xsamp)\n",
        "      xsamp = xsamp.to(device)\n",
        "      ximg = decoder(xsamp)\n",
        "\n",
        "      ximn = ximg.detach().cpu().numpy()\n",
        "#        resx2.append(ximn)\n",
        "#        resy2.append(ysamp)\n",
        "#        \n",
        "#        resx2 = np.vstack(resx2)\n",
        "#        resy2 = np.hstack(resy2)\n",
        "      resx.append(ximn)\n",
        "      resy.append(ysamp)\n",
        "  \n",
        "  resx1 = np.vstack(resx)\n",
        "  resy1 = np.hstack(resy)\n",
        "  resx1 = resx1.reshape(resx1.shape[0],-1)\n",
        "  X_train = X_train.reshape(X_train.shape[0],-1)\n",
        "  X_train = np.vstack((resx1,X_train))\n",
        "  y_train = np.hstack((resy1,y_train))\n",
        "  y_train = to_categorical(y_train)\n",
        "  X_train = X_train.reshape(-1, 3, IMAGE_W, IMAGE_H)\n",
        "  X_train = moveaxis(X_train, 1, 3)\n",
        "  X_train = X_train * max_el\n",
        "  return X_train, y_train"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0jrJ33lUDkCM"
      },
      "source": [
        "#Split dataset to train and val"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e6qneWL_Bs2U"
      },
      "outputs": [],
      "source": [
        "# stratified train and rem (20%) datasets\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, stratify=y_train, random_state=1)\n",
        "\n",
        "print('Train Data: ', X_train.shape)\n",
        "print('Remaining Data: ', X_val.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8Kef4r_zxjgk"
      },
      "outputs": [],
      "source": [
        "#Data Augmentation\n",
        "dataaugment = ImageDataGenerator(\n",
        "        rotation_range=90,  # randomly rotate images in the range (degrees, 0 to 180)\n",
        "        zoom_range = 0.1, # Randomly zoom image \n",
        "        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
        "        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
        "        horizontal_flip=True,  # randomly flip images\n",
        "        vertical_flip=True,  # randomly flip images\n",
        "        shear_range = 10) \n",
        "\n",
        "dataaugment.fit(X_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B2PgksTFkOAq"
      },
      "source": [
        "#Fine Tune"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nr1jnSM7yzJc"
      },
      "outputs": [],
      "source": [
        "limit = 171\n",
        "for layer in model.layers[:limit]:\n",
        "   layer.trainable = False\n",
        "for layer in model.layers[limit:]:\n",
        "   layer.trainable = True\n",
        "\n",
        "optimizer_SGD = SGD(learning_rate=0.0001, momentum=0.9)\n",
        "model.compile(optimizer = optimizer_SGD , loss = \"categorical_crossentropy\", metrics=['accuracy', balanced_acc])\n",
        "hst2 = model.fit(train_data_batches,\n",
        "                    epochs = EPOCHS, validation_data = valid_data_batches,\n",
        "                    callbacks=[learning_rate_reduction,early_stopping_monitor, mc])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vO1aAQBmiy0K"
      },
      "outputs": [],
      "source": [
        "# summarize history for accuracy\n",
        "plt.plot(hst2.history['balanced_acc'])\n",
        "plt.plot(hst2.history['val_balanced_acc'])\n",
        "plt.title('model balance_acc after tunning')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'val'], loc='upper left')\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "UswA0co2y1wl",
        "iDRWiTnO0MGh",
        "eaK4zbtoaAaC",
        "3K908bbiYwbS",
        "kE8Ziq-BlEP4",
        "RcRGeofw-8tK",
        "cNBXx28B9yGu",
        "0jrJ33lUDkCM",
        "B2PgksTFkOAq"
      ],
      "machine_shape": "hm",
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}